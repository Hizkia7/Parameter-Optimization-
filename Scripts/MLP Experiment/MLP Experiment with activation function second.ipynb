{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_linear(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_relu(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_sigmoid(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_tanh(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 424us/step - loss: 15260.5826 - val_loss: 14692.0924\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12507.5074 - val_loss: 9073.4720\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4430.4034 - val_loss: 715.0791\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 137.5885 - val_loss: 45.2511\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 29.2205 - val_loss: 26.7284\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.7939 - val_loss: 25.5107\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1410 - val_loss: 26.0592\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9248 - val_loss: 25.9089\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7591 - val_loss: 25.8346\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7075 - val_loss: 25.9522\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6893 - val_loss: 26.3981\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6397 - val_loss: 26.0764\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.7402 - val_loss: 26.0540\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.7138 - val_loss: 25.7894\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6355 - val_loss: 26.1609\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7879 - val_loss: 26.6349\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7105 - val_loss: 26.6493\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8212 - val_loss: 25.8865\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5244 - val_loss: 25.7978\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5443 - val_loss: 25.7711\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6418 - val_loss: 26.2085\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8966 - val_loss: 25.8454\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5377 - val_loss: 25.6347\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6535 - val_loss: 26.2888\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6932 - val_loss: 25.8619\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6085 - val_loss: 25.8694\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7021 - val_loss: 25.7704\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.5365 - val_loss: 25.8777\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6961 - val_loss: 25.8683\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1165 - val_loss: 25.7582\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6745 - val_loss: 25.6447\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5933 - val_loss: 25.8534\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.4704 - val_loss: 25.4823\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 21.6027 - val_loss: 25.8968\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7701 - val_loss: 25.9341\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6548 - val_loss: 25.6001\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.0760 - val_loss: 25.8856\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.6900 - val_loss: 26.2764\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.6383 - val_loss: 26.0453\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5506 - val_loss: 25.9600\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6875 - val_loss: 25.5425\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7702 - val_loss: 25.6454\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7346 - val_loss: 25.6630\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9490 - val_loss: 25.9692\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0222 - val_loss: 26.7445\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6824 - val_loss: 26.0526\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7115 - val_loss: 26.2820\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.4812 - val_loss: 26.3128\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6442 - val_loss: 25.9486\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5832 - val_loss: 26.0813\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7448 - val_loss: 25.5995\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7578 - val_loss: 25.7994\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8226 - val_loss: 25.6941\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7334 - val_loss: 25.7986\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.3199 - val_loss: 26.5085\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7050 - val_loss: 25.9200\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.8604 - val_loss: 25.3307\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7154 - val_loss: 25.6295\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3022 - val_loss: 25.7087\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4902 - val_loss: 25.6004\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.1891 - val_loss: 26.3599\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0307 - val_loss: 26.8403\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0765 - val_loss: 25.9180\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9184 - val_loss: 26.1618\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6514 - val_loss: 26.1778\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9011 - val_loss: 25.2557\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9253 - val_loss: 26.8822\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8224 - val_loss: 25.6590\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2565 - val_loss: 25.3309\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3864 - val_loss: 26.4314\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1299 - val_loss: 26.0179\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5662 - val_loss: 26.1044\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5649 - val_loss: 25.6651\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1080 - val_loss: 25.8302\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6778 - val_loss: 25.7891\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2849 - val_loss: 25.6936\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7661 - val_loss: 26.5033\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7786 - val_loss: 26.4185\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3688 - val_loss: 25.6406\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7877 - val_loss: 26.0183\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6307 - val_loss: 26.5230\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1441 - val_loss: 25.4344\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6788 - val_loss: 26.8399\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8920 - val_loss: 26.2008\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3695 - val_loss: 28.0010\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2424 - val_loss: 26.3533\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2851 - val_loss: 25.7290\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9379 - val_loss: 25.4905\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8660 - val_loss: 26.8356\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9823 - val_loss: 25.6314\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3762 - val_loss: 26.5859\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2341 - val_loss: 25.7249\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1218 - val_loss: 27.7993\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.0197 - val_loss: 26.3833\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4455 - val_loss: 27.9707\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7185 - val_loss: 25.7742\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8948 - val_loss: 26.4257\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0580 - val_loss: 26.2492\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.5316 - val_loss: 25.7917\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.6923 - val_loss: 25.9599\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4763 - val_loss: 25.7133\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8571 - val_loss: 27.1202\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0507 - val_loss: 25.5143\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0571 - val_loss: 25.8705\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0976 - val_loss: 26.7919\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8887 - val_loss: 26.4094\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2382 - val_loss: 25.5675\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3183 - val_loss: 26.4272\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0888 - val_loss: 25.3408\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2656 - val_loss: 25.4724\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6143 - val_loss: 27.4152\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1288 - val_loss: 26.8190\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4985 - val_loss: 25.2917\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7554 - val_loss: 25.5179\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0992 - val_loss: 26.3307\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3008 - val_loss: 25.6497\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8312 - val_loss: 27.1554\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.2095 - val_loss: 26.5946\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0820 - val_loss: 25.5561\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6210 - val_loss: 26.1332\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0326 - val_loss: 25.4443\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8322 - val_loss: 26.2380\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2281 - val_loss: 27.1418\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.3020 - val_loss: 25.8460\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4601 - val_loss: 25.8637\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.2013 - val_loss: 26.1025\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8694 - val_loss: 26.2115\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4810 - val_loss: 26.5109\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.8288 - val_loss: 26.2790\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6863 - val_loss: 25.8370\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8078 - val_loss: 25.8109\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8737 - val_loss: 25.4973\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.8219 - val_loss: 25.8012\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0390 - val_loss: 26.4136\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.4315 - val_loss: 26.0625\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2088 - val_loss: 26.0446\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8864 - val_loss: 26.4164\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3416 - val_loss: 25.6419\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0478 - val_loss: 25.4057\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.8110 - val_loss: 27.7081\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5989 - val_loss: 25.6591\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0785 - val_loss: 26.2292\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8308 - val_loss: 26.9076\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.0201 - val_loss: 25.4238\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5811 - val_loss: 26.6687\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7068 - val_loss: 26.2613\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2354 - val_loss: 26.3618\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.4323 - val_loss: 26.9516\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.2738 - val_loss: 26.9830\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8796 - val_loss: 25.1765\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1130 - val_loss: 27.1070\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9893 - val_loss: 26.6700\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8658 - val_loss: 26.7716\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.0652 - val_loss: 26.2315\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.6704 - val_loss: 25.6333\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 23.0427 - val_loss: 25.5196\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.1319 - val_loss: 27.7893\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.1753 - val_loss: 27.9813\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.3519 - val_loss: 27.2753\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 22.2952 - val_loss: 26.2422\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.4102 - val_loss: 26.7136\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.1623 - val_loss: 25.9966\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2951 - val_loss: 27.3888\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.1198 - val_loss: 26.2263\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.8022 - val_loss: 26.3532\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.8842 - val_loss: 26.4894\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2373 - val_loss: 25.6482\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.8561 - val_loss: 26.3202\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.0954 - val_loss: 27.2397\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.3299 - val_loss: 25.5508\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1734 - val_loss: 25.7948\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.3194 - val_loss: 25.9416\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8269 - val_loss: 26.6230\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4093 - val_loss: 26.4933\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.5632 - val_loss: 26.2235\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1032 - val_loss: 27.7629\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0314 - val_loss: 25.2451\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.8742 - val_loss: 26.2668\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2158 - val_loss: 26.2949\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.1269 - val_loss: 29.7004\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.0036 - val_loss: 26.2868\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3112 - val_loss: 25.7201\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6459 - val_loss: 25.4510\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8518 - val_loss: 25.9408\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1305 - val_loss: 26.6682\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.8016 - val_loss: 25.2942\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.1245 - val_loss: 26.9580\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.2025 - val_loss: 26.9778\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.9315 - val_loss: 26.3793\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7042 - val_loss: 26.7503\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.7267 - val_loss: 26.1077\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1025 - val_loss: 25.6793\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5815 - val_loss: 25.2185\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4963 - val_loss: 25.7126\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4360 - val_loss: 26.1001\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7961 - val_loss: 27.8896\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9720 - val_loss: 25.4284\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 21.2558 - val_loss: 25.5598\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5188 - val_loss: 24.9201\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.3299 - val_loss: 25.7984\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.1581 - val_loss: 25.2401\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.9449 - val_loss: 24.7849\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.8338 - val_loss: 26.9906\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.2637 - val_loss: 25.9999\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.4084 - val_loss: 24.7692\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5161 - val_loss: 24.1970\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.5999 - val_loss: 24.6951\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.0073 - val_loss: 23.6951\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.0735 - val_loss: 24.2609\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.9597 - val_loss: 23.6529\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.5296 - val_loss: 23.3828\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3657 - val_loss: 24.0431\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.5801 - val_loss: 25.7234\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1463 - val_loss: 22.7546\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5150 - val_loss: 23.6951\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8865 - val_loss: 22.6560\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5925 - val_loss: 22.3197\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5338 - val_loss: 22.2244\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8161 - val_loss: 22.3816\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4567 - val_loss: 23.1881\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9804 - val_loss: 21.5265\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.0638 - val_loss: 20.9008\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1927 - val_loss: 21.1199\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4998 - val_loss: 20.7854\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5666 - val_loss: 20.6396\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9400 - val_loss: 20.3771\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7135 - val_loss: 22.0634\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5081 - val_loss: 21.2197\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1885 - val_loss: 19.8674\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1075 - val_loss: 20.0958\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4477 - val_loss: 21.4222\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8243 - val_loss: 21.0842\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3876 - val_loss: 21.3358\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1390 - val_loss: 18.7263\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.5379 - val_loss: 19.6001\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4717 - val_loss: 19.2215\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.6640 - val_loss: 18.6606\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4376 - val_loss: 19.8362\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0594 - val_loss: 19.2584\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2964 - val_loss: 19.3610\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.6948 - val_loss: 18.9079\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4095 - val_loss: 19.2028\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0571 - val_loss: 18.0685\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.0542 - val_loss: 18.0636\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.8880 - val_loss: 19.1674\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.8839 - val_loss: 20.0356\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.5181 - val_loss: 18.6684\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9466 - val_loss: 18.6046\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1161 - val_loss: 18.9370\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.1251 - val_loss: 18.0394\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2823 - val_loss: 18.0779\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8061 - val_loss: 17.6322\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.0099 - val_loss: 18.1158\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2670 - val_loss: 19.0259\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6876 - val_loss: 17.5836\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1945 - val_loss: 19.0981\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.8133 - val_loss: 18.6692\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.7004 - val_loss: 17.3848\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.9428 - val_loss: 17.8578\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.9951 - val_loss: 18.9895\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1092 - val_loss: 21.7017\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.0749 - val_loss: 17.8293\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9151 - val_loss: 17.8588\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6971 - val_loss: 18.6815\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9888 - val_loss: 18.4294\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.2780 - val_loss: 17.6672\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7326 - val_loss: 17.8179\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.2441 - val_loss: 20.0997\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.2809 - val_loss: 17.4495\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0411 - val_loss: 16.8266\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.9526 - val_loss: 16.4651\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3414 - val_loss: 17.9076\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6472 - val_loss: 16.5218\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9707 - val_loss: 16.7948\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9377 - val_loss: 17.2484\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9847 - val_loss: 16.3311\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6705 - val_loss: 16.3590\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9439 - val_loss: 19.9091\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1874 - val_loss: 16.7726\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2351 - val_loss: 16.1263\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8956 - val_loss: 16.5855\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3426 - val_loss: 18.8504\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2093 - val_loss: 16.3796\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.3491 - val_loss: 17.7665\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8704 - val_loss: 19.5331\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5870 - val_loss: 16.9162\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4152 - val_loss: 21.3592\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8473 - val_loss: 15.3274\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8028 - val_loss: 17.1958\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1902 - val_loss: 16.5702\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7659 - val_loss: 16.6561\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8350 - val_loss: 15.8790\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4029 - val_loss: 15.1843\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0623 - val_loss: 14.7333\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5594 - val_loss: 15.0017\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2040 - val_loss: 15.3397\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7113 - val_loss: 14.6781\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6923 - val_loss: 16.1626\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1906 - val_loss: 15.1758\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0413 - val_loss: 14.2071\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0412 - val_loss: 17.9693\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2472 - val_loss: 15.3491\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7436 - val_loss: 14.4877\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5224 - val_loss: 18.6103\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5982 - val_loss: 14.4675\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6679 - val_loss: 15.0039\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9602 - val_loss: 15.6236\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8182 - val_loss: 15.6922\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5585 - val_loss: 13.7796\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1748 - val_loss: 17.7230\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9570 - val_loss: 14.6615\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5903 - val_loss: 13.0865\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5901 - val_loss: 13.7725\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0907 - val_loss: 14.1543\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6551 - val_loss: 14.8794\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7850 - val_loss: 13.7904\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9747 - val_loss: 12.9697\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2720 - val_loss: 13.6098\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9343 - val_loss: 13.8548\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2948 - val_loss: 14.8425\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1337 - val_loss: 14.1381\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0365 - val_loss: 13.5003\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.6224 - val_loss: 13.1251\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.8729 - val_loss: 13.7702\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.3166 - val_loss: 14.0013\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.7293 - val_loss: 12.9073\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 10.5523 - val_loss: 13.5389\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.6172 - val_loss: 12.5459\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.3937 - val_loss: 17.4444\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 10.2989 - val_loss: 13.7380\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.3845 - val_loss: 12.6773\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.2674 - val_loss: 13.1912\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4459 - val_loss: 13.0025\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5261 - val_loss: 12.8062\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1365 - val_loss: 14.4971\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1486 - val_loss: 13.4149\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0939 - val_loss: 12.7806\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8956 - val_loss: 12.4742\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5416 - val_loss: 12.0586\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5641 - val_loss: 15.5343\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2722 - val_loss: 12.3261\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9752 - val_loss: 13.0097\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4293 - val_loss: 12.3172\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8548 - val_loss: 11.9819\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7427 - val_loss: 12.5012\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0595 - val_loss: 11.8128\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1510 - val_loss: 14.0023\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.7204 - val_loss: 12.3531\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9210 - val_loss: 13.0849\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7339 - val_loss: 11.8892\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6245 - val_loss: 11.5286\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7855 - val_loss: 13.1622\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8750 - val_loss: 12.6137\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5159 - val_loss: 12.0994\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2204 - val_loss: 12.1103\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1808 - val_loss: 12.1889\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9891 - val_loss: 12.5000\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6205 - val_loss: 12.3802\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.3686 - val_loss: 12.2565\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5764 - val_loss: 11.0316\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6753 - val_loss: 11.8115\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1216 - val_loss: 13.4155\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3925 - val_loss: 12.4189\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2985 - val_loss: 12.2893\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5055 - val_loss: 14.3013\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6954 - val_loss: 11.5930\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4396 - val_loss: 11.6437\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5048 - val_loss: 13.1421\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9224 - val_loss: 12.4603\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0015 - val_loss: 11.2164\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2408 - val_loss: 11.1998\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1324 - val_loss: 11.6313\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4220 - val_loss: 11.6352\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1857 - val_loss: 10.8163\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9007 - val_loss: 11.5925\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4318 - val_loss: 11.6380\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0805 - val_loss: 11.1830\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3605 - val_loss: 12.8217\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6269 - val_loss: 10.7613\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1798 - val_loss: 12.4810\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1951 - val_loss: 11.6762\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3911 - val_loss: 10.9781\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0896 - val_loss: 11.1512\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9539 - val_loss: 11.5722\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9444 - val_loss: 11.8020\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2394 - val_loss: 12.6501\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0362 - val_loss: 11.8064\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2104 - val_loss: 10.4305\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3725 - val_loss: 11.5017\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0241 - val_loss: 11.0934\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3273 - val_loss: 11.0589\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9574 - val_loss: 12.0001\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9310 - val_loss: 11.9040\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3988 - val_loss: 11.0698\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1876 - val_loss: 11.7203\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5052 - val_loss: 11.0257\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3725 - val_loss: 12.6652\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2491 - val_loss: 10.7834\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0830 - val_loss: 10.8636\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2703 - val_loss: 12.2236\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1126 - val_loss: 10.8798\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2434 - val_loss: 12.6115\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2518 - val_loss: 10.4769\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8853 - val_loss: 10.6293\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8178 - val_loss: 10.7081\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8629 - val_loss: 10.7424\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9795 - val_loss: 11.4159\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8044 - val_loss: 11.5024\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0113 - val_loss: 11.1786\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.1054 - val_loss: 11.1807\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4126 - val_loss: 13.0212\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0666 - val_loss: 11.1506\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8096 - val_loss: 10.9409\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1381 - val_loss: 11.9598\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8658 - val_loss: 12.3687\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9199 - val_loss: 10.6882\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9159 - val_loss: 10.9155\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2849 - val_loss: 10.9392\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7694 - val_loss: 11.1753\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7047 - val_loss: 11.1767\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4873 - val_loss: 10.6527\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8806 - val_loss: 10.4271\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7579 - val_loss: 11.8171\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7435 - val_loss: 12.0768\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9649 - val_loss: 11.2045\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8132 - val_loss: 10.5970\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7210 - val_loss: 10.2323\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9931 - val_loss: 10.6408\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7168 - val_loss: 10.3739\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7157 - val_loss: 10.8321\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1131 - val_loss: 10.7779\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1074 - val_loss: 10.2346\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7198 - val_loss: 11.0689\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0750 - val_loss: 10.9535\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7652 - val_loss: 10.0603\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8029 - val_loss: 10.8672\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8431 - val_loss: 11.0969\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9305 - val_loss: 12.9224\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2161 - val_loss: 10.5388\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7902 - val_loss: 11.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1259 - val_loss: 10.7414\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6843 - val_loss: 10.3538\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0924 - val_loss: 11.4260\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8686 - val_loss: 10.3719\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8354 - val_loss: 10.5138\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2508 - val_loss: 11.9431\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7313 - val_loss: 11.0535\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.7671 - val_loss: 11.2078\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6685 - val_loss: 10.5273\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8150 - val_loss: 11.2217\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2262 - val_loss: 13.5500\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1751 - val_loss: 10.7359\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7211 - val_loss: 10.6873\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7714 - val_loss: 11.0151\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0673 - val_loss: 10.7330\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6861 - val_loss: 12.9776\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2263 - val_loss: 10.4849\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8186 - val_loss: 10.4029\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7109 - val_loss: 10.7607\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6398 - val_loss: 10.2153\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1702 - val_loss: 12.4507\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6639 - val_loss: 10.5283\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5870 - val_loss: 11.4501\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7961 - val_loss: 12.1767\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6123 - val_loss: 11.7551\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7553 - val_loss: 10.1195\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3700 - val_loss: 11.3806\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7921 - val_loss: 10.2715\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7420 - val_loss: 10.7722\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8269 - val_loss: 10.4566\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5590 - val_loss: 10.1514\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6570 - val_loss: 11.9089\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9157 - val_loss: 11.1031\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8337 - val_loss: 10.8115\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7552 - val_loss: 10.5099\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7849 - val_loss: 10.7324\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8865 - val_loss: 11.2334\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0252 - val_loss: 10.6889\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7242 - val_loss: 10.3035\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6130 - val_loss: 10.3089\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4756 - val_loss: 11.4245\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7356 - val_loss: 11.0459\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7136 - val_loss: 11.2379\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3096 - val_loss: 11.7929\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7791 - val_loss: 10.2187\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7607 - val_loss: 11.3900\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1513 - val_loss: 11.1925\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4842 - val_loss: 11.1578\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6588 - val_loss: 11.1253\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6829 - val_loss: 11.2252\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7004 - val_loss: 10.6349\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5446 - val_loss: 12.2800\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9517 - val_loss: 10.4748\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5562 - val_loss: 11.3253\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8916 - val_loss: 9.9767\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6680 - val_loss: 10.2198\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0354 - val_loss: 11.3609\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9540 - val_loss: 10.0241\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5252 - val_loss: 10.2787\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.5559 - val_loss: 10.3763\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0401 - val_loss: 10.1288\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3868 - val_loss: 10.5122\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5147 - val_loss: 11.2101\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5702 - val_loss: 10.1230\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7163 - val_loss: 9.8937\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8382 - val_loss: 11.5923\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4995 - val_loss: 10.0509\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3927 - val_loss: 10.3934\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6212 - val_loss: 11.3061\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0783 - val_loss: 10.0751\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7009 - val_loss: 9.8801\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.6566 - val_loss: 11.0220\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7507 - val_loss: 10.1731\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5756 - val_loss: 12.8316\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9683 - val_loss: 10.3523\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7886 - val_loss: 9.9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8128 - val_loss: 10.7746\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3588 - val_loss: 10.3635\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8066 - val_loss: 9.8764\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7981 - val_loss: 11.9233\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7222 - val_loss: 10.1334\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6425 - val_loss: 10.1696\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4274 - val_loss: 10.0139\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5584 - val_loss: 9.8034\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3642 - val_loss: 9.6590\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0971 - val_loss: 10.3320\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6003 - val_loss: 10.0231\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4446 - val_loss: 10.2129\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8026 - val_loss: 10.2588\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6281 - val_loss: 10.1546\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8294 - val_loss: 9.9617\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5381 - val_loss: 10.5720\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5113 - val_loss: 10.1015\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1048 - val_loss: 10.9752\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0957 - val_loss: 10.7835\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1244 - val_loss: 10.4291\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0032 - val_loss: 13.9010\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7765 - val_loss: 10.3794\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8646 - val_loss: 10.1206\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7961 - val_loss: 10.0847\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3485 - val_loss: 9.9936\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5152 - val_loss: 10.0157\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3911 - val_loss: 10.1683\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3324 - val_loss: 10.3278\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5854 - val_loss: 10.5588\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5592 - val_loss: 11.3791\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6781 - val_loss: 11.0718\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3043 - val_loss: 9.9247\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7641 - val_loss: 10.7781\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7467 - val_loss: 10.0572\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6058 - val_loss: 10.3481\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6074 - val_loss: 11.3630\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8688 - val_loss: 10.7765\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4254 - val_loss: 9.8168\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7424 - val_loss: 12.1282\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7438 - val_loss: 10.6659\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6147 - val_loss: 10.0116\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8588 - val_loss: 10.8408\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3412 - val_loss: 10.1632\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7416 - val_loss: 11.4862\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6600 - val_loss: 10.1927\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7418 - val_loss: 10.0705\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7231 - val_loss: 10.2279\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8485 - val_loss: 9.9789\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4873 - val_loss: 10.0068\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5993 - val_loss: 9.5651\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3682 - val_loss: 9.8564\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6604 - val_loss: 10.1006\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6674 - val_loss: 9.7095\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4882 - val_loss: 12.1746\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5069 - val_loss: 10.3827\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6090 - val_loss: 9.7607\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6573 - val_loss: 10.6449\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4747 - val_loss: 9.8607\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2499 - val_loss: 10.1755\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5180 - val_loss: 9.9110\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3318 - val_loss: 11.0702\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3790 - val_loss: 9.9742\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5053 - val_loss: 11.9620\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4597 - val_loss: 10.3558\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7836 - val_loss: 9.9883\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6029 - val_loss: 9.9271\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3084 - val_loss: 11.3368\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3807 - val_loss: 10.3514\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2884 - val_loss: 9.8901\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8216 - val_loss: 12.8081\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7979 - val_loss: 10.3453\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5852 - val_loss: 10.8638\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6344 - val_loss: 12.3427\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6071 - val_loss: 10.0612\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3388 - val_loss: 10.6827\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4225 - val_loss: 9.9921\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6918 - val_loss: 9.8383\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4155 - val_loss: 10.7284\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3811 - val_loss: 10.3628\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4337 - val_loss: 9.6396\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4289 - val_loss: 10.9068\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4464 - val_loss: 10.3738\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7696 - val_loss: 9.9662\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8449 - val_loss: 9.6275\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3462 - val_loss: 10.1351\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5601 - val_loss: 9.4253\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3989 - val_loss: 9.9571\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3949 - val_loss: 9.9818\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7136 - val_loss: 10.1248\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3539 - val_loss: 10.1152\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4010 - val_loss: 9.9216\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7030 - val_loss: 10.1237\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3960 - val_loss: 10.0797\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4853 - val_loss: 10.4838\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5099 - val_loss: 9.9874\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7350 - val_loss: 9.9391\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2201 - val_loss: 9.5519\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8800 - val_loss: 9.6021\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8746 - val_loss: 9.6201\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3260 - val_loss: 9.6202\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1943 - val_loss: 9.9994\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9013 - val_loss: 10.8894\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4751 - val_loss: 10.6697\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1726 - val_loss: 9.5097\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3685 - val_loss: 10.0523\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6416 - val_loss: 10.4179\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0561 - val_loss: 9.4744\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5151 - val_loss: 11.0367\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9030 - val_loss: 10.6152\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3550 - val_loss: 9.8573\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2341 - val_loss: 10.4288\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0510 - val_loss: 9.8702\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5443 - val_loss: 9.7327\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9369 - val_loss: 10.4311\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7461 - val_loss: 11.7217\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5834 - val_loss: 10.4878\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4508 - val_loss: 10.3289\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4761 - val_loss: 9.6344\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2136 - val_loss: 10.4673\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4132 - val_loss: 9.6113\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2599 - val_loss: 10.5125\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4242 - val_loss: 10.1159\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3296 - val_loss: 10.6888\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6883 - val_loss: 9.6898\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5677 - val_loss: 9.6137\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7003 - val_loss: 9.4856\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2475 - val_loss: 11.1763\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3314 - val_loss: 10.1112\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3060 - val_loss: 10.3180\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3016 - val_loss: 10.5361\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4138 - val_loss: 11.1886\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5909 - val_loss: 9.4919\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5308 - val_loss: 9.6824\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4135 - val_loss: 9.9558\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3725 - val_loss: 9.7758\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4718 - val_loss: 9.6471\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6364 - val_loss: 10.5974\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1849 - val_loss: 11.6741\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7398 - val_loss: 9.9197\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5915 - val_loss: 9.7265\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8261 - val_loss: 11.2099\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4551 - val_loss: 10.9612\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2190 - val_loss: 9.3761\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3653 - val_loss: 9.4049\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6832 - val_loss: 11.2978\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4254 - val_loss: 9.4376\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5087 - val_loss: 9.7638\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4683 - val_loss: 9.6169\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6512 - val_loss: 12.0772\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5103 - val_loss: 9.4763\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8936 - val_loss: 10.1871\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5240 - val_loss: 9.7942\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4221 - val_loss: 10.4248\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4503 - val_loss: 11.1031\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2683 - val_loss: 10.5242\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3358 - val_loss: 10.8978\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3256 - val_loss: 10.8422\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4165 - val_loss: 9.2675\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2240 - val_loss: 10.2235\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1198 - val_loss: 9.5027\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3060 - val_loss: 9.7398\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0383 - val_loss: 9.8928\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1978 - val_loss: 9.4624\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4748 - val_loss: 10.4504\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4821 - val_loss: 9.6164\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5779 - val_loss: 9.3077\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2401 - val_loss: 12.2741\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1573 - val_loss: 11.1492\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.4649 - 0s 89us/step - loss: 8.2739 - val_loss: 9.4880\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2302 - val_loss: 9.6236\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4166 - val_loss: 11.2394\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3465 - val_loss: 12.4569\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0829 - val_loss: 10.7025\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7798 - val_loss: 10.5380\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7343 - val_loss: 9.6141\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5048 - val_loss: 9.4032\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1642 - val_loss: 9.7507\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0604 - val_loss: 9.2512\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2295 - val_loss: 10.6430\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2686 - val_loss: 9.6181\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1119 - val_loss: 9.6519\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2943 - val_loss: 10.4999\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0046 - val_loss: 10.6457\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3075 - val_loss: 9.8645\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2087 - val_loss: 9.6646\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2735 - val_loss: 12.0289\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7640 - val_loss: 9.9183\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2645 - val_loss: 9.5418\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1190 - val_loss: 9.5907\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5405 - val_loss: 10.6059\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7039 - val_loss: 9.5430\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1947 - val_loss: 9.7596\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1684 - val_loss: 10.0340\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3548 - val_loss: 10.0204\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4846 - val_loss: 9.5108\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1330 - val_loss: 9.2980\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2016 - val_loss: 9.3354\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3870 - val_loss: 9.6398\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2395 - val_loss: 9.7501\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3867 - val_loss: 10.6244\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5922 - val_loss: 10.0274\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2562 - val_loss: 10.1687\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6690 - val_loss: 10.7262\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3397 - val_loss: 10.1251\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0374 - val_loss: 9.5037\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5523 - val_loss: 9.5860\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5319 - val_loss: 9.4802\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4066 - val_loss: 10.0246\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1570 - val_loss: 11.4660\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3836 - val_loss: 9.8388\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5999 - val_loss: 9.9080\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3418 - val_loss: 9.7082\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5050 - val_loss: 10.9840\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3461 - val_loss: 9.2079\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3780 - val_loss: 10.3353\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0272 - val_loss: 9.6528\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0509 - val_loss: 10.1648\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1288 - val_loss: 9.7112\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1840 - val_loss: 9.7469\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3507 - val_loss: 9.8979\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1662 - val_loss: 10.1307\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5471 - val_loss: 9.9030\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7796 - val_loss: 9.7686\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4722 - val_loss: 9.3394\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1428 - val_loss: 9.2904\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2957 - val_loss: 9.3588\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3514 - val_loss: 9.5988\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2735 - val_loss: 11.4344\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2487 - val_loss: 9.4868\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6664 - val_loss: 9.4441\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4847 - val_loss: 9.9513\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5969 - val_loss: 9.9732\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1512 - val_loss: 9.7910\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0897 - val_loss: 9.4362\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1167 - val_loss: 10.1319\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1038 - val_loss: 9.5188\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1146 - val_loss: 10.6961\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3879 - val_loss: 9.2460\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3920 - val_loss: 9.2585\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0509 - val_loss: 9.1107\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3736 - val_loss: 9.1907\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2691 - val_loss: 9.8840\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2714 - val_loss: 9.8291\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4021 - val_loss: 9.8499\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1764 - val_loss: 9.5829\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4127 - val_loss: 10.5855\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5663 - val_loss: 9.3926\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9527 - val_loss: 9.7668\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2094 - val_loss: 9.3720\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2543 - val_loss: 9.0767\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4455 - val_loss: 9.8783\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1195 - val_loss: 9.2087\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1658 - val_loss: 10.3574\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4079 - val_loss: 9.4369\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6157 - val_loss: 10.2343\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3202 - val_loss: 11.4047\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5276 - val_loss: 10.1832\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1990 - val_loss: 10.5427\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3822 - val_loss: 9.2610\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1327 - val_loss: 9.6431\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1028 - val_loss: 12.9567\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5275 - val_loss: 9.6169\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7257 - val_loss: 11.2425\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5207 - val_loss: 10.9210\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0436 - val_loss: 9.8320\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4099 - val_loss: 9.7275\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5225 - val_loss: 12.5370\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6012 - val_loss: 9.3717\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2254 - val_loss: 9.9521\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3939 - val_loss: 9.3704\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2566 - val_loss: 10.4562\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1684 - val_loss: 9.0811\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0984 - val_loss: 9.9048\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0765 - val_loss: 9.6457\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6824 - val_loss: 13.8929\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4345 - val_loss: 9.2453\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1018 - val_loss: 9.9208\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1653 - val_loss: 10.5236\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8621 - val_loss: 9.3457\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2930 - val_loss: 10.3050\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6942 - val_loss: 9.6703\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2747 - val_loss: 9.7337\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6050 - val_loss: 9.6146\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2119 - val_loss: 9.0501\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4832 - val_loss: 9.5378\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9445 - val_loss: 9.5470\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0667 - val_loss: 9.7697\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3410 - val_loss: 9.6098\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1248 - val_loss: 10.0196\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3748 - val_loss: 9.7231\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4326 - val_loss: 11.0527\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0442 - val_loss: 9.8114\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2069 - val_loss: 9.1482\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0688 - val_loss: 9.1609\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0996 - val_loss: 9.2499\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3406 - val_loss: 9.1683\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1788 - val_loss: 9.6764\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5246 - val_loss: 9.4833\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2027 - val_loss: 9.6368\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1278 - val_loss: 10.3313\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5500 - val_loss: 9.3380\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4283 - val_loss: 10.0158\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1013 - val_loss: 10.3231\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1704 - val_loss: 9.8836\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5682 - val_loss: 9.7284\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1240 - val_loss: 11.0201\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5475 - val_loss: 14.1508\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9016 - val_loss: 10.8664\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0439 - val_loss: 9.0589\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3292 - val_loss: 9.3244\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3532 - val_loss: 9.8085\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0949 - val_loss: 11.3893\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1998 - val_loss: 10.1649\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6199 - val_loss: 11.2239\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2573 - val_loss: 9.8125\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2819 - val_loss: 10.3101\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2406 - val_loss: 9.3653\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2348 - val_loss: 10.1279\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8702 - val_loss: 9.6364\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4825 - val_loss: 9.4706\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6689 - val_loss: 9.5015\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0813 - val_loss: 9.3969\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1618 - val_loss: 9.2902\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1065 - val_loss: 9.2003\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1534 - val_loss: 9.8739\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3373 - val_loss: 9.5377\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4653 - val_loss: 10.5795\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9214 - val_loss: 10.1534\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0756 - val_loss: 10.3551\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3658 - val_loss: 9.8265\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2356 - val_loss: 9.7536\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4313 - val_loss: 11.9783\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3729 - val_loss: 10.5375\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4380 - val_loss: 10.0075\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0053 - val_loss: 9.0208\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0029 - val_loss: 9.5303\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0971 - val_loss: 9.5849\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0374 - val_loss: 9.3342\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5668 - val_loss: 9.3434\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4907 - val_loss: 9.8809\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0993 - val_loss: 10.4092\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0471 - val_loss: 9.1019\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1193 - val_loss: 9.1527\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9411 - val_loss: 9.3905\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2962 - val_loss: 11.1000\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8298 - val_loss: 9.5513\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4466 - val_loss: 10.3502\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2258 - val_loss: 10.5051\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3585 - val_loss: 9.4525\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2828 - val_loss: 10.1442\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0672 - val_loss: 9.6426\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3792 - val_loss: 9.8506\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4920 - val_loss: 9.1700\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6326 - val_loss: 9.5763\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6829 - val_loss: 9.6458\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5630 - val_loss: 10.2840\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0505 - val_loss: 10.0034\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1676 - val_loss: 9.5246\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3818 - val_loss: 12.7649\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8824 - val_loss: 9.8113\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3510 - val_loss: 9.6835\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3110 - val_loss: 9.0657\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4260 - val_loss: 9.7437\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0032 - val_loss: 10.5803\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4517 - val_loss: 10.1770\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0208 - val_loss: 10.9709\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0187 - val_loss: 9.8427\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9367 - val_loss: 9.8908\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2784 - val_loss: 9.1709\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6013 - val_loss: 10.7096\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4391 - val_loss: 10.6823\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8766 - val_loss: 9.2217\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2899 - val_loss: 9.1733\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9964 - val_loss: 9.7249\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3542 - val_loss: 10.5211\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2058 - val_loss: 10.1067\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4680 - val_loss: 9.9071\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0585 - val_loss: 9.5779\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2268 - val_loss: 8.9905\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0848 - val_loss: 9.0115\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2969 - val_loss: 9.5112\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9904 - val_loss: 10.2019\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6091 - val_loss: 9.2266\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9495 - val_loss: 9.7043\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0636 - val_loss: 9.5831\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2075 - val_loss: 9.7070\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5188 - val_loss: 9.2588\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3295 - val_loss: 9.3678\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2819 - val_loss: 10.8230\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2420 - val_loss: 9.7216\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0647 - val_loss: 9.2838\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3253 - val_loss: 9.3368\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2204 - val_loss: 10.0303\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3218 - val_loss: 9.4987\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0054 - val_loss: 10.7272\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3920 - val_loss: 9.4977\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3210 - val_loss: 9.2899\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1792 - val_loss: 8.9397\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4601 - val_loss: 9.2598\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4556 - val_loss: 10.3419\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1952 - val_loss: 9.5185\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2543 - val_loss: 9.1835\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0899 - val_loss: 9.0889\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2398 - val_loss: 9.2280\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0545 - val_loss: 9.3654\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0762 - val_loss: 10.0819\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6566 - val_loss: 10.9196\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8135 - val_loss: 9.4857\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1000 - val_loss: 15.0458\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5711 - val_loss: 9.2800\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1236 - val_loss: 11.2752\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7086 - val_loss: 9.7960\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0660 - val_loss: 9.7642\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9892 - val_loss: 8.9806\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5869 - val_loss: 9.7755\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1552 - val_loss: 11.6564\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4113 - val_loss: 9.0196\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1657 - val_loss: 9.3359\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2616 - val_loss: 9.3482\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1653 - val_loss: 10.6320\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1277 - val_loss: 10.6634\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0722 - val_loss: 9.6328\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2186 - val_loss: 11.4453\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9421 - val_loss: 9.0561\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3438 - val_loss: 10.2354\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1888 - val_loss: 9.2859\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2786 - val_loss: 9.5945\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2753 - val_loss: 10.2432\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4603 - val_loss: 9.0675\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4184 - val_loss: 9.6407\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4381 - val_loss: 9.0723\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0527 - val_loss: 10.2433\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1971 - val_loss: 10.4689\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3811 - val_loss: 10.5780\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3370 - val_loss: 9.3524\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2368 - val_loss: 9.3441\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0694 - val_loss: 10.1198\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1066 - val_loss: 9.9346\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1344 - val_loss: 9.5047\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0536 - val_loss: 11.4024\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2094 - val_loss: 10.2588\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7938 - val_loss: 10.2713\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1712 - val_loss: 9.3509\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2766 - val_loss: 8.9879\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8560 - val_loss: 10.3650\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7574 - val_loss: 9.1660\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1027 - val_loss: 9.7773\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4757 - val_loss: 9.0254\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1128 - val_loss: 9.2858\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1355 - val_loss: 10.1764\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0451 - val_loss: 9.9310\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9525 - val_loss: 11.3785\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8632 - val_loss: 9.6242\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3108 - val_loss: 12.2241\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6290 - val_loss: 9.2106\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2154 - val_loss: 9.4438\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7003 - val_loss: 9.2012\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7726 - val_loss: 9.3150\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3505 - val_loss: 9.4430\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4349 - val_loss: 10.3408\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8435 - val_loss: 10.5995\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1662 - val_loss: 9.5739\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0953 - val_loss: 10.0570\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3524 - val_loss: 11.1177\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4357 - val_loss: 9.6901\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3798 - val_loss: 12.2679\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2878 - val_loss: 10.6538\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0802 - val_loss: 10.2405\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2802 - val_loss: 9.5437\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3698 - val_loss: 9.3956\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0585 - val_loss: 9.8237\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1871 - val_loss: 10.3783\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1825 - val_loss: 10.4473\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3682 - val_loss: 9.2245\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5277 - val_loss: 9.5492\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1114 - val_loss: 9.4106\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3119 - val_loss: 9.0574\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2210 - val_loss: 10.0250\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9330 - val_loss: 9.0228\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1676 - val_loss: 9.9012\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0014 - val_loss: 8.9323\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9286 - val_loss: 9.1274\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9117 - val_loss: 9.2661\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9605 - val_loss: 9.1379\n",
      "8.607352256774902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.1769592 , -1.9100463 , -3.710127  , -0.7330457 , -3.192411  ],\n",
       "        [-0.18609002,  0.49548793,  0.18342125, -1.4196376 ,  0.07634293],\n",
       "        [-0.2968387 ,  0.39592448, -0.70780814, -1.6240458 , -0.00972272],\n",
       "        [ 0.1067272 ,  0.01967674,  0.14045534,  0.24968916,  0.0558002 ],\n",
       "        [-0.15981774, -0.31168342, -0.31994483,  0.3565672 , -2.356783  ]],\n",
       "       dtype=float32),\n",
       " array([ 1.3463533, -1.2876322, -4.6895347, -0.7310286, -4.682707 ],\n",
       "       dtype=float32),\n",
       " array([[-1.2818673 , -1.7822881 , -1.2047614 , -1.5327519 ,  2.217907  ,\n",
       "          2.0535457 ,  1.1480447 ,  2.0110862 , -1.2878984 , -1.0638355 ],\n",
       "        [-0.04187602, -0.27881634, -0.81227756, -0.6709211 ,  0.98949784,\n",
       "          0.57823056,  0.36546516,  0.25199446, -1.1619004 , -1.0453991 ],\n",
       "        [ 2.437426  ,  1.4255244 ,  2.4320202 ,  2.3462694 , -2.458256  ,\n",
       "         -2.0413668 , -2.2727752 , -2.5238566 ,  2.0347672 ,  2.1538606 ],\n",
       "        [-0.5307615 , -0.22970738, -0.25091624,  0.3168216 ,  0.47034743,\n",
       "          0.53320897,  0.37733498,  0.7492733 ,  0.03630306, -0.22935905],\n",
       "        [ 1.5919145 ,  1.2178682 ,  1.7334143 ,  1.8393044 , -2.1043515 ,\n",
       "         -1.4189504 , -2.0508635 , -2.029438  ,  1.5194689 ,  1.054824  ]],\n",
       "       dtype=float32),\n",
       " array([-1.8823241, -1.8070232, -1.8130699, -1.8949527,  1.8296615,\n",
       "         1.8996562,  1.8799112,  1.8324163, -1.9940085, -2.0088716],\n",
       "       dtype=float32),\n",
       " array([[-1.9090436],\n",
       "        [-1.9709003],\n",
       "        [-2.0359   ],\n",
       "        [-1.885523 ],\n",
       "        [ 2.0986533],\n",
       "        [ 1.8368807],\n",
       "        [ 1.801034 ],\n",
       "        [ 2.177264 ],\n",
       "        [-1.5066491],\n",
       "        [-1.4140713]], dtype=float32),\n",
       " array([1.8495547], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_linear(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_linear_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 199us/step - loss: 7709.1093 - val_loss: 613.0920\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 549.1475 - val_loss: 291.4908\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 222.4235 - val_loss: 149.5294\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 124.7435 - val_loss: 99.6321\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 78.1358 - val_loss: 65.1535\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 56.0867 - val_loss: 51.8522\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 46.7334 - val_loss: 44.3026\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 40.1691 - val_loss: 39.9915\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 36.5653 - val_loss: 37.2699\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 34.1463 - val_loss: 36.9496\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 32.0755 - val_loss: 35.3128\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 30.5016 - val_loss: 34.4407\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 29.7086 - val_loss: 35.7794\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 29.8229 - val_loss: 34.3014\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 27.7025 - val_loss: 33.1093\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 26.9528 - val_loss: 31.7235\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 26.2501 - val_loss: 31.6434\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 26.9542 - val_loss: 32.1030\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 25.7916 - val_loss: 31.1493\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 25.5135 - val_loss: 30.5758\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 24.9653 - val_loss: 29.2929\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 24.7487 - val_loss: 30.1859\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.5212 - val_loss: 29.1667\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 24.1472 - val_loss: 29.5704\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.1372 - val_loss: 29.2393\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.0193 - val_loss: 28.7679\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.9304 - val_loss: 28.4940\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 23.3124 - val_loss: 28.8430\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.1016 - val_loss: 27.6951\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.9464 - val_loss: 28.5174\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 23.1276 - val_loss: 27.7345\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.0810 - val_loss: 27.4219\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.4566 - val_loss: 27.7398\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.7193 - val_loss: 27.3770\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3442 - val_loss: 26.8761\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6994 - val_loss: 26.8526\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2766 - val_loss: 27.6029\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2255 - val_loss: 26.7645\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7609 - val_loss: 26.9651\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6422 - val_loss: 26.9085\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7398 - val_loss: 26.4534\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5970 - val_loss: 26.8684\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.9729 - val_loss: 26.9874\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.2453 - val_loss: 25.8643\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.2735 - val_loss: 26.7085\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.0098 - val_loss: 26.5693\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.0962 - val_loss: 26.8267\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3629 - val_loss: 26.3111\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.7941 - val_loss: 26.6184\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0875 - val_loss: 26.6170\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.8469 - val_loss: 25.1311\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.6381 - val_loss: 25.6755\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.6126 - val_loss: 26.2831\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.6058 - val_loss: 26.0239\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9186 - val_loss: 26.1222\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.0250 - val_loss: 25.0957\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.7114 - val_loss: 26.3025\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.9431 - val_loss: 24.7687\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.3877 - val_loss: 25.4776\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.1851 - val_loss: 24.3410\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8656 - val_loss: 24.6079\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3727 - val_loss: 24.6896\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.9077 - val_loss: 25.8477\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1988 - val_loss: 24.4489\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7364 - val_loss: 24.3354\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8764 - val_loss: 25.1088\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.6358 - val_loss: 24.2244\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0557 - val_loss: 23.8615\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.7136 - val_loss: 24.0489\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7824 - val_loss: 24.6124\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6436 - val_loss: 23.0741\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8326 - val_loss: 22.9621\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6159 - val_loss: 23.2590\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8985 - val_loss: 24.0257\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3194 - val_loss: 22.8749\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4666 - val_loss: 23.1761\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6187 - val_loss: 23.3276\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3196 - val_loss: 24.0754\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9229 - val_loss: 23.6795\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6299 - val_loss: 25.1007\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8122 - val_loss: 24.3682\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1780 - val_loss: 24.3699\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7018 - val_loss: 23.6772\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8214 - val_loss: 24.8907\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3526 - val_loss: 24.2545\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3809 - val_loss: 23.6354\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5177 - val_loss: 23.3440\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7754 - val_loss: 23.8591\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4727 - val_loss: 23.7725\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.4428 - val_loss: 25.6913\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1319 - val_loss: 25.5547\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.8762 - val_loss: 27.7296\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7956 - val_loss: 23.2563\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6688 - val_loss: 23.9565\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.5483 - val_loss: 23.8060\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6396 - val_loss: 23.6379\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0021 - val_loss: 24.8147\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5276 - val_loss: 22.7944\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5838 - val_loss: 24.4662\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7236 - val_loss: 23.7245\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2623 - val_loss: 24.1380\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7824 - val_loss: 23.1032\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2611 - val_loss: 23.5135\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3597 - val_loss: 23.5489\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.8409 - val_loss: 25.0896\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7261 - val_loss: 24.2323\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3712 - val_loss: 24.8127\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0639 - val_loss: 24.2589\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3097 - val_loss: 22.8276\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.3043 - val_loss: 23.0522\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9753 - val_loss: 23.1124\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.4396 - val_loss: 25.1189\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.0211 - val_loss: 23.5669\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.4286 - val_loss: 24.2291\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6924 - val_loss: 25.8510\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2002 - val_loss: 24.8194\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9262 - val_loss: 23.0383\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2694 - val_loss: 23.3426\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4232 - val_loss: 25.9069\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4804 - val_loss: 23.3325\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2568 - val_loss: 22.7962\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6423 - val_loss: 22.5616\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0452 - val_loss: 22.8756\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7469 - val_loss: 23.4524\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.2502 - val_loss: 23.7987\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1302 - val_loss: 23.4959\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6271 - val_loss: 22.9240\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.6188 - val_loss: 23.6192\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4257 - val_loss: 23.4342\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5443 - val_loss: 23.4596\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6459 - val_loss: 24.1630\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1861 - val_loss: 24.4525\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4551 - val_loss: 23.9871\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3059 - val_loss: 23.1468\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3746 - val_loss: 23.0911\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 19.1852 - val_loss: 23.3487\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.2886 - val_loss: 23.8491\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1530 - val_loss: 24.4837\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3219 - val_loss: 24.3661\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1978 - val_loss: 22.2920\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5754 - val_loss: 23.2306\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5542 - val_loss: 22.8250\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2671 - val_loss: 23.4340\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1318 - val_loss: 22.7748\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1190 - val_loss: 22.8355\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6325 - val_loss: 24.2544\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2572 - val_loss: 22.8432\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2760 - val_loss: 22.9245\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3149 - val_loss: 24.8699\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7594 - val_loss: 23.4399\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.5695 - val_loss: 25.5925\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.8323 - val_loss: 23.3415\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5326 - val_loss: 25.1496\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9476 - val_loss: 23.0669\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 18.4587 - val_loss: 24.0842\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 18.6170 - val_loss: 25.1478\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2344 - val_loss: 23.7085\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.4669 - val_loss: 23.3507\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.4264 - val_loss: 24.1692\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.9415 - val_loss: 23.6565\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5993 - val_loss: 22.6928\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.2930 - val_loss: 22.3707\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1095 - val_loss: 22.5320\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8736 - val_loss: 24.5146\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1855 - val_loss: 23.7670\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8428 - val_loss: 25.4951\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.8223 - val_loss: 23.5620\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6737 - val_loss: 24.6670\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9489 - val_loss: 22.9812\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1477 - val_loss: 23.4008\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1952 - val_loss: 23.2591\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1800 - val_loss: 24.9178\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4573 - val_loss: 22.6167\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1423 - val_loss: 23.4823\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.9325 - val_loss: 26.1292\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.2633 - val_loss: 22.6392\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.5628 - val_loss: 27.1089\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4131 - val_loss: 25.1759\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6660 - val_loss: 24.4872\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0940 - val_loss: 24.0220\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0398 - val_loss: 24.4705\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.8537 - val_loss: 22.6412\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4230 - val_loss: 23.9099\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9041 - val_loss: 24.2874\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3820 - val_loss: 22.9662\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4773 - val_loss: 23.1084\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0269 - val_loss: 22.8802\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8054 - val_loss: 27.4012\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1129 - val_loss: 24.0043\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.4652 - val_loss: 22.9801\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7211 - val_loss: 22.8750\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3027 - val_loss: 23.5231\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3591 - val_loss: 24.7499\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2779 - val_loss: 22.5059\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7660 - val_loss: 23.2797\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6465 - val_loss: 23.9847\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1632 - val_loss: 25.0570\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.0299 - val_loss: 22.7036\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2054 - val_loss: 22.4280\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8876 - val_loss: 22.9317\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0124 - val_loss: 23.0213\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7284 - val_loss: 22.8009\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7919 - val_loss: 23.0165\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3221 - val_loss: 22.6251\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2227 - val_loss: 22.6570\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7347 - val_loss: 22.6222\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5027 - val_loss: 25.4619\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.3267 - val_loss: 23.1180\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4034 - val_loss: 22.8267\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3897 - val_loss: 25.2581\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3226 - val_loss: 23.7154\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0640 - val_loss: 22.5462\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0910 - val_loss: 23.9962\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2167 - val_loss: 23.2383\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3591 - val_loss: 23.8293\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7983 - val_loss: 24.1073\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7002 - val_loss: 21.9183\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4893 - val_loss: 21.9205\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5650 - val_loss: 22.6754\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8786 - val_loss: 23.0533\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1164 - val_loss: 22.2106\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9568 - val_loss: 22.1723\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3311 - val_loss: 22.6167\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9403 - val_loss: 22.6274\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3075 - val_loss: 22.2635\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8011 - val_loss: 24.8437\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.2908 - val_loss: 24.8866\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5086 - val_loss: 24.9170\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.7803 - val_loss: 22.7709\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4396 - val_loss: 22.6056\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5353 - val_loss: 22.4546\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2180 - val_loss: 22.8830\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.7257 - val_loss: 22.6820\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6142 - val_loss: 23.5146\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8372 - val_loss: 23.9659\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6090 - val_loss: 23.0159\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8038 - val_loss: 23.7077\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0476 - val_loss: 24.3697\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3125 - val_loss: 22.2352\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7719 - val_loss: 22.2953\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9087 - val_loss: 23.5540\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5085 - val_loss: 22.5125\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.5457 - val_loss: 26.5785\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3585 - val_loss: 22.4587\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0700 - val_loss: 23.8859\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.0139 - val_loss: 22.8245\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3799 - val_loss: 24.2095\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4879 - val_loss: 22.1135\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3226 - val_loss: 22.7001\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7468 - val_loss: 24.6288\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0519 - val_loss: 22.6765\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8717 - val_loss: 23.6195\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5459 - val_loss: 22.8832\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3377 - val_loss: 23.1279\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2288 - val_loss: 23.0817\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8329 - val_loss: 22.3338\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7443 - val_loss: 22.9702\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.9307 - val_loss: 22.3033\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3412 - val_loss: 22.7252\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7661 - val_loss: 22.5252\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5414 - val_loss: 23.2832\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8747 - val_loss: 23.3169\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1476 - val_loss: 23.7124\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3082 - val_loss: 22.0125\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8598 - val_loss: 25.2208\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9967 - val_loss: 22.2567\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.8299 - val_loss: 22.6817\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7070 - val_loss: 22.2032\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9321 - val_loss: 23.2365\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2104 - val_loss: 22.1973\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7159 - val_loss: 22.4697\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0131 - val_loss: 22.4469\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1497 - val_loss: 23.2233\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7812 - val_loss: 22.7362\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1916 - val_loss: 25.7293\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2117 - val_loss: 22.5070\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1803 - val_loss: 23.3427\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.8416 - val_loss: 24.4686\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 18.1167 - val_loss: 24.3266\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.2652 - val_loss: 22.2625\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6194 - val_loss: 22.1080\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1175 - val_loss: 24.1975\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6856 - val_loss: 23.7297\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9800 - val_loss: 22.4715\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0252 - val_loss: 22.5883\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8541 - val_loss: 22.6437\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3989 - val_loss: 22.3950\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2538 - val_loss: 22.1537\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3869 - val_loss: 23.3593\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8746 - val_loss: 23.4980\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9353 - val_loss: 22.7937\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.5643 - val_loss: 24.0551\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9643 - val_loss: 23.2770\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8719 - val_loss: 23.5711\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7030 - val_loss: 23.1065\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.3067 - val_loss: 22.1823\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1524 - val_loss: 23.9762\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6878 - val_loss: 22.5465\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7455 - val_loss: 22.4115\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1767 - val_loss: 23.3954\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7705 - val_loss: 22.6076\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8025 - val_loss: 22.9172\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1690 - val_loss: 23.9485\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8036 - val_loss: 23.3616\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8011 - val_loss: 22.4525\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7525 - val_loss: 26.1597\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5941 - val_loss: 22.2941\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6147 - val_loss: 22.5931\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8615 - val_loss: 22.8125\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1111 - val_loss: 22.0308\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9585 - val_loss: 21.8422\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2913 - val_loss: 22.4681\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0628 - val_loss: 22.7602\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0416 - val_loss: 23.1575\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.2328 - val_loss: 24.1852\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8871 - val_loss: 22.8051\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5812 - val_loss: 24.2063\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1685 - val_loss: 24.2002\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0376 - val_loss: 26.2792\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.6704 - val_loss: 22.6765\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.4333 - val_loss: 23.3431\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.0735 - val_loss: 28.4205\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.2743 - val_loss: 22.2256\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.5554 - val_loss: 22.4488\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.3663 - val_loss: 22.7366\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8873 - val_loss: 23.5494\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3588 - val_loss: 23.5319\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.1912 - val_loss: 23.3043\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2489 - val_loss: 22.2107\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6838 - val_loss: 22.8957\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8452 - val_loss: 25.5853\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1380 - val_loss: 23.7141\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8495 - val_loss: 23.1401\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3214 - val_loss: 23.1386\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6026 - val_loss: 22.0602\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0648 - val_loss: 23.8218\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7736 - val_loss: 22.8748\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5147 - val_loss: 24.1568\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8178 - val_loss: 22.1897\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7891 - val_loss: 24.2580\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3362 - val_loss: 22.8374\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8646 - val_loss: 22.4267\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4590 - val_loss: 22.7391\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6613 - val_loss: 22.2196\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7522 - val_loss: 21.7347\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6356 - val_loss: 21.7390\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5967 - val_loss: 22.4068\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5314 - val_loss: 22.6234\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6147 - val_loss: 22.8407\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7039 - val_loss: 22.8811\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5081 - val_loss: 22.7344\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4901 - val_loss: 24.5124\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8945 - val_loss: 22.9542\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6180 - val_loss: 21.6634\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7191 - val_loss: 22.3589\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5916 - val_loss: 23.1987\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1724 - val_loss: 22.2763\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4053 - val_loss: 22.1699\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5920 - val_loss: 21.7687\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5152 - val_loss: 23.0764\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5766 - val_loss: 25.6135\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9856 - val_loss: 21.8876\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9915 - val_loss: 22.1484\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3017 - val_loss: 22.8694\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3385 - val_loss: 23.0574\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9579 - val_loss: 21.9154\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9377 - val_loss: 21.7852\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3900 - val_loss: 21.8780\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3837 - val_loss: 22.2978\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7724 - val_loss: 22.4480\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6025 - val_loss: 22.2921\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5732 - val_loss: 22.7319\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1268 - val_loss: 21.7782\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3825 - val_loss: 21.5062\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3910 - val_loss: 22.6469\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6570 - val_loss: 22.9045\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8690 - val_loss: 21.7623\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7823 - val_loss: 22.2232\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1842 - val_loss: 23.2590\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3052 - val_loss: 23.1792\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0701 - val_loss: 21.6456\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4055 - val_loss: 22.2191\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1606 - val_loss: 21.9541\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4722 - val_loss: 23.5464\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2225 - val_loss: 21.7694\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2527 - val_loss: 23.4692\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9111 - val_loss: 21.5528\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1191 - val_loss: 22.3757\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1758 - val_loss: 22.7785\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6627 - val_loss: 22.7402\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2486 - val_loss: 21.4900\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9985 - val_loss: 23.8973\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8262 - val_loss: 22.4246\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7133 - val_loss: 22.5559\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0981 - val_loss: 22.3427\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.1086 - val_loss: 22.9613\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0189 - val_loss: 25.1712\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8247 - val_loss: 22.9489\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4258 - val_loss: 21.1674\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2409 - val_loss: 21.9874\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3046 - val_loss: 22.6853\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7346 - val_loss: 23.1033\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4702 - val_loss: 21.9934\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1671 - val_loss: 23.3262\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8600 - val_loss: 23.3106\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7467 - val_loss: 22.6363\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7026 - val_loss: 21.7405\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3071 - val_loss: 21.0563\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3865 - val_loss: 21.5010\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4019 - val_loss: 23.6694\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3425 - val_loss: 23.0869\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4389 - val_loss: 21.9328\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1638 - val_loss: 23.0381\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3441 - val_loss: 22.2345\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2735 - val_loss: 22.4924\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1542 - val_loss: 22.1414\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0013 - val_loss: 22.1188\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9357 - val_loss: 24.7906\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1507 - val_loss: 23.5079\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9790 - val_loss: 22.2443\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3050 - val_loss: 23.6563\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2968 - val_loss: 21.5673\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8543 - val_loss: 22.9895\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3307 - val_loss: 23.8238\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1848 - val_loss: 21.9923\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0342 - val_loss: 21.9012\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0605 - val_loss: 23.9565\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6026 - val_loss: 22.2915\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4257 - val_loss: 23.0845\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3424 - val_loss: 22.2440\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1643 - val_loss: 21.5464\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0203 - val_loss: 24.1689\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.0912 - val_loss: 23.7149\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3845 - val_loss: 26.5988\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7501 - val_loss: 22.9505\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.6568 - val_loss: 22.0493\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7510 - val_loss: 21.7748\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5634 - val_loss: 22.7558\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4789 - val_loss: 23.8431\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8937 - val_loss: 22.4275\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3189 - val_loss: 24.2045\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7480 - val_loss: 23.6594\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3614 - val_loss: 22.2632\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4122 - val_loss: 22.3451\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1787 - val_loss: 22.5096\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6500 - val_loss: 21.4659\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4661 - val_loss: 22.5797\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8390 - val_loss: 22.2588\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1623 - val_loss: 23.0084\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3967 - val_loss: 21.4088\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1932 - val_loss: 22.6787\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1457 - val_loss: 26.8746\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8409 - val_loss: 21.0914\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3505 - val_loss: 22.6795\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2296 - val_loss: 21.7999\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0830 - val_loss: 22.2031\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1536 - val_loss: 23.8626\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9082 - val_loss: 21.4469\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2145 - val_loss: 22.6099\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5835 - val_loss: 21.8809\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9012 - val_loss: 23.1664\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6518 - val_loss: 21.8110\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4718 - val_loss: 22.2266\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2308 - val_loss: 23.1919\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2693 - val_loss: 22.7941\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.2397 - val_loss: 29.8554\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7553 - val_loss: 22.6137\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5745 - val_loss: 22.9391\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4160 - val_loss: 23.4261\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1231 - val_loss: 22.4010\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3564 - val_loss: 21.3916\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8477 - val_loss: 23.4102\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4664 - val_loss: 23.6606\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6917 - val_loss: 23.1674\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2415 - val_loss: 22.6302\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4452 - val_loss: 24.9005\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2079 - val_loss: 23.7010\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2737 - val_loss: 22.0365\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1979 - val_loss: 22.9235\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.8314 - val_loss: 21.2689\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1061 - val_loss: 22.1022\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9892 - val_loss: 22.9348\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5772 - val_loss: 22.1521\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1841 - val_loss: 23.2562\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3221 - val_loss: 23.4110\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4215 - val_loss: 23.3331\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.3937 - val_loss: 21.9858\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.8595 - val_loss: 22.3238\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.4163 - val_loss: 22.3708\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.1426 - val_loss: 23.1783\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 18.2701 - val_loss: 23.1117\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 17.7806 - val_loss: 24.0387\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.2185 - val_loss: 22.1814\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.0350 - val_loss: 22.1981\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6698 - val_loss: 22.3453\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2756 - val_loss: 24.3524\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9687 - val_loss: 21.7676\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3106 - val_loss: 21.7142\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1320 - val_loss: 23.8187\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3602 - val_loss: 23.6858\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5303 - val_loss: 22.1964\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5724 - val_loss: 24.1606\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2474 - val_loss: 25.2149\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0359 - val_loss: 22.4559\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7383 - val_loss: 21.5489\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0416 - val_loss: 21.9891\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9603 - val_loss: 21.5882\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1332 - val_loss: 23.9382\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2418 - val_loss: 22.8192\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3785 - val_loss: 23.0056\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.3782 - val_loss: 22.5129\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1910 - val_loss: 21.8514\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5712 - val_loss: 22.1374\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3795 - val_loss: 22.3786\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3549 - val_loss: 22.7672\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6842 - val_loss: 22.2904\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4939 - val_loss: 23.5112\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4090 - val_loss: 22.2523\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6441 - val_loss: 23.2099\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2280 - val_loss: 23.9450\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3498 - val_loss: 22.7586\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0474 - val_loss: 23.6842\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7613 - val_loss: 21.8702\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3005 - val_loss: 23.7607\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2557 - val_loss: 22.5530\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3923 - val_loss: 22.0037\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1937 - val_loss: 22.9669\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5739 - val_loss: 21.8245\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2419 - val_loss: 21.5146\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1192 - val_loss: 21.5578\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4862 - val_loss: 22.7439\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3485 - val_loss: 23.7339\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2680 - val_loss: 22.9734\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.9219 - val_loss: 22.1737\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3927 - val_loss: 22.4027\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.0294 - val_loss: 22.6836\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5317 - val_loss: 24.2443\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 17.4092 - val_loss: 22.5203\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 18.0465 - val_loss: 21.9487\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.1248 - val_loss: 24.1097\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 17.7841 - val_loss: 22.8965\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 17.40 - 0s 114us/step - loss: 17.4809 - val_loss: 21.7544\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2858 - val_loss: 22.7169\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6653 - val_loss: 21.4815\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0780 - val_loss: 22.9161\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0518 - val_loss: 21.8120\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1800 - val_loss: 21.6598\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0027 - val_loss: 21.7854\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9950 - val_loss: 23.6690\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5003 - val_loss: 23.2293\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2052 - val_loss: 22.3413\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1446 - val_loss: 21.7267\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2659 - val_loss: 22.2166\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6365 - val_loss: 22.5836\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6571 - val_loss: 23.7004\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8991 - val_loss: 23.8685\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8879 - val_loss: 22.0384\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9179 - val_loss: 21.8352\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.9478 - val_loss: 23.4300\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4040 - val_loss: 22.5956\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.8925 - val_loss: 22.8649\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.1716 - val_loss: 21.4686\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2394 - val_loss: 21.2282\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.0332 - val_loss: 23.9518\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.0909 - val_loss: 22.3852\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6917 - val_loss: 22.2586\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.1877 - val_loss: 22.0098\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6642 - val_loss: 22.6745\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1116 - val_loss: 22.4376\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1580 - val_loss: 23.0186\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5116 - val_loss: 23.4529\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5825 - val_loss: 22.6023\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3607 - val_loss: 22.4920\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2545 - val_loss: 22.2553\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.1747 - val_loss: 24.4606\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4625 - val_loss: 23.5675\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3877 - val_loss: 22.5682\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2650 - val_loss: 21.9761\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3060 - val_loss: 21.8716\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.8121 - val_loss: 22.0753\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0633 - val_loss: 22.7455\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3100 - val_loss: 24.3557\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5930 - val_loss: 23.8282\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0369 - val_loss: 22.8660\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.0709 - val_loss: 23.1768\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 18.0927 - val_loss: 21.5139\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4856 - val_loss: 22.0093\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7457 - val_loss: 24.3706\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0043 - val_loss: 22.7716\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8578 - val_loss: 23.4747\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2763 - val_loss: 22.3668\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7264 - val_loss: 24.3254\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 16.8251 - val_loss: 21.8616\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2195 - val_loss: 22.8474\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6135 - val_loss: 22.1272\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5603 - val_loss: 22.8863\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8047 - val_loss: 23.4423\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3407 - val_loss: 26.2848\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4476 - val_loss: 22.0823\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3941 - val_loss: 24.3263\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1403 - val_loss: 21.9130\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2067 - val_loss: 21.8545\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5766 - val_loss: 22.3927\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3133 - val_loss: 22.4219\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8694 - val_loss: 24.0711\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.4655 - val_loss: 22.4767\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 18.3647 - val_loss: 24.2937\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3175 - val_loss: 21.3934\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.7212 - val_loss: 23.0939\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3023 - val_loss: 23.2584\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1384 - val_loss: 21.7502\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5466 - val_loss: 22.0982\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1304 - val_loss: 22.1162\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1166 - val_loss: 23.4420\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.3623 - val_loss: 22.9840\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2600 - val_loss: 22.0851\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4236 - val_loss: 22.6241\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0300 - val_loss: 22.4545\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1285 - val_loss: 22.4394\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5449 - val_loss: 22.7834\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9097 - val_loss: 21.9228\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0636 - val_loss: 22.6713\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7591 - val_loss: 23.8234\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.6134 - val_loss: 25.4024\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8101 - val_loss: 22.8540\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7904 - val_loss: 23.7164\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2486 - val_loss: 21.8673\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1593 - val_loss: 22.4216\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6920 - val_loss: 22.3592\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2503 - val_loss: 25.4370\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.6214 - val_loss: 24.9030\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.1740 - val_loss: 22.7321\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7219 - val_loss: 21.3812\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8078 - val_loss: 22.1811\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0224 - val_loss: 23.8782\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8030 - val_loss: 21.8662\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6421 - val_loss: 22.5408\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5982 - val_loss: 23.9998\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7377 - val_loss: 24.2484\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8165 - val_loss: 22.8704\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6497 - val_loss: 21.8614\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2674 - val_loss: 23.1099\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4539 - val_loss: 24.5092\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7056 - val_loss: 22.1089\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9714 - val_loss: 23.9296\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.0574 - val_loss: 22.6337\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9105 - val_loss: 21.8292\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0076 - val_loss: 21.8894\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1661 - val_loss: 22.7568\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8021 - val_loss: 22.7264\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.2690 - val_loss: 22.4652\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.5116 - val_loss: 21.8131\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.4358 - val_loss: 21.8923\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.4321 - val_loss: 21.8391\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.6213 - val_loss: 24.1218\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.6004 - val_loss: 22.6087\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.9461 - val_loss: 22.9641\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 17.2555 - val_loss: 22.1051\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0260 - val_loss: 22.3284\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6090 - val_loss: 21.4807\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3336 - val_loss: 24.2117\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4058 - val_loss: 21.7001\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4262 - val_loss: 22.8804\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5885 - val_loss: 21.9941\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3221 - val_loss: 22.2622\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.2774 - val_loss: 22.4164\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4233 - val_loss: 24.0526\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3833 - val_loss: 22.1503\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7533 - val_loss: 22.9840\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9627 - val_loss: 23.3188\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7585 - val_loss: 21.9021\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1401 - val_loss: 22.0609\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0419 - val_loss: 23.6270\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0690 - val_loss: 21.7166\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2232 - val_loss: 23.4486\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4239 - val_loss: 22.1981\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.9555 - val_loss: 22.0569\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4563 - val_loss: 22.9373\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8744 - val_loss: 23.9842\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7483 - val_loss: 23.1272\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2498 - val_loss: 23.1745\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.9398 - val_loss: 23.1096\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4132 - val_loss: 22.8525\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2188 - val_loss: 22.0884\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6283 - val_loss: 22.8023\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3208 - val_loss: 22.4211\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.1723 - val_loss: 23.0265\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5765 - val_loss: 24.3310\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6076 - val_loss: 21.6183\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7665 - val_loss: 22.0728\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6978 - val_loss: 22.8645\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3641 - val_loss: 23.2900\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4980 - val_loss: 21.7521\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9600 - val_loss: 23.2815\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.5253 - val_loss: 22.2214\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9469 - val_loss: 22.1194\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2490 - val_loss: 22.8863\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3187 - val_loss: 22.2322\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9521 - val_loss: 21.5533\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5300 - val_loss: 22.1402\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 17.1709 - val_loss: 23.4276\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.2687 - val_loss: 23.2910\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.0057 - val_loss: 22.4936\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9450 - val_loss: 22.5991\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4989 - val_loss: 22.1891\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5514 - val_loss: 22.7060\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7732 - val_loss: 21.6395\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2955 - val_loss: 22.6427\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 16.9543 - val_loss: 22.1047\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1461 - val_loss: 22.7985\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0088 - val_loss: 22.1502\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4789 - val_loss: 24.4728\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5957 - val_loss: 22.5825\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2635 - val_loss: 22.4154\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2157 - val_loss: 21.9301\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4933 - val_loss: 23.4410\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5974 - val_loss: 23.0427\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2436 - val_loss: 21.6176\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.2055 - val_loss: 22.4941\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0665 - val_loss: 21.2907\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2608 - val_loss: 22.6580\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2426 - val_loss: 22.1670\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2872 - val_loss: 25.8010\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6976 - val_loss: 21.7943\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1662 - val_loss: 22.4996\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3180 - val_loss: 22.0228\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1782 - val_loss: 23.8843\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9640 - val_loss: 23.9305\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7950 - val_loss: 21.5270\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0692 - val_loss: 22.1029\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2225 - val_loss: 22.0353\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8856 - val_loss: 22.8202\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5430 - val_loss: 22.4566\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.9882 - val_loss: 23.5632\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9104 - val_loss: 23.2019\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4831 - val_loss: 21.9972\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6625 - val_loss: 22.0605\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2121 - val_loss: 23.1176\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4073 - val_loss: 22.5867\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5544 - val_loss: 22.7821\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0069 - val_loss: 23.1098\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5675 - val_loss: 23.1821\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7007 - val_loss: 22.7805\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0112 - val_loss: 21.8797\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8625 - val_loss: 22.3742\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4145 - val_loss: 23.5965\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3404 - val_loss: 23.4278\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5946 - val_loss: 23.8919\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3083 - val_loss: 24.2871\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3414 - val_loss: 22.5556\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3393 - val_loss: 22.0190\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9594 - val_loss: 22.4534\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2630 - val_loss: 25.1876\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9487 - val_loss: 21.8919\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2489 - val_loss: 23.8746\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0839 - val_loss: 22.3490\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4219 - val_loss: 23.5605\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3421 - val_loss: 22.2565\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2563 - val_loss: 22.7377\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1947 - val_loss: 22.6353\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3125 - val_loss: 23.0271\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3660 - val_loss: 23.0425\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9869 - val_loss: 23.3185\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2855 - val_loss: 22.6652\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.6782 - val_loss: 23.2186\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1528 - val_loss: 22.2008\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7967 - val_loss: 25.3654\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8927 - val_loss: 21.6160\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8034 - val_loss: 26.0630\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3823 - val_loss: 22.4187\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3808 - val_loss: 22.5356\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4126 - val_loss: 22.7140\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7590 - val_loss: 22.1597\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8538 - val_loss: 21.7899\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6497 - val_loss: 22.3875\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3040 - val_loss: 22.6219\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0451 - val_loss: 22.6789\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8543 - val_loss: 22.5269\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2654 - val_loss: 22.0763\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 17.3858 - val_loss: 22.0226\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.2331 - val_loss: 23.0404\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3163 - val_loss: 22.3987\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9610 - val_loss: 21.9530\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2803 - val_loss: 21.5024\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6627 - val_loss: 22.6783\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2405 - val_loss: 21.2978\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0375 - val_loss: 21.8876\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2520 - val_loss: 21.3567\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4579 - val_loss: 22.7261\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.8531 - val_loss: 22.5987\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0882 - val_loss: 24.2752\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3683 - val_loss: 22.7797\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.9321 - val_loss: 21.6310\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2164 - val_loss: 22.4953\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4143 - val_loss: 22.3863\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7480 - val_loss: 22.8570\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8451 - val_loss: 22.3226\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 16.9330 - val_loss: 21.6864\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8525 - val_loss: 22.2754\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9995 - val_loss: 22.9174\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1457 - val_loss: 24.0129\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4292 - val_loss: 22.8599\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6560 - val_loss: 22.3429\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4644 - val_loss: 25.0162\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.9289 - val_loss: 23.1059\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7601 - val_loss: 23.0271\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3960 - val_loss: 21.4189\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6000 - val_loss: 22.6905\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3769 - val_loss: 24.6825\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3885 - val_loss: 24.1388\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5622 - val_loss: 21.8445\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6546 - val_loss: 21.5461\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9668 - val_loss: 22.6224\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1353 - val_loss: 22.9092\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2377 - val_loss: 22.2862\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 16.9107 - val_loss: 23.0167\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4764 - val_loss: 22.8529\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 18.1712 - val_loss: 21.6859\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.5169 - val_loss: 22.6874\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7923 - val_loss: 22.0918\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.7489 - val_loss: 22.4654\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.1944 - val_loss: 21.9340\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.8595 - val_loss: 23.5922\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3628 - val_loss: 22.6145\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7726 - val_loss: 21.4965\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8037 - val_loss: 22.6601\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7409 - val_loss: 23.2754\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3853 - val_loss: 22.2189\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2474 - val_loss: 21.6441\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2075 - val_loss: 22.7885\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5490 - val_loss: 22.4781\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8372 - val_loss: 21.8818\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.9576 - val_loss: 21.5856\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5835 - val_loss: 23.4950\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0466 - val_loss: 21.5050\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9712 - val_loss: 25.1538\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4202 - val_loss: 22.6218\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2629 - val_loss: 22.0900\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1716 - val_loss: 23.0249\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.9270 - val_loss: 22.2969\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3520 - val_loss: 22.2188\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1296 - val_loss: 21.5711\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.0003 - val_loss: 22.1868\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1850 - val_loss: 22.0302\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3202 - val_loss: 23.2629\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2044 - val_loss: 22.1987\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6561 - val_loss: 21.4806\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0860 - val_loss: 21.9991\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3107 - val_loss: 24.1661\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6483 - val_loss: 21.9907\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1177 - val_loss: 23.2004\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6073 - val_loss: 22.2189\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0766 - val_loss: 21.4840\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8912 - val_loss: 22.4354\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7561 - val_loss: 23.2192\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9682 - val_loss: 22.6036\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0778 - val_loss: 23.3501\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4262 - val_loss: 23.9497\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3309 - val_loss: 21.8712\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1741 - val_loss: 22.4134\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.1633 - val_loss: 21.9884\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1529 - val_loss: 21.8530\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0532 - val_loss: 23.8117\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8639 - val_loss: 23.1420\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6828 - val_loss: 22.8517\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5427 - val_loss: 22.2809\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3330 - val_loss: 22.9500\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1024 - val_loss: 22.2320\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8049 - val_loss: 24.5660\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3548 - val_loss: 21.9959\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.0002 - val_loss: 21.3955\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5080 - val_loss: 24.0680\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6251 - val_loss: 23.7774\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2863 - val_loss: 22.6518\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6127 - val_loss: 22.2866\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.9767 - val_loss: 24.3760\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4859 - val_loss: 22.8211\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4665 - val_loss: 21.5796\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0247 - val_loss: 22.2510\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9603 - val_loss: 22.0679\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4261 - val_loss: 21.1742\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1288 - val_loss: 22.3093\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4155 - val_loss: 22.7605\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1979 - val_loss: 22.3703\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6602 - val_loss: 22.2142\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9509 - val_loss: 22.3708\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1540 - val_loss: 23.4372\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5263 - val_loss: 22.8602\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3122 - val_loss: 21.6457\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.2707 - val_loss: 22.2537\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6621 - val_loss: 22.7870\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6388 - val_loss: 21.7015\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2487 - val_loss: 23.5681\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0365 - val_loss: 23.0233\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9728 - val_loss: 23.8535\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9014 - val_loss: 22.3771\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6678 - val_loss: 23.2460\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9197 - val_loss: 22.2403\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0835 - val_loss: 22.7032\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.3731 - val_loss: 23.0658\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3980 - val_loss: 22.4642\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5194 - val_loss: 24.3656\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2975 - val_loss: 22.3341\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2776 - val_loss: 22.1761\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.1563 - val_loss: 25.2469\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8199 - val_loss: 22.6339\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5818 - val_loss: 21.7707\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4032 - val_loss: 22.1647\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5767 - val_loss: 23.9186\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2111 - val_loss: 22.8821\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2121 - val_loss: 21.9482\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2603 - val_loss: 21.9536\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9055 - val_loss: 22.4985\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.2768 - val_loss: 22.1168\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0010 - val_loss: 21.3224\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1705 - val_loss: 25.2725\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8008 - val_loss: 21.7850\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0745 - val_loss: 22.6255\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1063 - val_loss: 23.2283\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5570 - val_loss: 21.9789\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6723 - val_loss: 22.8504\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5634 - val_loss: 23.2168\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2359 - val_loss: 22.4253\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2147 - val_loss: 22.2091\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8373 - val_loss: 22.5793\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2559 - val_loss: 21.6521\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0032 - val_loss: 22.9740\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2210 - val_loss: 22.0327\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3598 - val_loss: 23.9777\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0348 - val_loss: 22.4915\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1979 - val_loss: 22.7245\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.9806 - val_loss: 22.5623\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.6778 - val_loss: 21.8214\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2522 - val_loss: 23.9782\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2889 - val_loss: 22.9643\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7403 - val_loss: 23.1089\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6365 - val_loss: 22.0133\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3867 - val_loss: 22.0560\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3448 - val_loss: 22.2030\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7861 - val_loss: 23.4251\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5971 - val_loss: 22.1739\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0701 - val_loss: 22.5041\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3916 - val_loss: 22.9099\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.9178 - val_loss: 22.9504\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7069 - val_loss: 23.3713\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4759 - val_loss: 22.3528\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9950 - val_loss: 22.4409\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1235 - val_loss: 22.4048\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4585 - val_loss: 22.0154\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8717 - val_loss: 22.2880\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5565 - val_loss: 23.4767\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9998 - val_loss: 21.8201\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.1961 - val_loss: 21.2074\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9089 - val_loss: 23.7625\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7323 - val_loss: 21.9957\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0661 - val_loss: 22.4705\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4230 - val_loss: 23.5805\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2825 - val_loss: 22.3015\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7378 - val_loss: 23.1266\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0144 - val_loss: 22.9837\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0340 - val_loss: 23.4939\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1343 - val_loss: 22.0259\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7503 - val_loss: 22.0251\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8964 - val_loss: 23.4307\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0953 - val_loss: 22.1759\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4241 - val_loss: 21.4363\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.1450 - val_loss: 23.6430\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8959 - val_loss: 22.2434\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0625 - val_loss: 22.3017\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2499 - val_loss: 23.7993\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7019 - val_loss: 22.8869\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4929 - val_loss: 23.8098\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9738 - val_loss: 21.6176\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4449 - val_loss: 22.1052\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2457 - val_loss: 21.8374\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2112 - val_loss: 21.9898\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3392 - val_loss: 22.6727\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7658 - val_loss: 22.0030\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2562 - val_loss: 23.0348\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7568 - val_loss: 22.1616\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.0548 - val_loss: 21.9059\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.3614 - val_loss: 22.9294\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.9252 - val_loss: 22.0130\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.4246 - val_loss: 23.5034\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.1855 - val_loss: 22.3003\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4920 - val_loss: 21.9677\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.9254 - val_loss: 22.3267\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.1857 - val_loss: 21.2566\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 17.5557 - val_loss: 22.5284\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7309 - val_loss: 24.8319\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7362 - val_loss: 21.4885\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4779 - val_loss: 22.9060\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1224 - val_loss: 23.2605\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.1377 - val_loss: 22.5146\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2148 - val_loss: 21.7385\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1073 - val_loss: 23.3483\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1521 - val_loss: 22.3171\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1596 - val_loss: 22.4280\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9796 - val_loss: 22.8914\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3548 - val_loss: 22.1297\n",
      "15.67021535350158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.5439516 , -0.2850951 , -0.5038556 , -0.01980588,  1.6049594 ],\n",
       "        [-0.04670838, -0.09782287,  0.12158583, -0.2985098 , -0.5313407 ],\n",
       "        [ 2.1282825 , -0.8228036 , -0.40089998,  0.7831243 , -0.7990883 ],\n",
       "        [ 0.05432128,  0.4532102 , -0.8419722 ,  0.53309405, -0.07131425],\n",
       "        [ 0.03138215,  0.08613851, -0.47052607, -0.11091782, -0.4379164 ]],\n",
       "       dtype=float32),\n",
       " array([2.21736   , 4.1826305 , 3.0609474 , 1.4030826 , 0.23487292],\n",
       "       dtype=float32),\n",
       " array([[-0.08854456,  0.59191865, -0.29357487, -0.947443  , -1.0523553 ,\n",
       "          0.16253084,  1.2060856 ,  0.20450011,  0.8258223 ,  0.2002914 ],\n",
       "        [-0.8074934 ,  1.7370238 , -0.36671808, -0.33099744, -1.1870208 ,\n",
       "          0.99632233,  1.6797211 ,  1.5286862 ,  2.0566661 ,  1.373589  ],\n",
       "        [-0.5327261 ,  1.0119091 , -0.4687797 , -0.4098936 , -0.36504132,\n",
       "          0.8162868 ,  0.36756527,  0.35469282,  1.4260429 , -0.4051751 ],\n",
       "        [-0.27847177,  0.7199743 , -0.78104734, -0.67232746, -0.4244911 ,\n",
       "         -0.23619506,  0.21221791,  0.46138608,  0.6609257 , -2.056332  ],\n",
       "        [-1.1781882 ,  0.31121826, -0.2596643 ,  0.125795  , -0.6057545 ,\n",
       "          0.47111493,  0.30915532,  0.6343249 ,  0.87323415, -0.52796876]],\n",
       "       dtype=float32),\n",
       " array([-0.83355653,  3.6819363 , -0.7289854 , -0.4413162 , -0.8236418 ,\n",
       "         3.4874253 ,  3.6984591 ,  3.3788044 ,  3.702031  ,  2.471602  ],\n",
       "       dtype=float32),\n",
       " array([[0.06910184],\n",
       "        [1.8005285 ],\n",
       "        [0.51666254],\n",
       "        [0.31998482],\n",
       "        [0.3504818 ],\n",
       "        [0.98591053],\n",
       "        [1.6895831 ],\n",
       "        [1.064936  ],\n",
       "        [1.8680372 ],\n",
       "        [0.86667717]], dtype=float32),\n",
       " array([3.7261648], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_relu(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_relu_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 228us/step - loss: 13509.5500 - val_loss: 11507.7667\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10025.2456 - val_loss: 8670.5615\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7673.3723 - val_loss: 6854.8436\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6159.2698 - val_loss: 5590.6292\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5063.8897 - val_loss: 4637.9342\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4184.6081 - val_loss: 3788.8552\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 3307.1997 - val_loss: 2935.0783\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 2522.9732 - val_loss: 2188.7093\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 1894.5130 - val_loss: 1666.6220\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 1453.2062 - val_loss: 1291.3410\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 1129.9019 - val_loss: 1010.2231\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 885.1401 - val_loss: 796.2399\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 697.9007 - val_loss: 629.7472\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 552.7183 - val_loss: 500.0535\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 439.3620 - val_loss: 399.6998\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 351.2070 - val_loss: 320.9279\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 282.4121 - val_loss: 258.9478\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 228.6329 - val_loss: 210.4918\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 186.6171 - val_loss: 172.8940\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 154.0697 - val_loss: 143.3654\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 128.7978 - val_loss: 120.3324\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 109.3159 - val_loss: 102.3853\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 94.2553 - val_loss: 88.6399\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 82.6875 - val_loss: 78.1789\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 73.9100 - val_loss: 70.0304\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 67.1965 - val_loss: 63.7479\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 62.1122 - val_loss: 58.9703\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 58.2934 - val_loss: 55.2816\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 55.3751 - val_loss: 52.5786\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 53.2396 - val_loss: 50.4701\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 51.6284 - val_loss: 48.8967\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 50.4601 - val_loss: 47.6479\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 49.5823 - val_loss: 46.7376\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 48.9402 - val_loss: 46.1152\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 48.4899 - val_loss: 45.5817\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 48.1736 - val_loss: 45.1130\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.9138 - val_loss: 44.8869\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.7678 - val_loss: 44.6131\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.6290 - val_loss: 44.4746\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.5548 - val_loss: 44.3382\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.4946 - val_loss: 44.2411\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.4537 - val_loss: 44.1690\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.4245 - val_loss: 44.1461\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.4025 - val_loss: 44.0838\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3834 - val_loss: 44.0509\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3700 - val_loss: 44.0180\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3643 - val_loss: 43.9771\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3560 - val_loss: 43.9585\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3388 - val_loss: 43.9553\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.2669 - val_loss: 43.7789\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 43.9364 - val_loss: 38.0625\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 36.9235 - val_loss: 33.6638\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 28.2790 - val_loss: 29.3773\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 25.0188 - val_loss: 27.7018\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.3167 - val_loss: 26.3905\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2849 - val_loss: 25.7013\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.4812 - val_loss: 24.8270\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.8682 - val_loss: 24.2283\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.2007 - val_loss: 23.5545\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.5722 - val_loss: 23.0192\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0876 - val_loss: 22.4468\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8135 - val_loss: 22.2957\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3523 - val_loss: 21.6812\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2618 - val_loss: 21.4706\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9072 - val_loss: 21.6145\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8245 - val_loss: 21.1881\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7967 - val_loss: 21.4008\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5838 - val_loss: 21.5784\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5986 - val_loss: 21.2392\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3896 - val_loss: 20.6821\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4579 - val_loss: 20.8102\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1785 - val_loss: 21.0643\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0234 - val_loss: 20.5754\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8681 - val_loss: 20.2235\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4627 - val_loss: 19.9483\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6363 - val_loss: 19.3099\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.1794 - val_loss: 18.9852\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.0939 - val_loss: 19.1632\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8907 - val_loss: 19.1653\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.8048 - val_loss: 18.9419\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6833 - val_loss: 18.5720\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3542 - val_loss: 18.7663\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0045 - val_loss: 18.5188\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0320 - val_loss: 18.4310\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9465 - val_loss: 18.4652\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7701 - val_loss: 18.1195\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9058 - val_loss: 18.2821\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7036 - val_loss: 18.2597\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5750 - val_loss: 18.2333\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5924 - val_loss: 18.1767\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4390 - val_loss: 18.2470\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.4851 - val_loss: 18.2201\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5083 - val_loss: 18.2796\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.4388 - val_loss: 18.5774\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5317 - val_loss: 18.0938\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.4390 - val_loss: 17.9120\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3579 - val_loss: 18.1220\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3184 - val_loss: 18.0652\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.4262 - val_loss: 17.8531\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.2698 - val_loss: 18.0670\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3191 - val_loss: 17.8022\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2677 - val_loss: 18.2105\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.2867 - val_loss: 18.0122\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1951 - val_loss: 18.3774\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3619 - val_loss: 18.0589\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4024 - val_loss: 17.9514\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.2631 - val_loss: 17.8138\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.1776 - val_loss: 18.0645\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1883 - val_loss: 18.1275\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.2030 - val_loss: 17.6982\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1757 - val_loss: 17.6568\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.2093 - val_loss: 17.9262\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1794 - val_loss: 17.7533\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1196 - val_loss: 17.8164\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1318 - val_loss: 17.8395\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1340 - val_loss: 18.1041\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1026 - val_loss: 17.9085\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9738 - val_loss: 17.7404\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1359 - val_loss: 17.8387\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1045 - val_loss: 17.6868\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.0742 - val_loss: 17.8020\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1015 - val_loss: 17.7471\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.1419 - val_loss: 17.9826\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1679 - val_loss: 17.7091\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0401 - val_loss: 17.6680\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9518 - val_loss: 17.6381\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9804 - val_loss: 17.7008\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9387 - val_loss: 17.5850\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.9144 - val_loss: 17.6282\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8534 - val_loss: 18.0406\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9878 - val_loss: 17.6879\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9336 - val_loss: 17.7014\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.0092 - val_loss: 17.7175\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9983 - val_loss: 17.6209\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9692 - val_loss: 17.7140\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9364 - val_loss: 17.6661\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.8697 - val_loss: 17.6229\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.8630 - val_loss: 17.4692\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.8670 - val_loss: 17.6100\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.8120 - val_loss: 17.5163\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 102us/step - loss: 12.8319 - val_loss: 17.6616\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.7904 - val_loss: 17.6051\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 12.8244 - val_loss: 17.5875\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.8211 - val_loss: 17.7079\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.8399 - val_loss: 17.7634\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7483 - val_loss: 17.5310\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7869 - val_loss: 17.7231\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7351 - val_loss: 17.3294\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7408 - val_loss: 17.4870\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7853 - val_loss: 17.3969\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7250 - val_loss: 17.4104\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7731 - val_loss: 17.4289\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7669 - val_loss: 17.4705\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.8573 - val_loss: 17.3408\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.7987 - val_loss: 17.5528\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6843 - val_loss: 17.3551\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6515 - val_loss: 17.1487\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6209 - val_loss: 17.3950\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6384 - val_loss: 17.1948\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6614 - val_loss: 17.2935\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6179 - val_loss: 17.1687\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.6537 - val_loss: 17.1437\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.6711 - val_loss: 17.7638\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6089 - val_loss: 17.8740\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7089 - val_loss: 17.5307\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5612 - val_loss: 17.2460\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.5145 - val_loss: 17.5885\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5606 - val_loss: 17.0809\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5238 - val_loss: 17.2380\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4876 - val_loss: 17.5056\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5876 - val_loss: 17.9000\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.6185 - val_loss: 17.5116\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.3507 - val_loss: 17.0463\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.3827 - val_loss: 16.9749\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3568 - val_loss: 16.9555\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3859 - val_loss: 16.8602\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4973 - val_loss: 17.0655\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3518 - val_loss: 16.9732\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4048 - val_loss: 16.8646\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.4583 - val_loss: 17.7642\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4016 - val_loss: 16.8281\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2447 - val_loss: 17.0112\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3129 - val_loss: 16.8464\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4009 - val_loss: 17.3571\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4684 - val_loss: 16.9548\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.3046 - val_loss: 16.9836\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2946 - val_loss: 16.8983\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1806 - val_loss: 16.8489\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3847 - val_loss: 17.0121\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2963 - val_loss: 16.9099\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.3010 - val_loss: 16.7003\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1275 - val_loss: 17.7229\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3006 - val_loss: 17.0874\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.1851 - val_loss: 17.2166\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.1863 - val_loss: 16.9626\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2208 - val_loss: 17.0574\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1562 - val_loss: 17.2609\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.2242 - val_loss: 16.8912\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1159 - val_loss: 17.2891\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1292 - val_loss: 17.1219\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0974 - val_loss: 17.0743\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1369 - val_loss: 17.2178\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.1426 - val_loss: 17.5729\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1330 - val_loss: 17.1017\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1097 - val_loss: 16.9509\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.0463 - val_loss: 17.1303\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1587 - val_loss: 17.0873\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0676 - val_loss: 16.9221\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1218 - val_loss: 17.3080\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.1725 - val_loss: 17.4874\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.0771 - val_loss: 17.4545\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0391 - val_loss: 17.5698\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1202 - val_loss: 17.1297\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1284 - val_loss: 16.9692\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0273 - val_loss: 17.0194\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0520 - val_loss: 17.1397\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9273 - val_loss: 17.0910\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0586 - val_loss: 16.8293\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9788 - val_loss: 17.2054\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.8869 - val_loss: 16.9403\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9711 - val_loss: 17.0731\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9432 - val_loss: 16.7024\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9155 - val_loss: 16.9080\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8525 - val_loss: 16.7817\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.9069 - val_loss: 16.9685\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.0519 - val_loss: 17.4250\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8538 - val_loss: 16.8851\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9434 - val_loss: 16.9478\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9531 - val_loss: 16.9859\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9380 - val_loss: 17.1083\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0335 - val_loss: 17.1989\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7766 - val_loss: 16.8251\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9502 - val_loss: 16.8668\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9437 - val_loss: 16.9945\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.9106 - val_loss: 17.3259\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.8576 - val_loss: 16.7871\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9779 - val_loss: 17.5062\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9001 - val_loss: 16.8950\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9333 - val_loss: 16.6116\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8517 - val_loss: 17.0952\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7794 - val_loss: 16.9800\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8565 - val_loss: 16.8860\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8261 - val_loss: 16.9959\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9309 - val_loss: 16.6163\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8015 - val_loss: 16.9228\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7963 - val_loss: 17.0761\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.8312 - val_loss: 17.5234\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0347 - val_loss: 17.2022\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9501 - val_loss: 16.9276\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8751 - val_loss: 16.6794\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7669 - val_loss: 17.0006\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.8630 - val_loss: 16.7715\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8338 - val_loss: 17.1747\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8912 - val_loss: 16.9185\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.9282 - val_loss: 16.6541\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9016 - val_loss: 17.0458\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9399 - val_loss: 16.7253\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7858 - val_loss: 16.7996\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8106 - val_loss: 17.0790\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7823 - val_loss: 17.0075\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8507 - val_loss: 16.9650\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8324 - val_loss: 16.6897\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7884 - val_loss: 17.1088\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7294 - val_loss: 17.0590\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7569 - val_loss: 16.8850\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8246 - val_loss: 16.7816\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.8579 - val_loss: 16.9347\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8009 - val_loss: 16.7031\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8047 - val_loss: 16.9552\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7580 - val_loss: 16.7640\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8234 - val_loss: 16.7519\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8207 - val_loss: 17.2165\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6378 - val_loss: 16.7499\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7340 - val_loss: 16.8209\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7571 - val_loss: 17.1838\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7799 - val_loss: 16.8775\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7795 - val_loss: 16.8845\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8012 - val_loss: 16.8245\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8164 - val_loss: 16.6504\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8373 - val_loss: 17.6370\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7282 - val_loss: 16.8566\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6518 - val_loss: 16.7172\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7412 - val_loss: 16.7942\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.7543 - val_loss: 17.0846\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8654 - val_loss: 16.8757\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7212 - val_loss: 16.8188\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7280 - val_loss: 16.9800\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7304 - val_loss: 16.8106\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7028 - val_loss: 17.0774\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8140 - val_loss: 17.7151\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6775 - val_loss: 16.7143\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7324 - val_loss: 18.0515\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7924 - val_loss: 16.9875\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6634 - val_loss: 17.0106\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6873 - val_loss: 17.0053\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6929 - val_loss: 17.8135\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6900 - val_loss: 16.8691\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6860 - val_loss: 16.9392\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6754 - val_loss: 17.0048\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5812 - val_loss: 17.1046\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 11.7332 - val_loss: 16.7447\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.8051 - val_loss: 17.1266\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.7671 - val_loss: 17.0316\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7025 - val_loss: 16.9482\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.7039 - val_loss: 17.6929\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8162 - val_loss: 16.7458\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6887 - val_loss: 16.9369\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.6541 - val_loss: 17.3408\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6727 - val_loss: 16.7169\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7084 - val_loss: 17.2612\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7413 - val_loss: 17.1469\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6665 - val_loss: 17.0581\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6282 - val_loss: 17.0048\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7056 - val_loss: 17.0884\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5627 - val_loss: 16.6798\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6848 - val_loss: 17.0723\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7340 - val_loss: 16.9907\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6369 - val_loss: 17.0197\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6427 - val_loss: 16.9332\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6522 - val_loss: 16.7545\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7324 - val_loss: 16.9091\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7065 - val_loss: 16.9603\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7205 - val_loss: 17.1995\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6831 - val_loss: 17.4924\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7420 - val_loss: 17.1627\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7935 - val_loss: 16.8193\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6846 - val_loss: 17.0019\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6174 - val_loss: 17.0663\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6385 - val_loss: 18.0440\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7075 - val_loss: 17.0737\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6535 - val_loss: 16.8075\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6466 - val_loss: 17.3088\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7336 - val_loss: 17.5628\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8022 - val_loss: 17.0779\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7153 - val_loss: 16.8987\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8093 - val_loss: 17.0359\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6381 - val_loss: 17.8423\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8777 - val_loss: 17.2802\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6068 - val_loss: 17.0397\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8474 - val_loss: 17.0337\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7088 - val_loss: 17.2357\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8487 - val_loss: 16.7876\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7739 - val_loss: 16.8566\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6893 - val_loss: 17.7649\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7814 - val_loss: 17.2372\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6733 - val_loss: 16.8918\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6248 - val_loss: 17.1220\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6610 - val_loss: 16.8288\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6663 - val_loss: 17.4398\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6832 - val_loss: 17.9889\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6224 - val_loss: 17.1060\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6452 - val_loss: 16.9602\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7875 - val_loss: 17.0379\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6387 - val_loss: 17.4626\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6247 - val_loss: 17.1909\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5858 - val_loss: 17.0642\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6417 - val_loss: 17.2411\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7774 - val_loss: 17.0035\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7917 - val_loss: 17.5572\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9018 - val_loss: 17.1263\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7862 - val_loss: 16.9546\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6904 - val_loss: 18.1475\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8128 - val_loss: 17.2494\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7747 - val_loss: 16.9103\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7417 - val_loss: 17.3009\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6778 - val_loss: 16.9311\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5806 - val_loss: 17.1010\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7218 - val_loss: 17.3292\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6322 - val_loss: 16.8736\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7124 - val_loss: 17.4271\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7276 - val_loss: 17.2421\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6997 - val_loss: 17.0879\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6647 - val_loss: 16.9606\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7144 - val_loss: 16.8541\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5787 - val_loss: 16.9121\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5786 - val_loss: 17.0294\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6837 - val_loss: 17.0363\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6709 - val_loss: 17.2582\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6374 - val_loss: 16.8246\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6874 - val_loss: 16.9005\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6540 - val_loss: 16.9689\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6630 - val_loss: 17.6711\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6098 - val_loss: 17.3338\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7585 - val_loss: 16.8352\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5648 - val_loss: 17.0569\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7083 - val_loss: 17.0069\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6970 - val_loss: 17.2094\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5688 - val_loss: 17.1747\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7398 - val_loss: 16.7503\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5938 - val_loss: 16.9759\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5825 - val_loss: 17.0716\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5450 - val_loss: 17.0486\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7250 - val_loss: 16.7986\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7698 - val_loss: 16.6172\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6070 - val_loss: 17.4328\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7373 - val_loss: 16.8820\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6105 - val_loss: 17.1422\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5787 - val_loss: 17.0585\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5198 - val_loss: 17.1818\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6378 - val_loss: 17.0325\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6244 - val_loss: 16.9126\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7499 - val_loss: 16.7212\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7318 - val_loss: 16.8786\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6786 - val_loss: 17.0723\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5735 - val_loss: 17.0998\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5990 - val_loss: 17.2186\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5221 - val_loss: 17.0127\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5790 - val_loss: 17.0985\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7276 - val_loss: 16.7639\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.6408 - val_loss: 16.8996\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6650 - val_loss: 17.3556\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5947 - val_loss: 17.2748\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6590 - val_loss: 17.0308\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6362 - val_loss: 17.0492\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6628 - val_loss: 16.6627\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6398 - val_loss: 16.8351\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6624 - val_loss: 17.0713\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5474 - val_loss: 17.1019\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6325 - val_loss: 17.2241\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6853 - val_loss: 16.6644\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6766 - val_loss: 17.3413\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5268 - val_loss: 16.9528\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5310 - val_loss: 17.0581\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6120 - val_loss: 16.8448\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8335 - val_loss: 16.6087\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5859 - val_loss: 16.9428\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6555 - val_loss: 16.8324\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.6986 - val_loss: 16.9857\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7005 - val_loss: 16.8510\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6391 - val_loss: 16.9155\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6035 - val_loss: 16.8407\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5550 - val_loss: 16.7612\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6796 - val_loss: 16.8524\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5835 - val_loss: 16.8714\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6334 - val_loss: 16.7883\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6412 - val_loss: 16.6063\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5789 - val_loss: 16.9501\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6252 - val_loss: 16.7913\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6331 - val_loss: 17.0193\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6660 - val_loss: 17.2506\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5298 - val_loss: 17.0671\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5756 - val_loss: 17.2155\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5254 - val_loss: 16.7749\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6831 - val_loss: 17.5337\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5787 - val_loss: 16.8384\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5628 - val_loss: 17.1110\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5752 - val_loss: 16.7385\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5170 - val_loss: 17.1075\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6758 - val_loss: 16.6941\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6699 - val_loss: 16.9148\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7724 - val_loss: 17.1274\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7231 - val_loss: 16.7651\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6063 - val_loss: 17.1919\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.5940 - val_loss: 16.6511\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.5959 - val_loss: 16.7719\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4934 - val_loss: 16.6220\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6070 - val_loss: 16.9944\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4972 - val_loss: 16.6908\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5597 - val_loss: 16.5673\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5928 - val_loss: 17.0251\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6603 - val_loss: 16.7518\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6109 - val_loss: 17.1787\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5784 - val_loss: 16.5745\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4618 - val_loss: 16.9641\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5976 - val_loss: 16.7294\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6013 - val_loss: 16.8574\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.5050 - val_loss: 16.8167\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.7282 - val_loss: 16.6502\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.5886 - val_loss: 17.0840\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 11.5198 - val_loss: 17.5630\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.8407 - val_loss: 17.0971\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.5869 - val_loss: 16.3368\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5390 - val_loss: 17.5925\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.6462 - val_loss: 17.1824\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6193 - val_loss: 17.3850\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5526 - val_loss: 16.8795\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5991 - val_loss: 16.7514\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5776 - val_loss: 16.9593\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4949 - val_loss: 16.5066\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5237 - val_loss: 17.0464\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4879 - val_loss: 16.7907\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5302 - val_loss: 16.7102\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5928 - val_loss: 16.8035\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6194 - val_loss: 16.4979\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7579 - val_loss: 17.2051\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5881 - val_loss: 16.8137\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5245 - val_loss: 16.9375\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6464 - val_loss: 17.0604\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5466 - val_loss: 16.5572\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5377 - val_loss: 16.6661\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6048 - val_loss: 16.5968\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6341 - val_loss: 16.6321\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5322 - val_loss: 16.9206\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5596 - val_loss: 16.4905\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5702 - val_loss: 17.4035\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6516 - val_loss: 17.0288\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5416 - val_loss: 16.6690\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5647 - val_loss: 16.8432\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5924 - val_loss: 16.8305\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5178 - val_loss: 16.7958\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5506 - val_loss: 16.6157\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4378 - val_loss: 16.7781\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5801 - val_loss: 16.5799\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5359 - val_loss: 16.9946\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5991 - val_loss: 17.1826\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5837 - val_loss: 17.0281\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 11.5899 - val_loss: 17.0569\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6716 - val_loss: 17.2927\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7576 - val_loss: 16.7566\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6789 - val_loss: 16.5253\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4299 - val_loss: 16.5450\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6140 - val_loss: 16.6024\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5068 - val_loss: 17.0101\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6139 - val_loss: 16.7219\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6146 - val_loss: 16.4622\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4539 - val_loss: 16.5646\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5685 - val_loss: 16.3521\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5130 - val_loss: 16.8012\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5608 - val_loss: 16.6117\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6181 - val_loss: 16.5251\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5164 - val_loss: 16.8852\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5351 - val_loss: 16.9042\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4735 - val_loss: 16.5105\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4957 - val_loss: 16.7201\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.5696 - val_loss: 16.6256\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.5019 - val_loss: 16.4225\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6882 - val_loss: 16.6560\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6368 - val_loss: 16.7283\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5656 - val_loss: 16.7680\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4930 - val_loss: 16.5914\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4369 - val_loss: 16.6965\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4153 - val_loss: 16.6052\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5187 - val_loss: 17.5764\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5840 - val_loss: 16.9202\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5172 - val_loss: 16.7187\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4215 - val_loss: 16.5675\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6335 - val_loss: 16.6829\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5727 - val_loss: 16.6383\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6364 - val_loss: 16.4716\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5307 - val_loss: 16.6223\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4227 - val_loss: 16.6148\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5122 - val_loss: 16.6395\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5098 - val_loss: 16.5706\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4545 - val_loss: 16.3983\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4030 - val_loss: 16.8922\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4225 - val_loss: 16.4895\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6151 - val_loss: 16.5073\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5359 - val_loss: 16.6884\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4501 - val_loss: 16.8837\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5221 - val_loss: 16.8767\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5716 - val_loss: 17.5056\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6851 - val_loss: 16.5466\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4952 - val_loss: 16.5589\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3629 - val_loss: 16.6013\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3952 - val_loss: 17.0294\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4296 - val_loss: 16.5074\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4750 - val_loss: 17.4194\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4139 - val_loss: 16.4841\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5884 - val_loss: 16.5927\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5938 - val_loss: 17.0602\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5297 - val_loss: 17.0824\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6067 - val_loss: 16.5409\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6345 - val_loss: 17.1026\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4960 - val_loss: 16.5226\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5923 - val_loss: 16.4748\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5417 - val_loss: 16.7994\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4942 - val_loss: 16.9402\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4896 - val_loss: 16.7896\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5718 - val_loss: 17.5679\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.5674 - val_loss: 16.7173\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5676 - val_loss: 16.6076\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4707 - val_loss: 16.7600\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4558 - val_loss: 16.5366\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5217 - val_loss: 16.9129\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6276 - val_loss: 16.4664\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6018 - val_loss: 16.5647\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4864 - val_loss: 16.5981\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4251 - val_loss: 16.4830\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4521 - val_loss: 16.9903\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5688 - val_loss: 16.7592\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6350 - val_loss: 16.7671\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5809 - val_loss: 16.5839\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5684 - val_loss: 16.6364\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5905 - val_loss: 16.5115\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5252 - val_loss: 16.6163\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4782 - val_loss: 16.5413\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4721 - val_loss: 16.6585\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5120 - val_loss: 16.3970\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4920 - val_loss: 16.6913\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4599 - val_loss: 17.4813\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5875 - val_loss: 16.5533\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5424 - val_loss: 17.5025\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6109 - val_loss: 16.6143\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4023 - val_loss: 16.4434\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4712 - val_loss: 17.1031\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4460 - val_loss: 16.6245\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4014 - val_loss: 16.9322\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5448 - val_loss: 16.4785\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4464 - val_loss: 16.6023\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3655 - val_loss: 16.5143\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3684 - val_loss: 16.5745\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3927 - val_loss: 16.3964\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4793 - val_loss: 16.6331\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3734 - val_loss: 16.7182\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5468 - val_loss: 17.0427\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5177 - val_loss: 16.7224\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3514 - val_loss: 17.0366\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4806 - val_loss: 16.5122\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4262 - val_loss: 17.9578\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4295 - val_loss: 16.5477\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4265 - val_loss: 16.4380\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4373 - val_loss: 17.0242\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4848 - val_loss: 16.7483\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5563 - val_loss: 16.4726\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4630 - val_loss: 16.7539\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4466 - val_loss: 17.0444\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4463 - val_loss: 16.9797\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3573 - val_loss: 16.8742\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6534 - val_loss: 16.4633\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3926 - val_loss: 16.7587\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5227 - val_loss: 16.4846\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3471 - val_loss: 16.8669\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5344 - val_loss: 16.7321\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3847 - val_loss: 16.6954\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3747 - val_loss: 16.9892\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3915 - val_loss: 16.9297\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3967 - val_loss: 16.5433\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3805 - val_loss: 16.6766\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3792 - val_loss: 16.8030\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3806 - val_loss: 17.0789\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3470 - val_loss: 17.3189\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 11.4549 - val_loss: 16.8745\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4944 - val_loss: 16.6368\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.4621 - val_loss: 17.1550\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.3664 - val_loss: 16.8350\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.4268 - val_loss: 16.4049\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3404 - val_loss: 17.2697\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.4376 - val_loss: 16.9451\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 11.3713 - val_loss: 16.5858\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3269 - val_loss: 17.1428\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4254 - val_loss: 16.9884\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3441 - val_loss: 17.1795\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8336 - val_loss: 16.3367\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5411 - val_loss: 16.9730\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4706 - val_loss: 17.0030\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4590 - val_loss: 16.5911\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4029 - val_loss: 16.4960\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4427 - val_loss: 16.5371\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4014 - val_loss: 16.3216\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4142 - val_loss: 16.8189\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3768 - val_loss: 16.5857\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.3926 - val_loss: 16.5383\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3332 - val_loss: 16.8075\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3330 - val_loss: 17.1215\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3814 - val_loss: 16.6909\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5984 - val_loss: 16.8869\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3615 - val_loss: 16.6809\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3652 - val_loss: 16.6348\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3167 - val_loss: 17.0843\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4555 - val_loss: 16.7049\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4250 - val_loss: 16.6887\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.5082 - val_loss: 16.7226\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4099 - val_loss: 16.6855\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4976 - val_loss: 16.3911\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4427 - val_loss: 16.5539\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6779 - val_loss: 16.3685\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4253 - val_loss: 16.4396\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3933 - val_loss: 16.8835\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4091 - val_loss: 17.2523\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4490 - val_loss: 16.7714\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3769 - val_loss: 16.7642\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5495 - val_loss: 16.7029\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5595 - val_loss: 16.5763\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.5494 - val_loss: 16.7988\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.2828 - val_loss: 16.9623\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2952 - val_loss: 16.4668\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.2949 - val_loss: 16.7703\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3300 - val_loss: 16.6573\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2763 - val_loss: 16.8929\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3456 - val_loss: 16.8986\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3109 - val_loss: 16.3405\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2557 - val_loss: 16.6636\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.2760 - val_loss: 16.4523\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3052 - val_loss: 17.1362\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3746 - val_loss: 16.2605\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3637 - val_loss: 16.7242\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4583 - val_loss: 17.0357\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3040 - val_loss: 16.7402\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2891 - val_loss: 16.5095\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3447 - val_loss: 16.1613\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4861 - val_loss: 16.4947\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3007 - val_loss: 16.6356\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4760 - val_loss: 16.9737\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3348 - val_loss: 16.7079\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4036 - val_loss: 16.7318\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3481 - val_loss: 17.3545\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4956 - val_loss: 16.6325\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3449 - val_loss: 16.2873\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3601 - val_loss: 16.1704\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3056 - val_loss: 16.7169\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2835 - val_loss: 16.9204\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3137 - val_loss: 16.8865\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3322 - val_loss: 16.2441\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3452 - val_loss: 16.4739\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2643 - val_loss: 16.5583\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2645 - val_loss: 16.5678\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3109 - val_loss: 16.6734\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2823 - val_loss: 16.2275\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2651 - val_loss: 16.5911\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3327 - val_loss: 16.3614\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3174 - val_loss: 15.9467\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2424 - val_loss: 16.4234\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.3123 - val_loss: 16.0037\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3090 - val_loss: 16.3119\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3350 - val_loss: 15.7041\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4729 - val_loss: 16.0590\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2998 - val_loss: 16.0831\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1535 - val_loss: 16.3434\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3058 - val_loss: 15.9526\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1219 - val_loss: 15.8104\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.2793 - val_loss: 15.8704\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1461 - val_loss: 15.9079\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2214 - val_loss: 16.0257\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1929 - val_loss: 15.9523\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0011 - val_loss: 15.6279\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0348 - val_loss: 15.7388\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0052 - val_loss: 15.7403\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9794 - val_loss: 15.2704\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0449 - val_loss: 15.3447\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.7638 - val_loss: 15.4707\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.9492 - val_loss: 15.3789\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6833 - val_loss: 15.1012\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6615 - val_loss: 15.2422\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9134 - val_loss: 15.4610\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6703 - val_loss: 15.1613\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.5676 - val_loss: 14.6674\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3537 - val_loss: 14.4376\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.5281 - val_loss: 12.5254\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8820 - val_loss: 13.0945\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3857 - val_loss: 12.8712\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9856 - val_loss: 11.5927\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4364 - val_loss: 11.9916\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3557 - val_loss: 11.9925\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2254 - val_loss: 11.8938\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3579 - val_loss: 11.3736\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3565 - val_loss: 12.1222\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2683 - val_loss: 11.3922\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1336 - val_loss: 11.5489\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1808 - val_loss: 11.1097\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1729 - val_loss: 11.4392\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1506 - val_loss: 11.8870\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9991 - val_loss: 11.0531\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8993 - val_loss: 11.4032\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9506 - val_loss: 10.9467\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1876 - val_loss: 11.4158\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6086 - val_loss: 11.4204\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9748 - val_loss: 10.8700\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1705 - val_loss: 10.8372\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0501 - val_loss: 10.8343\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0078 - val_loss: 11.1159\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9138 - val_loss: 11.7968\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7287 - val_loss: 11.8154\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8319 - val_loss: 11.0482\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7198 - val_loss: 10.9227\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9234 - val_loss: 10.9466\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7479 - val_loss: 10.9898\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.5679 - val_loss: 11.2469\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7873 - val_loss: 10.6107\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4295 - val_loss: 10.9079\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6506 - val_loss: 10.7261\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5487 - val_loss: 11.0162\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6772 - val_loss: 10.5766\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6965 - val_loss: 10.4383\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5906 - val_loss: 11.3250\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5512 - val_loss: 10.8220\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5770 - val_loss: 10.8489\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5314 - val_loss: 10.8559\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4020 - val_loss: 10.4989\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4507 - val_loss: 10.4320\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2916 - val_loss: 10.7190\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5125 - val_loss: 10.9729\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2873 - val_loss: 10.6754\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1628 - val_loss: 10.5882\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2715 - val_loss: 10.2547\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2960 - val_loss: 10.2017\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1864 - val_loss: 10.5552\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2119 - val_loss: 10.3365\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2031 - val_loss: 10.6949\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2389 - val_loss: 10.5457\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1627 - val_loss: 10.2614\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1628 - val_loss: 10.5675\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2199 - val_loss: 10.3835\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1014 - val_loss: 10.4435\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2084 - val_loss: 10.6037\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0658 - val_loss: 10.3530\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1508 - val_loss: 10.4536\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3472 - val_loss: 10.7057\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2208 - val_loss: 10.7103\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1809 - val_loss: 10.4846\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9730 - val_loss: 10.0937\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.9470 - val_loss: 10.2570\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9409 - val_loss: 10.0198\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9819 - val_loss: 10.1890\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0070 - val_loss: 10.1165\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.0141 - val_loss: 10.3471\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1338 - val_loss: 10.2741\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9830 - val_loss: 10.2291\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0620 - val_loss: 10.3101\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9028 - val_loss: 10.2070\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9388 - val_loss: 10.2746\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9859 - val_loss: 10.3738\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0249 - val_loss: 10.5236\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2273 - val_loss: 10.5201\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0679 - val_loss: 10.3876\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9480 - val_loss: 10.2574\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0270 - val_loss: 10.3648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0149 - val_loss: 10.4693\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0412 - val_loss: 10.2457\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9451 - val_loss: 10.1023\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0295 - val_loss: 10.0267\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9252 - val_loss: 10.1173\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9081 - val_loss: 10.2038\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9270 - val_loss: 10.1193\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.9082 - val_loss: 10.0476\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9264 - val_loss: 10.4241\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8956 - val_loss: 10.1739\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8303 - val_loss: 10.0785\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9255 - val_loss: 10.0896\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9883 - val_loss: 9.9665\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8699 - val_loss: 10.2517\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9351 - val_loss: 10.1622\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8642 - val_loss: 10.1164\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9279 - val_loss: 10.0764\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0352 - val_loss: 9.9688\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9514 - val_loss: 10.0471\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7908 - val_loss: 10.0718\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7189 - val_loss: 10.1428\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8173 - val_loss: 10.1068\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8678 - val_loss: 10.8675\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7995 - val_loss: 10.2959\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0157 - val_loss: 9.9336\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9486 - val_loss: 10.0998\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9383 - val_loss: 9.8843\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8499 - val_loss: 9.7526\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7519 - val_loss: 10.0000\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7301 - val_loss: 9.8953\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6935 - val_loss: 9.7099\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8171 - val_loss: 10.0776\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8954 - val_loss: 10.0347\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9968 - val_loss: 10.5558\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0258 - val_loss: 10.0987\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8275 - val_loss: 10.4609\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9897 - val_loss: 9.9362\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7425 - val_loss: 9.9517\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5946 - val_loss: 9.9200\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6830 - val_loss: 9.8025\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7936 - val_loss: 9.8124\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8306 - val_loss: 9.8598\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7488 - val_loss: 9.8051\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6639 - val_loss: 9.7837\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7982 - val_loss: 10.1778\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9489 - val_loss: 9.8733\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8612 - val_loss: 9.8004\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.8729 - val_loss: 10.0671\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 7.8581 - val_loss: 10.0633\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.7561 - val_loss: 9.9848\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.6586 - val_loss: 9.7903\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.7616 - val_loss: 10.0014\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8487 - val_loss: 10.4242\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8239 - val_loss: 10.1013\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8708 - val_loss: 10.2549\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7351 - val_loss: 9.7568\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7265 - val_loss: 10.0342\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5516 - val_loss: 9.7748\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8236 - val_loss: 9.8616\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7502 - val_loss: 9.7697\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.8313 - val_loss: 10.0979\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8160 - val_loss: 10.4078\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.7081 - val_loss: 9.9737\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9024 - val_loss: 9.8234\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.6282 - val_loss: 9.6464\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7432 - val_loss: 9.8628\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9447 - val_loss: 9.7407\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7114 - val_loss: 9.7150\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6443 - val_loss: 9.6413\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5938 - val_loss: 9.6857\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7912 - val_loss: 10.1024\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6880 - val_loss: 9.7092\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6246 - val_loss: 9.6412\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.8342 - val_loss: 9.8443\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6981 - val_loss: 9.9867\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6241 - val_loss: 10.2610\n",
      "Epoch 893/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7033 - val_loss: 9.7511\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6202 - val_loss: 9.6368\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6507 - val_loss: 10.2785\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6017 - val_loss: 9.9790\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5845 - val_loss: 10.0852\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7547 - val_loss: 10.0535\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0381 - val_loss: 10.4103\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.6738 - val_loss: 9.9140\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6982 - val_loss: 9.7628\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7031 - val_loss: 9.8995\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5191 - val_loss: 9.7117\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6231 - val_loss: 9.9371\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6705 - val_loss: 9.7512\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5571 - val_loss: 9.5888\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6249 - val_loss: 9.9273\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8050 - val_loss: 10.0001\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7722 - val_loss: 9.9225\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5978 - val_loss: 9.5350\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5438 - val_loss: 9.6207\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 7.5658 - val_loss: 10.2286\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4980 - val_loss: 9.8899\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6742 - val_loss: 9.9013\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.5215 - val_loss: 9.7171\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.6376 - val_loss: 9.9153\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6490 - val_loss: 9.5995\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.5558 - val_loss: 9.9226\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.5060 - val_loss: 9.8269\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6413 - val_loss: 9.7485\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.6177 - val_loss: 10.0665\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.6396 - val_loss: 9.4978\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6549 - val_loss: 9.9764\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.6723 - val_loss: 9.5497\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5280 - val_loss: 9.6907\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6391 - val_loss: 9.7744\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5996 - val_loss: 9.8829\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6068 - val_loss: 9.6743\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5903 - val_loss: 10.2011\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6152 - val_loss: 9.8321\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6047 - val_loss: 10.2296\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6422 - val_loss: 9.9215\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7727 - val_loss: 9.5789\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5162 - val_loss: 9.6376\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6077 - val_loss: 9.8413\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4389 - val_loss: 9.6252\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6126 - val_loss: 9.8215\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5985 - val_loss: 9.7036\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4776 - val_loss: 9.6575\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5160 - val_loss: 9.9003\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6145 - val_loss: 9.6919\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7531 - val_loss: 9.9590\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6462 - val_loss: 9.6264\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4497 - val_loss: 9.3978\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5534 - val_loss: 9.7299\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4464 - val_loss: 9.4943\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6247 - val_loss: 9.6554\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4173 - val_loss: 9.9729\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7820 - val_loss: 9.6381\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5442 - val_loss: 9.8098\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5375 - val_loss: 9.5284\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3848 - val_loss: 9.4509\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3162 - val_loss: 9.4267\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4848 - val_loss: 10.0112\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5298 - val_loss: 9.4673\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.3620 - val_loss: 9.3142\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5214 - val_loss: 9.3484\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.4810 - val_loss: 9.4850\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.4329 - val_loss: 9.8852\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.4566 - val_loss: 9.2960\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.3578 - val_loss: 9.5562\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2847 - val_loss: 9.2234\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 7.2991 - val_loss: 9.2215\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.0900 - val_loss: 8.8245\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1472 - val_loss: 9.0743\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1533 - val_loss: 8.6460\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.0973 - val_loss: 9.3323\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0461 - val_loss: 8.8015\n",
      "Epoch 969/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.9790 - val_loss: 8.5993\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9632 - val_loss: 8.6568\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0486 - val_loss: 8.9641\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2187 - val_loss: 8.7001\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0448 - val_loss: 8.8437\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.2171 - val_loss: 8.6281\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.9548 - val_loss: 8.9330\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 7.0374 - val_loss: 8.5722\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.9613 - val_loss: 8.3476\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 6.8994 - val_loss: 9.1295\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1216 - val_loss: 8.5627\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.8654 - val_loss: 9.2962\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.0217 - val_loss: 8.6002\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.8351 - val_loss: 8.4410\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8504 - val_loss: 8.5458\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1268 - val_loss: 8.6250\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0499 - val_loss: 8.5882\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.1594 - val_loss: 8.5284\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0680 - val_loss: 8.3044\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.7988 - val_loss: 8.4895\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8833 - val_loss: 8.2605\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7301 - val_loss: 8.5184\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.8605 - val_loss: 8.5021\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.8946 - val_loss: 8.3600\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7126 - val_loss: 8.1579\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.6972 - val_loss: 8.5217\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.8856 - val_loss: 8.1849\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.7520 - val_loss: 8.3237\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7847 - val_loss: 8.1902\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8495 - val_loss: 8.3257\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.8353 - val_loss: 8.4443\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.9644 - val_loss: 8.1492\n",
      "6.9854147539729565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.6698604 ,  2.3367116 , -1.0199645 ,  2.2972414 ,  3.4574733 ],\n",
       "        [ 1.8625656 , -0.7192344 , -0.50644684, -2.7564816 , -0.77488464],\n",
       "        [ 3.017841  ,  1.7193338 ,  3.2250261 , -2.1390846 , -3.297612  ],\n",
       "        [-0.12032692, -0.20894322,  0.14290702,  0.06873189, -0.06423615],\n",
       "        [ 1.1598681 ,  0.15013571, -0.16314313,  0.66092056,  1.0038007 ]],\n",
       "       dtype=float32),\n",
       " array([-1.1243118 ,  3.8461075 ,  3.2035608 ,  1.9705693 ,  0.19349001],\n",
       "       dtype=float32),\n",
       " array([[ 2.7477982 , -0.3332051 , -1.4985319 ,  0.9098487 , -0.8314651 ,\n",
       "         -0.46028247,  2.8709044 ,  5.217002  ,  4.4809093 ,  3.9020743 ],\n",
       "        [-4.1530943 , -2.642728  ,  0.4352868 ,  4.1686516 ,  0.45212018,\n",
       "         -1.2220286 ,  1.5131849 ,  0.9637588 , -1.5002705 ,  2.3621504 ],\n",
       "        [ 5.579906  ,  1.1464422 ,  3.7274806 ,  5.201348  ,  3.128038  ,\n",
       "          1.0689194 ,  3.844951  ,  2.6416163 ,  1.0576779 , -1.6738511 ],\n",
       "        [ 1.5928547 ,  0.999633  , -2.4938486 , -3.5321002 , -2.1025994 ,\n",
       "          1.0865973 , -2.3206213 , -2.0909781 ,  0.41644445, -1.1502314 ],\n",
       "        [ 6.1023707 ,  0.48548427,  7.860776  ,  4.5639844 ,  6.690051  ,\n",
       "         -0.10999341,  4.0329766 ,  3.2033436 ,  1.0790927 ,  9.11151   ]],\n",
       "       dtype=float32),\n",
       " array([-2.9927425 ,  2.1541388 ,  1.8423069 ,  2.916958  ,  4.4081955 ,\n",
       "         0.24179143,  3.3746364 , -0.35387385,  3.9793458 ,  3.5047994 ],\n",
       "       dtype=float32),\n",
       " array([[13.113498 ],\n",
       "        [10.238444 ],\n",
       "        [12.503925 ],\n",
       "        [12.494635 ],\n",
       "        [12.436861 ],\n",
       "        [16.411472 ],\n",
       "        [12.404036 ],\n",
       "        [11.989856 ],\n",
       "        [11.7289915],\n",
       "        [12.04056  ]], dtype=float32),\n",
       " array([11.641755], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_sigmoid(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sigmoid_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 254us/step - loss: 13104.8581 - val_loss: 10418.7420\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8681.9730 - val_loss: 7281.9586\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6271.7726 - val_loss: 5437.8694\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4753.8564 - val_loss: 4189.3410\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 3690.8376 - val_loss: 3283.9028\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 2905.7863 - val_loss: 2601.1118\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 2306.9654 - val_loss: 2076.0502\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 1842.6266 - val_loss: 1664.2702\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 1477.6676 - val_loss: 1338.1758\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 1187.8858 - val_loss: 1079.4022\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 957.6800 - val_loss: 871.1299\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 773.1439 - val_loss: 704.3626\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 624.8063 - val_loss: 572.2305\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 506.7097 - val_loss: 464.7909\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 411.6642 - val_loss: 378.4103\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 335.3527 - val_loss: 309.6543\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 274.5584 - val_loss: 254.2595\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 226.1058 - val_loss: 209.6421\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 187.2441 - val_loss: 174.7414\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 156.7188 - val_loss: 146.4688\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 132.3970 - val_loss: 124.3219\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 113.2379 - val_loss: 106.7857\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 98.1970 - val_loss: 92.9525\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 86.4715 - val_loss: 81.8971\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 77.2342 - val_loss: 73.4416\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 70.1610 - val_loss: 66.6873\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 64.6387 - val_loss: 61.4956\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 60.4202 - val_loss: 57.4384\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 57.1838 - val_loss: 54.3219\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 54.6820 - val_loss: 51.9813\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 52.8305 - val_loss: 50.0688\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 51.3925 - val_loss: 48.6463\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 50.3274 - val_loss: 47.5508\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 49.5355 - val_loss: 46.7061\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 48.9458 - val_loss: 46.0580\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 48.4986 - val_loss: 45.5863\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 48.1810 - val_loss: 45.2036\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.9445 - val_loss: 44.9180\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.7844 - val_loss: 44.6560\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.6548 - val_loss: 44.4985\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.5659 - val_loss: 44.3871\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 47.5074 - val_loss: 44.2623\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 47.4608 - val_loss: 44.1863\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.4205 - val_loss: 44.1346\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.3955 - val_loss: 44.1059\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 47.3761 - val_loss: 44.0544\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 47.3562 - val_loss: 44.0183\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 47.3318 - val_loss: 44.0015\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.3003 - val_loss: 43.9908\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.2384 - val_loss: 43.9335\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.0422 - val_loss: 43.8510\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 46.1214 - val_loss: 43.0494\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 45.7314 - val_loss: 42.5916\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 44.0605 - val_loss: 38.1759\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 39.6856 - val_loss: 37.1981\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 38.2430 - val_loss: 36.3717\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 36.6498 - val_loss: 35.4900\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 33.6948 - val_loss: 31.6930\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 27.0718 - val_loss: 26.4227\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 22.6535 - val_loss: 25.2253\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 20.9339 - val_loss: 23.3330\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.5283 - val_loss: 22.7745\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.4008 - val_loss: 21.4850\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7528 - val_loss: 21.1251\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4319 - val_loss: 20.6703\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.8964 - val_loss: 20.1765\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6299 - val_loss: 20.6119\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.4949 - val_loss: 19.6876\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1888 - val_loss: 19.7177\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.8348 - val_loss: 19.1090\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.6658 - val_loss: 19.2549\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5135 - val_loss: 19.5901\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.4001 - val_loss: 18.8764\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2333 - val_loss: 19.0774\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.1975 - val_loss: 18.6233\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0108 - val_loss: 18.2415\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8651 - val_loss: 18.2321\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9880 - val_loss: 18.5103\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2279 - val_loss: 18.9376\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8316 - val_loss: 18.3147\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.6710 - val_loss: 18.1514\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6504 - val_loss: 18.0956\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.5832 - val_loss: 18.2423\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5850 - val_loss: 18.4748\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.5960 - val_loss: 17.8226\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5516 - val_loss: 18.2507\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.3785 - val_loss: 18.3918\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6102 - val_loss: 17.9328\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.5353 - val_loss: 18.0438\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4411 - val_loss: 17.9594\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.4134 - val_loss: 18.1453\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4547 - val_loss: 18.2647\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4203 - val_loss: 17.8163\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.4832 - val_loss: 17.8697\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4445 - val_loss: 18.1552\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.4942 - val_loss: 17.7778\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4764 - val_loss: 18.1190\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4303 - val_loss: 18.4619\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4200 - val_loss: 18.6817\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2810 - val_loss: 18.5113\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6339 - val_loss: 17.9611\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.5683 - val_loss: 18.0594\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.2997 - val_loss: 18.6253\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.3332 - val_loss: 18.1833\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.2534 - val_loss: 18.7405\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2367 - val_loss: 18.0371\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2229 - val_loss: 18.5296\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.2446 - val_loss: 18.7779\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3196 - val_loss: 18.3090\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.1177 - val_loss: 18.2788\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4235 - val_loss: 18.7308\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1838 - val_loss: 18.0157\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.1304 - val_loss: 18.1639\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1265 - val_loss: 18.3001\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.1385 - val_loss: 18.3131\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.0319 - val_loss: 18.1416\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0791 - val_loss: 18.2710\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.1396 - val_loss: 18.1992\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.2953 - val_loss: 18.1311\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.0675 - val_loss: 18.6316\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 14.0568 - val_loss: 17.9762\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0165 - val_loss: 18.1562\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.9957 - val_loss: 18.3849\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9423 - val_loss: 17.8466\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0362 - val_loss: 18.2439\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9871 - val_loss: 17.9763\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9219 - val_loss: 17.9023\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.7729 - val_loss: 17.8293\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9005 - val_loss: 18.0465\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8027 - val_loss: 18.6247\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0722 - val_loss: 17.9780\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0540 - val_loss: 18.5109\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9050 - val_loss: 17.8238\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8979 - val_loss: 17.8120\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7689 - val_loss: 18.1325\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8797 - val_loss: 18.1328\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6272 - val_loss: 17.8312\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8885 - val_loss: 17.9762\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6984 - val_loss: 17.5453\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7979 - val_loss: 17.7824\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6900 - val_loss: 19.1946\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8169 - val_loss: 17.5220\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8069 - val_loss: 17.9010\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6650 - val_loss: 18.2701\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0404 - val_loss: 17.3786\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8067 - val_loss: 17.3686\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5631 - val_loss: 17.5883\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6525 - val_loss: 17.1478\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6269 - val_loss: 17.2037\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6357 - val_loss: 17.3001\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6194 - val_loss: 17.3339\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.5776 - val_loss: 17.2886\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6562 - val_loss: 17.1406\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6328 - val_loss: 17.1293\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7973 - val_loss: 17.0164\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6082 - val_loss: 17.5860\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7273 - val_loss: 17.2356\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7837 - val_loss: 17.3962\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4862 - val_loss: 17.0980\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5234 - val_loss: 17.2008\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.4907 - val_loss: 17.0759\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5569 - val_loss: 17.1301\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.3882 - val_loss: 16.9776\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5434 - val_loss: 17.7374\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.7176 - val_loss: 17.0721\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.7242 - val_loss: 17.2787\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.4196 - val_loss: 17.6428\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7790 - val_loss: 17.8195\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3662 - val_loss: 16.8500\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.2362 - val_loss: 17.5920\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3357 - val_loss: 16.8237\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2738 - val_loss: 17.0432\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.3192 - val_loss: 17.1238\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.4659 - val_loss: 17.2390\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.3162 - val_loss: 17.3299\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.4371 - val_loss: 16.8589\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.1693 - val_loss: 17.3284\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.2608 - val_loss: 17.1222\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2399 - val_loss: 16.8718\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6384 - val_loss: 16.9137\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3804 - val_loss: 16.9590\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.2984 - val_loss: 17.2290\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2287 - val_loss: 16.5879\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0736 - val_loss: 16.6415\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2530 - val_loss: 16.6215\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1802 - val_loss: 17.0786\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.9839 - val_loss: 16.5140\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7908 - val_loss: 16.3229\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7480 - val_loss: 16.7966\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8804 - val_loss: 16.7935\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8083 - val_loss: 16.2933\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7552 - val_loss: 16.6830\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9320 - val_loss: 16.5924\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.7316 - val_loss: 17.0671\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6693 - val_loss: 16.4623\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7960 - val_loss: 17.2607\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8578 - val_loss: 16.4051\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.9484 - val_loss: 16.3791\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.5042 - val_loss: 16.0098\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5676 - val_loss: 16.5669\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6117 - val_loss: 15.9403\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.5232 - val_loss: 15.9227\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4344 - val_loss: 16.9504\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5523 - val_loss: 16.0506\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3737 - val_loss: 16.3005\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4519 - val_loss: 16.9240\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3206 - val_loss: 16.5107\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7146 - val_loss: 16.0150\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8832 - val_loss: 17.4815\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9767 - val_loss: 16.5172\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7561 - val_loss: 16.4196\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.4723 - val_loss: 16.1803\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4734 - val_loss: 16.0836\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3972 - val_loss: 15.9790\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1600 - val_loss: 15.9722\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4794 - val_loss: 16.3814\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4028 - val_loss: 16.4536\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3695 - val_loss: 15.9548\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3363 - val_loss: 17.1955\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4396 - val_loss: 16.2918\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3551 - val_loss: 16.6973\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0470 - val_loss: 13.4582\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.7072 - val_loss: 12.6738\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0968 - val_loss: 16.4801\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7138 - val_loss: 12.9500\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1235 - val_loss: 13.0843\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7226 - val_loss: 11.4676\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1833 - val_loss: 11.5046\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3031 - val_loss: 10.9781\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3422 - val_loss: 11.7387\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5454 - val_loss: 10.9683\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1406 - val_loss: 11.3093\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1989 - val_loss: 10.3110\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5212 - val_loss: 9.5385\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3871 - val_loss: 9.5011\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3492 - val_loss: 9.8154\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4998 - val_loss: 9.1837\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3578 - val_loss: 9.6158\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1114 - val_loss: 9.1481\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2649 - val_loss: 9.3807\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2783 - val_loss: 8.6873\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1787 - val_loss: 8.7386\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.9393 - val_loss: 8.2927\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6543 - val_loss: 10.4346\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3814 - val_loss: 8.2940\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0791 - val_loss: 8.4109\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0159 - val_loss: 8.4032\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9191 - val_loss: 9.6195\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9087 - val_loss: 8.9190\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.0321 - val_loss: 8.8211\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8768 - val_loss: 7.9572\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.7978 - val_loss: 7.7860\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.8868 - val_loss: 8.1866\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9321 - val_loss: 8.5196\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0256 - val_loss: 7.6839\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.6199 - val_loss: 8.5558\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7465 - val_loss: 7.7101\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4916 - val_loss: 7.8761\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.870 - 0s 87us/step - loss: 6.7565 - val_loss: 8.3740\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.7447 - val_loss: 7.6342\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.6042 - val_loss: 8.1864\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.3355 - val_loss: 8.5755\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6751 - val_loss: 7.9609\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.7839 - val_loss: 8.3508\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5947 - val_loss: 8.0548\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5648 - val_loss: 7.4360\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7186 - val_loss: 7.9541\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4226 - val_loss: 8.2866\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4663 - val_loss: 7.8522\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3754 - val_loss: 7.6410\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3754 - val_loss: 7.3979\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8116 - val_loss: 8.9784\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8135 - val_loss: 7.3484\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2797 - val_loss: 7.7584\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2830 - val_loss: 8.1841\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2792 - val_loss: 7.3126\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7950 - val_loss: 7.3649\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4977 - val_loss: 8.0943\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0239 - val_loss: 8.8070\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7442 - val_loss: 7.7768\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 6.4270 - val_loss: 7.9197\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 6.2474 - val_loss: 7.3929\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3426 - val_loss: 7.2155\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 6.5461 - val_loss: 8.3762\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.0428 - val_loss: 8.0381\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.6293 - val_loss: 7.3761\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2682 - val_loss: 8.1050\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1478 - val_loss: 8.7992\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.4268 - val_loss: 7.2427\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.6340 - val_loss: 9.5937\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.2763 - val_loss: 8.2040\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.2169 - val_loss: 7.8814\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4601 - val_loss: 7.7441\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.4025 - val_loss: 7.5618\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0783 - val_loss: 7.5790\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2932 - val_loss: 8.5826\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1300 - val_loss: 7.6450\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.2759 - val_loss: 7.2775\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0122 - val_loss: 7.7728\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3432 - val_loss: 7.2992\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3124 - val_loss: 7.5049\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1778 - val_loss: 7.8491\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3257 - val_loss: 7.7550\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.1635 - val_loss: 8.5734\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5533 - val_loss: 7.2390\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3205 - val_loss: 7.8979\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 5.9930 - val_loss: 7.3678\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9641 - val_loss: 7.3205\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1971 - val_loss: 8.2867\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3131 - val_loss: 8.0284\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 6.0851 - val_loss: 8.1521\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 6.0272 - val_loss: 8.0928\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.2734 - val_loss: 9.1457\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0757 - val_loss: 7.1677\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2447 - val_loss: 8.2677\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5828 - val_loss: 8.3176\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3348 - val_loss: 7.6751\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0440 - val_loss: 7.8688\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.3356 - val_loss: 7.4751\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 6.0910 - val_loss: 8.2779\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3050 - val_loss: 7.2740\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2701 - val_loss: 7.4563\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1538 - val_loss: 7.7429\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.1062 - val_loss: 7.7446\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2125 - val_loss: 7.6366\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 6.0714 - val_loss: 7.2946\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2886 - val_loss: 7.3489\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9205 - val_loss: 7.3534\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9395 - val_loss: 8.3789\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 6.0175 - val_loss: 7.8389\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2638 - val_loss: 7.2320\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.8968 - val_loss: 7.3083\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 6.2423 - val_loss: 7.2216\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.8944 - val_loss: 7.2607\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 6.3515 - val_loss: 7.4275\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.9501 - val_loss: 8.1689\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 6.1775 - val_loss: 7.4558\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 6.4171 - val_loss: 8.3376\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 6.0324 - val_loss: 6.9882\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0273 - val_loss: 8.3019\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.9999 - val_loss: 6.7650\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8035 - val_loss: 7.1994\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.5505 - val_loss: 8.0712\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1139 - val_loss: 6.8408\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0216 - val_loss: 7.3836\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2793 - val_loss: 7.1281\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2170 - val_loss: 7.3223\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.8503 - val_loss: 7.2704\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5.8337 - val_loss: 7.4576\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0947 - val_loss: 6.9215\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0389 - val_loss: 7.4272\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0255 - val_loss: 7.5439\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1428 - val_loss: 7.0843\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9869 - val_loss: 8.2775\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.4304 - val_loss: 7.1970\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9645 - val_loss: 7.2884\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8524 - val_loss: 7.7168\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8066 - val_loss: 6.8778\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0575 - val_loss: 7.6752\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8663 - val_loss: 7.6073\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1197 - val_loss: 7.2080\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 5.8760 - val_loss: 7.2313\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9842 - val_loss: 7.0542\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.8357 - val_loss: 6.9444\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9239 - val_loss: 7.4380\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.3636 - val_loss: 9.1913\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1285 - val_loss: 8.0952\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6943 - val_loss: 7.5169\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3305 - val_loss: 7.5496\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 6.2137 - val_loss: 7.8895\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0118 - val_loss: 7.2898\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5.8936 - val_loss: 7.4180\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0424 - val_loss: 7.5390\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1086 - val_loss: 9.1983\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.2046 - val_loss: 7.2631\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.0058 - val_loss: 7.3405\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.2116 - val_loss: 7.4232\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1313 - val_loss: 7.8655\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.3444 - val_loss: 7.8619\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.1037 - val_loss: 6.9777\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5415 - val_loss: 7.4984\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.9342 - val_loss: 7.3954\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8472 - val_loss: 7.1498\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9179 - val_loss: 9.1263\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6144 - val_loss: 9.2630\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3043 - val_loss: 7.2661\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7846 - val_loss: 7.0004\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7044 - val_loss: 7.8690\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9196 - val_loss: 8.1619\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2503 - val_loss: 7.6482\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9507 - val_loss: 6.9692\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7634 - val_loss: 6.9214\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0286 - val_loss: 6.9166\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 5.9133 - val_loss: 7.1634\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9290 - val_loss: 6.9934\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8343 - val_loss: 8.0592\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1957 - val_loss: 7.4016\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1904 - val_loss: 7.1099\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 6.0770 - val_loss: 7.3572\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 5.8117 - val_loss: 7.9072\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7670 - val_loss: 7.0759\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6665 - val_loss: 7.0439\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.9324 - val_loss: 8.1867\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 6.0390 - val_loss: 7.6427\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3407 - val_loss: 8.1394\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8981 - val_loss: 6.9639\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9775 - val_loss: 7.7792\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9923 - val_loss: 7.7160\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7415 - val_loss: 6.9918\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0234 - val_loss: 7.4586\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8826 - val_loss: 7.0762\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7808 - val_loss: 6.9781\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.8710 - val_loss: 6.8560\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8310 - val_loss: 8.0816\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7984 - val_loss: 7.1094\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9144 - val_loss: 7.4656\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1277 - val_loss: 7.1812\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.4277 - val_loss: 7.3584\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9441 - val_loss: 6.8526\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.8298 - val_loss: 7.0333\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8402 - val_loss: 7.4690\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1276 - val_loss: 7.2880\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0409 - val_loss: 6.8681\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0337 - val_loss: 7.5460\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2763 - val_loss: 7.8717\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9328 - val_loss: 7.0595\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7620 - val_loss: 6.9317\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.8366 - val_loss: 7.9624\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8245 - val_loss: 7.6936\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9275 - val_loss: 7.9597\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8463 - val_loss: 6.8450\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6175 - val_loss: 7.0148\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1011 - val_loss: 7.7373\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0962 - val_loss: 7.4146\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9622 - val_loss: 8.1267\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7880 - val_loss: 7.0716\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7090 - val_loss: 7.4461\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.1797 - val_loss: 6.9293\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.0813 - val_loss: 7.9422\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.1822 - val_loss: 7.7574\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 6.1706 - val_loss: 7.2263\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9310 - val_loss: 7.0246\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9947 - val_loss: 7.1793\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7092 - val_loss: 7.9628\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.1022 - val_loss: 7.1388\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3946 - val_loss: 8.2691\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 6.3751 - val_loss: 7.0824\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7591 - val_loss: 6.9269\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.7707 - val_loss: 6.9825\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.6240 - val_loss: 8.2664\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7693 - val_loss: 6.9765\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 5.9352 - val_loss: 7.6258\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.8801 - val_loss: 7.0038\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 134us/step - loss: 5.9741 - val_loss: 7.0576\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 5.9876 - val_loss: 6.9769\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 134us/step - loss: 5.9825 - val_loss: 7.5764\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9859 - val_loss: 6.9487\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 5.8890 - val_loss: 6.8241\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0065 - val_loss: 7.3652\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8687 - val_loss: 7.1128\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7729 - val_loss: 6.9605\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9586 - val_loss: 7.4671\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8387 - val_loss: 6.8070\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0303 - val_loss: 7.7900\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9484 - val_loss: 6.8999\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7816 - val_loss: 7.1612\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7109 - val_loss: 7.1054\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8302 - val_loss: 7.9970\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8469 - val_loss: 6.7184\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.7691 - val_loss: 7.6396\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 5.9839 - val_loss: 8.3919\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 6.0258 - val_loss: 6.6683\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.9856 - val_loss: 6.9777\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 5.8103 - val_loss: 8.1650\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.0324 - val_loss: 7.5122\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.9717 - val_loss: 6.7942\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.9773 - val_loss: 8.3328\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8641 - val_loss: 7.0559\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.6193 - val_loss: 6.7427\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 5.8873 - val_loss: 7.1448\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5.7441 - val_loss: 6.5945\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7556 - val_loss: 7.0420\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.0576 - val_loss: 6.9094\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.6432 - val_loss: 6.9651\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8277 - val_loss: 8.2192\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 5.8967 - val_loss: 7.1194\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8667 - val_loss: 7.4720\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9598 - val_loss: 6.8895\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.9144 - val_loss: 7.5641\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7953 - val_loss: 8.3256\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7939 - val_loss: 7.0938\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.8625 - val_loss: 7.1670\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0524 - val_loss: 7.2038\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8402 - val_loss: 7.3322\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6700 - val_loss: 6.5939\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.7836 - val_loss: 7.7470\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 6.0180 - val_loss: 7.1186\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2626 - val_loss: 8.4476\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7495 - val_loss: 6.9608\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.6371 - val_loss: 6.7613\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7019 - val_loss: 7.0312\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1275 - val_loss: 9.1558\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0604 - val_loss: 7.2055\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.0015 - val_loss: 7.6151\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3316 - val_loss: 8.1938\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 6.6543 - val_loss: 9.6308\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9428 - val_loss: 6.8382\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5515 - val_loss: 7.0371\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7801 - val_loss: 7.1017\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5.8188 - val_loss: 7.8081\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.6513 - val_loss: 7.2515\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7606 - val_loss: 6.7644\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6986 - val_loss: 6.9220\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7397 - val_loss: 6.6546\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6770 - val_loss: 6.8844\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9191 - val_loss: 7.4000\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5933 - val_loss: 7.0652\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6955 - val_loss: 7.2608\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9154 - val_loss: 7.5600\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1427 - val_loss: 8.2176\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8419 - val_loss: 6.6630\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6967 - val_loss: 7.3814\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6886 - val_loss: 6.9156\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7099 - val_loss: 7.2374\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6343 - val_loss: 7.0112\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7373 - val_loss: 8.1457\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8365 - val_loss: 7.1938\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7828 - val_loss: 6.7722\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6031 - val_loss: 6.7322\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7354 - val_loss: 8.0103\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0222 - val_loss: 7.8182\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0591 - val_loss: 6.8186\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.8072 - val_loss: 7.9720\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8229 - val_loss: 6.5054\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6228 - val_loss: 7.2058\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7535 - val_loss: 7.0055\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7292 - val_loss: 7.1296\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.7427 - val_loss: 7.2740\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9268 - val_loss: 8.5273\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.6814 - val_loss: 6.5977\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9370 - val_loss: 7.1624\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.1145 - val_loss: 6.7354\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5649 - val_loss: 6.8575\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8836 - val_loss: 7.0266\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7026 - val_loss: 7.4727\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7164 - val_loss: 6.9372\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.7088 - val_loss: 6.8831\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7161 - val_loss: 6.8494\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.9177 - val_loss: 7.2402\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0491 - val_loss: 6.8807\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5993 - val_loss: 6.6899\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9604 - val_loss: 7.1573\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.7287 - val_loss: 7.1075\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7595 - val_loss: 7.5318\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.9056 - val_loss: 7.1984\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.8298 - val_loss: 7.0685\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6220 - val_loss: 7.7006\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8828 - val_loss: 7.8774\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7728 - val_loss: 6.9784\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6880 - val_loss: 7.5725\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9253 - val_loss: 6.6339\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8534 - val_loss: 8.0292\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.6087 - val_loss: 7.7375\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8454 - val_loss: 7.3264\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7433 - val_loss: 7.2845\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5594 - val_loss: 7.4825\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.7548 - val_loss: 7.3584\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8820 - val_loss: 7.4550\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.3549 - val_loss: 8.0199\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7899 - val_loss: 7.7468\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.5592 - val_loss: 7.3800\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0521 - val_loss: 7.4518\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6225 - val_loss: 6.7709\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 6.0718 - val_loss: 7.6257\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9485 - val_loss: 6.7405\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.4928 - val_loss: 6.7125\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6031 - val_loss: 7.6802\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.3806 - val_loss: 7.5666\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1866 - val_loss: 7.0092\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7387 - val_loss: 7.4014\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9990 - val_loss: 8.0468\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9049 - val_loss: 7.2215\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 5.7432 - val_loss: 7.3370\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 5.5659 - val_loss: 6.9571\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0008 - val_loss: 6.7355\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.5235 - val_loss: 7.4068\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7275 - val_loss: 7.2728\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.8862 - val_loss: 7.6603\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9645 - val_loss: 6.5559\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.7263 - val_loss: 6.9074\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 122us/step - loss: 6.1205 - val_loss: 7.2689\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7271 - val_loss: 6.7479\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 5.6953 - val_loss: 7.0484\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.8305 - val_loss: 7.1829\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5288 - val_loss: 6.5315\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.8129 - val_loss: 7.4192\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6289 - val_loss: 6.9593\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6272 - val_loss: 6.8506\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7692 - val_loss: 7.1765\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6510 - val_loss: 6.4532\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.8697 - val_loss: 8.9265\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6055 - val_loss: 6.5691\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4181 - val_loss: 7.5387\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8290 - val_loss: 6.8559\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0855 - val_loss: 6.9311\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9914 - val_loss: 7.1687\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4374 - val_loss: 8.4078\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7189 - val_loss: 6.9288\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7339 - val_loss: 6.4860\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5405 - val_loss: 6.5369\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7698 - val_loss: 6.6022\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 5.6879 - val_loss: 7.2628\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 5.7912 - val_loss: 7.2861\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.6942 - val_loss: 8.1532\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.8002 - val_loss: 6.7063\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 5.8136 - val_loss: 6.9705\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 5.7670 - val_loss: 6.7530\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 122us/step - loss: 5.4376 - val_loss: 6.3700\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.6716 - val_loss: 7.6079\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 128us/step - loss: 5.7652 - val_loss: 7.2513\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 6.2137 - val_loss: 6.9228\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.6578 - val_loss: 7.0759\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8577 - val_loss: 8.6324\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.5491 - val_loss: 7.1063\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5859 - val_loss: 6.6892\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8650 - val_loss: 6.4827\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8203 - val_loss: 7.5049\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6807 - val_loss: 6.4958\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8043 - val_loss: 8.2193\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9626 - val_loss: 6.9277\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4933 - val_loss: 7.8341\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1750 - val_loss: 6.9693\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7307 - val_loss: 7.1773\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.7567 - val_loss: 6.7428\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5320 - val_loss: 7.4356\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4343 - val_loss: 6.6262\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6544 - val_loss: 6.7636\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8345 - val_loss: 8.9425\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3771 - val_loss: 7.1630\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8124 - val_loss: 6.4921\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.5675 - val_loss: 6.4501\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5684 - val_loss: 6.9045\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9578 - val_loss: 7.4750\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.6921 - val_loss: 6.7956\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.2821 - val_loss: 7.8099\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8108 - val_loss: 6.6333\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.5871 - val_loss: 7.0033\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.6898 - val_loss: 6.7532\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.5859 - val_loss: 6.6077\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.7349 - val_loss: 6.9773\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7511 - val_loss: 6.9349\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8778 - val_loss: 7.9888\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.7395 - val_loss: 6.3124\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5705 - val_loss: 6.5836\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5635 - val_loss: 7.2263\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5687 - val_loss: 6.4399\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.5214 - val_loss: 6.9688\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.6180 - val_loss: 6.6971\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.1853 - val_loss: 6.5931\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 159us/step - loss: 5.5937 - val_loss: 7.4530\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5219 - val_loss: 7.2034\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7518 - val_loss: 7.6184\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1818 - val_loss: 6.6298\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6673 - val_loss: 7.2778\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6618 - val_loss: 6.9502\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 6.0191 - val_loss: 7.0339\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7551 - val_loss: 7.2617\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9082 - val_loss: 7.9220\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.9598 - val_loss: 6.9159\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6659 - val_loss: 6.8334\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7835 - val_loss: 7.6364\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7127 - val_loss: 6.5248\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0357 - val_loss: 7.3911\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8248 - val_loss: 8.5667\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.9898 - val_loss: 6.9850\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1314 - val_loss: 7.3591\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.0558 - val_loss: 7.1161\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8282 - val_loss: 7.3891\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7940 - val_loss: 6.7146\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9067 - val_loss: 7.0456\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7399 - val_loss: 7.1683\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5236 - val_loss: 6.4982\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.4105 - val_loss: 6.6173\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.7698 - val_loss: 7.4194\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7704 - val_loss: 6.8542\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8615 - val_loss: 6.3327\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5524 - val_loss: 6.5017\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5529 - val_loss: 7.0138\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.1541 - val_loss: 8.5473\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.6772 - val_loss: 7.1469\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.6799 - val_loss: 6.6560\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.6082 - val_loss: 6.3973\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.5555 - val_loss: 6.2361\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9252 - val_loss: 7.3727\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7567 - val_loss: 7.2360\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6394 - val_loss: 7.2158\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8235 - val_loss: 6.8035\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5569 - val_loss: 6.8780\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7264 - val_loss: 6.7859\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7624 - val_loss: 6.8302\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.5671 - val_loss: 8.9536\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3380 - val_loss: 7.3013\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8020 - val_loss: 6.5161\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0311 - val_loss: 7.4102\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 5.8394 - val_loss: 7.1918\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9239 - val_loss: 7.2145\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7215 - val_loss: 6.4616\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.8643 - val_loss: 7.4292\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.9417 - val_loss: 6.8060\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.4260 - val_loss: 6.7863\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 5.7415 - val_loss: 6.8904\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 5.4461 - val_loss: 6.8219\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.4577 - val_loss: 6.5228\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8832 - val_loss: 7.0172\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7262 - val_loss: 6.9228\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1267 - val_loss: 7.7512\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2986 - val_loss: 7.3695\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8945 - val_loss: 7.5015\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1783 - val_loss: 6.9794\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.8923 - val_loss: 7.4525\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 6.0953 - val_loss: 6.5960\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5496 - val_loss: 6.6074\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.5575 - val_loss: 6.9135\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.6377 - val_loss: 7.3976\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.6126 - val_loss: 6.8370\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5887 - val_loss: 6.5257\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4532 - val_loss: 6.2770\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7255 - val_loss: 6.3879\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7536 - val_loss: 8.7701\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9009 - val_loss: 7.3355\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7277 - val_loss: 7.0197\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8775 - val_loss: 7.2496\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5577 - val_loss: 7.0519\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2350 - val_loss: 7.6678\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8242 - val_loss: 6.6192\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5266 - val_loss: 6.7198\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.8047 - val_loss: 9.5648\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.6163 - val_loss: 7.3779\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9821 - val_loss: 7.9241\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7388 - val_loss: 6.5457\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5259 - val_loss: 7.3970\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6021 - val_loss: 6.9109\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5689 - val_loss: 8.1309\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 6.1281 - val_loss: 6.6839\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5277 - val_loss: 7.1024\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8138 - val_loss: 6.5212\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.7244 - val_loss: 7.7328\n",
      "Epoch 748/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6983 - val_loss: 6.5832\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7749 - val_loss: 6.6203\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.7367 - val_loss: 6.5111\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4705 - val_loss: 6.2516\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4912 - val_loss: 7.0868\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5.5313 - val_loss: 6.3801\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6897 - val_loss: 7.4034\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9475 - val_loss: 6.5275\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7591 - val_loss: 6.3778\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6272 - val_loss: 6.6884\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5758 - val_loss: 6.8542\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4610 - val_loss: 6.4220\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.4633 - val_loss: 6.6968\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 121us/step - loss: 5.6873 - val_loss: 7.2792\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6160 - val_loss: 6.7073\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6692 - val_loss: 6.9777\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.5857 - val_loss: 7.2877\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6603 - val_loss: 6.3213\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.6400 - val_loss: 6.4705\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6096 - val_loss: 6.2669\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7030 - val_loss: 6.4723\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.7498 - val_loss: 6.7971\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 5.4750 - val_loss: 6.3281\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5393 - val_loss: 6.7176\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.4832 - val_loss: 7.6512\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7729 - val_loss: 6.3631\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.9058 - val_loss: 6.5009\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5989 - val_loss: 6.3781\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.3055 - val_loss: 7.3952\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6757 - val_loss: 6.7464\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0880 - val_loss: 6.7942\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4945 - val_loss: 6.8273\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5414 - val_loss: 7.0177\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0361 - val_loss: 7.1575\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7825 - val_loss: 8.1531\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7964 - val_loss: 7.0286\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 5.8333 - val_loss: 8.3789\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.7294 - val_loss: 6.9826\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5144 - val_loss: 6.6998\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 5.7613 - val_loss: 7.2595\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8860 - val_loss: 6.8424\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7896 - val_loss: 6.4372\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.9423 - val_loss: 6.4677\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5287 - val_loss: 6.4571\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.5932 - val_loss: 7.1030\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.6182 - val_loss: 6.7290\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6409 - val_loss: 6.4236\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8264 - val_loss: 6.5488\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6524 - val_loss: 6.2239\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6813 - val_loss: 6.3780\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.4619 - val_loss: 6.4083\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7668 - val_loss: 7.7677\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0030 - val_loss: 6.8860\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7928 - val_loss: 6.5959\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8914 - val_loss: 7.3280\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9703 - val_loss: 6.9229\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5962 - val_loss: 6.9278\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8811 - val_loss: 8.7009\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5389 - val_loss: 6.9359\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8864 - val_loss: 6.8392\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6660 - val_loss: 7.0416\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2278 - val_loss: 7.1265\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8297 - val_loss: 7.2569\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.9180 - val_loss: 6.8056\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7326 - val_loss: 6.0451\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7240 - val_loss: 6.5497\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6623 - val_loss: 6.8339\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6447 - val_loss: 6.6781\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4660 - val_loss: 6.5188\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.5130 - val_loss: 6.6996\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5899 - val_loss: 6.4483\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4644 - val_loss: 6.9967\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9929 - val_loss: 6.7929\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4173 - val_loss: 7.3874\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4719 - val_loss: 6.8649\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.7444 - val_loss: 6.8659\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5216 - val_loss: 6.9397\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0046 - val_loss: 6.2524\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6490 - val_loss: 6.7800\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6889 - val_loss: 6.4676\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5948 - val_loss: 6.7439\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8100 - val_loss: 6.3932\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7299 - val_loss: 7.3992\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9612 - val_loss: 6.6350\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4704 - val_loss: 6.8186\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.6835 - val_loss: 6.7978\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8950 - val_loss: 6.6957\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4102 - val_loss: 6.5296\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3547 - val_loss: 6.6122\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4912 - val_loss: 6.5360\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5070 - val_loss: 6.7657\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7750 - val_loss: 6.9893\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5075 - val_loss: 6.5368\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5910 - val_loss: 6.9542\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7611 - val_loss: 7.0013\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8349 - val_loss: 8.5119\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9106 - val_loss: 7.3690\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.5809 - val_loss: 6.4606\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.6750 - val_loss: 7.0194\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6053 - val_loss: 6.9601\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6685 - val_loss: 6.4802\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.6031 - val_loss: 6.7049\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5899 - val_loss: 6.4409\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.6949 - val_loss: 7.0770\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9182 - val_loss: 6.8091\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.7471 - val_loss: 6.8903\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6569 - val_loss: 7.9335\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7264 - val_loss: 6.7577\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6793 - val_loss: 6.7629\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.569 - 0s 82us/step - loss: 5.4748 - val_loss: 6.6165\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5930 - val_loss: 7.2355\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.8107 - val_loss: 6.6876\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.6935 - val_loss: 6.9115\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8283 - val_loss: 6.8438\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6639 - val_loss: 6.5610\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.7570 - val_loss: 7.0451\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.3208 - val_loss: 6.2837\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5922 - val_loss: 7.0158\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 5.5898 - val_loss: 6.5403\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9124 - val_loss: 6.9389\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6219 - val_loss: 6.8000\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 141us/step - loss: 5.5191 - val_loss: 7.2362\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 5.3959 - val_loss: 6.8148\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.9458 - val_loss: 6.7456\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0965 - val_loss: 7.5263\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7367 - val_loss: 6.5710\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7188 - val_loss: 7.0123\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8958 - val_loss: 7.4295\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5325 - val_loss: 7.6341\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5881 - val_loss: 6.2544\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4162 - val_loss: 7.2022\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5262 - val_loss: 6.7488\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7751 - val_loss: 6.9026\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3766 - val_loss: 8.6264\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3734 - val_loss: 6.9585\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5350 - val_loss: 6.9588\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4524 - val_loss: 6.9011\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7573 - val_loss: 6.4065\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5798 - val_loss: 6.9570\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0042 - val_loss: 6.6967\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0967 - val_loss: 7.5829\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5361 - val_loss: 7.4979\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9757 - val_loss: 6.2995\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4206 - val_loss: 6.4976\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4632 - val_loss: 6.5303\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7379 - val_loss: 6.4337\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4952 - val_loss: 6.7596\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6697 - val_loss: 7.0374\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6966 - val_loss: 6.7285\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5061 - val_loss: 7.1468\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6888 - val_loss: 6.8825\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5992 - val_loss: 7.1364\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8845 - val_loss: 6.9284\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5884 - val_loss: 6.6299\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4612 - val_loss: 6.3715\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4490 - val_loss: 6.4567\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7959 - val_loss: 6.3531\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6682 - val_loss: 7.4956\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5623 - val_loss: 6.6894\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8692 - val_loss: 6.7638\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6816 - val_loss: 6.3961\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8972 - val_loss: 7.1478\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8074 - val_loss: 7.5474\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.259 - 0s 88us/step - loss: 5.4373 - val_loss: 6.4678\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4770 - val_loss: 6.6679\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5370 - val_loss: 6.8272\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4477 - val_loss: 6.7258\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6127 - val_loss: 7.1711\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5722 - val_loss: 7.0602\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5968 - val_loss: 6.6116\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6370 - val_loss: 6.7230\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8424 - val_loss: 6.4951\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.6470 - val_loss: 6.6507\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6336 - val_loss: 6.6500\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8187 - val_loss: 6.8252\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5443 - val_loss: 6.5218\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5584 - val_loss: 6.6146\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7132 - val_loss: 7.3520\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4126 - val_loss: 8.4483\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5691 - val_loss: 6.5877\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5239 - val_loss: 7.1579\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4152 - val_loss: 6.2740\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4461 - val_loss: 6.8901\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7659 - val_loss: 7.0062\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7747 - val_loss: 7.1863\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9140 - val_loss: 7.8710\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8225 - val_loss: 7.4430\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 5.6117 - val_loss: 6.9714\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6652 - val_loss: 6.8911\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7154 - val_loss: 6.7585\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4990 - val_loss: 6.7647\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5904 - val_loss: 7.0075\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6685 - val_loss: 6.5165\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6844 - val_loss: 8.0952\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0370 - val_loss: 7.5473\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5808 - val_loss: 6.4907\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0765 - val_loss: 7.4860\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6044 - val_loss: 6.2964\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3964 - val_loss: 6.5776\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6297 - val_loss: 7.5964\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8923 - val_loss: 6.9791\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7018 - val_loss: 6.6628\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8887 - val_loss: 7.0159\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5260 - val_loss: 6.6079\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4907 - val_loss: 6.5616\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4456 - val_loss: 6.6038\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.5175 - val_loss: 6.2345\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4183 - val_loss: 7.8707\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7818 - val_loss: 6.3222\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5304 - val_loss: 6.5982\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6487 - val_loss: 7.3418\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7555 - val_loss: 6.5955\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6569 - val_loss: 6.6203\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3172 - val_loss: 6.9221\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7817 - val_loss: 6.5593\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5622 - val_loss: 6.8323\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7090 - val_loss: 6.5061\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3937 - val_loss: 6.4065\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6165 - val_loss: 6.6929\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.639 - 0s 87us/step - loss: 5.8760 - val_loss: 6.5957\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7373 - val_loss: 7.3742\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9578 - val_loss: 6.5159\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5651 - val_loss: 6.8121\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7004 - val_loss: 6.3908\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7132 - val_loss: 6.8135\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7501 - val_loss: 6.4836\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4864 - val_loss: 6.9253\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8512 - val_loss: 6.5588\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7066 - val_loss: 6.6589\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7468 - val_loss: 6.6695\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4992 - val_loss: 6.8166\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5988 - val_loss: 6.9244\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6817 - val_loss: 6.6567\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.7016 - val_loss: 6.9716\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6499 - val_loss: 6.5558\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0207 - val_loss: 6.5080\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.9181 - val_loss: 6.7509\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6131 - val_loss: 6.6355\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5080 - val_loss: 6.1740\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5137 - val_loss: 6.2841\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4373 - val_loss: 6.6229\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8298 - val_loss: 7.1953\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0062 - val_loss: 8.3323\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6802 - val_loss: 6.8464\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6910 - val_loss: 6.2822\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6910 - val_loss: 6.8916\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4968 - val_loss: 7.1004\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2451 - val_loss: 6.8445\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3684 - val_loss: 6.4653\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4480 - val_loss: 6.6812\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4218 - val_loss: 6.8093\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5551 - val_loss: 6.3567\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8518 - val_loss: 7.2380\n",
      "5.542920640084596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.4630461e+00,  4.9712732e-01, -1.2574962e+00,  1.1052965e+00,\n",
       "         -3.3215189e+00],\n",
       "        [ 3.3546504e-01, -6.4337105e-02, -1.5781964e+00,  8.8481653e-01,\n",
       "         -1.1144971e+00],\n",
       "        [-1.3360842e-01, -2.6173387e+00, -1.6948987e+00,  3.2664686e-01,\n",
       "         -6.4817256e-01],\n",
       "        [-1.4254083e-01,  3.3331582e-01,  3.4243137e-01, -2.4920966e-01,\n",
       "          4.9856105e-01],\n",
       "        [ 4.8959276e-01,  5.5950022e-01, -1.3957974e-01,  9.7747308e-01,\n",
       "         -3.8608964e-04]], dtype=float32),\n",
       " array([-0.6172113 , -0.8928102 , -0.46716642,  2.039005  , -1.0738779 ],\n",
       "       dtype=float32),\n",
       " array([[-0.31958768,  0.3194537 ,  1.3429111 ,  0.3177818 ,  0.3204141 ,\n",
       "         -0.3196611 ,  0.31349212,  0.19467573, -1.8852876 , -1.1351919 ],\n",
       "        [-2.9312623 ,  2.9342828 ,  0.33660072,  2.9353313 , -0.19023427,\n",
       "         -2.9306366 ,  3.0055728 ,  0.3215589 , -1.4263799 ,  2.1770751 ],\n",
       "        [-0.20935294,  0.20721328,  0.18921827,  0.20492558,  0.3082143 ,\n",
       "         -0.2097745 ,  0.15083937,  0.25342107,  1.6245797 ,  4.239585  ],\n",
       "        [-4.6589193 ,  4.651449  , -1.8177875 ,  4.610229  ,  0.70335406,\n",
       "         -4.662407  ,  4.356645  , -0.3408516 ,  1.8087617 ,  2.3218865 ],\n",
       "        [-1.8785092 ,  1.8782585 , -0.49055824,  1.8657899 , -0.5619579 ,\n",
       "         -1.8792876 ,  1.8351918 ,  0.575914  ,  0.6465172 ,  1.0945772 ]],\n",
       "       dtype=float32),\n",
       " array([-0.8508576 ,  0.52400136, -2.0778804 ,  1.007138  ,  0.8949632 ,\n",
       "        -0.87649107, -0.47012356,  0.49131227,  4.59661   ,  0.73333293],\n",
       "       dtype=float32),\n",
       " array([[-12.94061  ],\n",
       "        [ 13.316053 ],\n",
       "        [ -9.516853 ],\n",
       "        [ 12.651524 ],\n",
       "        [ 12.776448 ],\n",
       "        [-12.913777 ],\n",
       "        [ 12.794534 ],\n",
       "        [ 14.7440605],\n",
       "        [ 10.250283 ],\n",
       "        [ 12.535021 ]], dtype=float32),\n",
       " array([11.969263], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_tanh(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_tanh_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 683us/step - loss: 473.7677 - val_loss: 275.9758\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 219.1831 - val_loss: 66.8052\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 54.4038 - val_loss: 38.4389\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 32.3091 - val_loss: 28.6068\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 27.0142 - val_loss: 24.3796\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 25.4887 - val_loss: 22.2270\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 23.4905 - val_loss: 20.6020\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.2669 - val_loss: 20.0568\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.3432 - val_loss: 19.1098\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 20.2940 - val_loss: 18.9092\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 19.9909 - val_loss: 18.5932\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.3992 - val_loss: 18.4301\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 19.2473 - val_loss: 18.6501\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.8714 - val_loss: 17.9527\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 17.3135 - val_loss: 16.8325\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.0640 - val_loss: 15.9020\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.3585 - val_loss: 14.8918\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.0921 - val_loss: 14.2045\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 13.1249 - val_loss: 13.3502\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.3697 - val_loss: 12.2996\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 11.2360 - val_loss: 11.6128\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 10.5959 - val_loss: 11.3414\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.6153 - val_loss: 10.8409\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.0348 - val_loss: 9.9112\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.9226 - val_loss: 9.7616\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6888 - val_loss: 9.5035\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3028 - val_loss: 9.2778\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2598 - val_loss: 9.0647\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5162 - val_loss: 8.5505\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.5000 - val_loss: 9.2944\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.2757 - val_loss: 9.2946\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9179 - val_loss: 9.0208\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7234 - val_loss: 8.9553\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7858 - val_loss: 8.8741\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7260 - val_loss: 8.6712\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5766 - val_loss: 8.9658\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5582 - val_loss: 8.9750\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5127 - val_loss: 8.9858\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4706 - val_loss: 8.8176\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5230 - val_loss: 8.6106\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5360 - val_loss: 8.7302\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6788 - val_loss: 8.6703\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3817 - val_loss: 8.9234\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3226 - val_loss: 8.9720\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4649 - val_loss: 8.7019\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2448 - val_loss: 8.9908\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2191 - val_loss: 8.7849\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.2286 - val_loss: 8.8340\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3156 - val_loss: 8.7753\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4165 - val_loss: 8.9178\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4808 - val_loss: 8.5997\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1380 - val_loss: 8.7812\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3200 - val_loss: 8.6249\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2375 - val_loss: 8.7588\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0551 - val_loss: 8.6004\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1198 - val_loss: 8.4317\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0922 - val_loss: 8.6831\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.0462 - val_loss: 8.6711\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0981 - val_loss: 8.6560\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4089 - val_loss: 8.8433\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1093 - val_loss: 8.5487\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9179 - val_loss: 8.4129\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9155 - val_loss: 8.6931\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0284 - val_loss: 8.6638\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1745 - val_loss: 8.5236\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0986 - val_loss: 8.4525\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9667 - val_loss: 8.5179\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7669 - val_loss: 8.3422\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 6.9310 - val_loss: 8.2102\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0412 - val_loss: 8.7251\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0518 - val_loss: 8.3560\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7950 - val_loss: 8.5791\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7407 - val_loss: 8.5847\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8961 - val_loss: 8.3042\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7189 - val_loss: 8.4078\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8752 - val_loss: 8.4941\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6761 - val_loss: 8.2647\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1173 - val_loss: 8.5065\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8388 - val_loss: 8.1254\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6755 - val_loss: 8.2746\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6424 - val_loss: 8.3781\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6507 - val_loss: 8.3038\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6171 - val_loss: 8.2920\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5496 - val_loss: 8.1410\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5936 - val_loss: 8.2915\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6267 - val_loss: 8.4542\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5149 - val_loss: 8.2068\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6706 - val_loss: 8.1596\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5669 - val_loss: 8.3345\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5683 - val_loss: 8.2197\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6557 - val_loss: 8.2166\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6209 - val_loss: 8.1331\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5712 - val_loss: 8.1878\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8247 - val_loss: 8.1640\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7235 - val_loss: 8.2953\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5820 - val_loss: 8.2735\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6043 - val_loss: 8.4245\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5821 - val_loss: 8.2743\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4891 - val_loss: 8.1968\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5036 - val_loss: 8.1188\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4749 - val_loss: 8.3383\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5128 - val_loss: 8.2398\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5052 - val_loss: 8.2224\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3824 - val_loss: 8.4361\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4484 - val_loss: 8.4417\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3733 - val_loss: 8.4152\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4547 - val_loss: 8.2135\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3957 - val_loss: 8.2791\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5720 - val_loss: 8.1512\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3196 - val_loss: 8.2990\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3379 - val_loss: 8.3645\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3572 - val_loss: 8.3394\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3191 - val_loss: 8.3599\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3307 - val_loss: 8.2071\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3893 - val_loss: 8.3652\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5250 - val_loss: 8.3154\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4134 - val_loss: 8.4320\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2918 - val_loss: 8.5479\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3565 - val_loss: 8.3762\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3311 - val_loss: 8.3270\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3504 - val_loss: 8.3243\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3985 - val_loss: 8.2032\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3830 - val_loss: 8.3842\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4028 - val_loss: 8.1176\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2612 - val_loss: 8.2647\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2811 - val_loss: 8.1296\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2938 - val_loss: 8.4612\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2855 - val_loss: 8.4853\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2965 - val_loss: 8.3567\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2163 - val_loss: 8.5240\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2465 - val_loss: 8.2906\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2709 - val_loss: 8.3802\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4266 - val_loss: 8.5292\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4628 - val_loss: 8.3099\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3173 - val_loss: 8.4661\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2413 - val_loss: 8.3627\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1791 - val_loss: 8.3192\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3015 - val_loss: 8.3953\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3856 - val_loss: 8.1797\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2512 - val_loss: 8.5539\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2239 - val_loss: 8.1917\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2292 - val_loss: 8.5299\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2135 - val_loss: 8.3531\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1667 - val_loss: 8.3608\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3768 - val_loss: 8.4141\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3159 - val_loss: 8.3294\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.2012 - val_loss: 8.3237\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2840 - val_loss: 8.4351\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2217 - val_loss: 8.3225\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1668 - val_loss: 8.3846\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1802 - val_loss: 8.3307\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3387 - val_loss: 8.5661\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4690 - val_loss: 8.5033\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3408 - val_loss: 8.4467\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2364 - val_loss: 8.5267\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1026 - val_loss: 8.4744\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1564 - val_loss: 8.2118\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1749 - val_loss: 8.2876\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1395 - val_loss: 8.3911\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1331 - val_loss: 8.3795\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0889 - val_loss: 8.3557\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1342 - val_loss: 8.5052\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0882 - val_loss: 8.5066\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1174 - val_loss: 8.3609\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1488 - val_loss: 8.5695\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0921 - val_loss: 8.3764\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4301 - val_loss: 8.5378\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9624 - val_loss: 8.4607\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2062 - val_loss: 8.4999\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0957 - val_loss: 8.3362\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1308 - val_loss: 8.5530\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0562 - val_loss: 8.4563\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3122 - val_loss: 8.2853\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1528 - val_loss: 8.5135\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1437 - val_loss: 8.4133\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2143 - val_loss: 8.5337\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0218 - val_loss: 8.6695\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1478 - val_loss: 8.5867\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2524 - val_loss: 8.5390\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3420 - val_loss: 8.3812\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1650 - val_loss: 8.5567\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3155 - val_loss: 8.3932\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0133 - val_loss: 8.7006\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0651 - val_loss: 8.5499\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9717 - val_loss: 8.5852\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9024 - val_loss: 8.4202\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9407 - val_loss: 8.7591\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8092 - val_loss: 8.6090\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0390 - val_loss: 8.7880\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9014 - val_loss: 8.5303\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9033 - val_loss: 8.6826\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8396 - val_loss: 8.5903\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8593 - val_loss: 8.7741\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8731 - val_loss: 8.7111\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7793 - val_loss: 8.6299\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8012 - val_loss: 8.5745\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7833 - val_loss: 8.5839\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8317 - val_loss: 8.5291\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8880 - val_loss: 8.7119\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7813 - val_loss: 8.6205\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7851 - val_loss: 8.6402\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8064 - val_loss: 8.5537\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7559 - val_loss: 8.6302\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7499 - val_loss: 8.5536\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7869 - val_loss: 8.5264\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7285 - val_loss: 8.5300\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9209 - val_loss: 8.6917\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0952 - val_loss: 8.5603\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8377 - val_loss: 8.5820\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7926 - val_loss: 8.5013\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6813 - val_loss: 8.4998\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6973 - val_loss: 8.4925\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7032 - val_loss: 8.6375\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6593 - val_loss: 8.5726\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6874 - val_loss: 8.4052\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7389 - val_loss: 8.6744\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7876 - val_loss: 8.7245\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6920 - val_loss: 8.7105\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7485 - val_loss: 8.5086\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.7035 - val_loss: 8.4495\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7169 - val_loss: 8.4520\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8891 - val_loss: 8.5130\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8162 - val_loss: 8.3764\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7377 - val_loss: 8.3464\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.7454 - val_loss: 8.4034\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6034 - val_loss: 8.5010\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6585 - val_loss: 8.4547\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6389 - val_loss: 8.5135\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6361 - val_loss: 8.5601\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5616 - val_loss: 8.4007\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5968 - val_loss: 8.4202\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5504 - val_loss: 8.4576\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6143 - val_loss: 8.2811\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5789 - val_loss: 8.4552\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6365 - val_loss: 8.4936\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7514 - val_loss: 8.4281\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6087 - val_loss: 8.4312\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.6172 - val_loss: 8.4333\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5903 - val_loss: 8.5886\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6017 - val_loss: 8.5641\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6352 - val_loss: 8.4584\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6535 - val_loss: 8.3453\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5848 - val_loss: 8.5231\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5522 - val_loss: 8.4144\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6839 - val_loss: 8.4094\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6311 - val_loss: 8.4977\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7681 - val_loss: 8.4000\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6565 - val_loss: 8.5542\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6376 - val_loss: 8.4684\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5598 - val_loss: 8.4559\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7708 - val_loss: 8.3897\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8193 - val_loss: 8.2497\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6087 - val_loss: 8.4204\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6051 - val_loss: 8.4085\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9534 - val_loss: 8.6969\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8745 - val_loss: 8.2915\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.8400 - val_loss: 8.4635\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6505 - val_loss: 8.5117\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8183 - val_loss: 8.3988\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5477 - val_loss: 8.3929\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5792 - val_loss: 8.4419\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6035 - val_loss: 8.4610\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5498 - val_loss: 8.5011\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5177 - val_loss: 8.4973\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6201 - val_loss: 8.4590\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6565 - val_loss: 8.4426\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5106 - val_loss: 8.4579\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5827 - val_loss: 8.1697\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5480 - val_loss: 8.2606\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5893 - val_loss: 8.3567\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4696 - val_loss: 8.5605\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5180 - val_loss: 8.4126\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5799 - val_loss: 8.3762\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5035 - val_loss: 8.2841\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6414 - val_loss: 8.2987\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5525 - val_loss: 8.2927\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6125 - val_loss: 8.4260\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4702 - val_loss: 8.4186\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5465 - val_loss: 8.3189\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4670 - val_loss: 8.3591\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4482 - val_loss: 8.4761\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4765 - val_loss: 8.4836\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6212 - val_loss: 8.4707\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8623 - val_loss: 8.3076\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7058 - val_loss: 8.4714\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4780 - val_loss: 8.5610\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4984 - val_loss: 8.5732\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8776 - val_loss: 8.7154\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7228 - val_loss: 8.3607\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4453 - val_loss: 8.3361\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4906 - val_loss: 8.3791\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6318 - val_loss: 8.4633\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3943 - val_loss: 8.6006\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6149 - val_loss: 8.3898\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6471 - val_loss: 8.6313\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5553 - val_loss: 8.2797\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5237 - val_loss: 8.5022\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6213 - val_loss: 8.3931\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4728 - val_loss: 8.3825\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4999 - val_loss: 8.2696\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4691 - val_loss: 8.3343\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5035 - val_loss: 8.4777\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.4301 - val_loss: 8.3546\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5807 - val_loss: 8.2199\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5883 - val_loss: 8.2670\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4856 - val_loss: 8.3841\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4120 - val_loss: 8.4086\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4844 - val_loss: 8.4286\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5798 - val_loss: 8.5621\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5348 - val_loss: 8.4089\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4349 - val_loss: 8.2885\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6164 - val_loss: 8.2628\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6067 - val_loss: 8.2643\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4371 - val_loss: 8.3569\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4133 - val_loss: 8.3127\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4378 - val_loss: 8.3458\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4830 - val_loss: 8.3939\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4389 - val_loss: 8.4176\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5365 - val_loss: 8.2925\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4855 - val_loss: 8.3903\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4240 - val_loss: 8.6602\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5697 - val_loss: 8.4741\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6813 - val_loss: 8.4702\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4550 - val_loss: 8.2871\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4241 - val_loss: 8.2087\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4394 - val_loss: 8.3043\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4408 - val_loss: 8.3004\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4505 - val_loss: 8.4241\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5098 - val_loss: 8.3040\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4553 - val_loss: 8.4320\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6772 - val_loss: 8.3442\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5339 - val_loss: 8.4645\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4383 - val_loss: 8.2809\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4217 - val_loss: 8.3104\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3889 - val_loss: 8.2860\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4636 - val_loss: 8.4154\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4849 - val_loss: 8.2291\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8048 - val_loss: 8.4031\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0543 - val_loss: 8.2614\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6708 - val_loss: 8.3333\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6741 - val_loss: 8.1540\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5371 - val_loss: 8.3557\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3877 - val_loss: 8.3132\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3836 - val_loss: 8.3795\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4681 - val_loss: 8.3459\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4001 - val_loss: 8.4282\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5723 - val_loss: 8.3155\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6849 - val_loss: 8.4118\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5258 - val_loss: 8.3051\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4737 - val_loss: 8.4181\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.5695 - val_loss: 8.6032\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4893 - val_loss: 8.4930\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5490 - val_loss: 8.2883\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5720 - val_loss: 8.3949\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8950 - val_loss: 8.1800\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5579 - val_loss: 8.1938\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3689 - val_loss: 8.2079\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4252 - val_loss: 8.2575\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4779 - val_loss: 8.0788\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6047 - val_loss: 8.3868\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4214 - val_loss: 8.3523\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4641 - val_loss: 8.4152\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4865 - val_loss: 8.3431\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4139 - val_loss: 8.2136\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3651 - val_loss: 8.2729\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4125 - val_loss: 8.3280\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5803 - val_loss: 8.2927\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4595 - val_loss: 8.3690\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3055 - val_loss: 8.2532\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4045 - val_loss: 8.1826\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3806 - val_loss: 8.0832\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3649 - val_loss: 8.1030\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3844 - val_loss: 8.2870\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4794 - val_loss: 8.3727\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3918 - val_loss: 8.2596\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4333 - val_loss: 8.2477\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3643 - val_loss: 8.5063\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3958 - val_loss: 8.3663\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3861 - val_loss: 8.4348\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3631 - val_loss: 8.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3241 - val_loss: 8.4105\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6534 - val_loss: 8.3445\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4820 - val_loss: 8.5311\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4333 - val_loss: 8.3815\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2995 - val_loss: 8.3009\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4581 - val_loss: 8.4368\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6573 - val_loss: 8.2926\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6063 - val_loss: 8.4642\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5180 - val_loss: 8.2186\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3850 - val_loss: 8.4851\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4545 - val_loss: 8.3101\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6063 - val_loss: 8.5646\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6947 - val_loss: 8.4289\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7813 - val_loss: 8.4239\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4252 - val_loss: 8.3600\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3254 - val_loss: 8.3646\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3761 - val_loss: 8.2187\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5698 - val_loss: 8.2966\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4695 - val_loss: 8.2602\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3586 - val_loss: 8.3892\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4591 - val_loss: 8.3216\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3770 - val_loss: 8.3218\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5113 - val_loss: 8.4543\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4508 - val_loss: 8.3437\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4158 - val_loss: 8.3418\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.4148 - val_loss: 8.2294\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5190 - val_loss: 8.4533\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5168 - val_loss: 8.1367\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5227 - val_loss: 8.1290\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4756 - val_loss: 8.4079\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3551 - val_loss: 8.3509\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3799 - val_loss: 8.0759\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4851 - val_loss: 8.3034\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6081 - val_loss: 8.3285\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4764 - val_loss: 8.3423\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4223 - val_loss: 8.2069\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.3156 - val_loss: 8.2926\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3635 - val_loss: 8.2406\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2901 - val_loss: 8.2468\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.3752 - val_loss: 8.3625\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3386 - val_loss: 8.3198\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3135 - val_loss: 8.0214\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3097 - val_loss: 8.0278\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3208 - val_loss: 8.2075\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3725 - val_loss: 8.1391\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.4449 - val_loss: 8.3588\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4226 - val_loss: 8.4957\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3359 - val_loss: 8.1967\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3052 - val_loss: 8.2294\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3353 - val_loss: 8.1919\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5014 - val_loss: 8.2907\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4856 - val_loss: 8.0785\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4650 - val_loss: 8.2407\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3658 - val_loss: 8.2307\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4009 - val_loss: 8.4887\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3954 - val_loss: 8.2945\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4655 - val_loss: 8.4160\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3069 - val_loss: 8.5146\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3338 - val_loss: 8.2823\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6308 - val_loss: 8.3803\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5741 - val_loss: 8.0692\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3911 - val_loss: 8.1526\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3508 - val_loss: 8.3371\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4114 - val_loss: 8.2532\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4344 - val_loss: 8.2717\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2917 - val_loss: 8.2310\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4636 - val_loss: 8.4583\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5244 - val_loss: 8.1839\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4684 - val_loss: 8.4241\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5193 - val_loss: 8.1016\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3857 - val_loss: 8.3604\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3301 - val_loss: 8.1732\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3200 - val_loss: 8.1938\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4948 - val_loss: 8.5105\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4018 - val_loss: 8.1482\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2575 - val_loss: 8.2055\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3541 - val_loss: 8.1300\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.3502 - val_loss: 8.2977\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2947 - val_loss: 8.2276\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3246 - val_loss: 8.2431\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2720 - val_loss: 8.2542\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2682 - val_loss: 8.1437\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2628 - val_loss: 8.0980\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3009 - val_loss: 8.2541\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3368 - val_loss: 8.1743\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3240 - val_loss: 8.1692\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4466 - val_loss: 8.1737\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1945 - val_loss: 8.1250\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3594 - val_loss: 8.1175\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3446 - val_loss: 8.4714\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4305 - val_loss: 8.1713\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2920 - val_loss: 8.4764\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4033 - val_loss: 8.0747\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5938 - val_loss: 8.1609\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4588 - val_loss: 8.0183\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2329 - val_loss: 8.2166\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2593 - val_loss: 8.1531\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3890 - val_loss: 8.1480\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2190 - val_loss: 8.1626\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2192 - val_loss: 8.1356\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3183 - val_loss: 8.1262\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4181 - val_loss: 8.2907\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6314 - val_loss: 8.1330\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3725 - val_loss: 8.2546\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3734 - val_loss: 8.2593\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2417 - val_loss: 8.1219\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3657 - val_loss: 8.1672\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3382 - val_loss: 8.0438\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8563 - val_loss: 8.4926\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3292 - val_loss: 8.1279\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3054 - val_loss: 8.1168\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3282 - val_loss: 8.1798\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2393 - val_loss: 8.2045\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3402 - val_loss: 8.2923\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3771 - val_loss: 8.2485\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3318 - val_loss: 8.0476\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3044 - val_loss: 8.1294\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2900 - val_loss: 8.1690\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2998 - val_loss: 8.1984\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2570 - val_loss: 8.1785\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3078 - val_loss: 8.2620\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3455 - val_loss: 8.1414\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4732 - val_loss: 7.9777\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4036 - val_loss: 8.2421\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2369 - val_loss: 8.1792\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3647 - val_loss: 7.9929\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2564 - val_loss: 8.1165\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3626 - val_loss: 8.3387\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3153 - val_loss: 8.0270\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2787 - val_loss: 8.1288\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3496 - val_loss: 8.2019\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2624 - val_loss: 8.1205\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3278 - val_loss: 7.9339\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2445 - val_loss: 8.1215\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5470 - val_loss: 7.9247\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4883 - val_loss: 8.1395\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3536 - val_loss: 8.1840\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3401 - val_loss: 8.1883\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2447 - val_loss: 8.1165\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2785 - val_loss: 8.1707\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2669 - val_loss: 8.0697\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2500 - val_loss: 7.9647\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3806 - val_loss: 8.3438\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3332 - val_loss: 7.9959\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4056 - val_loss: 8.1638\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3562 - val_loss: 8.1192\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2870 - val_loss: 8.1901\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.2133 - val_loss: 7.9493\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2667 - val_loss: 8.0525\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2487 - val_loss: 8.0377\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1952 - val_loss: 8.2732\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2394 - val_loss: 8.0800\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3178 - val_loss: 8.1746\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4167 - val_loss: 8.0752\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3436 - val_loss: 8.0779\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 94us/step - loss: 5.2172 - val_loss: 8.2623\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4367 - val_loss: 8.0360\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3510 - val_loss: 8.2364\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2722 - val_loss: 7.9754\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2213 - val_loss: 8.0832\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3848 - val_loss: 8.0636\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2626 - val_loss: 8.1032\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3592 - val_loss: 8.0111\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2438 - val_loss: 8.1457\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3668 - val_loss: 7.9613\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2759 - val_loss: 7.9543\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3144 - val_loss: 7.9521\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2627 - val_loss: 8.1469\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2249 - val_loss: 8.1544\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3094 - val_loss: 7.9044\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3643 - val_loss: 8.1830\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3678 - val_loss: 8.1948\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3260 - val_loss: 8.1238\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2716 - val_loss: 8.0182\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2217 - val_loss: 8.2482\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3180 - val_loss: 8.0139\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3458 - val_loss: 8.0721\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2490 - val_loss: 7.9709\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2741 - val_loss: 8.0921\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3301 - val_loss: 7.9551\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3488 - val_loss: 8.2210\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2675 - val_loss: 8.0459\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2179 - val_loss: 8.0216\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3793 - val_loss: 8.0618\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3566 - val_loss: 8.3896\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2683 - val_loss: 7.9372\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2483 - val_loss: 8.1353\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2414 - val_loss: 8.1402\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2520 - val_loss: 8.0111\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3111 - val_loss: 8.1615\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1862 - val_loss: 8.0996\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3180 - val_loss: 7.9968\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.2869 - val_loss: 7.9372\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3026 - val_loss: 8.1311\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2810 - val_loss: 8.0445\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2172 - val_loss: 8.1318\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1772 - val_loss: 7.9475\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1677 - val_loss: 7.9432\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2026 - val_loss: 8.1192\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1983 - val_loss: 8.0610\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2506 - val_loss: 8.0036\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2038 - val_loss: 7.9347\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2112 - val_loss: 7.9793\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1793 - val_loss: 8.0739\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2444 - val_loss: 7.8414\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6450 - val_loss: 8.4572\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4546 - val_loss: 8.0545\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2277 - val_loss: 8.4480\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3769 - val_loss: 7.9088\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2167 - val_loss: 8.0199\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2012 - val_loss: 8.0992\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2230 - val_loss: 8.1174\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2380 - val_loss: 7.9955\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2320 - val_loss: 7.8591\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2930 - val_loss: 8.1642\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1965 - val_loss: 7.9213\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2551 - val_loss: 7.9147\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3026 - val_loss: 7.9336\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3783 - val_loss: 8.1856\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3107 - val_loss: 8.1298\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3345 - val_loss: 7.9269\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3303 - val_loss: 7.9525\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2012 - val_loss: 7.9198\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2722 - val_loss: 8.0028\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3712 - val_loss: 7.9938\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2935 - val_loss: 8.0837\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3773 - val_loss: 7.8963\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3635 - val_loss: 8.0866\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1966 - val_loss: 7.8868\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1653 - val_loss: 8.2556\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4765 - val_loss: 7.9120\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5409 - val_loss: 8.3675\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2840 - val_loss: 8.0490\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.2818 - val_loss: 7.9784\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1686 - val_loss: 8.1536\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2736 - val_loss: 7.8783\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3197 - val_loss: 8.1857\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3087 - val_loss: 8.0050\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2277 - val_loss: 7.9369\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3793 - val_loss: 7.8092\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2379 - val_loss: 8.1653\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2070 - val_loss: 7.8594\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1705 - val_loss: 7.9905\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2225 - val_loss: 7.8180\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2359 - val_loss: 8.1378\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2089 - val_loss: 7.9270\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1913 - val_loss: 8.0367\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2380 - val_loss: 7.7800\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1936 - val_loss: 7.8878\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2142 - val_loss: 8.0391\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2501 - val_loss: 8.1048\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2548 - val_loss: 8.1645\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2174 - val_loss: 8.1099\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4226 - val_loss: 7.8133\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2707 - val_loss: 8.0769\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3678 - val_loss: 7.9994\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2457 - val_loss: 8.0065\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3222 - val_loss: 7.8757\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2868 - val_loss: 8.2002\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3522 - val_loss: 8.1449\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2770 - val_loss: 8.0743\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2413 - val_loss: 8.0342\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1859 - val_loss: 8.1185\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1881 - val_loss: 7.9693\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2090 - val_loss: 7.9670\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1774 - val_loss: 7.9642\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4407 - val_loss: 8.1315\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3170 - val_loss: 7.8735\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3175 - val_loss: 8.0732\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2776 - val_loss: 8.0944\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3290 - val_loss: 7.9648\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2892 - val_loss: 8.1584\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1741 - val_loss: 8.0859\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1517 - val_loss: 7.9812\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.2517 - val_loss: 7.7252\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1824 - val_loss: 7.9270\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1695 - val_loss: 7.9060\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1994 - val_loss: 7.9601\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1728 - val_loss: 8.0094\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2880 - val_loss: 7.9483\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1216 - val_loss: 8.1224\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2016 - val_loss: 7.8678\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2913 - val_loss: 8.0874\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2398 - val_loss: 8.0422\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2277 - val_loss: 8.0165\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3886 - val_loss: 7.8072\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2431 - val_loss: 8.0377\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1920 - val_loss: 7.9171\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3419 - val_loss: 8.1484\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2501 - val_loss: 7.8602\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2712 - val_loss: 8.1156\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6209 - val_loss: 7.8401\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3846 - val_loss: 8.1037\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2593 - val_loss: 7.9884\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2426 - val_loss: 7.9560\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2964 - val_loss: 8.0149\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1777 - val_loss: 7.8695\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1753 - val_loss: 8.0760\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4363 - val_loss: 7.8588\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2987 - val_loss: 8.1286\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2159 - val_loss: 7.9381\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1858 - val_loss: 7.8320\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3772 - val_loss: 7.8600\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3112 - val_loss: 8.2314\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2994 - val_loss: 7.8927\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1751 - val_loss: 7.9720\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1701 - val_loss: 7.7751\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2180 - val_loss: 7.8798\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2558 - val_loss: 7.7461\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3828 - val_loss: 8.0389\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2042 - val_loss: 7.7701\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.1701 - val_loss: 7.9675\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2043 - val_loss: 7.9870\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2250 - val_loss: 7.9846\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2850 - val_loss: 8.0695\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3017 - val_loss: 7.8461\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1550 - val_loss: 7.9734\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3949 - val_loss: 7.7523\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3355 - val_loss: 8.1918\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4001 - val_loss: 7.8753\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2862 - val_loss: 8.1617\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2539 - val_loss: 7.7945\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2461 - val_loss: 7.8777\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2929 - val_loss: 7.8075\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2288 - val_loss: 7.9051\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1331 - val_loss: 7.8270\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2158 - val_loss: 7.9450\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4486 - val_loss: 7.9492\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3312 - val_loss: 8.2585\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4478 - val_loss: 7.8575\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2631 - val_loss: 8.1359\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2613 - val_loss: 7.8937\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1121 - val_loss: 8.0940\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2246 - val_loss: 7.9706\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3076 - val_loss: 7.9049\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3350 - val_loss: 7.9627\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2939 - val_loss: 7.6881\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3934 - val_loss: 8.0037\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4978 - val_loss: 7.7058\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1700 - val_loss: 7.8677\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2545 - val_loss: 7.8126\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1752 - val_loss: 7.9153\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1574 - val_loss: 7.9500\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2460 - val_loss: 7.7201\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4621 - val_loss: 7.9183\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4645 - val_loss: 7.7288\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4967 - val_loss: 8.2835\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3202 - val_loss: 7.9964\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1557 - val_loss: 8.0706\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1824 - val_loss: 7.7729\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1363 - val_loss: 7.8427\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2226 - val_loss: 7.7789\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2574 - val_loss: 7.9486\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2925 - val_loss: 7.6973\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5910 - val_loss: 7.6699\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2598 - val_loss: 8.1352\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2712 - val_loss: 7.8268\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1381 - val_loss: 7.9130\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1315 - val_loss: 7.8836\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2232 - val_loss: 8.2326\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3971 - val_loss: 7.7591\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3237 - val_loss: 8.0227\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2528 - val_loss: 7.8521\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1749 - val_loss: 7.9591\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1466 - val_loss: 7.9420\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1653 - val_loss: 7.9404\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3246 - val_loss: 7.7159\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2584 - val_loss: 8.1141\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3574 - val_loss: 7.7370\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2699 - val_loss: 8.0083\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1920 - val_loss: 7.9625\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1649 - val_loss: 7.9012\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2416 - val_loss: 8.0048\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1176 - val_loss: 7.7529\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1947 - val_loss: 7.8319\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3238 - val_loss: 7.9128\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3368 - val_loss: 7.7056\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1908 - val_loss: 7.8268\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1963 - val_loss: 7.9369\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1810 - val_loss: 7.8560\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1486 - val_loss: 7.8357\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1246 - val_loss: 7.9718\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2738 - val_loss: 8.1128\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3190 - val_loss: 7.8805\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4323 - val_loss: 7.9586\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2225 - val_loss: 8.0046\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2447 - val_loss: 7.9004\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1758 - val_loss: 7.8754\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2128 - val_loss: 8.0725\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.2934 - val_loss: 7.9735\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2006 - val_loss: 7.8964\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4015 - val_loss: 7.7706\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5151 - val_loss: 8.2058\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3698 - val_loss: 7.9478\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4656 - val_loss: 8.3621\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3558 - val_loss: 7.8753\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4859 - val_loss: 8.2045\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3400 - val_loss: 7.9205\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2499 - val_loss: 7.7597\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1394 - val_loss: 7.8610\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1504 - val_loss: 7.9701\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1696 - val_loss: 7.8830\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2312 - val_loss: 7.7777\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2144 - val_loss: 8.0029\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0868 - val_loss: 7.8568\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1618 - val_loss: 7.9674\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2157 - val_loss: 7.7766\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1207 - val_loss: 8.2448\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1932 - val_loss: 7.9972\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.006 - 0s 91us/step - loss: 5.1374 - val_loss: 8.0096\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1444 - val_loss: 7.8324\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1672 - val_loss: 8.0028\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1627 - val_loss: 7.7687\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2798 - val_loss: 8.0626\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4881 - val_loss: 7.9367\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1235 - val_loss: 8.2008\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.2627 - val_loss: 7.8559\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1435 - val_loss: 7.9255\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1856 - val_loss: 7.8512\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0915 - val_loss: 7.8820\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2010 - val_loss: 7.6839\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.1761 - val_loss: 7.9643\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2289 - val_loss: 7.8591\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1864 - val_loss: 7.9222\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2377 - val_loss: 8.1188\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3109 - val_loss: 7.9012\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2486 - val_loss: 7.9650\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3362 - val_loss: 8.1431\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3796 - val_loss: 7.7870\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3292 - val_loss: 8.2372\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5059 - val_loss: 8.0314\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3344 - val_loss: 7.9886\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1970 - val_loss: 7.7999\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3237 - val_loss: 7.7945\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2127 - val_loss: 8.0480\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1647 - val_loss: 7.8647\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1637 - val_loss: 7.7395\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1237 - val_loss: 7.8813\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1898 - val_loss: 7.7319\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1337 - val_loss: 7.9006\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.3226 - val_loss: 7.8547\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4171 - val_loss: 7.8084\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1716 - val_loss: 8.0363\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2117 - val_loss: 7.8597\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1892 - val_loss: 7.7913\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2429 - val_loss: 7.8727\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2161 - val_loss: 7.8400\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1265 - val_loss: 7.8859\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3562 - val_loss: 7.8924\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3591 - val_loss: 7.7562\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3173 - val_loss: 7.9218\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1656 - val_loss: 7.8795\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1161 - val_loss: 7.8784\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1294 - val_loss: 7.7804\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2857 - val_loss: 7.7470\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1800 - val_loss: 8.1439\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1495 - val_loss: 7.9352\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2253 - val_loss: 7.9299\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4154 - val_loss: 8.2494\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3098 - val_loss: 7.6535\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2032 - val_loss: 7.8205\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1445 - val_loss: 7.5968\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1715 - val_loss: 7.7626\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1196 - val_loss: 7.7293\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3546 - val_loss: 8.0498\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3155 - val_loss: 7.6519\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2037 - val_loss: 8.0412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4126 - val_loss: 7.7370\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1603 - val_loss: 7.8576\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1768 - val_loss: 7.6931\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1300 - val_loss: 7.8535\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3310 - val_loss: 7.6948\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1423 - val_loss: 7.6163\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2879 - val_loss: 7.8747\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1721 - val_loss: 7.8008\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.2038 - val_loss: 7.9163\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1881 - val_loss: 8.0382\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2283 - val_loss: 8.0978\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2778 - val_loss: 7.7046\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1372 - val_loss: 7.7397\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3263 - val_loss: 7.7434\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4429 - val_loss: 7.8219\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2105 - val_loss: 7.9402\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0919 - val_loss: 7.9460\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2489 - val_loss: 7.8541\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2793 - val_loss: 7.8102\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3574 - val_loss: 7.7967\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2479 - val_loss: 8.0490\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1285 - val_loss: 7.8149\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1391 - val_loss: 7.8184\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1235 - val_loss: 7.7879\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3564 - val_loss: 7.8269\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2004 - val_loss: 7.8488\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1158 - val_loss: 7.9480\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2012 - val_loss: 8.0992\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2044 - val_loss: 7.9590\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2258 - val_loss: 7.8411\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1972 - val_loss: 7.9421\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1774 - val_loss: 7.7649\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1356 - val_loss: 7.7657\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2890 - val_loss: 7.7151\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1740 - val_loss: 7.8973\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2042 - val_loss: 7.8220\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1940 - val_loss: 7.8132\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1610 - val_loss: 7.7130\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1290 - val_loss: 7.9256\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2725 - val_loss: 7.6931\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1974 - val_loss: 8.0136\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0983 - val_loss: 7.8535\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1858 - val_loss: 8.0538\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4189 - val_loss: 7.6722\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1779 - val_loss: 8.0684\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2400 - val_loss: 7.7504\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2165 - val_loss: 7.9663\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1419 - val_loss: 7.7964\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1170 - val_loss: 7.7327\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1984 - val_loss: 7.8632\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1404 - val_loss: 7.8567\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1316 - val_loss: 7.9521\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1203 - val_loss: 7.7349\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3104 - val_loss: 8.1325\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3491 - val_loss: 7.9079\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0999 - val_loss: 8.0852\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1334 - val_loss: 7.7269\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1576 - val_loss: 7.7488\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1991 - val_loss: 7.7713\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0906 - val_loss: 7.8255\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1848 - val_loss: 7.8700\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1494 - val_loss: 7.8653\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1381 - val_loss: 7.6919\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0854 - val_loss: 7.6831\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2618 - val_loss: 7.9296\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3723 - val_loss: 8.0548\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2441 - val_loss: 7.6706\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.3093 - val_loss: 7.9186\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2686 - val_loss: 7.7027\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1978 - val_loss: 7.8475\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.1010 - val_loss: 7.8272\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1098 - val_loss: 7.7749\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1433 - val_loss: 7.7686\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1450 - val_loss: 7.7658\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1325 - val_loss: 7.8876\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2451 - val_loss: 7.8299\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1674 - val_loss: 7.8900\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1606 - val_loss: 7.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1293 - val_loss: 7.8182\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1004 - val_loss: 7.9410\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1917 - val_loss: 7.8724\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2548 - val_loss: 7.8174\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2604 - val_loss: 7.8793\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2275 - val_loss: 7.8540\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1773 - val_loss: 7.8519\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2038 - val_loss: 7.8044\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0918 - val_loss: 7.7023\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1920 - val_loss: 8.1129\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1490 - val_loss: 7.8070\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1767 - val_loss: 8.0406\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2998 - val_loss: 7.6613\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4805 - val_loss: 8.2855\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2001 - val_loss: 7.7855\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2121 - val_loss: 7.7618\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1283 - val_loss: 7.6823\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1042 - val_loss: 7.8404\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1065 - val_loss: 7.8153\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1587 - val_loss: 7.8014\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1182 - val_loss: 7.6980\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1913 - val_loss: 7.6248\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1653 - val_loss: 7.8970\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4580 - val_loss: 7.7828\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1694 - val_loss: 8.1879\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3876 - val_loss: 7.6135\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1247 - val_loss: 7.9612\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1976 - val_loss: 7.8303\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1783 - val_loss: 7.8779\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2395 - val_loss: 7.8143\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1162 - val_loss: 8.1064\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1300 - val_loss: 7.9101\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1398 - val_loss: 7.7321\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2544 - val_loss: 7.8245\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2239 - val_loss: 7.7556\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1567 - val_loss: 7.8300\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1295 - val_loss: 7.7840\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0944 - val_loss: 8.0240\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3143 - val_loss: 7.7739\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.0839 - val_loss: 8.0191\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1520 - val_loss: 7.8792\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0772 - val_loss: 7.8679\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1694 - val_loss: 7.8735\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2517 - val_loss: 7.8652\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2749 - val_loss: 7.8081\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0978 - val_loss: 7.7442\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1826 - val_loss: 7.9144\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3083 - val_loss: 7.6903\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2952 - val_loss: 8.1639\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.3709 - val_loss: 7.7645\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1539 - val_loss: 7.8062\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0982 - val_loss: 7.7860\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2193 - val_loss: 7.8543\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2487 - val_loss: 7.8734\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2902 - val_loss: 7.9257\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3439 - val_loss: 8.1410\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.1519 - val_loss: 7.7190\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1898 - val_loss: 8.1661\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3128 - val_loss: 7.7773\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2050 - val_loss: 8.0387\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0860 - val_loss: 7.7392\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2205 - val_loss: 8.0957\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2383 - val_loss: 7.7117\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3152 - val_loss: 7.9919\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1697 - val_loss: 7.7517\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.2086 - val_loss: 7.8375\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1807 - val_loss: 7.9562\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1417 - val_loss: 7.8670\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1408 - val_loss: 7.9982\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2358 - val_loss: 7.8320\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0380 - val_loss: 7.7618\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1239 - val_loss: 7.8659\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2684 - val_loss: 7.9553\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5312 - val_loss: 7.9863\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2072 - val_loss: 7.9557\n",
      "7.169451422610526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.28635108,  2.9167414 , -0.23144896,  0.68618214, -0.7680612 ],\n",
       "        [-0.48407128,  1.3466688 ,  1.0518687 ,  1.2875695 , -0.70855916],\n",
       "        [-0.2260401 , -1.4053946 , -1.451052  ,  0.64102286, -0.48801693],\n",
       "        [-0.1558429 ,  0.03466629, -2.008324  , -2.8242705 , -0.0749555 ],\n",
       "        [-0.73916876,  0.55035764,  1.0508839 ,  0.8255887 , -0.39244083],\n",
       "        [ 0.5261591 ,  0.96124864,  0.84337956,  1.5368651 , -0.1428345 ],\n",
       "        [ 1.3142924 , -2.7074087 , -1.1096908 ,  0.4523525 ,  1.0735618 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.1329527,  1.9479085,  0.5942557, -2.1764657, -1.040667 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.6702776 ,  0.29393542,  0.5812508 ,  0.58492976,  0.41550812,\n",
       "          0.09322894,  0.33460608,  0.72041297,  0.17871282, -0.73566467],\n",
       "        [ 0.9246796 , -0.6927309 , -0.00647283,  1.0504009 ,  0.6562957 ,\n",
       "          1.0918528 , -0.8806661 ,  0.3345802 ,  0.0279017 ,  0.10776122],\n",
       "        [-0.4444281 , -0.21675685,  0.6993185 , -0.07312663, -0.47601902,\n",
       "          0.7318203 , -0.63371176,  0.42768034, -0.22295615, -0.25440103],\n",
       "        [ 0.51260823, -0.14512207,  1.0368423 ,  0.64576286,  0.889199  ,\n",
       "         -0.17787625, -0.13532087,  0.08882476, -0.25021806,  0.0669269 ],\n",
       "        [ 1.193066  , -0.8753045 ,  0.2942267 ,  0.8916696 ,  1.0880771 ,\n",
       "          1.2588104 , -0.61971366,  1.2095857 , -0.8085715 , -0.6755815 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.8906727, -1.886399 ,  1.8174456,  1.83841  ,  1.8482944,\n",
       "         1.7671975, -1.8236394,  1.8152014, -1.9373192, -1.7601506],\n",
       "       dtype=float32),\n",
       " array([[ 1.2458234 ],\n",
       "        [-0.9877914 ],\n",
       "        [ 1.4164138 ],\n",
       "        [ 1.4985073 ],\n",
       "        [ 0.87554204],\n",
       "        [ 1.4259069 ],\n",
       "        [-1.0497841 ],\n",
       "        [ 1.2216014 ],\n",
       "        [-0.70865065],\n",
       "        [-0.87547415]], dtype=float32),\n",
       " array([1.6943309], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_linear(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_linear_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 768us/step - loss: 489.6943 - val_loss: 200.0193\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 128.8673 - val_loss: 70.8332\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 68.5360 - val_loss: 62.4540\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 34.0450 - val_loss: 31.1837\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 21.1878 - val_loss: 16.7320\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 16.3049 - val_loss: 10.6692\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 13.6640 - val_loss: 9.6709\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.2429 - val_loss: 10.2802\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.9431 - val_loss: 9.5491\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.3353 - val_loss: 9.8480\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.6561 - val_loss: 9.0917\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.2151 - val_loss: 8.7184\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.0752 - val_loss: 8.4959\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.8847 - val_loss: 8.4526\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.2328 - val_loss: 8.9524\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.2172 - val_loss: 8.4822\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 9.3436 - val_loss: 8.4280\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9928 - val_loss: 8.3146\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.8375 - val_loss: 8.2260\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7709 - val_loss: 8.2968\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.6881 - val_loss: 8.1463\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7665 - val_loss: 8.0231\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5076 - val_loss: 8.1095\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6312 - val_loss: 8.1722\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4608 - val_loss: 8.0962\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5429 - val_loss: 8.5426\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6451 - val_loss: 8.0825\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4333 - val_loss: 8.3291\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3882 - val_loss: 8.0252\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3398 - val_loss: 8.5518\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.5136 - val_loss: 8.2540\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2910 - val_loss: 8.3913\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3423 - val_loss: 7.9924\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1342 - val_loss: 8.3128\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1584 - val_loss: 8.2353\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0649 - val_loss: 8.2783\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0512 - val_loss: 8.1149\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1642 - val_loss: 7.9816\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.1934 - val_loss: 8.0294\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0740 - val_loss: 8.1175\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0506 - val_loss: 8.0367\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0522 - val_loss: 8.5135\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2366 - val_loss: 8.0210\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9876 - val_loss: 8.0072\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9083 - val_loss: 7.7495\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9594 - val_loss: 7.9042\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9417 - val_loss: 7.6721\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0704 - val_loss: 7.6180\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9264 - val_loss: 7.4888\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8207 - val_loss: 7.8792\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1110 - val_loss: 7.5517\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0567 - val_loss: 7.7757\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.6774 - val_loss: 7.2210\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7134 - val_loss: 7.3226\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.7054 - val_loss: 7.0333\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6239 - val_loss: 6.8465\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5616 - val_loss: 7.3093\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8332 - val_loss: 7.0414\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.5281 - val_loss: 6.7375\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6299 - val_loss: 6.8515\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5308 - val_loss: 6.6345\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.7666 - val_loss: 6.8338\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6722 - val_loss: 6.8879\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7636 - val_loss: 6.5781\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.6793 - val_loss: 7.2924\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4167 - val_loss: 6.6128\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6295 - val_loss: 6.9993\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2294 - val_loss: 6.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7365 - val_loss: 6.6486\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4913 - val_loss: 7.4083\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6619 - val_loss: 6.6389\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.4948 - val_loss: 6.6729\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7573 - val_loss: 6.7043\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7216 - val_loss: 6.3907\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4887 - val_loss: 6.7755\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.7938 - val_loss: 6.4753\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4877 - val_loss: 7.1544\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5127 - val_loss: 6.3849\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.5895 - val_loss: 6.9433\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3327 - val_loss: 6.5439\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5808 - val_loss: 6.8264\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4404 - val_loss: 7.0759\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3910 - val_loss: 6.4575\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3951 - val_loss: 6.4822\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.4406 - val_loss: 6.5780\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4864 - val_loss: 6.7144\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5068 - val_loss: 6.8257\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4170 - val_loss: 6.7339\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2975 - val_loss: 6.7381\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3775 - val_loss: 6.4809\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.4824 - val_loss: 6.5648\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3675 - val_loss: 6.4746\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3257 - val_loss: 6.7160\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3240 - val_loss: 6.5442\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4641 - val_loss: 6.6357\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.146 - 0s 102us/step - loss: 7.4344 - val_loss: 6.4977\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7259 - val_loss: 6.7090\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6199 - val_loss: 6.4183\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5259 - val_loss: 6.9435\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3680 - val_loss: 6.4070\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3658 - val_loss: 6.7071\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3187 - val_loss: 7.0940\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.3914 - val_loss: 6.4945\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3087 - val_loss: 6.7462\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4408 - val_loss: 6.4693\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3197 - val_loss: 6.5304\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.3058 - val_loss: 6.8450\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3230 - val_loss: 6.7293\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2793 - val_loss: 6.5455\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3855 - val_loss: 6.6650\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2726 - val_loss: 6.9214\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2646 - val_loss: 6.5405\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2466 - val_loss: 6.6299\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2786 - val_loss: 6.5216\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3286 - val_loss: 6.4395\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2909 - val_loss: 6.5584\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.7133 - val_loss: 6.4407\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9642 - val_loss: 6.7405\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2978 - val_loss: 6.2534\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5363 - val_loss: 6.7609\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5669 - val_loss: 6.5292\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 7.6331 - val_loss: 6.9214\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9292 - val_loss: 6.3509\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6085 - val_loss: 6.6716\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3031 - val_loss: 6.2988\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2543 - val_loss: 6.7535\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5279 - val_loss: 6.6294\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3417 - val_loss: 6.4707\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1842 - val_loss: 7.0897\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2894 - val_loss: 6.4177\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3540 - val_loss: 6.5314\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2863 - val_loss: 6.6346\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3395 - val_loss: 6.5987\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5019 - val_loss: 6.5372\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2781 - val_loss: 6.5474\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3339 - val_loss: 6.8173\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5238 - val_loss: 6.5758\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1590 - val_loss: 6.4517\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1660 - val_loss: 6.3246\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2740 - val_loss: 6.8246\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1584 - val_loss: 6.4278\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2802 - val_loss: 6.5440\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1673 - val_loss: 6.4578\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1107 - val_loss: 6.8743\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1561 - val_loss: 6.6781\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 7.1008 - val_loss: 6.5620\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0682 - val_loss: 6.6758\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2274 - val_loss: 6.5394\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1455 - val_loss: 6.4379\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1162 - val_loss: 6.4538\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0972 - val_loss: 6.7274\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0538 - val_loss: 6.5956\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9928 - val_loss: 6.6743\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1250 - val_loss: 6.7280\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2728 - val_loss: 6.7620\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1680 - val_loss: 7.0111\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0870 - val_loss: 6.6034\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1720 - val_loss: 6.5587\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0101 - val_loss: 6.7252\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1216 - val_loss: 6.7228\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0624 - val_loss: 6.8523\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0743 - val_loss: 6.7572\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1056 - val_loss: 6.7380\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1314 - val_loss: 6.6936\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0978 - val_loss: 6.3806\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0664 - val_loss: 6.5531\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0180 - val_loss: 7.0663\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0554 - val_loss: 6.6232\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0866 - val_loss: 6.6245\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0375 - val_loss: 6.7531\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0770 - val_loss: 6.5550\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1163 - val_loss: 6.5738\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0939 - val_loss: 6.7527\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9236 - val_loss: 6.5502\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0419 - val_loss: 6.8266\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9801 - val_loss: 6.7126\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1260 - val_loss: 6.4842\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9720 - val_loss: 7.0661\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2156 - val_loss: 6.4646\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0559 - val_loss: 6.5619\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0007 - val_loss: 6.7687\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9716 - val_loss: 6.4769\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0879 - val_loss: 6.7746\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1258 - val_loss: 6.6156\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9277 - val_loss: 6.5943\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9936 - val_loss: 6.8156\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1277 - val_loss: 6.3776\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.9522 - val_loss: 6.6203\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9975 - val_loss: 6.7655\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9666 - val_loss: 6.4502\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8722 - val_loss: 7.0052\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0999 - val_loss: 6.6490\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1030 - val_loss: 6.7178\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2965 - val_loss: 6.6241\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1383 - val_loss: 6.6852\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9975 - val_loss: 6.7296\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0246 - val_loss: 6.5921\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9030 - val_loss: 6.5082\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9372 - val_loss: 6.6717\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9767 - val_loss: 6.5543\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9061 - val_loss: 6.5191\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9241 - val_loss: 6.4904\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1628 - val_loss: 6.5116\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2355 - val_loss: 6.4367\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0971 - val_loss: 6.4291\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9952 - val_loss: 6.6369\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0760 - val_loss: 6.7257\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9000 - val_loss: 6.6433\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8034 - val_loss: 6.9528\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1586 - val_loss: 6.5641\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0303 - val_loss: 6.5390\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9410 - val_loss: 6.7031\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0253 - val_loss: 6.7072\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8949 - val_loss: 6.5773\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9239 - val_loss: 6.3327\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9943 - val_loss: 6.5630\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8615 - val_loss: 6.5650\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1833 - val_loss: 6.8144\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7905 - val_loss: 6.6883\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8625 - val_loss: 6.7934\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8349 - val_loss: 6.5756\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9014 - val_loss: 6.5601\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 6.8828 - val_loss: 6.6083\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9098 - val_loss: 6.7160\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4233 - val_loss: 6.7660\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9177 - val_loss: 6.8945\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7843 - val_loss: 6.4641\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9580 - val_loss: 6.4500\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9359 - val_loss: 6.7008\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9332 - val_loss: 6.3353\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.8823 - val_loss: 6.5801\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0027 - val_loss: 6.4857\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9911 - val_loss: 6.7542\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2682 - val_loss: 6.5774\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0005 - val_loss: 6.8701\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8833 - val_loss: 6.5108\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9502 - val_loss: 6.6148\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9112 - val_loss: 6.6277\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7926 - val_loss: 6.7678\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8688 - val_loss: 6.5617\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9798 - val_loss: 6.8675\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8255 - val_loss: 6.7265\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8732 - val_loss: 6.6563\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.8719 - val_loss: 6.4828\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7824 - val_loss: 6.3995\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8284 - val_loss: 6.5000\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8681 - val_loss: 6.5784\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8614 - val_loss: 6.6273\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7989 - val_loss: 6.4622\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8295 - val_loss: 6.7742\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7959 - val_loss: 6.8950\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8155 - val_loss: 6.5614\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8207 - val_loss: 6.5566\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0571 - val_loss: 6.6385\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5535 - val_loss: 6.4494\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7724 - val_loss: 6.6615\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8444 - val_loss: 6.9171\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8376 - val_loss: 6.8284\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7834 - val_loss: 6.6717\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8275 - val_loss: 6.6328\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7404 - val_loss: 6.5673\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7977 - val_loss: 6.8025\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8125 - val_loss: 6.6944\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7034 - val_loss: 6.5558\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0246 - val_loss: 7.0531\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0686 - val_loss: 6.5800\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9067 - val_loss: 6.5817\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8081 - val_loss: 6.9493\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7720 - val_loss: 6.6809\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7299 - val_loss: 6.6518\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8008 - val_loss: 6.8410\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7858 - val_loss: 6.5261\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7594 - val_loss: 6.3971\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7766 - val_loss: 6.6472\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9203 - val_loss: 6.8185\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6899 - val_loss: 6.7541\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7560 - val_loss: 6.5714\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8441 - val_loss: 6.9615\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7795 - val_loss: 6.7281\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0681 - val_loss: 7.0303\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0274 - val_loss: 6.4169\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8708 - val_loss: 6.6465\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.9210 - val_loss: 6.6873\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7004 - val_loss: 6.5100\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9158 - val_loss: 6.6744\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9398 - val_loss: 6.6581\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9542 - val_loss: 6.6383\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9534 - val_loss: 6.6740\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1196 - val_loss: 6.7672\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8468 - val_loss: 6.6479\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7786 - val_loss: 6.6659\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7443 - val_loss: 6.5727\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7678 - val_loss: 6.7280\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6725 - val_loss: 6.5370\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8860 - val_loss: 6.7071\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7448 - val_loss: 6.6779\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6325 - val_loss: 6.7510\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7227 - val_loss: 6.5536\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7903 - val_loss: 6.5871\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 107us/step - loss: 6.7227 - val_loss: 6.8042\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7466 - val_loss: 6.4613\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6997 - val_loss: 6.9247\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6940 - val_loss: 6.6712\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7496 - val_loss: 6.8849\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9357 - val_loss: 6.8440\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7971 - val_loss: 6.9837\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6484 - val_loss: 6.5724\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9988 - val_loss: 7.4846\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7442 - val_loss: 6.9850\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7804 - val_loss: 6.6426\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7790 - val_loss: 7.0929\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9399 - val_loss: 6.5852\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9321 - val_loss: 6.8454\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7252 - val_loss: 6.5718\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6961 - val_loss: 6.5207\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6802 - val_loss: 6.5236\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6450 - val_loss: 6.9239\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5977 - val_loss: 7.0062\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8621 - val_loss: 6.5905\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7311 - val_loss: 6.8039\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.9600 - val_loss: 6.7832\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6806 - val_loss: 7.0109\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6082 - val_loss: 6.9344\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7619 - val_loss: 6.8816\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6899 - val_loss: 6.6451\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9175 - val_loss: 6.7424\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5018 - val_loss: 6.9898\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0467 - val_loss: 7.4640\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8276 - val_loss: 6.9215\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5987 - val_loss: 6.7846\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6093 - val_loss: 6.7390\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.7465 - val_loss: 6.8841\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6931 - val_loss: 7.3171\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7119 - val_loss: 6.8913\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5155 - val_loss: 6.9714\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7151 - val_loss: 6.7661\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6079 - val_loss: 7.1369\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6986 - val_loss: 6.8108\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6476 - val_loss: 6.7587\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9083 - val_loss: 7.3128\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7999 - val_loss: 7.1777\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1240 - val_loss: 7.1607\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9239 - val_loss: 7.3073\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9387 - val_loss: 6.8606\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5730 - val_loss: 6.7795\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7379 - val_loss: 6.8358\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5571 - val_loss: 7.1972\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5432 - val_loss: 6.8476\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6228 - val_loss: 7.0174\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5922 - val_loss: 7.2607\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5614 - val_loss: 7.1087\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5723 - val_loss: 6.8017\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5888 - val_loss: 7.0362\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4778 - val_loss: 6.9179\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5983 - val_loss: 7.1761\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5240 - val_loss: 7.0729\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4593 - val_loss: 6.9377\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4609 - val_loss: 7.1108\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6718 - val_loss: 7.1520\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7092 - val_loss: 7.2043\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6472 - val_loss: 6.9917\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7342 - val_loss: 6.9524\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6531 - val_loss: 7.1105\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.5444 - val_loss: 6.8938\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6105 - val_loss: 7.1399\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4749 - val_loss: 7.1023\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4648 - val_loss: 7.0543\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5448 - val_loss: 6.9077\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5324 - val_loss: 7.3464\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5605 - val_loss: 7.1390\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5731 - val_loss: 7.0519\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5086 - val_loss: 7.0207\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4404 - val_loss: 7.1228\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4376 - val_loss: 7.1949\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4410 - val_loss: 7.2252\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4599 - val_loss: 7.0200\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.5567 - val_loss: 7.3110\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7406 - val_loss: 7.3788\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5221 - val_loss: 7.0136\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4770 - val_loss: 7.0687\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5755 - val_loss: 7.3551\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7253 - val_loss: 7.4794\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4175 - val_loss: 7.1692\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3888 - val_loss: 7.1027\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5409 - val_loss: 7.6581\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9194 - val_loss: 7.1691\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7312 - val_loss: 7.4906\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6052 - val_loss: 7.1030\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4040 - val_loss: 7.2590\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7479 - val_loss: 7.2667\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4677 - val_loss: 7.1327\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4100 - val_loss: 7.1576\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4207 - val_loss: 7.8314\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6626 - val_loss: 7.2401\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5295 - val_loss: 7.4832\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7612 - val_loss: 7.1041\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6779 - val_loss: 7.5622\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5228 - val_loss: 7.1803\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4060 - val_loss: 7.2189\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4641 - val_loss: 7.4535\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4548 - val_loss: 7.5242\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4224 - val_loss: 7.2082\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4324 - val_loss: 7.1125\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4346 - val_loss: 7.3644\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6493 - val_loss: 7.5789\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7161 - val_loss: 7.6057\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8489 - val_loss: 7.1732\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5012 - val_loss: 7.1976\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3034 - val_loss: 7.2663\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3667 - val_loss: 7.1829\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5584 - val_loss: 7.4277\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1735 - val_loss: 7.1284\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6303 - val_loss: 7.6268\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3419 - val_loss: 7.1901\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4431 - val_loss: 7.4274\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4180 - val_loss: 7.3361\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5968 - val_loss: 7.6487\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4882 - val_loss: 7.5143\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3852 - val_loss: 7.5331\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6158 - val_loss: 6.9007\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4892 - val_loss: 7.5868\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7435 - val_loss: 7.6142\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5143 - val_loss: 7.3782\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5735 - val_loss: 7.3494\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4028 - val_loss: 7.1508\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6124 - val_loss: 7.1352\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5093 - val_loss: 7.5160\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2793 - val_loss: 7.3360\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3097 - val_loss: 7.3967\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3019 - val_loss: 7.2325\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2806 - val_loss: 7.2749\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3386 - val_loss: 7.2521\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3828 - val_loss: 7.3197\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4481 - val_loss: 7.5423\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3392 - val_loss: 7.6446\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2356 - val_loss: 7.2588\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3540 - val_loss: 7.5364\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3173 - val_loss: 7.2771\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2852 - val_loss: 7.4853\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2806 - val_loss: 7.4090\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3010 - val_loss: 7.5912\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4374 - val_loss: 7.4471\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2771 - val_loss: 7.4553\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1911 - val_loss: 7.3129\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1891 - val_loss: 7.3489\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2774 - val_loss: 7.5954\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3137 - val_loss: 7.5661\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3131 - val_loss: 7.6878\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4049 - val_loss: 7.4863\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2221 - val_loss: 7.3497\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3045 - val_loss: 7.7141\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2825 - val_loss: 7.4523\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2471 - val_loss: 7.4532\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 6.3785 - val_loss: 7.8604\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3103 - val_loss: 7.3850\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2641 - val_loss: 7.5877\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3397 - val_loss: 7.7825\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4968 - val_loss: 7.3268\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3449 - val_loss: 7.7831\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4278 - val_loss: 7.8216\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3130 - val_loss: 7.6973\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3982 - val_loss: 7.6528\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2588 - val_loss: 7.6249\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3438 - val_loss: 7.1790\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3371 - val_loss: 7.5691\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3285 - val_loss: 7.6489\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2459 - val_loss: 7.3008\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3137 - val_loss: 7.6339\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1448 - val_loss: 7.5524\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2156 - val_loss: 7.8864\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3619 - val_loss: 7.3143\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3292 - val_loss: 7.6054\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5767 - val_loss: 7.7426\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4026 - val_loss: 7.7801\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5884 - val_loss: 7.9894\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6217 - val_loss: 7.6303\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2313 - val_loss: 7.3570\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2188 - val_loss: 7.4482\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1760 - val_loss: 8.1048\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8132 - val_loss: 7.6414\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3080 - val_loss: 7.6634\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3492 - val_loss: 7.7222\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2539 - val_loss: 7.4930\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2112 - val_loss: 7.4189\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2308 - val_loss: 7.3834\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4811 - val_loss: 7.6373\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.2535 - val_loss: 7.7992\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2444 - val_loss: 7.3174\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1783 - val_loss: 7.5662\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1760 - val_loss: 7.3903\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3392 - val_loss: 7.5269\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3466 - val_loss: 7.4251\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5391 - val_loss: 7.8708\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2817 - val_loss: 7.1105\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1010 - val_loss: 8.3826\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7595 - val_loss: 7.4281\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3846 - val_loss: 8.1137\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4718 - val_loss: 7.4367\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3579 - val_loss: 7.5439\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2463 - val_loss: 7.3807\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2139 - val_loss: 7.2455\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4558 - val_loss: 7.4241\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6317 - val_loss: 7.6135\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.1642 - val_loss: 7.2483\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1021 - val_loss: 7.6921\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1651 - val_loss: 7.3051\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1911 - val_loss: 7.4113\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2966 - val_loss: 7.2923\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2406 - val_loss: 7.5450\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2462 - val_loss: 7.5534\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3914 - val_loss: 7.6395\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1078 - val_loss: 7.3759\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1470 - val_loss: 7.2817\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1375 - val_loss: 7.4666\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1293 - val_loss: 7.7511\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2434 - val_loss: 7.5197\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.1854 - val_loss: 7.2074\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.1354 - val_loss: 7.5947\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0953 - val_loss: 7.5331\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3418 - val_loss: 7.4507\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0958 - val_loss: 7.5357\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3205 - val_loss: 7.5362\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7131 - val_loss: 7.5776\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6129 - val_loss: 7.4394\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1532 - val_loss: 7.5486\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1491 - val_loss: 7.4920\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1836 - val_loss: 7.5518\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1631 - val_loss: 7.3006\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0694 - val_loss: 7.6921\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1565 - val_loss: 7.7180\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.1930 - val_loss: 7.2796\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1797 - val_loss: 7.3140\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4321 - val_loss: 7.9170\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3520 - val_loss: 7.3473\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2336 - val_loss: 7.5691\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3495 - val_loss: 7.6390\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4360 - val_loss: 7.5202\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1325 - val_loss: 7.4677\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1948 - val_loss: 7.3342\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1247 - val_loss: 7.3487\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0654 - val_loss: 7.4477\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0936 - val_loss: 7.3958\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1850 - val_loss: 7.3074\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2450 - val_loss: 7.5320\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1459 - val_loss: 7.8006\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1630 - val_loss: 7.2983\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1902 - val_loss: 7.3516\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2162 - val_loss: 7.4170\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2068 - val_loss: 7.7273\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2534 - val_loss: 7.4478\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4137 - val_loss: 7.5522\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1880 - val_loss: 7.4021\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1781 - val_loss: 7.3822\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2192 - val_loss: 7.2854\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2963 - val_loss: 7.9170\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2890 - val_loss: 7.7251\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2612 - val_loss: 7.1317\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1734 - val_loss: 7.2916\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1806 - val_loss: 7.6512\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2540 - val_loss: 7.4475\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1807 - val_loss: 7.3461\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2518 - val_loss: 7.8646\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3143 - val_loss: 7.4749\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0797 - val_loss: 7.3385\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2142 - val_loss: 7.5177\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2124 - val_loss: 7.4526\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1467 - val_loss: 7.4872\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0446 - val_loss: 7.2398\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0522 - val_loss: 7.3396\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.1019 - val_loss: 7.5798\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0904 - val_loss: 7.3253\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0769 - val_loss: 7.2317\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7247 - val_loss: 7.8572\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7819 - val_loss: 7.2422\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.410 - 0s 101us/step - loss: 6.8158 - val_loss: 7.6846\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1951 - val_loss: 7.5203\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1964 - val_loss: 7.3508\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2283 - val_loss: 7.3999\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0575 - val_loss: 7.1993\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0871 - val_loss: 7.4985\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0412 - val_loss: 7.4121\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2047 - val_loss: 7.2808\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1794 - val_loss: 7.2668\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1580 - val_loss: 7.3807\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0378 - val_loss: 7.4352\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1796 - val_loss: 7.4006\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1428 - val_loss: 7.4633\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0356 - val_loss: 7.6098\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3481 - val_loss: 7.4008\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1345 - val_loss: 7.7174\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0813 - val_loss: 7.7210\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1886 - val_loss: 7.7606\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2291 - val_loss: 7.0501\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2705 - val_loss: 7.5836\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1568 - val_loss: 7.5464\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2288 - val_loss: 7.3545\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4048 - val_loss: 7.4514\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0972 - val_loss: 7.2822\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4179 - val_loss: 7.9566\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4802 - val_loss: 7.3607\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4627 - val_loss: 7.8256\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3925 - val_loss: 7.2424\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1028 - val_loss: 7.3146\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1500 - val_loss: 7.5979\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0045 - val_loss: 7.5347\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0910 - val_loss: 7.6126\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4871 - val_loss: 7.1234\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.3518 - val_loss: 7.9809\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1912 - val_loss: 7.1969\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3571 - val_loss: 7.6112\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0680 - val_loss: 7.8059\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1608 - val_loss: 7.2711\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5458 - val_loss: 7.3074\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7546 - val_loss: 7.6404\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2721 - val_loss: 7.6727\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1619 - val_loss: 7.1602\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2223 - val_loss: 7.3507\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1639 - val_loss: 7.1851\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.4085 - val_loss: 7.2481\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0082 - val_loss: 8.1207\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2322 - val_loss: 7.2888\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1325 - val_loss: 7.2441\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0335 - val_loss: 7.2365\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0037 - val_loss: 7.5359\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0718 - val_loss: 7.6174\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0884 - val_loss: 7.6976\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1703 - val_loss: 7.4795\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5463 - val_loss: 7.6843\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3317 - val_loss: 7.1111\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0571 - val_loss: 7.4568\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0900 - val_loss: 7.4770\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2890 - val_loss: 7.5099\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2204 - val_loss: 7.7500\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1039 - val_loss: 7.1252\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1676 - val_loss: 7.2806\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0990 - val_loss: 7.8090\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2171 - val_loss: 7.8255\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0828 - val_loss: 7.3170\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2140 - val_loss: 7.4861\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4077 - val_loss: 7.1843\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6800 - val_loss: 7.4891\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9184 - val_loss: 7.2805\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8081 - val_loss: 7.5559\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4433 - val_loss: 7.4414\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1927 - val_loss: 7.2977\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1395 - val_loss: 7.2096\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2903 - val_loss: 7.2924\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9433 - val_loss: 7.5371\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0061 - val_loss: 7.4956\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2317 - val_loss: 7.3049\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0293 - val_loss: 7.3243\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0135 - val_loss: 7.3008\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9874 - val_loss: 7.4533\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1328 - val_loss: 7.5069\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9904 - val_loss: 7.5517\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1346 - val_loss: 7.5202\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2320 - val_loss: 7.2621\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.1107 - val_loss: 7.5998\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9638 - val_loss: 7.3320\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0966 - val_loss: 7.4142\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0062 - val_loss: 7.6036\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2790 - val_loss: 7.4754\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0645 - val_loss: 7.1852\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9905 - val_loss: 7.4002\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9775 - val_loss: 7.3680\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1909 - val_loss: 7.4271\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1335 - val_loss: 7.3740\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1627 - val_loss: 7.4066\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1005 - val_loss: 7.3450\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0300 - val_loss: 7.1688\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0372 - val_loss: 7.6008\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0232 - val_loss: 7.2600\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0232 - val_loss: 7.5641\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1147 - val_loss: 7.4089\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2147 - val_loss: 7.3226\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1325 - val_loss: 7.3919\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0828 - val_loss: 7.7481\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9886 - val_loss: 7.4630\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0026 - val_loss: 7.4912\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0870 - val_loss: 7.4358\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0478 - val_loss: 7.5848\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0830 - val_loss: 7.6327\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1657 - val_loss: 7.4930\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1038 - val_loss: 7.4147\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.9613 - val_loss: 7.1471\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1263 - val_loss: 7.1524\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1060 - val_loss: 7.7257\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0922 - val_loss: 7.2238\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1413 - val_loss: 7.4997\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9771 - val_loss: 7.5895\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1679 - val_loss: 7.4703\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0293 - val_loss: 7.7334\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1320 - val_loss: 7.4604\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0450 - val_loss: 7.2100\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1670 - val_loss: 7.5606\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5667 - val_loss: 7.4933\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2777 - val_loss: 7.3461\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0180 - val_loss: 7.3703\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9368 - val_loss: 7.2051\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9911 - val_loss: 7.1900\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9820 - val_loss: 7.0706\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2021 - val_loss: 7.2800\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3457 - val_loss: 7.9481\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1201 - val_loss: 7.3918\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3635 - val_loss: 7.5993\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2804 - val_loss: 7.5012\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1886 - val_loss: 7.1996\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0305 - val_loss: 7.2231\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0270 - val_loss: 7.2272\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2322 - val_loss: 7.3365\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1054 - val_loss: 7.5079\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0430 - val_loss: 7.4661\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1289 - val_loss: 7.1018\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5069 - val_loss: 7.5710\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0297 - val_loss: 7.5713\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0431 - val_loss: 7.6099\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1936 - val_loss: 7.2561\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2905 - val_loss: 7.6192\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3693 - val_loss: 7.3446\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0727 - val_loss: 7.9796\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0612 - val_loss: 7.4059\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0462 - val_loss: 7.3524\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2481 - val_loss: 7.3033\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2097 - val_loss: 7.6477\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5816 - val_loss: 7.4263\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0269 - val_loss: 7.3865\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0308 - val_loss: 7.4016\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0321 - val_loss: 7.5623\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2051 - val_loss: 7.4561\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9719 - val_loss: 7.3196\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0548 - val_loss: 7.7064\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1286 - val_loss: 7.7231\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2087 - val_loss: 8.2055\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4540 - val_loss: 7.0941\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1336 - val_loss: 7.4812\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9080 - val_loss: 7.2139\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9962 - val_loss: 7.9506\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0744 - val_loss: 7.2445\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2321 - val_loss: 7.2362\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1649 - val_loss: 7.6821\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0412 - val_loss: 7.6351\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1203 - val_loss: 7.2432\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9407 - val_loss: 7.3686\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8956 - val_loss: 7.4284\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9934 - val_loss: 7.3430\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9749 - val_loss: 7.4176\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1573 - val_loss: 7.5586\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0952 - val_loss: 7.8315\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0388 - val_loss: 7.4024\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9558 - val_loss: 7.5155\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1059 - val_loss: 7.6905\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9170 - val_loss: 7.7759\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9310 - val_loss: 7.3399\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1984 - val_loss: 7.2040\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2047 - val_loss: 7.7344\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1102 - val_loss: 7.5341\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9259 - val_loss: 7.2001\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9766 - val_loss: 7.1995\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9912 - val_loss: 7.5175\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0080 - val_loss: 7.4696\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0565 - val_loss: 7.7070\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.0497 - val_loss: 7.5863\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1002 - val_loss: 7.4730\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0324 - val_loss: 7.5288\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0286 - val_loss: 7.4694\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0288 - val_loss: 7.3934\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1195 - val_loss: 7.2267\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9565 - val_loss: 7.5745\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9325 - val_loss: 7.8895\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1052 - val_loss: 7.3948\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0261 - val_loss: 7.8310\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0088 - val_loss: 7.2239\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1598 - val_loss: 7.6088\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9686 - val_loss: 7.6088\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9653 - val_loss: 7.2464\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0208 - val_loss: 7.4220\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.9908 - val_loss: 7.6797\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1339 - val_loss: 7.4696\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0461 - val_loss: 7.8547\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0672 - val_loss: 7.3602\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9373 - val_loss: 7.8246\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0305 - val_loss: 7.6853\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3925 - val_loss: 7.2890\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2856 - val_loss: 7.8856\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1348 - val_loss: 7.6483\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0043 - val_loss: 7.8027\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8928 - val_loss: 7.2378\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8822 - val_loss: 7.3471\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9033 - val_loss: 7.3668\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0080 - val_loss: 7.6365\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4095 - val_loss: 7.3820\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0554 - val_loss: 7.5993\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0406 - val_loss: 7.6117\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3263 - val_loss: 7.4965\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0728 - val_loss: 7.8017\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0399 - val_loss: 7.7709\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0963 - val_loss: 7.2352\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9733 - val_loss: 7.4826\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0918 - val_loss: 7.3608\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1423 - val_loss: 8.0574\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3200 - val_loss: 7.4616\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4201 - val_loss: 8.0255\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4916 - val_loss: 7.5307\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2755 - val_loss: 7.4987\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0032 - val_loss: 7.8470\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1458 - val_loss: 7.3743\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1345 - val_loss: 7.6885\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0525 - val_loss: 7.9278\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4378 - val_loss: 7.4714\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0294 - val_loss: 7.5681\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9870 - val_loss: 7.3843\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9675 - val_loss: 7.6890\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0333 - val_loss: 7.3299\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9536 - val_loss: 7.5796\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0253 - val_loss: 7.6921\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1139 - val_loss: 7.4629\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9945 - val_loss: 7.5179\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9571 - val_loss: 7.4930\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8957 - val_loss: 7.4392\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0588 - val_loss: 7.2176\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9670 - val_loss: 7.5426\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8771 - val_loss: 7.9001\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9832 - val_loss: 8.0772\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2626 - val_loss: 7.3293\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2592 - val_loss: 8.2030\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9503 - val_loss: 7.6239\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1084 - val_loss: 7.1780\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0204 - val_loss: 7.2117\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9672 - val_loss: 7.9111\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9817 - val_loss: 7.6213\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0511 - val_loss: 7.6502\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9621 - val_loss: 7.4342\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0811 - val_loss: 8.1317\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2893 - val_loss: 7.7505\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2251 - val_loss: 7.5298\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8876 - val_loss: 7.5638\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0759 - val_loss: 7.5524\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9254 - val_loss: 7.4498\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.8685 - val_loss: 7.4473\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.149 - 0s 102us/step - loss: 5.9742 - val_loss: 7.3747\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9502 - val_loss: 7.7020\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0007 - val_loss: 7.5988\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9008 - val_loss: 7.3730\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9552 - val_loss: 7.5037\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8928 - val_loss: 7.6056\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0571 - val_loss: 7.7234\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9282 - val_loss: 7.7128\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0473 - val_loss: 7.4847\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9847 - val_loss: 7.4679\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9945 - val_loss: 7.4948\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2058 - val_loss: 8.0368\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5471 - val_loss: 7.5411\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3716 - val_loss: 7.5777\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2585 - val_loss: 7.4666\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2422 - val_loss: 7.5240\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2557 - val_loss: 7.3001\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9409 - val_loss: 7.8755\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9395 - val_loss: 7.5499\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8813 - val_loss: 7.5932\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0668 - val_loss: 7.5219\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3563 - val_loss: 7.3493\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0400 - val_loss: 7.3651\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0561 - val_loss: 7.3919\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9186 - val_loss: 7.4008\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9451 - val_loss: 7.5666\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9402 - val_loss: 7.6210\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.8921 - val_loss: 7.4814\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0187 - val_loss: 7.7040\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0268 - val_loss: 7.2761\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9449 - val_loss: 7.4932\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1070 - val_loss: 7.9001\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1356 - val_loss: 7.3087\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9830 - val_loss: 7.5611\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9449 - val_loss: 7.7277\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3828 - val_loss: 8.1046\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5756 - val_loss: 7.1626\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3864 - val_loss: 7.4207\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1039 - val_loss: 7.6079\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1606 - val_loss: 7.3994\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1560 - val_loss: 7.2992\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3439 - val_loss: 7.8943\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0500 - val_loss: 7.5912\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9630 - val_loss: 7.2426\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8584 - val_loss: 7.4877\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9202 - val_loss: 7.6084\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9394 - val_loss: 7.7581\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1834 - val_loss: 7.4726\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1256 - val_loss: 7.6064\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9096 - val_loss: 7.2652\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9494 - val_loss: 7.8060\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3607 - val_loss: 7.4031\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2741 - val_loss: 7.3413\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3755 - val_loss: 7.7897\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0622 - val_loss: 7.3008\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9542 - val_loss: 7.5526\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0346 - val_loss: 7.4507\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4072 - val_loss: 7.5012\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9689 - val_loss: 7.2941\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1890 - val_loss: 7.6536\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3328 - val_loss: 7.7510\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1646 - val_loss: 7.2697\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0921 - val_loss: 7.8103\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9694 - val_loss: 7.7417\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9986 - val_loss: 7.2960\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9472 - val_loss: 7.1800\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9420 - val_loss: 7.4811\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9998 - val_loss: 7.8709\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9870 - val_loss: 7.3449\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8643 - val_loss: 7.6315\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5408 - val_loss: 7.8357\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1229 - val_loss: 7.3425\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0570 - val_loss: 7.6397\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9669 - val_loss: 7.4383\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.9943 - val_loss: 7.6470\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9651 - val_loss: 7.5887\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9041 - val_loss: 7.2781\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9315 - val_loss: 7.7101\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9063 - val_loss: 7.2375\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8910 - val_loss: 7.6352\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2653 - val_loss: 7.7638\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2364 - val_loss: 7.2948\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0248 - val_loss: 7.6227\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2499 - val_loss: 8.1617\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2264 - val_loss: 7.3078\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9531 - val_loss: 7.5993\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9288 - val_loss: 7.8024\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0827 - val_loss: 7.2571\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5163 - val_loss: 7.7769\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1731 - val_loss: 7.3722\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1282 - val_loss: 7.5404\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9873 - val_loss: 7.4818\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9289 - val_loss: 7.6205\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9821 - val_loss: 7.4510\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0176 - val_loss: 7.5068\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9505 - val_loss: 7.8570\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9715 - val_loss: 7.5039\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0724 - val_loss: 7.3208\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8926 - val_loss: 7.3865\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8673 - val_loss: 7.5155\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0102 - val_loss: 7.3798\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0012 - val_loss: 7.3537\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1244 - val_loss: 7.5357\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9086 - val_loss: 7.4978\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9776 - val_loss: 7.5579\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2372 - val_loss: 7.4734\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2119 - val_loss: 7.8707\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1832 - val_loss: 7.4035\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0333 - val_loss: 7.4132\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9678 - val_loss: 7.8034\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9540 - val_loss: 7.5703\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0267 - val_loss: 7.7084\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9780 - val_loss: 7.6522\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0043 - val_loss: 7.6924\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0083 - val_loss: 7.8239\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8672 - val_loss: 7.4383\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9186 - val_loss: 7.3846\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9563 - val_loss: 7.1945\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9983 - val_loss: 7.6414\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9320 - val_loss: 7.7046\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9945 - val_loss: 7.5296\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8828 - val_loss: 7.8403\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9359 - val_loss: 7.6192\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9439 - val_loss: 7.6367\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0365 - val_loss: 7.6866\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2854 - val_loss: 7.7755\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0591 - val_loss: 7.2863\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0156 - val_loss: 7.5542\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9398 - val_loss: 7.3512\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0524 - val_loss: 7.8547\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9588 - val_loss: 7.4794\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8844 - val_loss: 7.7358\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9724 - val_loss: 7.5443\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9229 - val_loss: 7.6309\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5601 - val_loss: 7.9064\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3130 - val_loss: 7.3034\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8782 - val_loss: 7.4632\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8741 - val_loss: 7.5742\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9307 - val_loss: 7.4265\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8764 - val_loss: 7.4474\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8284 - val_loss: 7.6473\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9159 - val_loss: 7.6935\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0148 - val_loss: 7.5015\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8501 - val_loss: 7.7779\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8420 - val_loss: 7.5229\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8688 - val_loss: 7.6887\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8708 - val_loss: 7.2054\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9167 - val_loss: 7.7377\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8858 - val_loss: 7.7248\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9612 - val_loss: 7.1833\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8783 - val_loss: 7.7808\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9445 - val_loss: 7.4296\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8957 - val_loss: 7.5919\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.1064 - val_loss: 7.6345\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8710 - val_loss: 7.5262\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9020 - val_loss: 7.3175\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8060 - val_loss: 7.7679\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8790 - val_loss: 7.3873\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9302 - val_loss: 7.4819\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8183 - val_loss: 7.3258\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9173 - val_loss: 7.8066\n",
      "6.3480804087752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0224689 ,  0.21921225, -1.1375356 , -0.08617499, -0.6026804 ],\n",
       "        [ 0.3352115 , -1.1281157 ,  2.3970206 , -1.3281008 ,  1.9482923 ],\n",
       "        [-0.9176933 , -0.5032424 ,  0.69182867, -0.5090911 ,  0.6385779 ],\n",
       "        [-1.8379833 ,  0.02913589, -0.9780376 ,  0.72872293, -0.9419593 ],\n",
       "        [ 0.32177228, -1.1819646 , -0.4367179 ,  0.804513  , -0.80972   ],\n",
       "        [ 0.5592985 , -1.0580313 ,  0.41903102,  1.0395093 , -0.6335145 ],\n",
       "        [ 0.9933881 , -0.78222674, -0.23747157,  0.0714065 , -0.8467175 ]],\n",
       "       dtype=float32),\n",
       " array([-0.02740788,  1.3033552 ,  0.9431078 ,  0.26118585, -0.67131895],\n",
       "       dtype=float32),\n",
       " array([[-0.48873132,  0.6381111 ,  0.77224   , -0.48103845, -0.30789974,\n",
       "          1.1727566 , -0.34275046, -0.6356171 ,  0.71848613,  0.36373696],\n",
       "        [-0.45638183, -0.03181658,  0.5789742 , -0.17507464,  1.5215681 ,\n",
       "          0.5056999 , -0.687918  , -0.34925434,  0.23410194,  0.49957067],\n",
       "        [-0.5559578 ,  1.7359191 ,  0.96456647, -0.75845027, -1.536999  ,\n",
       "          1.0762376 , -1.0112334 , -0.36234227,  0.45018432,  1.0021927 ],\n",
       "        [-0.40072265,  0.7434935 , -0.03376557, -0.06300794,  0.1580502 ,\n",
       "          1.1190757 , -0.13515134, -0.2556062 ,  0.82357526,  0.6493571 ],\n",
       "        [-0.18399751, -2.4632678 , -0.8746965 , -0.19232428, -0.18322407,\n",
       "         -0.65984017, -0.70566416, -0.29851326, -0.10862739, -1.0713463 ]],\n",
       "       dtype=float32),\n",
       " array([-0.39850917,  1.4213312 ,  1.6735082 , -0.5925455 ,  1.0583918 ,\n",
       "         1.7767446 , -0.5980822 , -0.7266292 ,  1.6590344 ,  1.7123712 ],\n",
       "       dtype=float32),\n",
       " array([[0.22533809],\n",
       "        [1.0419443 ],\n",
       "        [0.78605473],\n",
       "        [0.4739626 ],\n",
       "        [1.0393306 ],\n",
       "        [1.183083  ],\n",
       "        [0.17431411],\n",
       "        [0.34016624],\n",
       "        [0.6812132 ],\n",
       "        [1.014586  ]], dtype=float32),\n",
       " array([1.7262235], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_relu(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_relu_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 770us/step - loss: 535.7743 - val_loss: 460.3685\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 374.1550 - val_loss: 339.0770\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 265.6770 - val_loss: 236.0250\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 187.0815 - val_loss: 170.5829\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 136.5474 - val_loss: 129.6147\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 106.3084 - val_loss: 100.8482\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 81.7341 - val_loss: 78.4526\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 67.6048 - val_loss: 66.4265\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 59.5819 - val_loss: 58.7112\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 54.5588 - val_loss: 53.4850\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 51.1092 - val_loss: 50.1535\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 48.7885 - val_loss: 48.1067\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 47.1364 - val_loss: 46.6165\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 45.8275 - val_loss: 45.5704\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 44.9095 - val_loss: 44.6580\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 44.0213 - val_loss: 43.7920\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 43.2824 - val_loss: 42.8109\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 42.4907 - val_loss: 42.1217\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 41.8095 - val_loss: 41.4473\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 41.1248 - val_loss: 40.8209\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 40.3582 - val_loss: 40.1160\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 39.5900 - val_loss: 39.7752\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 38.9468 - val_loss: 38.9521\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 38.2427 - val_loss: 38.5030\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 37.6502 - val_loss: 37.9848\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 37.0238 - val_loss: 37.4910\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 36.4775 - val_loss: 36.9479\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 35.8920 - val_loss: 36.5173\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 35.3496 - val_loss: 36.0394\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 34.8441 - val_loss: 35.5080\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 34.3627 - val_loss: 34.9536\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 33.8103 - val_loss: 34.3741\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 33.3065 - val_loss: 33.7239\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 32.7701 - val_loss: 33.1114\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 32.3187 - val_loss: 32.5392\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 31.8917 - val_loss: 31.9766\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 31.3658 - val_loss: 31.5562\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 30.9409 - val_loss: 31.1506\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 30.5349 - val_loss: 30.6658\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 30.0582 - val_loss: 30.2197\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 29.6823 - val_loss: 29.7322\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 29.2794 - val_loss: 29.2836\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.8623 - val_loss: 28.9627\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.5044 - val_loss: 28.6665\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.1403 - val_loss: 28.2686\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 27.7831 - val_loss: 27.9514\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 27.4386 - val_loss: 27.6557\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 27.1979 - val_loss: 27.0181\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 26.7167 - val_loss: 26.9058\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 26.4501 - val_loss: 26.7127\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 26.1245 - val_loss: 26.4879\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 25.8021 - val_loss: 26.1102\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 25.5119 - val_loss: 25.6360\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 25.2096 - val_loss: 25.0836\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 24.9522 - val_loss: 25.1694\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 24.6603 - val_loss: 24.9071\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 24.3772 - val_loss: 24.8649\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 24.1026 - val_loss: 24.5952\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 23.8499 - val_loss: 24.2777\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 23.5838 - val_loss: 24.1125\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 23.4197 - val_loss: 23.9585\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 23.0766 - val_loss: 23.9021\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 22.8351 - val_loss: 23.6603\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 22.6355 - val_loss: 23.3979\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 22.3901 - val_loss: 23.3017\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 22.1811 - val_loss: 23.2360\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 21.9995 - val_loss: 23.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 21.7279 - val_loss: 22.9875\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 21.5534 - val_loss: 22.8507\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 21.3175 - val_loss: 22.5180\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 21.1537 - val_loss: 22.6243\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 20.9100 - val_loss: 22.4975\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 20.7677 - val_loss: 22.3134\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 20.5264 - val_loss: 21.5115\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 20.3503 - val_loss: 21.9178\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 20.1753 - val_loss: 21.8753\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 20.0082 - val_loss: 21.5071\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.9069 - val_loss: 21.6540\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.6737 - val_loss: 21.4536\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 19.5073 - val_loss: 21.5258\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.3196 - val_loss: 21.3232\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 19.2165 - val_loss: 21.4132\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 19.0798 - val_loss: 21.2316\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 18.8425 - val_loss: 21.0849\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 18.7086 - val_loss: 21.0154\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 18.5856 - val_loss: 20.7597\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 18.4432 - val_loss: 20.8565\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.3444 - val_loss: 20.6715\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.1301 - val_loss: 20.5964\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.9963 - val_loss: 20.4640\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.9121 - val_loss: 20.5412\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.7521 - val_loss: 20.4315\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.6329 - val_loss: 20.2963\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.4860 - val_loss: 20.3822\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 17.3701 - val_loss: 20.2512\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 17.2620 - val_loss: 19.9332\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.1778 - val_loss: 20.2316\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.0963 - val_loss: 20.0558\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 16.9536 - val_loss: 19.7833\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 16.8084 - val_loss: 19.9513\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.7373 - val_loss: 19.7911\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 16.6000 - val_loss: 19.8336\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.4866 - val_loss: 19.8194\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.3924 - val_loss: 19.6079\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.2797 - val_loss: 19.6088\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 16.1851 - val_loss: 19.6658\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.1286 - val_loss: 19.5166\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.0168 - val_loss: 19.6027\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.9424 - val_loss: 19.4864\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.8308 - val_loss: 19.1536\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.7590 - val_loss: 19.2236\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.6640 - val_loss: 19.2150\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.5842 - val_loss: 19.2122\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.5353 - val_loss: 19.2619\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.4092 - val_loss: 18.9418\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.3897 - val_loss: 19.3318\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.2718 - val_loss: 19.1814\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1975 - val_loss: 19.0497\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.1428 - val_loss: 19.1087\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.0081 - val_loss: 18.9789\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.9744 - val_loss: 19.1853\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.8875 - val_loss: 19.1399\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.7824 - val_loss: 18.8039\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.7531 - val_loss: 18.8914\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.6891 - val_loss: 19.1760\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.6037 - val_loss: 18.9302\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.5545 - val_loss: 18.7262\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.4510 - val_loss: 18.9606\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.4180 - val_loss: 18.7306\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 14.3323 - val_loss: 18.5772\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.2683 - val_loss: 18.8890\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.2213 - val_loss: 18.6467\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.1478 - val_loss: 18.7090\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 14.1488 - val_loss: 18.4641\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.0427 - val_loss: 17.9838\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.0315 - val_loss: 18.7781\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 13.9802 - val_loss: 18.4748\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.7905 - val_loss: 18.2746\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.7888 - val_loss: 18.4341\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 13.6743 - val_loss: 18.4635\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.6896 - val_loss: 18.2443\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 13.5386 - val_loss: 18.2883\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 13.4765 - val_loss: 18.4351\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 13.3392 - val_loss: 18.4650\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.2081 - val_loss: 18.2924\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.2246 - val_loss: 18.2873\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.1411 - val_loss: 18.3032\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.0662 - val_loss: 18.2494\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.9177 - val_loss: 18.1826\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 12.8575 - val_loss: 18.1444\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.7901 - val_loss: 18.1119\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.7404 - val_loss: 17.9444\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.6734 - val_loss: 17.9555\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 12.5898 - val_loss: 18.0716\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.5400 - val_loss: 18.0277\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 12.4545 - val_loss: 18.0751\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.3590 - val_loss: 18.0038\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.3383 - val_loss: 18.2118\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.3197 - val_loss: 17.9913\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.1885 - val_loss: 17.8546\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.2227 - val_loss: 17.7201\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.1392 - val_loss: 17.8295\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.0455 - val_loss: 17.6817\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.0601 - val_loss: 17.8505\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 17.88 - 0s 100us/step - loss: 11.9816 - val_loss: 17.6114\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.7734 - val_loss: 17.9660\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.8494 - val_loss: 17.7456\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 11.7748 - val_loss: 17.5300\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.6532 - val_loss: 17.6597\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.6111 - val_loss: 17.6324\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.5415 - val_loss: 17.4624\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.4699 - val_loss: 17.4549\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.4427 - val_loss: 17.4378\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.4107 - val_loss: 17.4664\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.3586 - val_loss: 17.4150\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.3508 - val_loss: 17.1961\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.2458 - val_loss: 17.5614\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.1775 - val_loss: 17.4240\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 11.1136 - val_loss: 17.2179\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 11.0725 - val_loss: 17.1637\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.0584 - val_loss: 17.3745\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 10.9828 - val_loss: 17.1392\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.8777 - val_loss: 16.9753\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 10.8542 - val_loss: 17.1468\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.8444 - val_loss: 17.0147\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.7505 - val_loss: 16.9328\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.7165 - val_loss: 16.9984\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.6240 - val_loss: 17.2644\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.6211 - val_loss: 17.1509\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 10.5580 - val_loss: 17.1791\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.4874 - val_loss: 17.0192\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.5039 - val_loss: 17.0820\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.5188 - val_loss: 17.2379\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.5180 - val_loss: 16.6710\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.3473 - val_loss: 16.7941\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.2421 - val_loss: 16.7668\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.2554 - val_loss: 16.7237\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.3166 - val_loss: 16.7240\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.0772 - val_loss: 16.3884\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.6654 - val_loss: 15.7407\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.4364 - val_loss: 15.8651\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.3195 - val_loss: 15.8396\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 9.1474 - val_loss: 15.8040\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 9.1555 - val_loss: 15.6672\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 9.0121 - val_loss: 15.2634\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.9092 - val_loss: 15.4241\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.8830 - val_loss: 15.3440\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7550 - val_loss: 15.1636\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6576 - val_loss: 15.0863\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5870 - val_loss: 15.0113\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.4584 - val_loss: 14.8999\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.4033 - val_loss: 14.8288\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.3438 - val_loss: 14.5372\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3028 - val_loss: 14.3891\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.2467 - val_loss: 14.5525\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1709 - val_loss: 14.3548\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1576 - val_loss: 14.2633\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1366 - val_loss: 14.2902\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0857 - val_loss: 14.1470\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 8.0348 - val_loss: 14.0778\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9910 - val_loss: 14.2091\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9160 - val_loss: 14.0255\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8879 - val_loss: 13.9312\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8750 - val_loss: 13.6548\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8395 - val_loss: 13.6553\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7877 - val_loss: 13.7591\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7336 - val_loss: 13.8079\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7555 - val_loss: 13.7552\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7586 - val_loss: 13.6065\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.6759 - val_loss: 13.6465\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6553 - val_loss: 13.4976\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6343 - val_loss: 13.3361\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.6392 - val_loss: 13.3889\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5584 - val_loss: 13.2678\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5456 - val_loss: 13.1951\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6165 - val_loss: 13.1668\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5494 - val_loss: 13.1244\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5828 - val_loss: 12.9784\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5245 - val_loss: 13.0411\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5348 - val_loss: 12.8270\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.4209 - val_loss: 12.7593\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3382 - val_loss: 12.8310\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3596 - val_loss: 12.5206\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3424 - val_loss: 12.5392\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3243 - val_loss: 12.5589\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2832 - val_loss: 12.4346\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 7.2990 - val_loss: 12.2677\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2523 - val_loss: 12.2844\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2479 - val_loss: 12.2628\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2325 - val_loss: 12.2238\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1929 - val_loss: 12.0932\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.2078 - val_loss: 12.0813\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2208 - val_loss: 12.2743\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1945 - val_loss: 12.1851\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3107 - val_loss: 12.2756\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4163 - val_loss: 12.1275\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4677 - val_loss: 12.4236\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0085 - val_loss: 12.1516\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1571 - val_loss: 12.1322\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0970 - val_loss: 12.2096\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0305 - val_loss: 12.1606\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0002 - val_loss: 11.9770\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0357 - val_loss: 12.1008\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9821 - val_loss: 12.0177\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0616 - val_loss: 12.2501\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9755 - val_loss: 12.1074\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0250 - val_loss: 12.1260\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9536 - val_loss: 12.1065\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9287 - val_loss: 11.8396\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9759 - val_loss: 11.9812\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9014 - val_loss: 11.9486\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8468 - val_loss: 12.0053\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8421 - val_loss: 11.9156\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8499 - val_loss: 11.9231\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8533 - val_loss: 11.9743\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7981 - val_loss: 11.9689\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9638 - val_loss: 11.8770\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8528 - val_loss: 11.8386\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9904 - val_loss: 11.8718\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8346 - val_loss: 11.6839\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8176 - val_loss: 11.9482\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7548 - val_loss: 11.8551\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7954 - val_loss: 12.0829\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7268 - val_loss: 11.9282\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7254 - val_loss: 11.9317\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7147 - val_loss: 11.9118\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6929 - val_loss: 12.0145\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7393 - val_loss: 11.8662\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6931 - val_loss: 11.9418\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6558 - val_loss: 11.8987\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7032 - val_loss: 11.9057\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6493 - val_loss: 11.9738\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7554 - val_loss: 11.8028\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7136 - val_loss: 11.8800\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6595 - val_loss: 12.0209\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6600 - val_loss: 11.9014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5823 - val_loss: 11.8915\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6155 - val_loss: 11.8732\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.5724 - val_loss: 11.8485\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 6.5599 - val_loss: 11.8918\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5319 - val_loss: 11.9125\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5696 - val_loss: 11.8389\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5617 - val_loss: 11.8989\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6133 - val_loss: 11.9403\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4960 - val_loss: 11.8559\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4814 - val_loss: 11.9467\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5681 - val_loss: 11.9157\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4865 - val_loss: 11.8818\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4532 - val_loss: 11.7375\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4489 - val_loss: 11.7596\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5569 - val_loss: 11.8922\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4723 - val_loss: 11.7764\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8002 - val_loss: 11.8394\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4184 - val_loss: 11.8120\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5216 - val_loss: 11.7333\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4796 - val_loss: 11.6973\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4973 - val_loss: 11.8858\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4175 - val_loss: 11.7491\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4218 - val_loss: 11.5833\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4121 - val_loss: 11.7608\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4173 - val_loss: 11.7042\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3694 - val_loss: 11.9025\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5270 - val_loss: 11.8119\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5449 - val_loss: 11.8322\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5157 - val_loss: 11.4316\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5315 - val_loss: 11.6400\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3161 - val_loss: 11.4101\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4519 - val_loss: 11.3557\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3770 - val_loss: 11.1710\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3520 - val_loss: 11.2899\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3638 - val_loss: 11.3916\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3560 - val_loss: 11.3778\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3292 - val_loss: 11.5047\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3524 - val_loss: 11.2791\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3724 - val_loss: 11.5587\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3176 - val_loss: 11.4581\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3528 - val_loss: 11.4141\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.2630 - val_loss: 11.4922\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3059 - val_loss: 11.2920\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2447 - val_loss: 11.3481\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4736 - val_loss: 11.4683\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3487 - val_loss: 11.6015\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4738 - val_loss: 11.3546\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6491 - val_loss: 11.7920\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4036 - val_loss: 11.6317\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3581 - val_loss: 11.5278\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3052 - val_loss: 11.2870\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3409 - val_loss: 11.1975\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2895 - val_loss: 11.1498\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3992 - val_loss: 11.3175\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5859 - val_loss: 11.1449\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3747 - val_loss: 11.6352\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3838 - val_loss: 11.2899\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3146 - val_loss: 11.1470\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1961 - val_loss: 11.0674\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2737 - val_loss: 11.2039\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2000 - val_loss: 11.1823\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2259 - val_loss: 11.2399\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2657 - val_loss: 11.2294\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 198us/step - loss: 6.1788 - val_loss: 11.1789\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.1429 - val_loss: 11.3430\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2529 - val_loss: 11.2125\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1765 - val_loss: 11.2171\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2606 - val_loss: 11.2097\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1599 - val_loss: 11.0907\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2405 - val_loss: 11.1359\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1985 - val_loss: 11.1487\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1903 - val_loss: 11.1108\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2453 - val_loss: 11.3465\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1605 - val_loss: 11.1831\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1204 - val_loss: 11.0030\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1393 - val_loss: 10.9445\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2552 - val_loss: 11.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3538 - val_loss: 11.1537\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2247 - val_loss: 11.1208\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0959 - val_loss: 11.1193\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1301 - val_loss: 11.2026\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1340 - val_loss: 11.0305\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1248 - val_loss: 10.9582\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1432 - val_loss: 11.0152\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1876 - val_loss: 10.9953\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0354 - val_loss: 10.9000\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1913 - val_loss: 10.9630\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2307 - val_loss: 11.2129\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2042 - val_loss: 11.0122\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1463 - val_loss: 10.8687\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0817 - val_loss: 10.7140\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1056 - val_loss: 10.7132\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0698 - val_loss: 10.7449\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0685 - val_loss: 10.8119\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0631 - val_loss: 10.8817\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1265 - val_loss: 10.7909\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0628 - val_loss: 10.7617\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0253 - val_loss: 10.8613\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1305 - val_loss: 10.9205\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0899 - val_loss: 10.7291\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0776 - val_loss: 10.7943\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0825 - val_loss: 10.7517\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0773 - val_loss: 10.9402\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0414 - val_loss: 10.7905\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1398 - val_loss: 10.9085\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0299 - val_loss: 10.8603\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1375 - val_loss: 10.7129\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0484 - val_loss: 11.0400\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0007 - val_loss: 10.8959\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1786 - val_loss: 10.9065\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0437 - val_loss: 11.0802\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0232 - val_loss: 10.8876\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0157 - val_loss: 10.8197\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1250 - val_loss: 10.7942\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0057 - val_loss: 10.8528\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0050 - val_loss: 10.9828\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0003 - val_loss: 10.8163\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0582 - val_loss: 10.8425\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0315 - val_loss: 10.8095\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1311 - val_loss: 10.7514\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0136 - val_loss: 10.7767\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0076 - val_loss: 10.6986\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9942 - val_loss: 10.8628\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9806 - val_loss: 10.8423\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9694 - val_loss: 10.7784\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0340 - val_loss: 10.8565\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0509 - val_loss: 11.0744\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9758 - val_loss: 11.0235\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0612 - val_loss: 11.0080\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9744 - val_loss: 10.9969\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9827 - val_loss: 10.8710\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9734 - val_loss: 10.8603\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0041 - val_loss: 10.6687\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9565 - val_loss: 10.8121\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0181 - val_loss: 10.9407\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0739 - val_loss: 10.8312\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9757 - val_loss: 10.8732\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0690 - val_loss: 10.8919\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0286 - val_loss: 10.7470\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.0690 - val_loss: 10.7771\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1313 - val_loss: 11.0817\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0734 - val_loss: 10.9456\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9991 - val_loss: 11.0217\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0324 - val_loss: 10.8179\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1882 - val_loss: 10.8997\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1167 - val_loss: 11.2403\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2437 - val_loss: 11.1051\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9621 - val_loss: 11.2532\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0063 - val_loss: 10.9318\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9716 - val_loss: 10.9900\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0109 - val_loss: 10.8230\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9766 - val_loss: 11.1089\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1323 - val_loss: 10.9156\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0652 - val_loss: 11.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9076 - val_loss: 10.9226\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0064 - val_loss: 10.8651\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9788 - val_loss: 10.8923\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0234 - val_loss: 10.9443\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1186 - val_loss: 11.0517\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3069 - val_loss: 11.0741\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0132 - val_loss: 10.8565\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9186 - val_loss: 10.8880\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2232 - val_loss: 11.1186\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0709 - val_loss: 10.9354\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0028 - val_loss: 10.9193\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9475 - val_loss: 10.7791\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9537 - val_loss: 10.8258\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9416 - val_loss: 10.9435\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9808 - val_loss: 10.9289\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9842 - val_loss: 10.9136\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9034 - val_loss: 11.0011\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9307 - val_loss: 11.0043\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9430 - val_loss: 10.8439\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9778 - val_loss: 10.9443\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9527 - val_loss: 10.9164\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9572 - val_loss: 10.7061\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9248 - val_loss: 10.8799\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9460 - val_loss: 10.9866\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9274 - val_loss: 10.9696\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9353 - val_loss: 10.8247\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9810 - val_loss: 10.9224\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9691 - val_loss: 11.0866\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8826 - val_loss: 10.9703\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9703 - val_loss: 10.9247\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8918 - val_loss: 11.1424\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0625 - val_loss: 10.6938\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3990 - val_loss: 10.8888\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0717 - val_loss: 10.9805\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9366 - val_loss: 11.0734\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8432 - val_loss: 10.9531\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8783 - val_loss: 10.8672\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8298 - val_loss: 10.7987\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8375 - val_loss: 10.9100\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8508 - val_loss: 10.8533\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8725 - val_loss: 10.7925\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.9469 - val_loss: 11.0943\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1293 - val_loss: 10.9168\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0579 - val_loss: 11.1364\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8374 - val_loss: 10.8156\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9268 - val_loss: 10.9614\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8784 - val_loss: 11.0777\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8185 - val_loss: 10.8390\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8684 - val_loss: 10.9163\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9049 - val_loss: 10.9319\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8534 - val_loss: 10.8161\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8632 - val_loss: 10.8856\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2098 - val_loss: 10.9620\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0761 - val_loss: 11.2299\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9158 - val_loss: 10.9482\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8678 - val_loss: 11.0301\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8379 - val_loss: 10.8702\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8273 - val_loss: 10.9172\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8093 - val_loss: 10.9056\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7937 - val_loss: 10.8971\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8329 - val_loss: 11.0051\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8041 - val_loss: 10.8541\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.7884 - val_loss: 10.9858\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8250 - val_loss: 10.8322\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7926 - val_loss: 10.9568\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8265 - val_loss: 10.7233\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.7898 - val_loss: 10.6431\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7627 - val_loss: 10.7019\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7622 - val_loss: 10.7925\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7440 - val_loss: 10.8087\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.7274 - val_loss: 10.7666\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7839 - val_loss: 10.7263\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8771 - val_loss: 10.5002\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1677 - val_loss: 11.0185\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8220 - val_loss: 10.7372\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7618 - val_loss: 10.9470\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8346 - val_loss: 10.7675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7419 - val_loss: 10.6930\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7388 - val_loss: 10.7659\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7319 - val_loss: 10.8720\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7680 - val_loss: 10.8943\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7141 - val_loss: 10.7486\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7370 - val_loss: 10.5842\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6773 - val_loss: 10.7597\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6954 - val_loss: 10.7789\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7231 - val_loss: 10.6401\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6819 - val_loss: 10.5626\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6686 - val_loss: 10.6755\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6687 - val_loss: 10.6294\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7955 - val_loss: 10.6313\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6727 - val_loss: 10.7534\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6985 - val_loss: 10.8009\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6443 - val_loss: 10.7817\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6569 - val_loss: 10.7779\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6660 - val_loss: 10.5401\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6256 - val_loss: 10.5924\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6264 - val_loss: 10.5538\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6211 - val_loss: 10.6421\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5737 - val_loss: 10.6700\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6573 - val_loss: 10.5731\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6064 - val_loss: 10.5356\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6123 - val_loss: 10.5580\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6965 - val_loss: 10.5459\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5843 - val_loss: 10.7954\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6661 - val_loss: 10.5400\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8843 - val_loss: 10.7179\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5932 - val_loss: 10.6037\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6494 - val_loss: 10.5414\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5853 - val_loss: 10.8449\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6452 - val_loss: 10.7569\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7378 - val_loss: 10.8168\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5753 - val_loss: 10.5747\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7638 - val_loss: 10.7624\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5895 - val_loss: 10.5499\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5817 - val_loss: 10.7442\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5576 - val_loss: 10.4879\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5387 - val_loss: 10.5417\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5699 - val_loss: 10.4989\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5758 - val_loss: 10.5537\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5408 - val_loss: 10.6740\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5308 - val_loss: 10.5654\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6253 - val_loss: 10.4789\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5150 - val_loss: 10.6006\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5199 - val_loss: 10.5372\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5232 - val_loss: 10.5103\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5184 - val_loss: 10.4511\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4997 - val_loss: 10.5825\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6368 - val_loss: 10.5693\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5199 - val_loss: 10.3814\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4798 - val_loss: 10.5010\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4896 - val_loss: 10.3663\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5636 - val_loss: 10.4380\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4809 - val_loss: 10.2838\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4828 - val_loss: 10.3001\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4618 - val_loss: 10.5044\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4935 - val_loss: 10.3617\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4413 - val_loss: 10.4756\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4783 - val_loss: 10.4314\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5348 - val_loss: 10.4644\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5085 - val_loss: 10.3232\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4539 - val_loss: 10.5120\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4799 - val_loss: 10.3321\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4688 - val_loss: 10.3370\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4426 - val_loss: 10.2268\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4016 - val_loss: 10.2232\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4368 - val_loss: 10.4194\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4887 - val_loss: 10.2070\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6147 - val_loss: 10.4723\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4748 - val_loss: 10.2838\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4140 - val_loss: 10.4519\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4385 - val_loss: 10.2407\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4033 - val_loss: 10.3518\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4180 - val_loss: 10.3321\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4871 - val_loss: 10.2362\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4286 - val_loss: 10.2889\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3989 - val_loss: 10.2008\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4177 - val_loss: 10.4662\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4310 - val_loss: 10.3619\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3831 - val_loss: 10.3588\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4357 - val_loss: 10.2880\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4341 - val_loss: 10.2384\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4773 - val_loss: 10.2445\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3688 - val_loss: 10.2792\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3467 - val_loss: 10.3250\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3621 - val_loss: 10.2782\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3671 - val_loss: 10.2267\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3640 - val_loss: 10.3169\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3443 - val_loss: 10.3482\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3947 - val_loss: 10.3205\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3751 - val_loss: 10.2681\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3543 - val_loss: 10.1070\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4626 - val_loss: 10.5037\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4003 - val_loss: 10.2667\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3408 - val_loss: 10.3390\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3435 - val_loss: 10.3583\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3805 - val_loss: 10.2023\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3150 - val_loss: 10.1022\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3183 - val_loss: 10.2255\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3395 - val_loss: 10.0939\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3047 - val_loss: 10.2575\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4301 - val_loss: 10.0849\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3758 - val_loss: 10.3748\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3174 - val_loss: 10.2394\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3494 - val_loss: 10.2011\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3125 - val_loss: 10.2365\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4858 - val_loss: 10.1787\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4239 - val_loss: 10.2144\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3243 - val_loss: 10.1994\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3549 - val_loss: 10.1511\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3251 - val_loss: 10.1136\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3266 - val_loss: 10.1091\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2887 - val_loss: 10.1941\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5000 - val_loss: 10.4390\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6164 - val_loss: 10.3547\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5690 - val_loss: 10.1240\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3894 - val_loss: 10.3832\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.2716 - val_loss: 10.2074\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4088 - val_loss: 10.5022\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3151 - val_loss: 10.1712\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4467 - val_loss: 10.0979\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3549 - val_loss: 10.1885\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2718 - val_loss: 10.1975\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2802 - val_loss: 10.4063\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2976 - val_loss: 10.2226\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3042 - val_loss: 10.2839\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.2934 - val_loss: 10.2658\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2190 - val_loss: 10.2833\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2301 - val_loss: 10.1732\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2462 - val_loss: 10.1962\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3226 - val_loss: 10.1784\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3101 - val_loss: 10.1188\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3117 - val_loss: 10.0610\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2440 - val_loss: 10.3531\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2701 - val_loss: 10.2475\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2244 - val_loss: 10.4056\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2367 - val_loss: 10.2270\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3152 - val_loss: 10.2109\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2232 - val_loss: 10.1092\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2344 - val_loss: 10.1645\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2214 - val_loss: 10.2102\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2310 - val_loss: 10.3140\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3681 - val_loss: 10.1965\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2860 - val_loss: 10.1374\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1932 - val_loss: 10.0231\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2682 - val_loss: 10.2645\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2045 - val_loss: 10.2269\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2572 - val_loss: 10.0859\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1897 - val_loss: 10.1845\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2438 - val_loss: 10.1071\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2069 - val_loss: 10.1938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2397 - val_loss: 10.2108\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3434 - val_loss: 10.2451\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1347 - val_loss: 10.1637\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1617 - val_loss: 10.3058\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2380 - val_loss: 10.0045\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3859 - val_loss: 10.1234\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3021 - val_loss: 10.1982\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1503 - val_loss: 10.0933\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2396 - val_loss: 10.3138\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1646 - val_loss: 10.3080\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2510 - val_loss: 9.9919\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1799 - val_loss: 10.3540\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2431 - val_loss: 10.1331\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1705 - val_loss: 10.2487\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3331 - val_loss: 10.1096\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3482 - val_loss: 10.4635\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2773 - val_loss: 10.2171\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2535 - val_loss: 10.3450\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3344 - val_loss: 10.1403\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1490 - val_loss: 10.1308\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1882 - val_loss: 10.2004\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2622 - val_loss: 10.2784\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3088 - val_loss: 10.1778\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1578 - val_loss: 10.0525\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1195 - val_loss: 10.2081\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1682 - val_loss: 10.0602\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1660 - val_loss: 10.2193\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2369 - val_loss: 10.1086\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1814 - val_loss: 10.4129\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1380 - val_loss: 10.2840\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1213 - val_loss: 10.0349\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1418 - val_loss: 10.1144\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3219 - val_loss: 10.2765\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2070 - val_loss: 10.0465\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1566 - val_loss: 10.2681\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1446 - val_loss: 10.0617\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1422 - val_loss: 10.0236\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1124 - val_loss: 10.1947\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3042 - val_loss: 10.1472\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1461 - val_loss: 10.1445\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2175 - val_loss: 10.2092\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0746 - val_loss: 10.2686\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1986 - val_loss: 10.1113\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2269 - val_loss: 10.0285\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1203 - val_loss: 10.2056\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1254 - val_loss: 10.1371\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1356 - val_loss: 10.1748\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1350 - val_loss: 10.0382\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0309 - val_loss: 10.1257\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0754 - val_loss: 9.9822\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1397 - val_loss: 10.0268\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0985 - val_loss: 9.9619\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1622 - val_loss: 10.0703\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1775 - val_loss: 10.1330\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0814 - val_loss: 10.2044\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1111 - val_loss: 10.0430\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1366 - val_loss: 10.0269\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0410 - val_loss: 10.0000\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0606 - val_loss: 9.9897\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0977 - val_loss: 10.2481\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1400 - val_loss: 10.1516\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1828 - val_loss: 9.9477\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1292 - val_loss: 10.3130\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0636 - val_loss: 10.2050\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0423 - val_loss: 10.2952\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2146 - val_loss: 10.2249\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2159 - val_loss: 10.1103\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1240 - val_loss: 9.9488\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0494 - val_loss: 10.2328\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0806 - val_loss: 10.3881\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0523 - val_loss: 10.1926\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0393 - val_loss: 10.2629\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9894 - val_loss: 10.0993\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0490 - val_loss: 10.0420\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0847 - val_loss: 10.0199\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0158 - val_loss: 10.2511\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1891 - val_loss: 10.0515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9723 - val_loss: 10.1226\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9719 - val_loss: 9.9865\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0449 - val_loss: 10.2346\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9773 - val_loss: 10.1215\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9780 - val_loss: 9.9774\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0473 - val_loss: 9.9191\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9489 - val_loss: 10.0805\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9443 - val_loss: 9.9973\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 4.9614 - val_loss: 10.0660\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0769 - val_loss: 9.8701\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0407 - val_loss: 9.9284\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9659 - val_loss: 10.0308\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9385 - val_loss: 10.0366\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0161 - val_loss: 9.9615\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0001 - val_loss: 9.9971\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9999 - val_loss: 10.1155\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0093 - val_loss: 9.9050\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9534 - val_loss: 10.0332\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0688 - val_loss: 9.9666\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0012 - val_loss: 10.0176\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9548 - val_loss: 9.9706\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9690 - val_loss: 10.0580\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9933 - val_loss: 10.0499\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9364 - val_loss: 10.1072\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9604 - val_loss: 9.9367\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0030 - val_loss: 9.8807\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9800 - val_loss: 10.0541\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9557 - val_loss: 9.9893\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.9180 - val_loss: 10.0583\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9187 - val_loss: 10.3030\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8594 - val_loss: 10.0554\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8669 - val_loss: 10.0505\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.9357 - val_loss: 9.9971\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8909 - val_loss: 10.0346\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8907 - val_loss: 10.0782\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9599 - val_loss: 10.1150\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9798 - val_loss: 10.0360\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9837 - val_loss: 10.0342\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9093 - val_loss: 10.1005\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0152 - val_loss: 10.1534\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9381 - val_loss: 10.2264\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8598 - val_loss: 10.1075\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8311 - val_loss: 10.1603\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8721 - val_loss: 10.1371\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8949 - val_loss: 10.1695\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8771 - val_loss: 10.1100\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8534 - val_loss: 10.2647\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9507 - val_loss: 10.0720\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8872 - val_loss: 9.8714\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.834 - 0s 98us/step - loss: 4.8440 - val_loss: 10.0551\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9388 - val_loss: 10.1517\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8689 - val_loss: 9.9610\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8079 - val_loss: 10.1146\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8511 - val_loss: 10.2652\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8510 - val_loss: 10.2396\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8853 - val_loss: 10.1081\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8387 - val_loss: 10.0498\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9242 - val_loss: 10.0237\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.8508 - val_loss: 9.9614\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8380 - val_loss: 9.9386\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8515 - val_loss: 9.9361\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8382 - val_loss: 10.0206\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8313 - val_loss: 10.0102\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8521 - val_loss: 10.1285\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7961 - val_loss: 10.1383\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7830 - val_loss: 10.0955\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.8193 - val_loss: 10.2449\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7925 - val_loss: 10.2274\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7834 - val_loss: 10.0449\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7884 - val_loss: 10.1311\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8203 - val_loss: 10.1586\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8884 - val_loss: 10.0631\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0503 - val_loss: 10.0878\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8758 - val_loss: 10.2891\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7411 - val_loss: 10.1164\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7820 - val_loss: 9.9677\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7822 - val_loss: 10.0825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8021 - val_loss: 10.0976\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7578 - val_loss: 10.2218\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7630 - val_loss: 10.2299\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8037 - val_loss: 10.1385\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7078 - val_loss: 10.0433\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7415 - val_loss: 10.1842\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7654 - val_loss: 10.0458\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8175 - val_loss: 10.1199\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8285 - val_loss: 9.9976\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6908 - val_loss: 10.1620\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7881 - val_loss: 10.0381\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7897 - val_loss: 10.1520\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7816 - val_loss: 10.1708\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7118 - val_loss: 10.0252\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7875 - val_loss: 9.9868\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7520 - val_loss: 10.0687\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7271 - val_loss: 10.0472\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7393 - val_loss: 10.2523\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7196 - val_loss: 10.1628\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7652 - val_loss: 10.0872\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7383 - val_loss: 10.0919\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7001 - val_loss: 10.1804\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7053 - val_loss: 10.2442\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7367 - val_loss: 10.1277\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7792 - val_loss: 9.9918\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7087 - val_loss: 9.9561\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7842 - val_loss: 10.1530\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7307 - val_loss: 10.1477\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8405 - val_loss: 10.2901\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7181 - val_loss: 10.0817\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7310 - val_loss: 10.1535\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7099 - val_loss: 10.1127\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7092 - val_loss: 10.1134\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6587 - val_loss: 9.9836\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7851 - val_loss: 9.8662\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7115 - val_loss: 10.0086\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8459 - val_loss: 10.2336\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8511 - val_loss: 10.1035\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6979 - val_loss: 10.1962\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7030 - val_loss: 10.2430\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7027 - val_loss: 10.1495\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6850 - val_loss: 10.1060\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8249 - val_loss: 10.1043\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7803 - val_loss: 10.1377\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6320 - val_loss: 10.0487\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6543 - val_loss: 9.9916\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7069 - val_loss: 9.9576\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7166 - val_loss: 10.0894\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7601 - val_loss: 10.2253\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6676 - val_loss: 10.0833\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6609 - val_loss: 9.9846\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7106 - val_loss: 10.1075\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6822 - val_loss: 10.1241\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8956 - val_loss: 10.2507\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7164 - val_loss: 9.9697\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6753 - val_loss: 10.0820\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7141 - val_loss: 10.1093\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6388 - val_loss: 10.1950\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6744 - val_loss: 9.9354\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5998 - val_loss: 9.9401\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6317 - val_loss: 9.8864\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6487 - val_loss: 9.9662\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.6539 - val_loss: 10.0265\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6746 - val_loss: 9.9864\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5943 - val_loss: 9.9858\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7160 - val_loss: 9.8637\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6632 - val_loss: 9.9715\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6328 - val_loss: 9.8649\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6227 - val_loss: 9.9423\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6847 - val_loss: 10.0300\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8048 - val_loss: 9.7859\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6442 - val_loss: 9.8548\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6996 - val_loss: 9.9996\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6633 - val_loss: 9.8279\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6917 - val_loss: 9.8992\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.6151 - val_loss: 9.7643\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6661 - val_loss: 9.9053\n",
      "Epoch 912/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.6276 - val_loss: 9.9474\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5963 - val_loss: 9.8555\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5889 - val_loss: 9.8870\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6430 - val_loss: 9.9185\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5908 - val_loss: 9.9453\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5694 - val_loss: 9.8150\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6065 - val_loss: 9.9224\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5622 - val_loss: 9.8826\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5664 - val_loss: 9.9487\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7231 - val_loss: 9.9250\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6714 - val_loss: 9.9882\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8248 - val_loss: 9.8310\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7448 - val_loss: 9.9208\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6744 - val_loss: 9.7064\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5957 - val_loss: 10.0667\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6634 - val_loss: 9.7647\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6239 - val_loss: 9.8824\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7359 - val_loss: 9.6476\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8246 - val_loss: 9.8070\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7930 - val_loss: 9.8938\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6713 - val_loss: 9.8715\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5870 - val_loss: 9.7335\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5858 - val_loss: 9.6978\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5861 - val_loss: 9.8820\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5511 - val_loss: 9.7539\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6015 - val_loss: 9.7824\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8444 - val_loss: 9.8101\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7274 - val_loss: 9.6939\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7711 - val_loss: 9.6282\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8673 - val_loss: 9.6131\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5926 - val_loss: 9.9610\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5158 - val_loss: 9.8265\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5860 - val_loss: 9.7275\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6451 - val_loss: 9.7995\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.6632 - val_loss: 9.8605\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6887 - val_loss: 9.6822\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6381 - val_loss: 9.8238\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5796 - val_loss: 9.7544\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5672 - val_loss: 9.8664\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5410 - val_loss: 9.7818\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5587 - val_loss: 9.8242\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5769 - val_loss: 9.6672\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5457 - val_loss: 10.1667\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5834 - val_loss: 9.7603\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6332 - val_loss: 9.5208\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5196 - val_loss: 9.5568\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6414 - val_loss: 9.7027\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5935 - val_loss: 9.5751\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6483 - val_loss: 9.5304\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6131 - val_loss: 9.4669\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5580 - val_loss: 9.5308\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5091 - val_loss: 9.6296\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5006 - val_loss: 9.6541\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5155 - val_loss: 9.6869\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5574 - val_loss: 9.8570\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4427 - val_loss: 9.6991\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4993 - val_loss: 9.6885\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6195 - val_loss: 9.5627\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6468 - val_loss: 9.6572\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5927 - val_loss: 9.7075\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5296 - val_loss: 9.6186\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5078 - val_loss: 9.6685\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5395 - val_loss: 9.6840\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4828 - val_loss: 9.6438\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5196 - val_loss: 9.7923\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4715 - val_loss: 9.5723\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4731 - val_loss: 9.6697\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5047 - val_loss: 9.7324\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4929 - val_loss: 9.6444\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6188 - val_loss: 9.6828\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.5348 - val_loss: 9.6963\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5023 - val_loss: 9.7080\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5169 - val_loss: 9.6467\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5947 - val_loss: 9.7055\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5182 - val_loss: 9.7846\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4921 - val_loss: 9.6887\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4623 - val_loss: 9.5307\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 100us/step - loss: 4.4600 - val_loss: 9.5651\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4822 - val_loss: 9.5816\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4847 - val_loss: 9.3934\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5691 - val_loss: 9.3774\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5689 - val_loss: 9.6751\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5672 - val_loss: 9.6429\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6304 - val_loss: 9.3753\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4677 - val_loss: 9.4349\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.5014 - val_loss: 9.6188\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4296 - val_loss: 9.5337\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5463 - val_loss: 9.4994\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6376 - val_loss: 9.5779\n",
      "9.16065280720339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.3766391 ,  0.27925315,  1.4172825 ,  0.08412278,  1.7259717 ],\n",
       "        [ 0.35011595,  1.0511056 , -0.45420435,  2.4204068 ,  0.35269186],\n",
       "        [-1.292106  , -2.0360212 ,  2.5093586 , -0.37578198, -3.6503513 ],\n",
       "        [ 0.576231  , -2.074081  ,  2.023471  , -2.3220212 , -1.7237614 ],\n",
       "        [ 1.3628268 , -0.5754887 , -0.16974244, -0.14067908,  0.2831491 ],\n",
       "        [-1.7802343 ,  2.1303613 , -1.1232035 ,  2.1423337 ,  0.66110224],\n",
       "        [-2.8325272 ,  3.0432506 ,  0.99948084,  1.1257128 ,  0.76806134]],\n",
       "       dtype=float32),\n",
       " array([ 0.78084594,  1.6883808 , -0.38531366, -0.63162446, -0.39923006],\n",
       "       dtype=float32),\n",
       " array([[ 4.2405343 ,  3.8364203 ,  1.5094736 ,  2.054304  , -0.89266986,\n",
       "          4.8991675 , -1.8251492 , -0.06398264,  0.14101045, -0.9005411 ],\n",
       "        [ 4.010821  ,  2.8878114 , -0.6034095 ,  2.3255572 , -0.17043495,\n",
       "          2.8649137 , -1.8925574 ,  9.337868  , -5.7227287 ,  0.5320479 ],\n",
       "        [-0.38833794, -0.39229506,  2.071479  , -0.31024227, -1.172049  ,\n",
       "         -0.5518334 ,  0.30885255, -0.2878164 , -1.569551  , -8.773044  ],\n",
       "        [ 2.3706777 ,  4.4157825 , 13.807014  ,  1.5744523 ,  0.8839462 ,\n",
       "          5.102581  ,  0.58861446,  4.8004    ,  5.739276  , -4.31634   ],\n",
       "        [ 1.659224  ,  3.4189727 ,  8.003317  ,  2.3626437 ,  0.49380168,\n",
       "          2.7438025 ,  2.0552685 , -1.9975731 ,  3.5628176 , -0.74750185]],\n",
       "       dtype=float32),\n",
       " array([-2.548194 , -2.0156155, -0.7352659, -1.4917631, -1.276376 ,\n",
       "        -2.0678782,  1.6757108,  2.836218 , -2.0277526,  3.1418018],\n",
       "       dtype=float32),\n",
       " array([[ 1.7971518 ],\n",
       "        [ 1.6556317 ],\n",
       "        [ 2.6797683 ],\n",
       "        [ 0.85193837],\n",
       "        [18.906628  ],\n",
       "        [ 2.0424678 ],\n",
       "        [ 6.5331144 ],\n",
       "        [ 7.4444933 ],\n",
       "        [ 6.6123605 ],\n",
       "        [ 4.339396  ]], dtype=float32),\n",
       " array([1.0613445], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_sigmoid(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sigmoid_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 823us/step - loss: 456.0433 - val_loss: 306.4768\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 203.8311 - val_loss: 137.4009\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 97.2068 - val_loss: 74.6568\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 64.9337 - val_loss: 60.4204\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.7794 - val_loss: 59.3623\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 62.6797 - val_loss: 59.4009\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 62.4625 - val_loss: 59.3524\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 61.58 - 0s 105us/step - loss: 61.9304 - val_loss: 59.5894\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4640 - val_loss: 59.8975\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4366 - val_loss: 60.2207\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4591 - val_loss: 60.4880\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4879 - val_loss: 60.2939\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4243 - val_loss: 60.2441\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4056 - val_loss: 60.2339\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4493 - val_loss: 60.3683\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4231 - val_loss: 60.3286\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4185 - val_loss: 60.1209\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4368 - val_loss: 60.0697\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4391 - val_loss: 60.2027\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4142 - val_loss: 60.1830\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3980 - val_loss: 60.0642\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4149 - val_loss: 60.0042\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4243 - val_loss: 60.0000\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4151 - val_loss: 60.0550\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4200 - val_loss: 60.0526\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4607 - val_loss: 60.0038\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4662 - val_loss: 60.0279\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.5062 - val_loss: 60.3414\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4433 - val_loss: 60.3242\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3833 - val_loss: 60.1637\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4762 - val_loss: 59.9656\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4703 - val_loss: 60.1360\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.5243 - val_loss: 59.9653\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3972 - val_loss: 60.1448\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4506 - val_loss: 60.3317\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3927 - val_loss: 60.1600\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4137 - val_loss: 60.1521\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4059 - val_loss: 60.1129\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4062 - val_loss: 60.2103\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4303 - val_loss: 60.0943\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4156 - val_loss: 60.1878\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.4139 - val_loss: 60.1760\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4270 - val_loss: 60.3476\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4532 - val_loss: 60.1554\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3957 - val_loss: 60.2449\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4030 - val_loss: 60.3124\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4305 - val_loss: 60.2039\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.5011 - val_loss: 60.4151\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3783 - val_loss: 60.1275\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3995 - val_loss: 59.9588\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4120 - val_loss: 59.9783\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4321 - val_loss: 60.1119\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4111 - val_loss: 60.2112\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3994 - val_loss: 60.1445\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4309 - val_loss: 60.2047\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3972 - val_loss: 60.1549\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4073 - val_loss: 60.1068\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4103 - val_loss: 60.1333\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4043 - val_loss: 60.0953\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4050 - val_loss: 59.9616\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4044 - val_loss: 60.0086\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4040 - val_loss: 60.0849\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3930 - val_loss: 60.1098\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4006 - val_loss: 60.1430\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4249 - val_loss: 60.1641\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4197 - val_loss: 59.9953\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 61.4260 - val_loss: 60.1099\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3926 - val_loss: 60.1102\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3957 - val_loss: 60.1893\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3843 - val_loss: 60.2175\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.3777 - val_loss: 60.1537\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.3769 - val_loss: 60.1321\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.3975 - val_loss: 60.1799\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.3646 - val_loss: 60.0070\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3709 - val_loss: 59.9346\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3361 - val_loss: 60.0403\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.3475 - val_loss: 60.1574\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.3254 - val_loss: 59.9517\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.2649 - val_loss: 59.9551\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.2004 - val_loss: 59.8593\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 60.6631 - val_loss: 56.2154\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 48.8291 - val_loss: 47.0133\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 43.6587 - val_loss: 43.8918\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 41.1162 - val_loss: 41.2034\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 39.1525 - val_loss: 38.5447\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 37.2858 - val_loss: 36.4347\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 35.5634 - val_loss: 35.1176\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 33.5313 - val_loss: 33.8924\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 32.2140 - val_loss: 32.7122\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 31.1189 - val_loss: 31.4766\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 30.1213 - val_loss: 30.4628\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 29.2703 - val_loss: 29.6302\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.4688 - val_loss: 28.8340\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 27.6374 - val_loss: 28.1968\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 26.9785 - val_loss: 27.4813\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 26.5410 - val_loss: 27.0282\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 25.3713 - val_loss: 26.2085\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 24.7962 - val_loss: 25.1161\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 23.9385 - val_loss: 24.1200\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 23.3732 - val_loss: 22.8519\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 22.9570 - val_loss: 21.8841\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 22.1388 - val_loss: 21.5190\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 21.1178 - val_loss: 21.8709\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 20.7288 - val_loss: 20.5685\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.3493 - val_loss: 20.1938\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.6639 - val_loss: 20.1093\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 19.1347 - val_loss: 19.4287\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 18.6108 - val_loss: 19.4965\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.1602 - val_loss: 19.3012\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.8252 - val_loss: 18.9258\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.5265 - val_loss: 18.9049\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.3005 - val_loss: 19.1733\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.8860 - val_loss: 19.1415\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 16.5192 - val_loss: 19.2976\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.2039 - val_loss: 19.1713\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.9911 - val_loss: 19.0398\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.7195 - val_loss: 18.4631\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.5844 - val_loss: 18.8304\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 15.2508 - val_loss: 18.0427\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.0690 - val_loss: 18.2308\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.8177 - val_loss: 17.6335\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 14.5637 - val_loss: 17.7121\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.5307 - val_loss: 17.7311\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.5531 - val_loss: 17.9037\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3980 - val_loss: 17.1886\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 14.3046 - val_loss: 17.4604\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.8226 - val_loss: 17.0352\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.7945 - val_loss: 17.4488\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.3351 - val_loss: 16.8254\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.3357 - val_loss: 16.5039\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 13.0917 - val_loss: 16.5172\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.9015 - val_loss: 16.1537\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.7711 - val_loss: 16.5594\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.6162 - val_loss: 15.9179\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.5282 - val_loss: 16.1495\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.3259 - val_loss: 15.9341\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.3396 - val_loss: 16.2776\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.1246 - val_loss: 15.1714\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.9839 - val_loss: 15.9022\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.9170 - val_loss: 15.7192\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 11.6790 - val_loss: 15.5923\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.524 - 0s 98us/step - loss: 11.5504 - val_loss: 14.8817\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 11.4867 - val_loss: 15.1101\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.4160 - val_loss: 14.9813\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.3147 - val_loss: 14.9335\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.2269 - val_loss: 14.7532\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.9162 - val_loss: 13.5156\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.7289 - val_loss: 13.2051\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.4134 - val_loss: 12.6610\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9483 - val_loss: 12.1228\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7279 - val_loss: 11.7241\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5682 - val_loss: 11.8610\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.5352 - val_loss: 11.4737\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3312 - val_loss: 11.7619\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.0367 - val_loss: 11.7659\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6744 - val_loss: 12.0447\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1049 - val_loss: 11.1503\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9187 - val_loss: 10.9868\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6808 - val_loss: 10.9727\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5224 - val_loss: 11.2212\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4980 - val_loss: 11.0111\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5355 - val_loss: 10.7978\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3395 - val_loss: 10.8130\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3064 - val_loss: 11.0588\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2632 - val_loss: 10.9455\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4674 - val_loss: 11.1194\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2463 - val_loss: 10.5487\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3164 - val_loss: 11.3273\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2491 - val_loss: 11.1696\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3628 - val_loss: 11.4467\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2885 - val_loss: 11.2908\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4041 - val_loss: 11.2075\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.6102 - val_loss: 13.1286\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7876 - val_loss: 11.9281\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4821 - val_loss: 13.1726\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5397 - val_loss: 10.8726\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1290 - val_loss: 11.4628\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2640 - val_loss: 10.7902\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0201 - val_loss: 11.0583\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9832 - val_loss: 10.7692\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9607 - val_loss: 10.7207\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9550 - val_loss: 10.9950\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0119 - val_loss: 10.5225\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0149 - val_loss: 10.7042\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0098 - val_loss: 10.6492\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8666 - val_loss: 10.6906\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8669 - val_loss: 10.5125\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0129 - val_loss: 10.8422\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0312 - val_loss: 10.6260\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9692 - val_loss: 10.8238\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0006 - val_loss: 10.3639\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9367 - val_loss: 10.6917\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0059 - val_loss: 10.7361\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9105 - val_loss: 10.7628\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8530 - val_loss: 10.5775\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3687 - val_loss: 11.1648\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3083 - val_loss: 10.4881\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9143 - val_loss: 10.5766\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7426 - val_loss: 10.6711\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7491 - val_loss: 10.4551\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7978 - val_loss: 10.4516\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7649 - val_loss: 10.3739\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9511 - val_loss: 10.3662\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9612 - val_loss: 10.5498\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8743 - val_loss: 10.6592\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9773 - val_loss: 10.3963\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6945 - val_loss: 10.2607\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7211 - val_loss: 10.0638\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9019 - val_loss: 10.5261\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9649 - val_loss: 10.2469\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7074 - val_loss: 10.5324\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7663 - val_loss: 10.0924\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7114 - val_loss: 10.1782\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6991 - val_loss: 10.1189\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.8498 - val_loss: 10.3244\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8399 - val_loss: 10.2103\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7414 - val_loss: 9.9869\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6054 - val_loss: 10.2526\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6656 - val_loss: 9.7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7187 - val_loss: 9.7736\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7868 - val_loss: 10.0621\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6466 - val_loss: 9.9954\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7309 - val_loss: 10.1814\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6392 - val_loss: 9.7424\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8102 - val_loss: 10.0544\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6000 - val_loss: 9.9357\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5665 - val_loss: 9.6785\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5417 - val_loss: 9.8043\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6261 - val_loss: 9.6593\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7610 - val_loss: 9.8010\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5067 - val_loss: 9.5643\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7162 - val_loss: 10.3181\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9205 - val_loss: 9.8005\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6627 - val_loss: 9.8585\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6208 - val_loss: 9.7997\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8863 - val_loss: 9.5411\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7628 - val_loss: 9.9656\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6075 - val_loss: 9.5946\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5127 - val_loss: 9.7863\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7327 - val_loss: 9.6837\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6431 - val_loss: 9.6998\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6479 - val_loss: 9.9696\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.523 - 0s 109us/step - loss: 6.5107 - val_loss: 9.4401\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5672 - val_loss: 9.5509\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5067 - val_loss: 9.5766\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4716 - val_loss: 9.5117\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5055 - val_loss: 9.5092\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6054 - val_loss: 9.3341\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4995 - val_loss: 9.7185\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6399 - val_loss: 9.5471\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5536 - val_loss: 9.7714\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6389 - val_loss: 9.3285\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5086 - val_loss: 9.5750\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7454 - val_loss: 9.6158\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5316 - val_loss: 9.5812\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6292 - val_loss: 9.5198\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4529 - val_loss: 9.6694\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6866 - val_loss: 9.7094\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4590 - val_loss: 9.4720\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4153 - val_loss: 9.6070\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3803 - val_loss: 9.4353\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4310 - val_loss: 9.4512\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6451 - val_loss: 9.7065\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5924 - val_loss: 9.4310\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7586 - val_loss: 9.5760\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4861 - val_loss: 9.3421\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5035 - val_loss: 9.5702\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4073 - val_loss: 9.6835\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3965 - val_loss: 9.5583\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3386 - val_loss: 9.5389\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3638 - val_loss: 9.8354\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3411 - val_loss: 9.3931\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5692 - val_loss: 9.5852\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4652 - val_loss: 9.6362\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2973 - val_loss: 9.4707\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3363 - val_loss: 9.6310\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4124 - val_loss: 9.9304\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2252 - val_loss: 10.0853\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4675 - val_loss: 9.6156\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3200 - val_loss: 9.9058\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2206 - val_loss: 9.7996\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.3063 - val_loss: 10.0531\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2440 - val_loss: 9.7905\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2392 - val_loss: 9.7054\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4404 - val_loss: 9.8817\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5650 - val_loss: 9.6854\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2782 - val_loss: 9.4558\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2424 - val_loss: 9.8115\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2588 - val_loss: 9.5576\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2176 - val_loss: 9.7900\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2215 - val_loss: 9.5729\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2134 - val_loss: 9.6243\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2159 - val_loss: 9.8137\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3083 - val_loss: 9.6315\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3482 - val_loss: 9.7936\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.5845 - val_loss: 9.8529\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.9852 - val_loss: 10.0793\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5919 - val_loss: 9.7021\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2712 - val_loss: 9.5127\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4867 - val_loss: 9.7457\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2731 - val_loss: 9.9009\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2152 - val_loss: 9.8249\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2036 - val_loss: 9.7317\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2456 - val_loss: 9.6846\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2014 - val_loss: 9.6799\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1852 - val_loss: 9.6473\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2113 - val_loss: 9.8228\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1937 - val_loss: 9.7566\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1903 - val_loss: 9.5226\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1583 - val_loss: 9.6234\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2425 - val_loss: 9.6427\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1699 - val_loss: 9.7105\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2651 - val_loss: 9.4748\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4379 - val_loss: 9.5959\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1711 - val_loss: 9.6212\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1372 - val_loss: 9.6033\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2071 - val_loss: 9.7016\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.1825 - val_loss: 9.4152\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1472 - val_loss: 9.6867\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1727 - val_loss: 9.5037\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2480 - val_loss: 9.5888\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1527 - val_loss: 9.1870\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1247 - val_loss: 9.5622\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1189 - val_loss: 9.5243\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0414 - val_loss: 9.0967\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0318 - val_loss: 9.0392\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9769 - val_loss: 9.3751\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9975 - val_loss: 9.3602\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0694 - val_loss: 9.1154\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9790 - val_loss: 9.4367\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0174 - val_loss: 9.1551\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9329 - val_loss: 9.2751\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9988 - val_loss: 9.3329\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8822 - val_loss: 9.2453\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0054 - val_loss: 9.1743\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9358 - val_loss: 8.9710\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9632 - val_loss: 9.0992\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0586 - val_loss: 9.1095\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8807 - val_loss: 9.6066\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9127 - val_loss: 8.9222\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3566 - val_loss: 9.6879\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4362 - val_loss: 9.3122\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2304 - val_loss: 9.2974\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1992 - val_loss: 9.3339\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.0939 - val_loss: 9.4740\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1576 - val_loss: 9.3559\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0807 - val_loss: 9.0173\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0403 - val_loss: 9.3845\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3512 - val_loss: 9.4785\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0747 - val_loss: 9.2744\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1323 - val_loss: 9.2296\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0257 - val_loss: 9.1905\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8882 - val_loss: 9.2417\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0416 - val_loss: 9.1144\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3489 - val_loss: 9.1205\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1455 - val_loss: 9.2181\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0470 - val_loss: 8.8729\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8521 - val_loss: 9.0899\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9062 - val_loss: 9.1625\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8941 - val_loss: 9.0007\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8834 - val_loss: 9.0351\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9148 - val_loss: 9.2712\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8461 - val_loss: 9.1803\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8099 - val_loss: 8.8673\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7824 - val_loss: 9.2692\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9164 - val_loss: 9.3979\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8937 - val_loss: 8.9220\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0306 - val_loss: 9.2903\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0148 - val_loss: 9.1849\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9512 - val_loss: 8.8539\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8751 - val_loss: 9.1957\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8300 - val_loss: 9.0032\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8160 - val_loss: 9.0491\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 103us/step - loss: 5.7412 - val_loss: 8.9666\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8642 - val_loss: 9.1847\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9868 - val_loss: 9.2497\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8992 - val_loss: 9.3339\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8646 - val_loss: 9.0978\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1212 - val_loss: 8.8950\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8663 - val_loss: 9.3479\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0123 - val_loss: 9.1619\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7373 - val_loss: 9.6278\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0251 - val_loss: 9.1619\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9354 - val_loss: 9.3773\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0272 - val_loss: 9.2136\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8512 - val_loss: 9.1817\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8414 - val_loss: 9.1193\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8411 - val_loss: 9.0198\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7085 - val_loss: 9.0831\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7847 - val_loss: 9.0884\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9675 - val_loss: 9.1734\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9789 - val_loss: 9.2925\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0772 - val_loss: 9.1728\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8821 - val_loss: 8.8794\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7584 - val_loss: 9.4058\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8014 - val_loss: 9.2053\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7753 - val_loss: 8.9292\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8822 - val_loss: 9.0402\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7330 - val_loss: 9.3275\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7268 - val_loss: 8.9128\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6760 - val_loss: 8.9757\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8055 - val_loss: 9.0570\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8489 - val_loss: 8.9338\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8079 - val_loss: 8.9437\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8817 - val_loss: 9.1286\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7504 - val_loss: 9.0732\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6935 - val_loss: 8.9950\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7867 - val_loss: 8.9952\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6865 - val_loss: 9.2026\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7195 - val_loss: 9.0121\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7137 - val_loss: 9.0173\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8365 - val_loss: 9.0926\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8479 - val_loss: 9.2086\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8542 - val_loss: 8.9815\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7019 - val_loss: 9.1861\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9642 - val_loss: 9.2056\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0405 - val_loss: 9.2229\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7033 - val_loss: 8.8193\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7246 - val_loss: 9.2426\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8937 - val_loss: 9.4897\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7510 - val_loss: 9.3340\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6350 - val_loss: 9.2988\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6680 - val_loss: 9.4739\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7002 - val_loss: 9.4396\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6851 - val_loss: 9.4959\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8776 - val_loss: 9.7975\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1641 - val_loss: 9.3089\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0770 - val_loss: 9.5624\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7407 - val_loss: 9.8467\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6428 - val_loss: 9.7466\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8543 - val_loss: 9.8168\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7256 - val_loss: 9.8232\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6323 - val_loss: 10.0320\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8895 - val_loss: 9.7883\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0307 - val_loss: 10.3974\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9221 - val_loss: 10.2673\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7239 - val_loss: 10.3149\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7485 - val_loss: 10.4112\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6611 - val_loss: 10.2158\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6154 - val_loss: 10.2121\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6852 - val_loss: 10.2146\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6378 - val_loss: 10.1068\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6141 - val_loss: 10.3656\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5714 - val_loss: 9.9738\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7647 - val_loss: 10.5519\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5191 - val_loss: 10.0725\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7075 - val_loss: 10.2689\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6009 - val_loss: 10.0261\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6445 - val_loss: 10.3870\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7482 - val_loss: 10.2919\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9159 - val_loss: 10.4809\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8236 - val_loss: 10.2273\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7302 - val_loss: 10.1224\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7156 - val_loss: 10.2964\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7028 - val_loss: 10.5677\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6397 - val_loss: 10.1677\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6567 - val_loss: 10.0433\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8720 - val_loss: 10.3667\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5752 - val_loss: 10.1328\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5819 - val_loss: 10.1688\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6207 - val_loss: 10.1925\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7558 - val_loss: 9.9518\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6416 - val_loss: 10.4290\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5383 - val_loss: 9.9836\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7192 - val_loss: 10.4900\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9659 - val_loss: 10.1905\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8215 - val_loss: 10.1984\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8900 - val_loss: 10.2298\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9025 - val_loss: 10.3899\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3739 - val_loss: 10.5180\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5798 - val_loss: 10.8104\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6335 - val_loss: 10.0027\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5312 - val_loss: 10.2294\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5751 - val_loss: 9.9791\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5304 - val_loss: 9.9254\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5864 - val_loss: 10.3796\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5212 - val_loss: 10.1330\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5649 - val_loss: 10.0479\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5829 - val_loss: 10.1054\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5921 - val_loss: 10.0430\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6629 - val_loss: 10.2204\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6400 - val_loss: 10.2312\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8193 - val_loss: 9.9017\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8567 - val_loss: 10.2016\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5917 - val_loss: 10.2578\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5190 - val_loss: 9.8172\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5554 - val_loss: 10.1166\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6091 - val_loss: 10.3992\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5882 - val_loss: 10.0811\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5583 - val_loss: 9.9401\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6059 - val_loss: 10.1855\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7562 - val_loss: 9.7447\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6136 - val_loss: 10.2742\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8113 - val_loss: 10.3006\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0532 - val_loss: 10.1251\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8975 - val_loss: 10.0134\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8225 - val_loss: 10.3267\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6491 - val_loss: 9.9578\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6840 - val_loss: 9.8461\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6054 - val_loss: 10.2868\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5203 - val_loss: 9.9409\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6292 - val_loss: 9.9338\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4580 - val_loss: 10.1150\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5184 - val_loss: 9.9188\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5171 - val_loss: 10.2342\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4601 - val_loss: 10.2979\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5719 - val_loss: 9.8645\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5864 - val_loss: 9.9234\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5814 - val_loss: 10.2388\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7200 - val_loss: 10.0363\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5534 - val_loss: 10.0524\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5431 - val_loss: 10.1998\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5527 - val_loss: 10.4055\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8211 - val_loss: 10.1361\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6538 - val_loss: 9.8837\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7049 - val_loss: 10.2446\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7855 - val_loss: 9.8881\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7385 - val_loss: 9.8197\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5557 - val_loss: 10.1699\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6848 - val_loss: 10.0224\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5000 - val_loss: 10.5025\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4262 - val_loss: 9.9286\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5193 - val_loss: 9.9148\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5037 - val_loss: 9.9966\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6806 - val_loss: 10.1915\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8042 - val_loss: 10.1137\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5165 - val_loss: 10.2219\n",
      "Epoch 528/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4706 - val_loss: 9.9752\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4198 - val_loss: 10.3923\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4541 - val_loss: 9.8420\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5053 - val_loss: 10.0188\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5022 - val_loss: 10.1314\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5046 - val_loss: 10.0173\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4988 - val_loss: 10.1633\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4099 - val_loss: 9.9725\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5592 - val_loss: 9.9060\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4174 - val_loss: 9.8818\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4724 - val_loss: 10.1241\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5680 - val_loss: 9.9742\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7246 - val_loss: 10.0612\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8225 - val_loss: 10.2384\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6234 - val_loss: 10.7825\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5905 - val_loss: 9.7250\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6005 - val_loss: 10.2730\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4340 - val_loss: 9.8828\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0229 - val_loss: 10.5163\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6372 - val_loss: 10.1751\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4863 - val_loss: 9.7816\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6943 - val_loss: 9.7804\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6073 - val_loss: 10.6021\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5337 - val_loss: 9.7597\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6155 - val_loss: 10.1335\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4460 - val_loss: 9.9707\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4908 - val_loss: 9.7822\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0077 - val_loss: 10.1642\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5306 - val_loss: 10.1117\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5467 - val_loss: 9.7204\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4195 - val_loss: 9.7068\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4566 - val_loss: 9.8910\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5610 - val_loss: 9.9085\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5238 - val_loss: 9.8844\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3923 - val_loss: 9.8830\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3965 - val_loss: 9.8148\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4639 - val_loss: 10.0868\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5361 - val_loss: 10.1068\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6868 - val_loss: 9.7764\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6223 - val_loss: 9.9082\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3576 - val_loss: 9.9695\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5203 - val_loss: 10.2225\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4575 - val_loss: 10.2738\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4595 - val_loss: 9.7984\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4478 - val_loss: 10.1886\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3585 - val_loss: 10.5708\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4434 - val_loss: 10.0435\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3919 - val_loss: 10.2016\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4652 - val_loss: 10.1091\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6337 - val_loss: 10.0268\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0683 - val_loss: 9.8087\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1840 - val_loss: 9.9136\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6283 - val_loss: 10.2650\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7079 - val_loss: 10.0063\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8252 - val_loss: 10.0604\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5569 - val_loss: 10.0228\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4226 - val_loss: 9.9665\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3580 - val_loss: 9.9691\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3923 - val_loss: 10.0368\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5512 - val_loss: 10.1823\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3888 - val_loss: 10.0034\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3876 - val_loss: 10.0997\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4272 - val_loss: 10.1453\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4193 - val_loss: 9.9861\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3791 - val_loss: 10.1178\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3046 - val_loss: 9.8402\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5429 - val_loss: 9.9537\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4777 - val_loss: 10.1167\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3886 - val_loss: 9.9147\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6597 - val_loss: 9.9689\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5759 - val_loss: 10.0814\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3573 - val_loss: 10.3142\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4527 - val_loss: 10.0516\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3932 - val_loss: 9.8725\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3452 - val_loss: 9.9660\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4710 - val_loss: 9.8648\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6888 - val_loss: 10.1668\n",
      "Epoch 605/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5991 - val_loss: 9.8646\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8172 - val_loss: 9.9164\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8219 - val_loss: 10.2844\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6250 - val_loss: 9.8062\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8928 - val_loss: 9.8369\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5996 - val_loss: 9.9935\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5676 - val_loss: 10.3214\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6043 - val_loss: 9.9354\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4932 - val_loss: 9.9640\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3798 - val_loss: 9.9789\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3771 - val_loss: 10.1232\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3639 - val_loss: 9.9277\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4709 - val_loss: 10.1390\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3484 - val_loss: 10.0212\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3519 - val_loss: 9.8892\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4051 - val_loss: 10.0196\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6886 - val_loss: 9.9314\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5476 - val_loss: 10.2906\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8785 - val_loss: 10.0255\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5343 - val_loss: 10.3009\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6387 - val_loss: 10.0203\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4028 - val_loss: 9.8270\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4832 - val_loss: 9.9243\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5531 - val_loss: 10.0559\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3009 - val_loss: 9.7603\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4270 - val_loss: 10.1385\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4851 - val_loss: 9.8407\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6909 - val_loss: 10.2646\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6931 - val_loss: 9.9417\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4643 - val_loss: 9.8625\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3612 - val_loss: 9.8689\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3408 - val_loss: 9.9878\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4222 - val_loss: 9.8729\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4131 - val_loss: 10.1228\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3580 - val_loss: 9.8176\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3522 - val_loss: 10.1484\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3417 - val_loss: 9.8914\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3529 - val_loss: 9.9687\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4095 - val_loss: 10.1073\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4728 - val_loss: 10.1652\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4150 - val_loss: 9.9888\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3380 - val_loss: 9.8783\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4366 - val_loss: 9.9787\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4057 - val_loss: 9.8998\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4079 - val_loss: 9.7717\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4619 - val_loss: 10.4616\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3200 - val_loss: 10.0399\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3582 - val_loss: 9.9543\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4401 - val_loss: 10.0056\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4357 - val_loss: 10.0548\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3859 - val_loss: 10.2502\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5685 - val_loss: 10.2712\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3908 - val_loss: 10.3302\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3861 - val_loss: 9.8718\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3584 - val_loss: 10.2881\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3409 - val_loss: 10.1101\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4086 - val_loss: 9.7892\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3447 - val_loss: 9.9680\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2912 - val_loss: 10.1251\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4501 - val_loss: 9.8852\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5129 - val_loss: 9.8198\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8576 - val_loss: 10.3475\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4173 - val_loss: 10.0742\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4352 - val_loss: 10.4142\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6698 - val_loss: 9.8482\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7374 - val_loss: 10.1081\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6639 - val_loss: 10.1152\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5449 - val_loss: 10.3428\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3723 - val_loss: 10.0262\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3700 - val_loss: 10.2803\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4515 - val_loss: 9.9790\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4931 - val_loss: 10.0949\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5300 - val_loss: 10.1947\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4854 - val_loss: 9.9935\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3495 - val_loss: 10.1352\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3408 - val_loss: 10.0455\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3361 - val_loss: 10.0860\n",
      "Epoch 682/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.3984 - val_loss: 10.0195\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3448 - val_loss: 9.9584\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3039 - val_loss: 10.1223\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4658 - val_loss: 10.0520\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6891 - val_loss: 10.3449\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4318 - val_loss: 10.0027\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4504 - val_loss: 10.5520\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5172 - val_loss: 9.9380\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4058 - val_loss: 10.0366\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3049 - val_loss: 10.2194\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3796 - val_loss: 10.0301\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8793 - val_loss: 10.2217\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5408 - val_loss: 10.0995\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3737 - val_loss: 10.1977\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7366 - val_loss: 10.1960\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5634 - val_loss: 10.1295\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7143 - val_loss: 10.0935\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5954 - val_loss: 10.3074\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4202 - val_loss: 9.9566\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4478 - val_loss: 10.0495\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4074 - val_loss: 9.9970\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4253 - val_loss: 10.1332\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3825 - val_loss: 10.1696\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3045 - val_loss: 9.9845\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3038 - val_loss: 9.9955\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4095 - val_loss: 10.1051\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5977 - val_loss: 9.9482\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6302 - val_loss: 10.0912\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4079 - val_loss: 10.2745\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3389 - val_loss: 9.9335\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3295 - val_loss: 10.3390\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3173 - val_loss: 9.9131\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3334 - val_loss: 10.0198\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2892 - val_loss: 9.8938\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2948 - val_loss: 10.2191\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3435 - val_loss: 10.0843\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3351 - val_loss: 9.9184\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5297 - val_loss: 10.0911\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6566 - val_loss: 9.9121\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4741 - val_loss: 10.1922\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3600 - val_loss: 9.8982\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4315 - val_loss: 9.9262\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3136 - val_loss: 10.3988\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3950 - val_loss: 9.9025\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6215 - val_loss: 10.1196\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4092 - val_loss: 10.1178\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4732 - val_loss: 10.2379\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3324 - val_loss: 9.9880\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3424 - val_loss: 10.0242\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3849 - val_loss: 10.4238\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3312 - val_loss: 9.9772\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5089 - val_loss: 10.0228\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4979 - val_loss: 10.1579\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6367 - val_loss: 10.1221\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6157 - val_loss: 10.1801\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5796 - val_loss: 10.1470\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3836 - val_loss: 10.2563\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3184 - val_loss: 9.9473\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3601 - val_loss: 10.2214\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4622 - val_loss: 9.9998\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3214 - val_loss: 10.0100\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3236 - val_loss: 10.2012\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2981 - val_loss: 10.0011\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2893 - val_loss: 10.1521\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2977 - val_loss: 10.0421\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2422 - val_loss: 10.0788\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3187 - val_loss: 10.1762\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4571 - val_loss: 9.9307\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0267 - val_loss: 10.3215\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6698 - val_loss: 10.0595\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3343 - val_loss: 10.1013\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2436 - val_loss: 10.0973\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3327 - val_loss: 10.0305\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2568 - val_loss: 10.3040\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3481 - val_loss: 10.0608\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4189 - val_loss: 10.0987\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3437 - val_loss: 10.1426\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.5700 - val_loss: 10.0090\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2905 - val_loss: 10.2476\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3717 - val_loss: 10.0448\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2732 - val_loss: 10.2928\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2635 - val_loss: 9.9847\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3693 - val_loss: 10.0019\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2847 - val_loss: 10.0815\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4943 - val_loss: 10.1561\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4671 - val_loss: 10.2197\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3258 - val_loss: 10.5120\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3052 - val_loss: 10.0938\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2234 - val_loss: 10.2391\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3423 - val_loss: 10.0884\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2449 - val_loss: 10.0051\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2730 - val_loss: 10.0997\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6648 - val_loss: 10.4024\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5512 - val_loss: 10.2858\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6209 - val_loss: 10.1075\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3135 - val_loss: 10.1024\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3377 - val_loss: 9.9662\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3101 - val_loss: 10.2273\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5505 - val_loss: 10.0847\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4957 - val_loss: 10.1460\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3534 - val_loss: 10.1380\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3244 - val_loss: 10.1968\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3582 - val_loss: 9.9517\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6280 - val_loss: 10.1680\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5412 - val_loss: 10.2425\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2405 - val_loss: 10.6444\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3164 - val_loss: 10.0368\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7314 - val_loss: 10.3368\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8610 - val_loss: 10.2888\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6079 - val_loss: 10.2174\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.2340 - val_loss: 10.1801\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3082 - val_loss: 10.1609\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3770 - val_loss: 10.2217\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2773 - val_loss: 10.4382\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3497 - val_loss: 9.9607\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2974 - val_loss: 10.0768\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2488 - val_loss: 10.0757\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3512 - val_loss: 10.0957\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3707 - val_loss: 10.1321\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5912 - val_loss: 10.1108\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3180 - val_loss: 10.5704\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8136 - val_loss: 10.5649\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4833 - val_loss: 10.1729\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2980 - val_loss: 10.1677\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2220 - val_loss: 10.1317\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2396 - val_loss: 10.3710\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3015 - val_loss: 10.2919\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3104 - val_loss: 10.3400\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3478 - val_loss: 10.4765\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6971 - val_loss: 10.1419\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3617 - val_loss: 10.3994\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4188 - val_loss: 10.4288\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4210 - val_loss: 10.4856\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4018 - val_loss: 10.4947\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5492 - val_loss: 10.2010\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7981 - val_loss: 10.3696\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6455 - val_loss: 10.9832\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2652 - val_loss: 10.0279\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3004 - val_loss: 10.2638\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3432 - val_loss: 10.3924\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3219 - val_loss: 10.5172\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7192 - val_loss: 10.2322\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2750 - val_loss: 10.2386\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2579 - val_loss: 10.2183\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2593 - val_loss: 10.2229\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5174 - val_loss: 10.4220\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3448 - val_loss: 10.7540\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4798 - val_loss: 10.3213\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1960 - val_loss: 10.1926\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3163 - val_loss: 10.2743\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4090 - val_loss: 10.1539\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3441 - val_loss: 10.6622\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4175 - val_loss: 10.7164\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3412 - val_loss: 10.6747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2153 - val_loss: 10.4402\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3918 - val_loss: 10.3119\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6312 - val_loss: 10.6877\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4445 - val_loss: 10.6955\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6850 - val_loss: 10.5864\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7964 - val_loss: 10.5711\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3956 - val_loss: 10.4749\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3548 - val_loss: 10.5585\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5257 - val_loss: 10.6387\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2759 - val_loss: 10.5946\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4331 - val_loss: 10.4248\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2795 - val_loss: 10.8270\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3352 - val_loss: 10.4084\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4468 - val_loss: 10.7371\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3304 - val_loss: 10.6462\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2799 - val_loss: 10.5211\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2749 - val_loss: 10.9632\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5368 - val_loss: 10.7826\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2026 - val_loss: 10.7168\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4769 - val_loss: 10.7039\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5678 - val_loss: 10.6240\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2282 - val_loss: 10.5992\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1818 - val_loss: 10.3611\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2175 - val_loss: 10.6949\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3384 - val_loss: 10.9977\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2241 - val_loss: 10.3501\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1851 - val_loss: 10.3321\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3886 - val_loss: 10.9032\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3725 - val_loss: 10.9013\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4190 - val_loss: 10.4498\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4988 - val_loss: 10.5640\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9314 - val_loss: 10.7085\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9995 - val_loss: 10.6692\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5556 - val_loss: 10.6592\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3721 - val_loss: 10.7406\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3334 - val_loss: 10.8674\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2583 - val_loss: 10.9602\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2363 - val_loss: 11.1444\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2780 - val_loss: 10.6872\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.2235 - val_loss: 10.4452\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2492 - val_loss: 10.6284\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1711 - val_loss: 10.4075\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2238 - val_loss: 10.7039\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2600 - val_loss: 11.1609\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4635 - val_loss: 11.0105\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8080 - val_loss: 10.7013\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5007 - val_loss: 10.8152\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2135 - val_loss: 10.9537\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2680 - val_loss: 10.4557\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1917 - val_loss: 10.7543\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1806 - val_loss: 10.8109\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1927 - val_loss: 10.7662\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2096 - val_loss: 10.4203\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1972 - val_loss: 10.7260\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2124 - val_loss: 10.7409\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1951 - val_loss: 10.8679\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3040 - val_loss: 10.5305\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1179 - val_loss: 10.5303\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2804 - val_loss: 10.8147\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2443 - val_loss: 10.7337\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5665 - val_loss: 10.9536\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2857 - val_loss: 11.1780\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1742 - val_loss: 9.9953\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2969 - val_loss: 10.2920\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3467 - val_loss: 10.4660\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1711 - val_loss: 10.3358\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3303 - val_loss: 10.5967\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3224 - val_loss: 10.7441\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1390 - val_loss: 10.4523\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1225 - val_loss: 10.4919\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1751 - val_loss: 10.3089\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1632 - val_loss: 10.6118\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1163 - val_loss: 10.4337\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2134 - val_loss: 10.4149\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1215 - val_loss: 10.3812\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4656 - val_loss: 10.0130\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6059 - val_loss: 10.7660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4219 - val_loss: 10.8089\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3485 - val_loss: 10.3182\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1990 - val_loss: 11.0065\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5336 - val_loss: 10.0495\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2806 - val_loss: 10.1265\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1393 - val_loss: 10.1836\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0752 - val_loss: 10.4582\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2376 - val_loss: 10.2810\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4179 - val_loss: 10.3106\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1637 - val_loss: 10.3232\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1360 - val_loss: 10.3579\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1736 - val_loss: 10.4303\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2084 - val_loss: 10.3122\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1953 - val_loss: 10.4049\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1130 - val_loss: 10.2725\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0581 - val_loss: 10.4878\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2049 - val_loss: 10.5116\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2245 - val_loss: 10.3415\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1716 - val_loss: 10.5654\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1055 - val_loss: 10.4616\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1668 - val_loss: 10.2038\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1310 - val_loss: 10.2410\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0855 - val_loss: 10.5893\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1533 - val_loss: 10.2595\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2274 - val_loss: 10.3178\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2041 - val_loss: 10.4940\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3933 - val_loss: 10.4167\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1503 - val_loss: 10.2381\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0817 - val_loss: 10.1565\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2803 - val_loss: 10.2641\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0927 - val_loss: 10.2784\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2196 - val_loss: 10.0846\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6649 - val_loss: 10.4587\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3348 - val_loss: 10.2023\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1505 - val_loss: 10.1050\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1421 - val_loss: 10.2009\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2630 - val_loss: 10.2312\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2244 - val_loss: 10.1506\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4044 - val_loss: 9.9454\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1486 - val_loss: 9.9583\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1059 - val_loss: 10.0016\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0846 - val_loss: 10.1336\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1238 - val_loss: 10.5098\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4646 - val_loss: 10.3193\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3354 - val_loss: 9.8787\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2472 - val_loss: 9.9140\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0773 - val_loss: 9.8302\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1136 - val_loss: 9.8074\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0826 - val_loss: 10.1073\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0931 - val_loss: 9.9786\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2773 - val_loss: 9.9288\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1331 - val_loss: 10.0675\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0019 - val_loss: 9.7941\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2387 - val_loss: 9.9370\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7534 - val_loss: 9.9550\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2610 - val_loss: 9.9439\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2134 - val_loss: 9.8018\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4008 - val_loss: 9.9055\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3782 - val_loss: 9.8204\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4534 - val_loss: 9.7136\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1924 - val_loss: 9.8727\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0653 - val_loss: 9.7415\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0034 - val_loss: 9.8537\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2336 - val_loss: 10.0431\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0130 - val_loss: 9.7665\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1256 - val_loss: 9.7393\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1974 - val_loss: 10.0542\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1235 - val_loss: 9.9286\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2756 - val_loss: 9.7389\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1299 - val_loss: 9.7920\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1549 - val_loss: 9.8343\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1209 - val_loss: 9.7804\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0560 - val_loss: 9.8044\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1898 - val_loss: 9.9443\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0870 - val_loss: 9.7865\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0928 - val_loss: 9.6771\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1243 - val_loss: 9.9478\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.1515 - val_loss: 9.9660\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0848 - val_loss: 9.9932\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1268 - val_loss: 9.8425\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0788 - val_loss: 9.9182\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1493 - val_loss: 10.1000\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0334 - val_loss: 9.8916\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1068 - val_loss: 9.9012\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1804 - val_loss: 10.0026\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3021 - val_loss: 10.0681\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5082 - val_loss: 9.8606\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0618 - val_loss: 10.0744\n",
      "10.745060823731503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.93721586,  1.0142405 , -0.63533235,  1.4860946 ,  1.6661663 ],\n",
       "        [-1.2892848 ,  0.13725366, -1.0635946 , -1.0897348 ,  0.2607438 ],\n",
       "        [ 0.9041363 , -2.4055266 , -0.1755637 ,  1.5018466 , -2.0919046 ],\n",
       "        [ 0.6482353 , -0.88861954, -0.7893984 ,  1.5678409 , -0.15092516],\n",
       "        [-0.3523444 , -0.5832104 , -0.25203574,  0.50616693, -0.77049595],\n",
       "        [ 0.6109077 ,  1.5072347 ,  0.62969667, -1.0125368 ,  0.16259655],\n",
       "        [-0.06370833,  0.5220317 , -0.9184296 , -1.7730603 ,  0.47551584]],\n",
       "       dtype=float32),\n",
       " array([ 0.9841386 , -0.71666616,  0.35762247,  0.56887317, -0.3944741 ],\n",
       "       dtype=float32),\n",
       " array([[ -0.4670606 ,  -2.1155608 ,  -0.23940441,   0.5950548 ,\n",
       "           1.6993604 ,  -2.3058186 ,  -2.748654  ,   0.47687435,\n",
       "          -9.090973  ,   0.78415   ],\n",
       "        [ -1.4978926 ,  -0.98516583,   0.6066328 ,   1.4342366 ,\n",
       "           4.276979  ,  -0.4254415 ,  -1.170297  ,   0.15900937,\n",
       "         -10.3958845 ,   0.32857457],\n",
       "        [ -4.954319  ,  -2.2906322 ,  -0.24066499,  -4.141659  ,\n",
       "           3.812653  ,  -3.0386138 ,  -3.1009386 ,  -0.89404756,\n",
       "          -0.02819115,   3.209367  ],\n",
       "        [ -1.208444  ,  -0.77740395,  -5.392199  ,   0.13600524,\n",
       "          -0.37049696,  -0.6954488 ,  -0.46831644,  -0.377512  ,\n",
       "          -0.7778299 ,   0.21735458],\n",
       "        [  1.7258358 ,  -0.19706975,  -0.82286185,  -3.3676565 ,\n",
       "          -0.16562231,  -0.8784354 ,  -2.0244668 ,  -0.21176323,\n",
       "           1.7954305 ,   3.8273711 ]], dtype=float32),\n",
       " array([-0.19089635, -1.3692963 ,  0.20882775, -1.5350603 ,  1.2036078 ,\n",
       "        -1.1679577 , -0.4048864 ,  0.41745734,  0.24370027,  0.7956295 ],\n",
       "       dtype=float32),\n",
       " array([[-3.189226 ],\n",
       "        [-3.2446344],\n",
       "        [ 9.139548 ],\n",
       "        [-3.2704742],\n",
       "        [ 4.1053023],\n",
       "        [-2.96558  ],\n",
       "        [-3.4084828],\n",
       "        [-3.276479 ],\n",
       "        [-2.9267583],\n",
       "        [ 3.3727727]], dtype=float32),\n",
       " array([2.5561066], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_tanh(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_tanh_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1987 - val_loss: 0.0663\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0832 - val_loss: 0.1039\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0697 - val_loss: 0.0613\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0548 - val_loss: 0.0106\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0311 - val_loss: 0.0214\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0218 - val_loss: 0.0193\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0184 - val_loss: 0.0153\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 143us/step - loss: 0.0151 - val_loss: 0.0052\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0140 - val_loss: 0.0062\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0124 - val_loss: 0.0043\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0058\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 138us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0076\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0076\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0071\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0072\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "0.005055123008787632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.07926527e-01, -2.45262131e-01, -7.91803420e-01,\n",
       "          2.30019301e-01, -1.86502531e-01],\n",
       "        [ 2.80307643e-02, -1.10159302e+00,  2.63107359e-01,\n",
       "         -9.17307362e-02, -8.44111383e-01],\n",
       "        [-1.01208949e+00, -5.04398048e-01,  2.64170080e-01,\n",
       "          8.46432447e-02, -1.40624210e-01],\n",
       "        [-8.03521395e-01,  5.74957013e-01, -3.62008542e-01,\n",
       "          1.89931616e-01,  6.89588130e-01],\n",
       "        [ 1.43744722e-01,  4.79616553e-01, -5.99399395e-02,\n",
       "         -4.43951964e-01, -3.17525715e-01],\n",
       "        [ 1.37709546e+00,  4.73687351e-02, -2.30803639e-01,\n",
       "         -3.63167882e-01, -1.36871701e-02],\n",
       "        [-6.27183855e-01, -4.81542051e-01,  2.15626419e-01,\n",
       "          4.85081449e-02,  7.37508953e-01],\n",
       "        [ 2.27012619e-01,  4.11708169e-02, -1.06609434e-01,\n",
       "          1.23651810e-01, -4.22493994e-01],\n",
       "        [ 3.86635900e-01,  1.95587707e+00,  6.64027035e-01,\n",
       "         -7.17437267e-01,  4.43882048e-01],\n",
       "        [-5.06133884e-02, -1.24602056e+00, -3.52523953e-01,\n",
       "          1.25966597e+00, -2.20671847e-01],\n",
       "        [-3.24944466e-01,  5.95704138e-01,  6.44846618e-01,\n",
       "          3.13813537e-01, -1.23560697e-01],\n",
       "        [-2.98938900e-01, -5.32263100e-01,  9.78526846e-02,\n",
       "          9.21797931e-01,  8.11865449e-01],\n",
       "        [ 1.29469371e+00, -1.41310954e+00,  1.01560704e-01,\n",
       "          4.51805145e-01,  1.28038704e+00],\n",
       "        [ 2.18336248e+00,  1.22455919e+00, -5.48031777e-02,\n",
       "         -1.94315612e-01,  1.90477390e-02],\n",
       "        [ 2.16704533e-02, -1.37126565e-01,  1.07083309e+00,\n",
       "         -2.33230159e-01, -3.68479230e-02],\n",
       "        [-3.36985141e-01,  3.75349760e-01, -2.74486333e-01,\n",
       "          2.58584946e-01, -6.09426200e-01],\n",
       "        [-4.03026044e-01, -3.23422134e-01,  1.79594606e-01,\n",
       "         -3.55300084e-02,  4.69403386e-01],\n",
       "        [ 1.42712206e-01,  8.87324661e-02, -4.63896304e-01,\n",
       "          2.20244844e-02,  9.33594167e-01],\n",
       "        [ 8.48818963e-05,  7.47517943e-01,  5.05113304e-01,\n",
       "         -1.00480747e+00, -6.90737724e-01],\n",
       "        [-1.10856700e+00,  1.00024843e+00,  3.08156788e-01,\n",
       "          1.17761821e-01, -1.15825939e+00],\n",
       "        [-1.78491223e+00, -6.03415489e-01,  3.76080960e-01,\n",
       "          1.11155853e-01,  7.80048132e-01],\n",
       "        [-2.74392098e-01, -3.34588438e-01,  8.69664669e-01,\n",
       "          9.81875718e-01,  1.00481224e+00]], dtype=float32),\n",
       " array([-0.8074067 , -0.3199115 , -0.05119763,  0.08749302,  0.35844135],\n",
       "       dtype=float32),\n",
       " array([[ 0.22063553, -0.2486117 ,  0.4888275 , -0.1938035 ,  0.10748924,\n",
       "         -0.01283936, -0.20291543, -0.68858546, -0.14617147,  0.6779309 ],\n",
       "        [-0.31577644,  0.42312288, -0.07984105,  0.14141378, -0.7364399 ,\n",
       "         -0.03425269, -0.20663351, -0.0889571 ,  0.19302247,  0.20176005],\n",
       "        [-0.25965625,  0.04842303,  0.15455759, -0.22890006, -0.28983605,\n",
       "         -0.17234354,  0.09793448, -0.42062363, -0.03535131,  0.19107167],\n",
       "        [ 0.23997748, -0.2190659 ,  0.80123603,  0.2611245 , -0.1881105 ,\n",
       "         -0.194078  , -1.038039  , -0.047504  , -0.02061846,  0.25630862],\n",
       "        [-0.23220138,  0.64603645, -0.39868602, -0.3354023 , -0.21319547,\n",
       "          0.35720444,  0.06139299, -0.31307647,  0.14670554, -0.09248891]],\n",
       "       dtype=float32),\n",
       " array([ 0.11657862, -0.177253  ,  0.04297468,  0.11602016, -0.08054272,\n",
       "         0.03220912,  0.38036764, -0.05871351, -0.04111248,  0.18781817],\n",
       "       dtype=float32),\n",
       " array([[ 0.00165385],\n",
       "        [-0.0519327 ],\n",
       "        [ 0.3881531 ],\n",
       "        [ 0.02017366],\n",
       "        [-0.31978568],\n",
       "        [-0.02985883],\n",
       "        [-0.03149817],\n",
       "        [-0.03254116],\n",
       "        [-0.00417552],\n",
       "        [ 0.37173247]], dtype=float32),\n",
       " array([0.13440992], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_linear(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_linear_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1763 - val_loss: 0.0555\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0358 - val_loss: 0.0248\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0385 - val_loss: 0.0257\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0282\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0373 - val_loss: 0.0293\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0269\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0367 - val_loss: 0.0279\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0372 - val_loss: 0.0290\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.042 - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0367 - val_loss: 0.0274\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0257\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0372 - val_loss: 0.0290\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0285\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0277\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0374 - val_loss: 0.0257\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0271\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.014 - 0s 119us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0271\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.029 - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0265\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0278\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0281\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0263\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0287\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0265\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 120us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "0.05467016622424126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.38070178,  0.05093754,  0.28398916,  0.04300103, -0.68727183],\n",
       "        [-0.1014373 , -0.5660536 , -0.28945524,  0.18106064, -0.3436229 ],\n",
       "        [-0.82323325, -0.0955064 , -0.0691985 , -0.08945966, -0.2065902 ],\n",
       "        [-0.3538584 , -0.6491721 , -0.78472453, -0.45083833, -0.1546531 ],\n",
       "        [ 0.05209605, -0.19480152, -0.41885355, -0.22170794, -0.69067883],\n",
       "        [-0.5076685 , -0.1789403 , -0.25681943,  0.31936643,  0.05067737],\n",
       "        [-0.6441425 , -0.6381071 , -0.5410501 , -0.41913873, -0.7073273 ],\n",
       "        [-0.5863256 , -0.02686948, -0.15920386, -0.25277442, -0.7365268 ],\n",
       "        [-0.5942957 , -0.18908627, -0.2615877 , -0.2654875 , -0.02388259],\n",
       "        [-0.03458009, -0.68694305, -0.54144293, -0.4332741 , -0.1418482 ],\n",
       "        [-0.32284656,  0.04954637, -0.61614275,  0.45769444, -0.8198087 ],\n",
       "        [-0.5180238 , -0.3845863 , -0.40332273,  0.20796862,  0.04363811],\n",
       "        [-0.11034798, -0.57044834,  0.12929687, -0.33118182,  0.01734884],\n",
       "        [-0.3229761 , -0.6182617 ,  0.29625064,  0.32661507, -0.33750838],\n",
       "        [-0.18957637, -0.43363324,  0.00879044, -0.3929888 , -0.4509323 ],\n",
       "        [-0.689275  , -0.636541  , -0.24539012, -0.18669415, -0.54550916],\n",
       "        [ 0.0832005 , -0.45149338, -0.8628688 , -0.2541737 , -0.26330164],\n",
       "        [ 0.02789944,  0.09272855, -0.3048817 ,  0.07490596, -0.13902363],\n",
       "        [-0.6219604 , -0.26392844,  0.32218915,  0.10912642, -0.21711548],\n",
       "        [-0.2083934 , -0.3653776 , -0.41307166, -0.10251856, -0.00945077],\n",
       "        [-0.12851663,  0.06028337, -0.5145811 , -0.06494322, -0.00506335],\n",
       "        [-0.2723948 , -0.05729112, -0.47917324,  0.3476872 , -0.76727885]],\n",
       "       dtype=float32),\n",
       " array([-0.2762291 , -0.3361558 , -0.2938076 ,  0.        , -0.37825045],\n",
       "       dtype=float32),\n",
       " array([[-0.67320454,  0.12434566,  0.07188057,  0.43257815,  0.40470645,\n",
       "         -0.7839881 , -0.42942956,  0.22794361, -0.00481636,  0.4343833 ],\n",
       "        [ 0.02281594,  0.5475439 , -0.05522318, -0.13605809,  0.20427933,\n",
       "         -0.01921129, -0.30084908,  0.19426256,  0.27410895, -0.4187169 ],\n",
       "        [-0.9960127 ,  0.12946996, -0.5208288 , -0.3847806 , -0.88147944,\n",
       "         -0.6518312 ,  0.2166522 , -0.96406806, -0.9055622 ,  0.5931858 ],\n",
       "        [ 0.47102004, -0.41518074, -0.53248686, -0.19065705,  0.4429354 ,\n",
       "          0.26925695,  0.4248652 , -0.15282315,  0.3583225 ,  0.06532109],\n",
       "        [ 0.13711405,  0.0299895 , -0.5656497 , -0.5361509 , -0.3466071 ,\n",
       "         -0.11453463, -0.33207062, -0.6773111 , -0.18872702, -0.11088947]],\n",
       "       dtype=float32),\n",
       " array([-0.3491886 , -0.02198337, -0.34568992,  0.        , -0.33754623,\n",
       "        -0.35399464, -0.32106802, -0.349527  , -0.34415165, -0.23901644],\n",
       "       dtype=float32),\n",
       " array([[ 0.21445026],\n",
       "        [ 0.42404228],\n",
       "        [ 0.1629769 ],\n",
       "        [ 0.23486531],\n",
       "        [ 0.15810195],\n",
       "        [-0.3859217 ],\n",
       "        [-0.15464197],\n",
       "        [ 0.05714979],\n",
       "        [-0.18224207],\n",
       "        [-0.15391321]], dtype=float32),\n",
       " array([0.20996694], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_relu(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_relu_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.2360\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.1857 - val_loss: 0.0252\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0511 - val_loss: 0.0618\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0441 - val_loss: 0.0195\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0335 - val_loss: 0.0214\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0345 - val_loss: 0.0179\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0298 - val_loss: 0.0228\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0297 - val_loss: 0.0196\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0274 - val_loss: 0.0154\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0146\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0248 - val_loss: 0.0152\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0242 - val_loss: 0.0143\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0232 - val_loss: 0.0128\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0228 - val_loss: 0.0126\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0222 - val_loss: 0.0122\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0211 - val_loss: 0.0108\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0204 - val_loss: 0.0103\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0196 - val_loss: 0.0100\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0193 - val_loss: 0.0096\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0185 - val_loss: 0.0088\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0183 - val_loss: 0.0084\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0175 - val_loss: 0.0081\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0172 - val_loss: 0.0078\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0168 - val_loss: 0.0076\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0166 - val_loss: 0.0074\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0163 - val_loss: 0.0073\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0163 - val_loss: 0.0072\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0160 - val_loss: 0.0074\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0158 - val_loss: 0.0069\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0156 - val_loss: 0.0070\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0152 - val_loss: 0.0068\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0152 - val_loss: 0.0068\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0151 - val_loss: 0.0066\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0146 - val_loss: 0.0069\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0146 - val_loss: 0.0065\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0150 - val_loss: 0.0064\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0145 - val_loss: 0.0072\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0141 - val_loss: 0.0064\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0140 - val_loss: 0.0064\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0139 - val_loss: 0.0065\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0140 - val_loss: 0.0064\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0138 - val_loss: 0.0065\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0135 - val_loss: 0.0061\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0131 - val_loss: 0.0061\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0129 - val_loss: 0.0065\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0128 - val_loss: 0.0060\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0127 - val_loss: 0.0060\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0126 - val_loss: 0.0059\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0125 - val_loss: 0.0060\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0122 - val_loss: 0.0060\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0122 - val_loss: 0.0060\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0129 - val_loss: 0.0058\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0129 - val_loss: 0.0066\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0118 - val_loss: 0.0060\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0122 - val_loss: 0.0060\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0118 - val_loss: 0.0058\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0115 - val_loss: 0.0058\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0114 - val_loss: 0.0057\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0112 - val_loss: 0.0056\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0113 - val_loss: 0.0055\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0117 - val_loss: 0.0055\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0115 - val_loss: 0.0066\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0116 - val_loss: 0.0056\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0104 - val_loss: 0.0055\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0114 - val_loss: 0.0055\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0105 - val_loss: 0.0052\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0050\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0051\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0051\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 132us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "0.008190426975488663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 6.8932390e-01, -3.4172720e-01, -4.6320570e-01, -5.2318412e-01,\n",
       "         -1.8387462e-01],\n",
       "        [-1.3491477e-01, -2.2089702e-01, -1.3383634e-01, -6.9597280e-01,\n",
       "         -5.5431855e-01],\n",
       "        [-2.0201902e-01, -8.3530098e-02,  5.7456926e-02,  7.8027107e-02,\n",
       "         -3.3995131e-01],\n",
       "        [ 1.8516433e-01, -5.0327271e-02, -6.3716292e-01,  1.5194365e-01,\n",
       "         -1.4779061e-01],\n",
       "        [-2.1351235e-01, -1.8119872e-02,  7.3341899e-02, -5.9947900e-02,\n",
       "         -6.1143851e-01],\n",
       "        [ 9.1252488e-01, -1.8023443e-01, -8.0963099e-01,  1.3943671e-01,\n",
       "         -4.0973967e-01],\n",
       "        [-3.7120032e-01, -2.2296268e-01, -8.2238950e-02, -1.4245750e-01,\n",
       "         -5.7540447e-01],\n",
       "        [ 2.5287932e-01, -2.6341185e-01, -2.0357479e-01, -3.3594728e-01,\n",
       "         -3.3455682e-01],\n",
       "        [-7.3779918e-02, -3.5907689e-01, -7.3205662e-01, -6.0543364e-01,\n",
       "         -1.7458627e-01],\n",
       "        [ 9.0528846e-01,  1.9201013e-01, -8.0017632e-01, -1.0413492e-02,\n",
       "         -8.8062353e-02],\n",
       "        [-5.5566496e-01,  3.7500772e-01, -2.5278848e-01, -2.9181135e-01,\n",
       "         -1.9622658e-01],\n",
       "        [ 2.4290863e-01, -1.3941738e-01, -6.3609719e-01,  3.3251200e-02,\n",
       "         -6.4757735e-01],\n",
       "        [-3.6472595e-01, -4.6002981e-01, -4.9808067e-01, -1.4045544e-01,\n",
       "         -1.5923534e-01],\n",
       "        [ 3.7149732e+00,  4.1465670e-02, -4.1594750e-01, -4.8699778e-01,\n",
       "         -5.4440808e-01],\n",
       "        [ 2.3576720e-01,  2.2496969e-02, -4.5589581e-01, -2.8741956e-01,\n",
       "         -3.8070506e-01],\n",
       "        [-7.8680832e-04, -1.2637571e-01, -3.4359854e-01,  1.4286721e-01,\n",
       "         -1.8729216e-01],\n",
       "        [-2.4608591e-01, -3.4415543e-01, -7.3243178e-02, -3.7662795e-01,\n",
       "         -5.4605561e-01],\n",
       "        [ 8.0504626e-01,  7.3892325e-02, -5.2618194e-01, -2.2610877e-01,\n",
       "          4.0597204e-02],\n",
       "        [-1.1981412e+00, -1.5132448e-01, -4.5097500e-01, -1.6828470e-01,\n",
       "          1.0320020e-02],\n",
       "        [ 1.1074834e+00, -7.4990034e-02, -9.5100962e-02, -3.2646564e-01,\n",
       "         -1.4166738e-01],\n",
       "        [-2.7285199e+00,  1.6927603e-01, -9.1863699e-02, -2.1408091e-01,\n",
       "         -1.3665374e-01],\n",
       "        [-3.2684216e-01, -2.9155359e-01, -4.9596629e-01, -2.5157327e-02,\n",
       "         -5.9922868e-01]], dtype=float32),\n",
       " array([-0.10472986,  0.        , -0.39887375, -0.22177169, -0.39701638],\n",
       "       dtype=float32),\n",
       " array([[-0.9062275 , -0.7970763 , -0.49012983, -0.4774171 , -0.4402541 ,\n",
       "         -1.1991591 ,  0.5479544 , -2.508178  , -0.49913916, -1.376369  ],\n",
       "        [-0.2565599 ,  0.01354176, -0.36991203, -0.59810984, -0.09973902,\n",
       "         -0.32823858,  0.51370925,  0.4380595 ,  0.5133603 ,  0.42955607],\n",
       "        [-0.38689348, -0.71573   , -0.53499746,  0.03056982, -0.20562804,\n",
       "         -0.18561168,  0.51663494, -0.10733286, -0.15983853, -0.6851173 ],\n",
       "        [-0.82231516, -1.0337754 ,  0.02044585,  0.03949108, -0.3975192 ,\n",
       "          0.13710776,  0.50704944, -0.65417   , -0.14299928, -0.6346238 ],\n",
       "        [-0.29101804,  0.18207629, -0.8746902 ,  0.26275668,  0.06426844,\n",
       "         -0.37088266, -0.30785605,  0.24959761,  0.48441988, -0.663084  ]],\n",
       "       dtype=float32),\n",
       " array([-0.7389878 ,  1.7472699 , -0.6891172 ,  0.10580363, -0.57112545,\n",
       "        -0.27119675, -0.8678931 , -1.1688982 , -0.75264794,  0.03239495],\n",
       "       dtype=float32),\n",
       " array([[ 0.04764207],\n",
       "        [-0.78711903],\n",
       "        [-0.13240775],\n",
       "        [-0.46098214],\n",
       "        [-0.12729731],\n",
       "        [ 0.38345563],\n",
       "        [ 1.3137959 ],\n",
       "        [-0.2759006 ],\n",
       "        [-0.06516517],\n",
       "        [ 0.7024487 ]], dtype=float32),\n",
       " array([0.22598639], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_sigmoid(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sigmoid_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0254\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0297\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0386 - val_loss: 0.0293\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0402 - val_loss: 0.0259\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0388 - val_loss: 0.0250\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0374 - val_loss: 0.0322\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0377 - val_loss: 0.0257\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0262\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0292\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0376 - val_loss: 0.0257\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0298\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0277\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0258\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0292\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0277\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0253\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0372 - val_loss: 0.0277\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0256\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0290\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0256\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0376 - val_loss: 0.0264\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0310\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0263\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0280\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0256\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0290\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0275\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0375 - val_loss: 0.0256\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0281\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0256\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0264\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0289\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0251\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0270\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0279\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0373 - val_loss: 0.0290\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0266\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0309\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0374 - val_loss: 0.0273\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0255\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.038 - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0289\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0284\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0289\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0371 - val_loss: 0.0256\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0281\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0284\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0287\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0285\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.038 - 0s 133us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0269\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0263\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0287\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0374 - val_loss: 0.0276\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0266\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0273\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0288\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 170us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0276\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0288\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0287\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "0.054700180888175964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.70168304,  0.04651755,  0.10688117, -0.6131091 , -0.15943389],\n",
       "        [-0.32554382, -0.6729048 , -0.14768043, -0.01486701,  0.0990205 ],\n",
       "        [-0.03181594, -0.40534827, -0.40209556, -0.23426937, -0.22163515],\n",
       "        [-0.36851957, -0.19336285,  0.39547738, -0.6070916 ,  0.18342051],\n",
       "        [-0.357041  , -0.56808686, -0.29190534, -0.36353073, -0.3003848 ],\n",
       "        [-0.58956254, -0.26148033, -0.29410654, -0.36828968, -0.6109175 ],\n",
       "        [-0.72772324,  0.10183853, -0.3157071 , -0.380015  , -0.6470737 ],\n",
       "        [-0.7074462 ,  0.06710318, -0.31836987, -0.14888819, -0.5229826 ],\n",
       "        [-0.3365185 ,  0.21725246, -0.06206229, -0.38109732,  0.09730373],\n",
       "        [ 0.01747735, -0.19986258, -0.27517205,  0.06829961, -0.7212097 ],\n",
       "        [-0.21659635, -0.3896386 ,  0.1886845 , -0.22950661, -0.18680635],\n",
       "        [-0.52136123, -0.01033403,  0.44676337, -0.73050267, -0.63059574],\n",
       "        [-0.01871279,  0.19597559, -0.46867216, -0.63834685, -0.24275887],\n",
       "        [-0.1381751 , -0.33319503,  0.04036173, -0.58865035, -0.36473092],\n",
       "        [-0.6622195 , -0.36984855, -0.4702986 , -0.00459569, -0.7963684 ],\n",
       "        [-0.30209452, -0.42451346, -0.24756992, -0.38591754, -0.5931917 ],\n",
       "        [-0.5405807 , -0.467583  , -0.3227045 , -0.4529331 , -0.43185392],\n",
       "        [-0.7388456 ,  0.07036944, -0.11274901, -0.39511135, -0.13517457],\n",
       "        [-0.74484575,  0.24096838, -0.0072867 , -0.15095256, -0.37695634],\n",
       "        [-0.7102773 , -0.26098564,  0.27469024, -0.23879193, -0.22373116],\n",
       "        [-0.40461102, -0.6330971 ,  0.37637922, -0.6703039 , -0.00737145],\n",
       "        [-0.1780138 , -0.6132129 , -0.40745384, -0.26168022,  0.12108137]],\n",
       "       dtype=float32),\n",
       " array([-0.41441345, -0.27842125,  0.        , -0.31761762, -0.33772814],\n",
       "       dtype=float32),\n",
       " array([[-0.7052613 ,  0.19447258,  0.02158154, -0.31493798, -0.5678769 ,\n",
       "         -0.18621835,  0.02796759,  0.14289276, -0.45702654, -0.391976  ],\n",
       "        [ 0.18120007, -0.05232224,  0.36889216,  0.17941435, -0.04912947,\n",
       "         -0.6703531 ,  0.27192888,  0.2751713 , -0.04986313, -0.697663  ],\n",
       "        [-0.05308515, -0.3154307 , -0.2797196 ,  0.07342994,  0.1944114 ,\n",
       "          0.47262746,  0.52177995,  0.6046701 , -0.31458357,  0.32168877],\n",
       "        [-0.44239053, -0.33157948, -0.09349734,  0.48821324,  0.2776911 ,\n",
       "          0.4154528 ,  0.06687333, -0.27648234, -0.80736715,  0.00505822],\n",
       "        [ 0.2559767 , -0.5200511 ,  0.18219815, -0.39728078, -0.24981706,\n",
       "         -0.3420798 , -0.64922345,  0.12205448, -0.487886  ,  0.33373454]],\n",
       "       dtype=float32),\n",
       " array([ 1.8492185e-35,  1.4789702e-31, -1.2664953e-34, -4.1351564e-35,\n",
       "         9.8007185e-26,  2.8995850e-35, -8.4878764e-36, -5.5138285e-24,\n",
       "        -1.9181357e-35, -3.6014253e-24], dtype=float32),\n",
       " array([[ 2.5438757e-35],\n",
       "        [ 2.0698911e-31],\n",
       "        [-1.5777520e-34],\n",
       "        [ 3.5360807e-35],\n",
       "        [-1.1224153e-25],\n",
       "        [-8.5391816e-36],\n",
       "        [ 6.2647616e-35],\n",
       "        [-7.6911871e-24],\n",
       "        [-6.1469188e-35],\n",
       "        [-4.9117730e-24]], dtype=float32),\n",
       " array([0.20640244], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_tanh(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_tanh_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 37.0220 - val_loss: 38.0699\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.5482 - val_loss: 31.4097\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.9011 - val_loss: 25.4479\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 25.7163 - val_loss: 19.6317\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 20.2449 - val_loss: 13.5062\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 13.6605 - val_loss: 7.2750\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8189 - val_loss: 2.1976\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5613 - val_loss: 0.5523\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.8347 - val_loss: 3.6616\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7859 - val_loss: 6.9630\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5060 - val_loss: 6.6013\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4830 - val_loss: 4.0802\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7941 - val_loss: 1.6370\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4733 - val_loss: 0.3151\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3070 - val_loss: 0.1374\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1901 - val_loss: 0.6746\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6776 - val_loss: 1.4472\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3223 - val_loss: 2.1005\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8129 - val_loss: 2.4426\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0072 - val_loss: 2.4243\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9006 - val_loss: 2.0947\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5710 - val_loss: 1.5620\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1294 - val_loss: 0.9651\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6855 - val_loss: 0.4477\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3287 - val_loss: 0.1261\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1177 - val_loss: 0.0516\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0713 - val_loss: 0.1864\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1615 - val_loss: 0.4176\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3212 - val_loss: 0.6129\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4711 - val_loss: 0.6855\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5530 - val_loss: 0.6246\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5476 - val_loss: 0.4764\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4683 - val_loss: 0.3043\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3468 - val_loss: 0.1578\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2186 - val_loss: 0.0624\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1146 - val_loss: 0.0229\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0544 - val_loss: 0.0301\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0424 - val_loss: 0.0679\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0681 - val_loss: 0.1180\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1124 - val_loss: 0.1645\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1549 - val_loss: 0.1965\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1811 - val_loss: 0.2087\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1847 - val_loss: 0.2005\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1675 - val_loss: 0.1750\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.1363 - val_loss: 0.1379\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0998 - val_loss: 0.0961\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0657 - val_loss: 0.0574\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0248 - val_loss: 0.0160\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0216 - val_loss: 0.0183\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0280 - val_loss: 0.0314\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0399 - val_loss: 0.0471\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0519 - val_loss: 0.0575\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0592 - val_loss: 0.0582\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0596 - val_loss: 0.0496\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0535 - val_loss: 0.0362\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0435 - val_loss: 0.0235\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0157\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0241 - val_loss: 0.0141\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0178\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0247\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0161 - val_loss: 0.0323\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0181 - val_loss: 0.0388\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0208 - val_loss: 0.0430\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0232 - val_loss: 0.0443\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0244 - val_loss: 0.0429\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0240 - val_loss: 0.0392\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0340\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0193 - val_loss: 0.0281\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0174\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0136\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0132\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0088 - val_loss: 0.0126\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0141\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0089 - val_loss: 0.0145\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0088 - val_loss: 0.0139\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0086 - val_loss: 0.0132\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0114\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0086\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0087\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0086\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.9954e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.9044e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.8142e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.7253e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6374e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0012 - val_loss: 9.5506e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0012 - val_loss: 9.4648e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.3797e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.2958e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.2127e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.1306e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.0495e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.9693e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.8898e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.8115e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 8.7339e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.6573e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.5815e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.5067e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.4326e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.3593e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.2871e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.2152e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.1445e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.0743e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.0051e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.9365e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.8688e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.8018e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.7356e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.6702e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.6056e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.5416e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0010 - val_loss: 7.4785e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 7.4158e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.3539e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.2927e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 7.2321e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 7.1723e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0010 - val_loss: 7.1133e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 7.0546e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9728e-04 - val_loss: 6.9969e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9258e-04 - val_loss: 6.9396e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8792e-04 - val_loss: 6.8829e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8330e-04 - val_loss: 6.8269e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7872e-04 - val_loss: 6.7715e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7418e-04 - val_loss: 6.7168e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6968e-04 - val_loss: 6.6627e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6522e-04 - val_loss: 6.6091e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6080e-04 - val_loss: 6.5563e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5641e-04 - val_loss: 6.5038e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5208e-04 - val_loss: 6.4521e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4778e-04 - val_loss: 6.4007e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4350e-04 - val_loss: 6.3500e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3929e-04 - val_loss: 6.3001e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3509e-04 - val_loss: 6.2506e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3094e-04 - val_loss: 6.2015e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2681e-04 - val_loss: 6.1530e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2272e-04 - val_loss: 6.1051e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 9.1868e-04 - val_loss: 6.0577e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1466e-04 - val_loss: 6.0108e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1069e-04 - val_loss: 5.9644e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0674e-04 - val_loss: 5.9185e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0283e-04 - val_loss: 5.8732e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9895e-04 - val_loss: 5.8282e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9511e-04 - val_loss: 5.7839e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9130e-04 - val_loss: 5.7400e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8752e-04 - val_loss: 5.6965e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8377e-04 - val_loss: 5.6535e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8006e-04 - val_loss: 5.6110e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.7636e-04 - val_loss: 5.5688e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7270e-04 - val_loss: 5.5273e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6908e-04 - val_loss: 5.4861e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6549e-04 - val_loss: 5.4456e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6192e-04 - val_loss: 5.4050e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5840e-04 - val_loss: 5.3653e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5487e-04 - val_loss: 5.3260e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 8.5141e-04 - val_loss: 5.2870e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4796e-04 - val_loss: 5.2486e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4454e-04 - val_loss: 5.2103e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4113e-04 - val_loss: 5.1726e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3778e-04 - val_loss: 5.1353e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3443e-04 - val_loss: 5.0984e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3113e-04 - val_loss: 5.0619e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2784e-04 - val_loss: 5.0258e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.2459e-04 - val_loss: 4.9901e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2135e-04 - val_loss: 4.9545e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1814e-04 - val_loss: 4.9195e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1497e-04 - val_loss: 4.8850e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1182e-04 - val_loss: 4.8507e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0869e-04 - val_loss: 4.8169e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0559e-04 - val_loss: 4.7833e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0250e-04 - val_loss: 4.7499e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9944e-04 - val_loss: 4.7173e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.9642e-04 - val_loss: 4.6849e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9340e-04 - val_loss: 4.6528e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9041e-04 - val_loss: 4.6210e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8745e-04 - val_loss: 4.5897e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8452e-04 - val_loss: 4.5584e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8159e-04 - val_loss: 4.5278e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7870e-04 - val_loss: 4.4973e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7583e-04 - val_loss: 4.4673e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7299e-04 - val_loss: 4.4372e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7016e-04 - val_loss: 4.4077e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6735e-04 - val_loss: 4.3786e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6457e-04 - val_loss: 4.3497e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6180e-04 - val_loss: 4.3211e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5906e-04 - val_loss: 4.2928e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5633e-04 - val_loss: 4.2648e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5364e-04 - val_loss: 4.2372e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5095e-04 - val_loss: 4.2097e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4829e-04 - val_loss: 4.1825e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4565e-04 - val_loss: 4.1555e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.4304e-04 - val_loss: 4.1292e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4043e-04 - val_loss: 4.1028e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3785e-04 - val_loss: 4.0769e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3528e-04 - val_loss: 4.0511e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3274e-04 - val_loss: 4.0257e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3021e-04 - val_loss: 4.0006e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2771e-04 - val_loss: 3.9756e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2522e-04 - val_loss: 3.9508e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2274e-04 - val_loss: 3.9264e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2029e-04 - val_loss: 3.9022e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1786e-04 - val_loss: 3.8784e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1544e-04 - val_loss: 3.8545e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1304e-04 - val_loss: 3.8312e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1065e-04 - val_loss: 3.8079e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0828e-04 - val_loss: 3.7850e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0594e-04 - val_loss: 3.7623e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0360e-04 - val_loss: 3.7398e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0129e-04 - val_loss: 3.7174e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9899e-04 - val_loss: 3.6955e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9670e-04 - val_loss: 3.6736e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9443e-04 - val_loss: 3.6520e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9217e-04 - val_loss: 3.6306e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8995e-04 - val_loss: 3.6095e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8773e-04 - val_loss: 3.5884e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8552e-04 - val_loss: 3.5677e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8333e-04 - val_loss: 3.5472e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8116e-04 - val_loss: 3.5268e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.7900e-04 - val_loss: 3.5068e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7685e-04 - val_loss: 3.4870e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7473e-04 - val_loss: 3.4672e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.7260e-04 - val_loss: 3.4478e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7051e-04 - val_loss: 3.4284e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6842e-04 - val_loss: 3.4093e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6634e-04 - val_loss: 3.3904e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6429e-04 - val_loss: 3.3717e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6224e-04 - val_loss: 3.3532e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6021e-04 - val_loss: 3.3349e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5820e-04 - val_loss: 3.3166e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5619e-04 - val_loss: 3.2985e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5420e-04 - val_loss: 3.2808e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5222e-04 - val_loss: 3.2632e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5026e-04 - val_loss: 3.2457e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4831e-04 - val_loss: 3.2282e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4636e-04 - val_loss: 3.2111e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4444e-04 - val_loss: 3.1941e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4253e-04 - val_loss: 3.1774e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4063e-04 - val_loss: 3.1607e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3874e-04 - val_loss: 3.1443e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3686e-04 - val_loss: 3.1280e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3500e-04 - val_loss: 3.1119e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3314e-04 - val_loss: 3.0958e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3131e-04 - val_loss: 3.0801e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 6.2947e-04 - val_loss: 3.0644e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2765e-04 - val_loss: 3.0489e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2584e-04 - val_loss: 3.0334e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2405e-04 - val_loss: 3.0182e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2227e-04 - val_loss: 3.0031e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2051e-04 - val_loss: 2.9882e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1875e-04 - val_loss: 2.9735e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1699e-04 - val_loss: 2.9589e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1525e-04 - val_loss: 2.9443e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1352e-04 - val_loss: 2.9298e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1181e-04 - val_loss: 2.9156e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1010e-04 - val_loss: 2.9016e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.0841e-04 - val_loss: 2.8878e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0672e-04 - val_loss: 2.8739e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0504e-04 - val_loss: 2.8602e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0338e-04 - val_loss: 2.8465e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0173e-04 - val_loss: 2.8332e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0007e-04 - val_loss: 2.8198e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9845e-04 - val_loss: 2.8067e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9682e-04 - val_loss: 2.7936e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9521e-04 - val_loss: 2.7806e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9360e-04 - val_loss: 2.7678e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9200e-04 - val_loss: 2.7552e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9042e-04 - val_loss: 2.7425e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.8884e-04 - val_loss: 2.7300e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8728e-04 - val_loss: 2.7177e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8571e-04 - val_loss: 2.7055e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.8417e-04 - val_loss: 2.6934e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8263e-04 - val_loss: 2.6815e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8110e-04 - val_loss: 2.6697e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 5.7958e-04 - val_loss: 2.6579e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7807e-04 - val_loss: 2.6462e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.7655e-04 - val_loss: 2.6346e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.7506e-04 - val_loss: 2.6231e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7357e-04 - val_loss: 2.6117e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7209e-04 - val_loss: 2.6005e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7063e-04 - val_loss: 2.5892e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6916e-04 - val_loss: 2.5783e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6771e-04 - val_loss: 2.5673e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6626e-04 - val_loss: 2.5566e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6484e-04 - val_loss: 2.5457e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6340e-04 - val_loss: 2.5351e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6198e-04 - val_loss: 2.5246e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6057e-04 - val_loss: 2.5142e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5917e-04 - val_loss: 2.5038e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5778e-04 - val_loss: 2.4934e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5638e-04 - val_loss: 2.4834e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5499e-04 - val_loss: 2.4733e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.5362e-04 - val_loss: 2.4632e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5225e-04 - val_loss: 2.4533e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5090e-04 - val_loss: 2.4435e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4955e-04 - val_loss: 2.4338e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4821e-04 - val_loss: 2.4240e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4687e-04 - val_loss: 2.4145e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4554e-04 - val_loss: 2.4051e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4422e-04 - val_loss: 2.3957e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4291e-04 - val_loss: 2.3863e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4160e-04 - val_loss: 2.3770e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4029e-04 - val_loss: 2.3679e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3900e-04 - val_loss: 2.3589e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3772e-04 - val_loss: 2.3499e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3643e-04 - val_loss: 2.3410e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3516e-04 - val_loss: 2.3322e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3389e-04 - val_loss: 2.3234e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3263e-04 - val_loss: 2.3147e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3137e-04 - val_loss: 2.3061e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.3013e-04 - val_loss: 2.2974e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2889e-04 - val_loss: 2.2890e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2766e-04 - val_loss: 2.2806e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2643e-04 - val_loss: 2.2724e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2521e-04 - val_loss: 2.2640e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.2399e-04 - val_loss: 2.2559e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2279e-04 - val_loss: 2.2477e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2158e-04 - val_loss: 2.2398e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2039e-04 - val_loss: 2.2317e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1920e-04 - val_loss: 2.2238e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1801e-04 - val_loss: 2.2160e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1684e-04 - val_loss: 2.2081e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1567e-04 - val_loss: 2.2005e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1450e-04 - val_loss: 2.1927e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1334e-04 - val_loss: 2.1852e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1219e-04 - val_loss: 2.1776e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1103e-04 - val_loss: 2.1701e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0990e-04 - val_loss: 2.1627e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0875e-04 - val_loss: 2.1553e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0763e-04 - val_loss: 2.1481e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0650e-04 - val_loss: 2.1408e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0538e-04 - val_loss: 2.1336e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0426e-04 - val_loss: 2.1267e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0316e-04 - val_loss: 2.1194e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0205e-04 - val_loss: 2.1125e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0095e-04 - val_loss: 2.1056e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9986e-04 - val_loss: 2.0986e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9877e-04 - val_loss: 2.0918e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9769e-04 - val_loss: 2.0851e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9661e-04 - val_loss: 2.0782e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9554e-04 - val_loss: 2.0716e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9447e-04 - val_loss: 2.0650e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9341e-04 - val_loss: 2.0584e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9235e-04 - val_loss: 2.0520e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9130e-04 - val_loss: 2.0454e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9025e-04 - val_loss: 2.0391e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8921e-04 - val_loss: 2.0327e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8817e-04 - val_loss: 2.0262e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8713e-04 - val_loss: 2.0201e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8611e-04 - val_loss: 2.0138e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8509e-04 - val_loss: 2.0076e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8407e-04 - val_loss: 2.0015e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8305e-04 - val_loss: 1.9953e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8205e-04 - val_loss: 1.9893e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 4.8104e-04 - val_loss: 1.9834e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8004e-04 - val_loss: 1.9773e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7905e-04 - val_loss: 1.9715e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7806e-04 - val_loss: 1.9655e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7707e-04 - val_loss: 1.9597e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7609e-04 - val_loss: 1.9540e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7511e-04 - val_loss: 1.9483e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7414e-04 - val_loss: 1.9426e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7317e-04 - val_loss: 1.9369e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.7221e-04 - val_loss: 1.9314e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7125e-04 - val_loss: 1.9258e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7030e-04 - val_loss: 1.9202e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6934e-04 - val_loss: 1.9148e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6839e-04 - val_loss: 1.9093e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6745e-04 - val_loss: 1.9038e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6651e-04 - val_loss: 1.8985e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6558e-04 - val_loss: 1.8931e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6464e-04 - val_loss: 1.8877e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6372e-04 - val_loss: 1.8825e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6280e-04 - val_loss: 1.8772e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6188e-04 - val_loss: 1.8721e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.6097e-04 - val_loss: 1.8670e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6006e-04 - val_loss: 1.8619e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5915e-04 - val_loss: 1.8567e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5825e-04 - val_loss: 1.8518e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5735e-04 - val_loss: 1.8468e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5645e-04 - val_loss: 1.8418e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5556e-04 - val_loss: 1.8369e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5467e-04 - val_loss: 1.8320e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5379e-04 - val_loss: 1.8271e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5290e-04 - val_loss: 1.8223e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5203e-04 - val_loss: 1.8175e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 4.5116e-04 - val_loss: 1.8126e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5029e-04 - val_loss: 1.8080e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4943e-04 - val_loss: 1.8032e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4857e-04 - val_loss: 1.7985e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4770e-04 - val_loss: 1.7938e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4685e-04 - val_loss: 1.7892e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4600e-04 - val_loss: 1.7845e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4515e-04 - val_loss: 1.7800e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4431e-04 - val_loss: 1.7755e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4347e-04 - val_loss: 1.7709e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.4263e-04 - val_loss: 1.7664e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4179e-04 - val_loss: 1.7620e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.4097e-04 - val_loss: 1.7577e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4014e-04 - val_loss: 1.7532e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3932e-04 - val_loss: 1.7489e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3849e-04 - val_loss: 1.7446e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3768e-04 - val_loss: 1.7403e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3686e-04 - val_loss: 1.7361e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3605e-04 - val_loss: 1.7318e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3524e-04 - val_loss: 1.7276e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3444e-04 - val_loss: 1.7233e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3365e-04 - val_loss: 1.7192e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3284e-04 - val_loss: 1.7150e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3204e-04 - val_loss: 1.7109e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3125e-04 - val_loss: 1.7069e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3047e-04 - val_loss: 1.7028e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2969e-04 - val_loss: 1.6988e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2890e-04 - val_loss: 1.6947e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 4.2812e-04 - val_loss: 1.6907e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2735e-04 - val_loss: 1.6867e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2657e-04 - val_loss: 1.6828e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 4.2580e-04 - val_loss: 1.6788e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2503e-04 - val_loss: 1.6749e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2427e-04 - val_loss: 1.6710e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.2351e-04 - val_loss: 1.6671e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2275e-04 - val_loss: 1.6633e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2200e-04 - val_loss: 1.6596e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2125e-04 - val_loss: 1.6557e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2049e-04 - val_loss: 1.6520e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1974e-04 - val_loss: 1.6483e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1900e-04 - val_loss: 1.6445e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1826e-04 - val_loss: 1.6408e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1752e-04 - val_loss: 1.6371e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1678e-04 - val_loss: 1.6335e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1605e-04 - val_loss: 1.6298e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1532e-04 - val_loss: 1.6262e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1460e-04 - val_loss: 1.6225e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1386e-04 - val_loss: 1.6190e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1314e-04 - val_loss: 1.6154e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 4.1242e-04 - val_loss: 1.6119e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1171e-04 - val_loss: 1.6084e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1099e-04 - val_loss: 1.6048e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1028e-04 - val_loss: 1.6014e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0957e-04 - val_loss: 1.5979e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0886e-04 - val_loss: 1.5944e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.0816e-04 - val_loss: 1.5910e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0746e-04 - val_loss: 1.5877e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0676e-04 - val_loss: 1.5843e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0607e-04 - val_loss: 1.5809e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0537e-04 - val_loss: 1.5776e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0468e-04 - val_loss: 1.5742e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0399e-04 - val_loss: 1.5708e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0330e-04 - val_loss: 1.5676e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0261e-04 - val_loss: 1.5642e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0193e-04 - val_loss: 1.5610e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0126e-04 - val_loss: 1.5578e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0057e-04 - val_loss: 1.5546e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9990e-04 - val_loss: 1.5513e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9923e-04 - val_loss: 1.5481e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9856e-04 - val_loss: 1.5449e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 3.9790e-04 - val_loss: 1.5418e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9723e-04 - val_loss: 1.5385e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9656e-04 - val_loss: 1.5354e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9590e-04 - val_loss: 1.5323e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9525e-04 - val_loss: 1.5292e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9459e-04 - val_loss: 1.5261e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9394e-04 - val_loss: 1.5231e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9328e-04 - val_loss: 1.5200e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9264e-04 - val_loss: 1.5168e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9199e-04 - val_loss: 1.5138e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9134e-04 - val_loss: 1.5108e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9069e-04 - val_loss: 1.5078e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9005e-04 - val_loss: 1.5048e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8942e-04 - val_loss: 1.5018e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8878e-04 - val_loss: 1.4989e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.8815e-04 - val_loss: 1.4960e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8752e-04 - val_loss: 1.4931e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8689e-04 - val_loss: 1.4902e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8625e-04 - val_loss: 1.4872e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8563e-04 - val_loss: 1.4842e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8501e-04 - val_loss: 1.4814e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8438e-04 - val_loss: 1.4785e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8376e-04 - val_loss: 1.4756e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8315e-04 - val_loss: 1.4728e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8253e-04 - val_loss: 1.4700e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8192e-04 - val_loss: 1.4672e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8131e-04 - val_loss: 1.4644e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.8069e-04 - val_loss: 1.4615e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8009e-04 - val_loss: 1.4588e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7948e-04 - val_loss: 1.4560e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7888e-04 - val_loss: 1.4533e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7827e-04 - val_loss: 1.4505e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7768e-04 - val_loss: 1.4479e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7708e-04 - val_loss: 1.4451e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7648e-04 - val_loss: 1.4425e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7589e-04 - val_loss: 1.4397e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7529e-04 - val_loss: 1.4370e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7470e-04 - val_loss: 1.4344e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7412e-04 - val_loss: 1.4317e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7353e-04 - val_loss: 1.4290e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7294e-04 - val_loss: 1.4263e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7237e-04 - val_loss: 1.4238e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7177e-04 - val_loss: 1.4211e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7120e-04 - val_loss: 1.4186e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7062e-04 - val_loss: 1.4159e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7005e-04 - val_loss: 1.4134e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6947e-04 - val_loss: 1.4108e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6890e-04 - val_loss: 1.4082e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6833e-04 - val_loss: 1.4057e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6776e-04 - val_loss: 1.4032e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6720e-04 - val_loss: 1.4006e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6663e-04 - val_loss: 1.3981e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6607e-04 - val_loss: 1.3956e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6551e-04 - val_loss: 1.3931e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6494e-04 - val_loss: 1.3906e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6439e-04 - val_loss: 1.3881e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6383e-04 - val_loss: 1.3856e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6327e-04 - val_loss: 1.3831e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6272e-04 - val_loss: 1.3806e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6217e-04 - val_loss: 1.3782e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6162e-04 - val_loss: 1.3758e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6107e-04 - val_loss: 1.3734e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6052e-04 - val_loss: 1.3710e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5998e-04 - val_loss: 1.3686e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5944e-04 - val_loss: 1.3662e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5889e-04 - val_loss: 1.3638e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5836e-04 - val_loss: 1.3614e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5782e-04 - val_loss: 1.3591e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5729e-04 - val_loss: 1.3568e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5675e-04 - val_loss: 1.3544e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5621e-04 - val_loss: 1.3520e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5568e-04 - val_loss: 1.3497e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5515e-04 - val_loss: 1.3473e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5462e-04 - val_loss: 1.3451e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5409e-04 - val_loss: 1.3426e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5357e-04 - val_loss: 1.3404e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5304e-04 - val_loss: 1.3381e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5252e-04 - val_loss: 1.3358e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5199e-04 - val_loss: 1.3336e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.5148e-04 - val_loss: 1.3313e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5096e-04 - val_loss: 1.3290e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5044e-04 - val_loss: 1.3267e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4993e-04 - val_loss: 1.3245e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4941e-04 - val_loss: 1.3223e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4891e-04 - val_loss: 1.3199e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4839e-04 - val_loss: 1.3177e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.4788e-04 - val_loss: 1.3156e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4737e-04 - val_loss: 1.3134e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4686e-04 - val_loss: 1.3112e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4636e-04 - val_loss: 1.3090e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4586e-04 - val_loss: 1.3068e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4535e-04 - val_loss: 1.3047e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4486e-04 - val_loss: 1.3024e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4435e-04 - val_loss: 1.3003e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4385e-04 - val_loss: 1.2982e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4336e-04 - val_loss: 1.2960e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4287e-04 - val_loss: 1.2938e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4236e-04 - val_loss: 1.2917e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4188e-04 - val_loss: 1.2895e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4138e-04 - val_loss: 1.2875e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4089e-04 - val_loss: 1.2854e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4040e-04 - val_loss: 1.2833e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3992e-04 - val_loss: 1.2812e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3943e-04 - val_loss: 1.2791e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3895e-04 - val_loss: 1.2770e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3847e-04 - val_loss: 1.2750e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3798e-04 - val_loss: 1.2728e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3750e-04 - val_loss: 1.2707e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3703e-04 - val_loss: 1.2686e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3655e-04 - val_loss: 1.2666e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3607e-04 - val_loss: 1.2645e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3560e-04 - val_loss: 1.2626e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3512e-04 - val_loss: 1.2605e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3465e-04 - val_loss: 1.2585e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3417e-04 - val_loss: 1.2565e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3370e-04 - val_loss: 1.2545e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 3.3324e-04 - val_loss: 1.2524e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3277e-04 - val_loss: 1.2505e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3230e-04 - val_loss: 1.2485e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3184e-04 - val_loss: 1.2466e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3137e-04 - val_loss: 1.2444e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3091e-04 - val_loss: 1.2426e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3045e-04 - val_loss: 1.2405e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2999e-04 - val_loss: 1.2386e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2953e-04 - val_loss: 1.2366e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2907e-04 - val_loss: 1.2347e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2861e-04 - val_loss: 1.2327e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2816e-04 - val_loss: 1.2307e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2770e-04 - val_loss: 1.2288e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2725e-04 - val_loss: 1.2269e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2680e-04 - val_loss: 1.2250e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2634e-04 - val_loss: 1.2230e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2590e-04 - val_loss: 1.2212e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2545e-04 - val_loss: 1.2192e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 3.2500e-04 - val_loss: 1.2174e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2455e-04 - val_loss: 1.2154e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2411e-04 - val_loss: 1.2135e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2367e-04 - val_loss: 1.2117e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2323e-04 - val_loss: 1.2097e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2278e-04 - val_loss: 1.2079e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2235e-04 - val_loss: 1.2061e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2190e-04 - val_loss: 1.2043e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2146e-04 - val_loss: 1.2024e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2102e-04 - val_loss: 1.2005e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2059e-04 - val_loss: 1.1986e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2016e-04 - val_loss: 1.1968e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1973e-04 - val_loss: 1.1949e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1929e-04 - val_loss: 1.1930e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1886e-04 - val_loss: 1.1912e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1843e-04 - val_loss: 1.1894e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1799e-04 - val_loss: 1.1876e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1757e-04 - val_loss: 1.1858e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1714e-04 - val_loss: 1.1839e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.1671e-04 - val_loss: 1.1823e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1629e-04 - val_loss: 1.1805e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1586e-04 - val_loss: 1.1786e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1544e-04 - val_loss: 1.1768e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1502e-04 - val_loss: 1.1751e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1460e-04 - val_loss: 1.1733e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1418e-04 - val_loss: 1.1714e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1376e-04 - val_loss: 1.1697e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1334e-04 - val_loss: 1.1679e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1292e-04 - val_loss: 1.1661e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1251e-04 - val_loss: 1.1644e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1210e-04 - val_loss: 1.1625e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1168e-04 - val_loss: 1.1608e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1127e-04 - val_loss: 1.1591e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1086e-04 - val_loss: 1.1573e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1044e-04 - val_loss: 1.1557e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1003e-04 - val_loss: 1.1540e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0963e-04 - val_loss: 1.1523e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0921e-04 - val_loss: 1.1506e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0881e-04 - val_loss: 1.1488e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0840e-04 - val_loss: 1.1472e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0800e-04 - val_loss: 1.1454e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0760e-04 - val_loss: 1.1436e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0719e-04 - val_loss: 1.1420e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0679e-04 - val_loss: 1.1402e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0638e-04 - val_loss: 1.1385e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0599e-04 - val_loss: 1.1368e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0559e-04 - val_loss: 1.1351e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0518e-04 - val_loss: 1.1335e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0480e-04 - val_loss: 1.1317e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0439e-04 - val_loss: 1.1301e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0400e-04 - val_loss: 1.1285e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0360e-04 - val_loss: 1.1269e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0321e-04 - val_loss: 1.1252e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0282e-04 - val_loss: 1.1236e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0243e-04 - val_loss: 1.1219e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0203e-04 - val_loss: 1.1203e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0164e-04 - val_loss: 1.1187e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0126e-04 - val_loss: 1.1171e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0087e-04 - val_loss: 1.1154e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0048e-04 - val_loss: 1.1138e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0009e-04 - val_loss: 1.1120e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9971e-04 - val_loss: 1.1104e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9932e-04 - val_loss: 1.1088e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9894e-04 - val_loss: 1.1072e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9855e-04 - val_loss: 1.1055e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9818e-04 - val_loss: 1.1039e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9779e-04 - val_loss: 1.1023e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9741e-04 - val_loss: 1.1007e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9704e-04 - val_loss: 1.0990e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9665e-04 - val_loss: 1.0975e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9628e-04 - val_loss: 1.0960e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9590e-04 - val_loss: 1.0945e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9553e-04 - val_loss: 1.0929e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9514e-04 - val_loss: 1.0914e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9478e-04 - val_loss: 1.0897e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9440e-04 - val_loss: 1.0881e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.9403e-04 - val_loss: 1.0866e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9365e-04 - val_loss: 1.0850e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9328e-04 - val_loss: 1.0835e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9291e-04 - val_loss: 1.0818e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9255e-04 - val_loss: 1.0803e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9218e-04 - val_loss: 1.0787e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9181e-04 - val_loss: 1.0771e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9144e-04 - val_loss: 1.0757e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9108e-04 - val_loss: 1.0741e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9071e-04 - val_loss: 1.0726e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9035e-04 - val_loss: 1.0711e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8999e-04 - val_loss: 1.0696e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8962e-04 - val_loss: 1.0681e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8926e-04 - val_loss: 1.0666e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8889e-04 - val_loss: 1.0650e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8854e-04 - val_loss: 1.0636e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8817e-04 - val_loss: 1.0620e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8782e-04 - val_loss: 1.0605e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8746e-04 - val_loss: 1.0590e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8710e-04 - val_loss: 1.0575e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8675e-04 - val_loss: 1.0560e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8639e-04 - val_loss: 1.0545e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8603e-04 - val_loss: 1.0530e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8568e-04 - val_loss: 1.0515e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8533e-04 - val_loss: 1.0500e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8497e-04 - val_loss: 1.0485e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8462e-04 - val_loss: 1.0470e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8427e-04 - val_loss: 1.0455e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8392e-04 - val_loss: 1.0441e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8357e-04 - val_loss: 1.0427e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8322e-04 - val_loss: 1.0412e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8287e-04 - val_loss: 1.0397e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8252e-04 - val_loss: 1.0384e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8218e-04 - val_loss: 1.0369e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8183e-04 - val_loss: 1.0354e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8149e-04 - val_loss: 1.0340e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8114e-04 - val_loss: 1.0326e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8080e-04 - val_loss: 1.0311e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8045e-04 - val_loss: 1.0296e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8012e-04 - val_loss: 1.0282e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7977e-04 - val_loss: 1.0267e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7943e-04 - val_loss: 1.0253e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7909e-04 - val_loss: 1.0238e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7875e-04 - val_loss: 1.0224e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7841e-04 - val_loss: 1.0210e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7807e-04 - val_loss: 1.0195e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7774e-04 - val_loss: 1.0182e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7740e-04 - val_loss: 1.0167e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7707e-04 - val_loss: 1.0153e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7672e-04 - val_loss: 1.0139e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7639e-04 - val_loss: 1.0126e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7606e-04 - val_loss: 1.0112e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7573e-04 - val_loss: 1.0098e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7539e-04 - val_loss: 1.0085e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7506e-04 - val_loss: 1.0070e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.7473e-04 - val_loss: 1.0056e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7440e-04 - val_loss: 1.0042e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.7407e-04 - val_loss: 1.0029e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7374e-04 - val_loss: 1.0015e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7342e-04 - val_loss: 1.0001e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7309e-04 - val_loss: 9.9880e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7276e-04 - val_loss: 9.9734e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7243e-04 - val_loss: 9.9597e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7211e-04 - val_loss: 9.9456e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7178e-04 - val_loss: 9.9316e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7146e-04 - val_loss: 9.9183e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7113e-04 - val_loss: 9.9047e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7081e-04 - val_loss: 9.8913e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7048e-04 - val_loss: 9.8780e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7016e-04 - val_loss: 9.8647e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6984e-04 - val_loss: 9.8515e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6952e-04 - val_loss: 9.8373e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6920e-04 - val_loss: 9.8244e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6889e-04 - val_loss: 9.8114e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6856e-04 - val_loss: 9.7979e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6824e-04 - val_loss: 9.7844e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6793e-04 - val_loss: 9.7709e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.6761e-04 - val_loss: 9.7574e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6729e-04 - val_loss: 9.7445e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6698e-04 - val_loss: 9.7311e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6666e-04 - val_loss: 9.7188e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6635e-04 - val_loss: 9.7054e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6603e-04 - val_loss: 9.6919e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6573e-04 - val_loss: 9.6791e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6541e-04 - val_loss: 9.6657e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6510e-04 - val_loss: 9.6529e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6479e-04 - val_loss: 9.6401e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6448e-04 - val_loss: 9.6267e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6417e-04 - val_loss: 9.6139e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6386e-04 - val_loss: 9.6007e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6355e-04 - val_loss: 9.5885e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6324e-04 - val_loss: 9.5746e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6293e-04 - val_loss: 9.5619e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6263e-04 - val_loss: 9.5481e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6232e-04 - val_loss: 9.5364e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6202e-04 - val_loss: 9.5226e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6171e-04 - val_loss: 9.5100e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6140e-04 - val_loss: 9.4972e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6110e-04 - val_loss: 9.4853e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6079e-04 - val_loss: 9.4723e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6049e-04 - val_loss: 9.4599e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6019e-04 - val_loss: 9.4473e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5989e-04 - val_loss: 9.4347e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5958e-04 - val_loss: 9.4226e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5928e-04 - val_loss: 9.4098e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5899e-04 - val_loss: 9.3969e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5868e-04 - val_loss: 9.3844e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5839e-04 - val_loss: 9.3721e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5809e-04 - val_loss: 9.3593e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5779e-04 - val_loss: 9.3473e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5749e-04 - val_loss: 9.3346e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5720e-04 - val_loss: 9.3223e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5690e-04 - val_loss: 9.3098e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5661e-04 - val_loss: 9.2968e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5631e-04 - val_loss: 9.2843e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5602e-04 - val_loss: 9.2726e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5572e-04 - val_loss: 9.2602e-05\n",
      "6.101736653363332e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.34456074,  0.18667324, -0.3357817 , -0.50525033, -0.17290518],\n",
       "        [-0.5969446 , -1.0845784 ,  0.17641048,  0.6343975 ,  0.8350602 ],\n",
       "        [ 0.49135587, -1.0597149 , -1.053872  ,  1.0952581 ,  0.752351  ]],\n",
       "       dtype=float32),\n",
       " array([-0.30958238,  0.06540466, -0.30278826, -0.34116673, -0.42009982],\n",
       "       dtype=float32),\n",
       " array([[ 0.14764215,  0.33691332, -0.24587053,  0.5443069 , -0.20021267,\n",
       "          0.15024915,  0.40933308,  0.46032202,  0.22687644,  0.3384165 ],\n",
       "        [ 0.46556422, -0.10861446,  0.05371523,  0.07086184,  0.13462366,\n",
       "         -0.24595788, -0.19713579, -0.26751637,  0.64453834,  0.10684548],\n",
       "        [ 0.46351275,  0.5677999 , -0.19667733,  0.05971774,  0.40233865,\n",
       "          0.49786726,  0.2194255 ,  0.4042988 , -0.15127377,  0.25692993],\n",
       "        [ 0.37334844,  0.52951586,  0.30625427, -0.23887289,  0.04995485,\n",
       "         -0.01299719,  0.535041  ,  0.07566474,  0.450536  , -0.2761231 ],\n",
       "        [ 0.10907631,  0.2028453 , -0.4097871 ,  0.2046908 , -0.2667723 ,\n",
       "         -0.2566443 ,  0.01827976, -0.14030789,  0.18421516, -0.35288173]],\n",
       "       dtype=float32),\n",
       " array([-0.73117906, -0.64473146,  0.6936471 , -0.6535972 ,  0.69840544,\n",
       "        -0.71115464,  0.6590373 , -0.7006356 , -0.683264  ,  0.709393  ],\n",
       "       dtype=float32),\n",
       " array([[-1.0228206 ],\n",
       "        [-0.43227282],\n",
       "        [ 0.6694486 ],\n",
       "        [-0.53311825],\n",
       "        [ 0.6048966 ],\n",
       "        [-0.80941576],\n",
       "        [ 0.5930723 ],\n",
       "        [-0.70920527],\n",
       "        [-0.59242123],\n",
       "        [ 0.5858201 ]], dtype=float32),\n",
       " array([0.796487], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_linear(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_linear_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 31.7009 - val_loss: 28.3606\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 28.4799 - val_loss: 23.4084\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.2174 - val_loss: 18.0256\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19.5446 - val_loss: 13.1984\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 15.4287 - val_loss: 8.7185\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 12.1943 - val_loss: 5.4436\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8043 - val_loss: 3.8586\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5692 - val_loss: 3.3827\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1516 - val_loss: 3.2963\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2425 - val_loss: 3.1072\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4893 - val_loss: 2.4951\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6623 - val_loss: 1.5502\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5847 - val_loss: 0.8378\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1918 - val_loss: 0.6685\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9146 - val_loss: 0.9920\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.9618 - val_loss: 1.5497\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2521 - val_loss: 2.0629\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 2.5613 - val_loss: 2.3501\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7042 - val_loss: 2.3473\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6117 - val_loss: 2.0776\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.2914 - val_loss: 1.6310\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8140 - val_loss: 1.1333\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2884 - val_loss: 0.7130\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8323 - val_loss: 0.4649\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5420 - val_loss: 0.4159\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4497 - val_loss: 0.5077\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5127 - val_loss: 0.6234\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6296 - val_loss: 0.6558\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6978 - val_loss: 0.5687\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6693 - val_loss: 0.4066\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.5640 - val_loss: 0.2516\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4467 - val_loss: 0.1697\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3668 - val_loss: 0.1825\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3407 - val_loss: 0.2693\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3632 - val_loss: 0.3867\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.4092 - val_loss: 0.4890\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4485 - val_loss: 0.5434\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4587 - val_loss: 0.5361\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4310 - val_loss: 0.4722\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3714 - val_loss: 0.3695\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2980 - val_loss: 0.2545\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2288 - val_loss: 0.1543\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1827 - val_loss: 0.0859\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1680 - val_loss: 0.0560\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1807 - val_loss: 0.0559\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2060 - val_loss: 0.0701\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2266 - val_loss: 0.0840\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2308 - val_loss: 0.0902\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2166 - val_loss: 0.0890\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1911 - val_loss: 0.0857\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1650 - val_loss: 0.0856\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1470 - val_loss: 0.0909\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1404 - val_loss: 0.1003\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1430 - val_loss: 0.1096\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.1495 - val_loss: 0.1147\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1550 - val_loss: 0.1132\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1553 - val_loss: 0.1056\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1499 - val_loss: 0.0939\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1407 - val_loss: 0.0812\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1308 - val_loss: 0.0704\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1233 - val_loss: 0.0627\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1198 - val_loss: 0.0580\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1200 - val_loss: 0.0551\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1224 - val_loss: 0.0523\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1248 - val_loss: 0.0486\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1255 - val_loss: 0.0439\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1239 - val_loss: 0.0389\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1204 - val_loss: 0.0350\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1164 - val_loss: 0.0331\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1130 - val_loss: 0.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1111 - val_loss: 0.0353\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1106 - val_loss: 0.0380\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.1111 - val_loss: 0.0402\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1118 - val_loss: 0.0413\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1119 - val_loss: 0.0410\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1111 - val_loss: 0.0395\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1094 - val_loss: 0.0375\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1074 - val_loss: 0.0358\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1055 - val_loss: 0.0349\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1041 - val_loss: 0.0350\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1034 - val_loss: 0.0359\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1031 - val_loss: 0.0372\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1031 - val_loss: 0.0384\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1030 - val_loss: 0.0391\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.1027 - val_loss: 0.0393\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1020 - val_loss: 0.0388\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1011 - val_loss: 0.0380\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1001 - val_loss: 0.0370\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0993 - val_loss: 0.0360\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0986 - val_loss: 0.0350\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0982 - val_loss: 0.0341\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0978 - val_loss: 0.0332\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0974 - val_loss: 0.0322\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0970 - val_loss: 0.0310\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0964 - val_loss: 0.0298\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0958 - val_loss: 0.0285\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0952 - val_loss: 0.0273\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0946 - val_loss: 0.0262\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0940 - val_loss: 0.0253\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0936 - val_loss: 0.0246\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0932 - val_loss: 0.0240\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0928 - val_loss: 0.0235\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0925 - val_loss: 0.0230\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0920 - val_loss: 0.0227\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0915 - val_loss: 0.0224\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0910 - val_loss: 0.0221\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0905 - val_loss: 0.0219\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0901 - val_loss: 0.0218\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0896 - val_loss: 0.0216\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0892 - val_loss: 0.0215\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0889 - val_loss: 0.0213\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0885 - val_loss: 0.0212\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0881 - val_loss: 0.0210\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0877 - val_loss: 0.0209\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0874 - val_loss: 0.0207\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0870 - val_loss: 0.0205\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0867 - val_loss: 0.0203\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0864 - val_loss: 0.0201\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0861 - val_loss: 0.0199\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0858 - val_loss: 0.0196\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0855 - val_loss: 0.0194\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0853 - val_loss: 0.0191\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0851 - val_loss: 0.0188\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0848 - val_loss: 0.0186\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0846 - val_loss: 0.0183\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0843 - val_loss: 0.0181\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0839 - val_loss: 0.0180\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0837 - val_loss: 0.0178\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0835 - val_loss: 0.0176\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0833 - val_loss: 0.0175\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0830 - val_loss: 0.0173\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0828 - val_loss: 0.0172\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0825 - val_loss: 0.0171\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0823 - val_loss: 0.0170\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0820 - val_loss: 0.0168\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0817 - val_loss: 0.0167\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0815 - val_loss: 0.0166\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0812 - val_loss: 0.0166\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0810 - val_loss: 0.0165\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0808 - val_loss: 0.0165\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0805 - val_loss: 0.0164\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0803 - val_loss: 0.0164\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0801 - val_loss: 0.0163\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0798 - val_loss: 0.0162\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0796 - val_loss: 0.0161\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0794 - val_loss: 0.0160\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0792 - val_loss: 0.0159\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0789 - val_loss: 0.0158\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0787 - val_loss: 0.0157\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0785 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0783 - val_loss: 0.0155\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0781 - val_loss: 0.0154\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0778 - val_loss: 0.0153\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0776 - val_loss: 0.0153\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0774 - val_loss: 0.0152\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0772 - val_loss: 0.0152\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0770 - val_loss: 0.0152\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0768 - val_loss: 0.0151\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0766 - val_loss: 0.0150\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0764 - val_loss: 0.0149\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0762 - val_loss: 0.0148\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0760 - val_loss: 0.0148\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0758 - val_loss: 0.0147\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0756 - val_loss: 0.0146\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0754 - val_loss: 0.0146\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0752 - val_loss: 0.0145\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0750 - val_loss: 0.0144\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0748 - val_loss: 0.0144\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0746 - val_loss: 0.0143\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0744 - val_loss: 0.0142\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0742 - val_loss: 0.0142\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0740 - val_loss: 0.0142\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0738 - val_loss: 0.0141\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0736 - val_loss: 0.0141\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0734 - val_loss: 0.0141\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0733 - val_loss: 0.0140\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0731 - val_loss: 0.0140\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0729 - val_loss: 0.0140\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0727 - val_loss: 0.0140\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0725 - val_loss: 0.0140\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0723 - val_loss: 0.0140\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0721 - val_loss: 0.0139\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0720 - val_loss: 0.0139\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0718 - val_loss: 0.0138\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0716 - val_loss: 0.0138\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0714 - val_loss: 0.0138\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0712 - val_loss: 0.0137\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0710 - val_loss: 0.0137\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0709 - val_loss: 0.0137\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0707 - val_loss: 0.0137\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0705 - val_loss: 0.0136\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0704 - val_loss: 0.0136\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0702 - val_loss: 0.0136\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0700 - val_loss: 0.0135\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0698 - val_loss: 0.0134\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0697 - val_loss: 0.0134\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0695 - val_loss: 0.0133\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0693 - val_loss: 0.0132\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0691 - val_loss: 0.0132\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0690 - val_loss: 0.0131\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0688 - val_loss: 0.0131\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0687 - val_loss: 0.0131\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0685 - val_loss: 0.0130\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0684 - val_loss: 0.0129\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0682 - val_loss: 0.0128\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0681 - val_loss: 0.0127\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0679 - val_loss: 0.0126\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0677 - val_loss: 0.0125\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0676 - val_loss: 0.0125\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0674 - val_loss: 0.0124\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0673 - val_loss: 0.0123\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0671 - val_loss: 0.0123\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0670 - val_loss: 0.0123\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0668 - val_loss: 0.0123\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0666 - val_loss: 0.0123\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0665 - val_loss: 0.0123\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0663 - val_loss: 0.0123\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0662 - val_loss: 0.0123\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0660 - val_loss: 0.0123\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0659 - val_loss: 0.0123\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0657 - val_loss: 0.0123\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0656 - val_loss: 0.0123\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0654 - val_loss: 0.0123\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0653 - val_loss: 0.0122\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0651 - val_loss: 0.0122\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0650 - val_loss: 0.0121\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0648 - val_loss: 0.0121\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0647 - val_loss: 0.0120\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0645 - val_loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0644 - val_loss: 0.0119\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0643 - val_loss: 0.0118\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0641 - val_loss: 0.0118\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0640 - val_loss: 0.0117\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0638 - val_loss: 0.0117\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0637 - val_loss: 0.0116\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0636 - val_loss: 0.0116\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0634 - val_loss: 0.0115\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0633 - val_loss: 0.0115\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0631 - val_loss: 0.0115\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0630 - val_loss: 0.0114\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0628 - val_loss: 0.0114\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0627 - val_loss: 0.0114\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0626 - val_loss: 0.0113\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0624 - val_loss: 0.0113\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0623 - val_loss: 0.0113\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0622 - val_loss: 0.0112\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0620 - val_loss: 0.0112\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0619 - val_loss: 0.0112\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0618 - val_loss: 0.0111\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0616 - val_loss: 0.0111\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0615 - val_loss: 0.0111\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0614 - val_loss: 0.0110\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0612 - val_loss: 0.0110\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0611 - val_loss: 0.0110\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0610 - val_loss: 0.0109\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0609 - val_loss: 0.0109\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0607 - val_loss: 0.0108\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0606 - val_loss: 0.0108\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0605 - val_loss: 0.0108\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0603 - val_loss: 0.0107\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0602 - val_loss: 0.0107\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0601 - val_loss: 0.0106\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0599 - val_loss: 0.0106\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0598 - val_loss: 0.0106\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0597 - val_loss: 0.0105\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0596 - val_loss: 0.0105\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0594 - val_loss: 0.0105\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0593 - val_loss: 0.0104\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0592 - val_loss: 0.0104\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0591 - val_loss: 0.0103\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0589 - val_loss: 0.0103\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0588 - val_loss: 0.0102\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0587 - val_loss: 0.0102\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0586 - val_loss: 0.0101\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0584 - val_loss: 0.0101\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0583 - val_loss: 0.0101\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0582 - val_loss: 0.0100\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0581 - val_loss: 0.0100\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0579 - val_loss: 0.0100\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0578 - val_loss: 0.0099\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0577 - val_loss: 0.0099\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0576 - val_loss: 0.0099\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0575 - val_loss: 0.0098\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0573 - val_loss: 0.0098\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0572 - val_loss: 0.0097\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0571 - val_loss: 0.0097\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0570 - val_loss: 0.0097\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0569 - val_loss: 0.0096\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0567 - val_loss: 0.0096\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0566 - val_loss: 0.0095\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0565 - val_loss: 0.0095\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0564 - val_loss: 0.0094\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0563 - val_loss: 0.0094\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0561 - val_loss: 0.0093\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0560 - val_loss: 0.0093\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0559 - val_loss: 0.0093\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0558 - val_loss: 0.0093\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0557 - val_loss: 0.0092\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0556 - val_loss: 0.0092\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0554 - val_loss: 0.0091\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0553 - val_loss: 0.0091\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0552 - val_loss: 0.0091\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0551 - val_loss: 0.0090\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0550 - val_loss: 0.0090\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0549 - val_loss: 0.0090\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0548 - val_loss: 0.0089\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0546 - val_loss: 0.0089\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0545 - val_loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0544 - val_loss: 0.0088\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0543 - val_loss: 0.0088\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0542 - val_loss: 0.0087\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0541 - val_loss: 0.0087\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0540 - val_loss: 0.0087\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0539 - val_loss: 0.0086\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0537 - val_loss: 0.0086\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0536 - val_loss: 0.0086\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0535 - val_loss: 0.0086\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0534 - val_loss: 0.0085\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0533 - val_loss: 0.0085\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0532 - val_loss: 0.0084\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0531 - val_loss: 0.0084\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0530 - val_loss: 0.0084\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0529 - val_loss: 0.0083\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0528 - val_loss: 0.0083\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0526 - val_loss: 0.0082\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0525 - val_loss: 0.0082\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0524 - val_loss: 0.0082\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0523 - val_loss: 0.0082\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0522 - val_loss: 0.0082\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0521 - val_loss: 0.0081\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0520 - val_loss: 0.0081\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0519 - val_loss: 0.0080\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0518 - val_loss: 0.0080\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0517 - val_loss: 0.0080\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0516 - val_loss: 0.0080\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0515 - val_loss: 0.0079\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0513 - val_loss: 0.0079\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0512 - val_loss: 0.0079\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0511 - val_loss: 0.0079\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0510 - val_loss: 0.0078\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0509 - val_loss: 0.0078\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0508 - val_loss: 0.0077\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0507 - val_loss: 0.0077\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0506 - val_loss: 0.0077\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0505 - val_loss: 0.0076\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0504 - val_loss: 0.0076\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0503 - val_loss: 0.0076\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0502 - val_loss: 0.0076\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0501 - val_loss: 0.0075\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0500 - val_loss: 0.0075\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0499 - val_loss: 0.0075\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0498 - val_loss: 0.0075\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0497 - val_loss: 0.0074\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0496 - val_loss: 0.0074\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0495 - val_loss: 0.0074\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0494 - val_loss: 0.0073\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0493 - val_loss: 0.0073\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0492 - val_loss: 0.0073\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0491 - val_loss: 0.0073\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0490 - val_loss: 0.0072\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0489 - val_loss: 0.0072\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0487 - val_loss: 0.0072\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0486 - val_loss: 0.0071\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0486 - val_loss: 0.0071\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0485 - val_loss: 0.0071\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0483 - val_loss: 0.0071\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0482 - val_loss: 0.0070\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0481 - val_loss: 0.0070\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0480 - val_loss: 0.0070\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0480 - val_loss: 0.0070\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0478 - val_loss: 0.0069\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0477 - val_loss: 0.0069\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0477 - val_loss: 0.0069\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0476 - val_loss: 0.0068\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0475 - val_loss: 0.0068\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0474 - val_loss: 0.0068\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0473 - val_loss: 0.0068\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0472 - val_loss: 0.0068\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0471 - val_loss: 0.0067\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0470 - val_loss: 0.0067\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0469 - val_loss: 0.0067\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0468 - val_loss: 0.0067\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0467 - val_loss: 0.0067\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0466 - val_loss: 0.0066\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0465 - val_loss: 0.0066\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0464 - val_loss: 0.0066\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0463 - val_loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0462 - val_loss: 0.0065\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0461 - val_loss: 0.0065\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0460 - val_loss: 0.0065\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0459 - val_loss: 0.0064\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0458 - val_loss: 0.0064\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0457 - val_loss: 0.0064\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0456 - val_loss: 0.0064\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0455 - val_loss: 0.0063\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0454 - val_loss: 0.0063\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0453 - val_loss: 0.0063\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0452 - val_loss: 0.0063\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0451 - val_loss: 0.0062\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0450 - val_loss: 0.0062\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0449 - val_loss: 0.0062\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0449 - val_loss: 0.0062\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0448 - val_loss: 0.0062\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0447 - val_loss: 0.0062\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0446 - val_loss: 0.0061\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0445 - val_loss: 0.0061\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0444 - val_loss: 0.0061\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0443 - val_loss: 0.0061\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0442 - val_loss: 0.0061\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0441 - val_loss: 0.0060\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0060\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0439 - val_loss: 0.0060\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0438 - val_loss: 0.0060\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0437 - val_loss: 0.0059\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0436 - val_loss: 0.0059\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0436 - val_loss: 0.0059\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0435 - val_loss: 0.0059\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0434 - val_loss: 0.0058\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0433 - val_loss: 0.0058\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0058\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0431 - val_loss: 0.0058\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0430 - val_loss: 0.0058\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0429 - val_loss: 0.0057\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0428 - val_loss: 0.0057\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0427 - val_loss: 0.0057\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0426 - val_loss: 0.0057\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0426 - val_loss: 0.0057\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0425 - val_loss: 0.0057\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0424 - val_loss: 0.0056\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0423 - val_loss: 0.0056\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0422 - val_loss: 0.0056\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0421 - val_loss: 0.0056\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0420 - val_loss: 0.0056\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0419 - val_loss: 0.0055\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0418 - val_loss: 0.0055\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0418 - val_loss: 0.0055\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0417 - val_loss: 0.0055\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0416 - val_loss: 0.0055\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0415 - val_loss: 0.0054\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0414 - val_loss: 0.0054\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0413 - val_loss: 0.0054\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0412 - val_loss: 0.0054\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0411 - val_loss: 0.0053\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0411 - val_loss: 0.0053\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0410 - val_loss: 0.0053\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0409 - val_loss: 0.0053\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0408 - val_loss: 0.0053\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0407 - val_loss: 0.0053\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0406 - val_loss: 0.0052\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0405 - val_loss: 0.0052\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0404 - val_loss: 0.0052\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0404 - val_loss: 0.0052\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0403 - val_loss: 0.0052\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0402 - val_loss: 0.0052\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0401 - val_loss: 0.0051\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0400 - val_loss: 0.0051\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0399 - val_loss: 0.0051\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0398 - val_loss: 0.0051\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0398 - val_loss: 0.0051\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0397 - val_loss: 0.0051\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0396 - val_loss: 0.0050\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.0050\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0394 - val_loss: 0.0050\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0393 - val_loss: 0.0050\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0393 - val_loss: 0.0050\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0392 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0391 - val_loss: 0.0050\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0390 - val_loss: 0.0049\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0389 - val_loss: 0.0049\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0388 - val_loss: 0.0049\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0388 - val_loss: 0.0049\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0387 - val_loss: 0.0048\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0386 - val_loss: 0.0048\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0385 - val_loss: 0.0048\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0384 - val_loss: 0.0048\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0384 - val_loss: 0.0047\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0383 - val_loss: 0.0047\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0382 - val_loss: 0.0047\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0047\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0047\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0379 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0379 - val_loss: 0.0047\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0378 - val_loss: 0.0047\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0377 - val_loss: 0.0047\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0376 - val_loss: 0.0047\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0375 - val_loss: 0.0047\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0374 - val_loss: 0.0047\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0047\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0373 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0372 - val_loss: 0.0047\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0371 - val_loss: 0.0046\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0370 - val_loss: 0.0046\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0046\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0369 - val_loss: 0.0046\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0045\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0045\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0366 - val_loss: 0.0045\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0366 - val_loss: 0.0044\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.0044\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0364 - val_loss: 0.0044\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0044\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0362 - val_loss: 0.0043\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0362 - val_loss: 0.0043\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0043\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0360 - val_loss: 0.0043\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0359 - val_loss: 0.0043\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0358 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0043\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0357 - val_loss: 0.0043\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0356 - val_loss: 0.0043\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.0043\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0354 - val_loss: 0.0043\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0043\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0353 - val_loss: 0.0043\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0352 - val_loss: 0.0043\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0351 - val_loss: 0.0042\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0351 - val_loss: 0.0042\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0350 - val_loss: 0.0042\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0349 - val_loss: 0.0042\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.0042\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0348 - val_loss: 0.0042\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0042\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0346 - val_loss: 0.0041\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0345 - val_loss: 0.0041\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0041\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0041\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0343 - val_loss: 0.0041\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0342 - val_loss: 0.0041\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0341 - val_loss: 0.0040\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0341 - val_loss: 0.0040\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0340 - val_loss: 0.0040\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0339 - val_loss: 0.0040\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0338 - val_loss: 0.0040\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0338 - val_loss: 0.0040\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0040\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0336 - val_loss: 0.0040\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0335 - val_loss: 0.0039\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0335 - val_loss: 0.0039\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0334 - val_loss: 0.0039\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0333 - val_loss: 0.0039\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0332 - val_loss: 0.0039\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0332 - val_loss: 0.0039\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0331 - val_loss: 0.0039\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0330 - val_loss: 0.0039\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0038\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0328 - val_loss: 0.0038\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0327 - val_loss: 0.0038\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0327 - val_loss: 0.0038\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0326 - val_loss: 0.0038\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0325 - val_loss: 0.0038\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0324 - val_loss: 0.0038\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0324 - val_loss: 0.0037\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0323 - val_loss: 0.0037\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0037\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0321 - val_loss: 0.0037\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0321 - val_loss: 0.0037\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0320 - val_loss: 0.0037\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0319 - val_loss: 0.0037\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0319 - val_loss: 0.0036\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0318 - val_loss: 0.0036\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0317 - val_loss: 0.0036\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0316 - val_loss: 0.0036\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0316 - val_loss: 0.0036\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0315 - val_loss: 0.0036\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0314 - val_loss: 0.0036\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0314 - val_loss: 0.0036\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0036\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0312 - val_loss: 0.0036\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0311 - val_loss: 0.0036\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0311 - val_loss: 0.0036\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0310 - val_loss: 0.0036\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0309 - val_loss: 0.0036\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.0035\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0308 - val_loss: 0.0035\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0307 - val_loss: 0.0035\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0306 - val_loss: 0.0035\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0306 - val_loss: 0.0034\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0305 - val_loss: 0.0034\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0304 - val_loss: 0.0034\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0304 - val_loss: 0.0034\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0303 - val_loss: 0.0034\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0034\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0302 - val_loss: 0.0034\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0301 - val_loss: 0.0034\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0300 - val_loss: 0.0034\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0034\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0299 - val_loss: 0.0034\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0298 - val_loss: 0.0034\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0034\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0033\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0296 - val_loss: 0.0033\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0295 - val_loss: 0.0033\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0295 - val_loss: 0.0033\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0294 - val_loss: 0.0033\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0293 - val_loss: 0.0033\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0293 - val_loss: 0.0033\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0292 - val_loss: 0.0033\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0291 - val_loss: 0.0033\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0291 - val_loss: 0.0033\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0290 - val_loss: 0.0032\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0289 - val_loss: 0.0032\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0289 - val_loss: 0.0032\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0288 - val_loss: 0.0032\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.0032\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.0032\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0032\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 0.0285 - val_loss: 0.0032\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0285 - val_loss: 0.0031\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0284 - val_loss: 0.0031\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0283 - val_loss: 0.0031\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0283 - val_loss: 0.0031\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0282 - val_loss: 0.0031\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0281 - val_loss: 0.0031\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0281 - val_loss: 0.0031\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0280 - val_loss: 0.0031\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0031\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0031\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0278 - val_loss: 0.0031\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0277 - val_loss: 0.0031\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0277 - val_loss: 0.0031\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0276 - val_loss: 0.0031\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0275 - val_loss: 0.0030\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0275 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0030\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0273 - val_loss: 0.0030\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0273 - val_loss: 0.0030\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0272 - val_loss: 0.0030\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0272 - val_loss: 0.0030\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0271 - val_loss: 0.0030\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0270 - val_loss: 0.0030\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0270 - val_loss: 0.0030\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0030\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0029\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0268 - val_loss: 0.0029\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0267 - val_loss: 0.0029\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0266 - val_loss: 0.0029\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0266 - val_loss: 0.0029\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0029\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0264 - val_loss: 0.0029\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0029\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0263 - val_loss: 0.0029\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0263 - val_loss: 0.0028\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0262 - val_loss: 0.0028\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0261 - val_loss: 0.0028\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0261 - val_loss: 0.0028\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0260 - val_loss: 0.0028\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0259 - val_loss: 0.0028\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0259 - val_loss: 0.0028\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0258 - val_loss: 0.0028\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0258 - val_loss: 0.0028\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0257 - val_loss: 0.0028\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0256 - val_loss: 0.0028\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0256 - val_loss: 0.0028\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0255 - val_loss: 0.0028\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0255 - val_loss: 0.0028\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0254 - val_loss: 0.0027\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0253 - val_loss: 0.0027\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0253 - val_loss: 0.0027\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0252 - val_loss: 0.0027\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0251 - val_loss: 0.0027\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0251 - val_loss: 0.0027\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0250 - val_loss: 0.0027\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0250 - val_loss: 0.0027\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0027\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0248 - val_loss: 0.0027\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0248 - val_loss: 0.0027\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0247 - val_loss: 0.0026\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0026\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0246 - val_loss: 0.0026\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.0026\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.0026\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0244 - val_loss: 0.0026\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0244 - val_loss: 0.0026\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0243 - val_loss: 0.0026\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0242 - val_loss: 0.0026\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0242 - val_loss: 0.0026\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0241 - val_loss: 0.0026\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0026\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0240 - val_loss: 0.0026\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0239 - val_loss: 0.0026\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0239 - val_loss: 0.0026\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0238 - val_loss: 0.0025\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0025\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0237 - val_loss: 0.0025\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0237 - val_loss: 0.0025\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0236 - val_loss: 0.0025\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0235 - val_loss: 0.0025\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0235 - val_loss: 0.0025\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0234 - val_loss: 0.0025\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0234 - val_loss: 0.0025\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0233 - val_loss: 0.0025\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0233 - val_loss: 0.0025\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0232 - val_loss: 0.0025\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0024\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0231 - val_loss: 0.0024\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0230 - val_loss: 0.0024\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0230 - val_loss: 0.0024\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0024\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 467us/step - loss: 0.0229 - val_loss: 0.0024\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0024\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0024\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0024\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0226 - val_loss: 0.0024\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0024\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0225 - val_loss: 0.0024\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0224 - val_loss: 0.0024\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0223 - val_loss: 0.0024\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0223 - val_loss: 0.0023\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0023\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0023\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0023\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0023\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0023\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0023\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0023\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0023\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0218 - val_loss: 0.0023\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0217 - val_loss: 0.0023\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0217 - val_loss: 0.0023\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0216 - val_loss: 0.0023\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0216 - val_loss: 0.0023\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0215 - val_loss: 0.0022\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0215 - val_loss: 0.0022\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0214 - val_loss: 0.0022\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0214 - val_loss: 0.0022\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0213 - val_loss: 0.0022\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0212 - val_loss: 0.0022\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0212 - val_loss: 0.0022\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0211 - val_loss: 0.0022\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0211 - val_loss: 0.0022\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0210 - val_loss: 0.0022\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0210 - val_loss: 0.0022\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0209 - val_loss: 0.0022\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0022\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0208 - val_loss: 0.0022\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0208 - val_loss: 0.0022\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0207 - val_loss: 0.0022\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0207 - val_loss: 0.0022\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0206 - val_loss: 0.0022\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0205 - val_loss: 0.0022\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0205 - val_loss: 0.0021\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0204 - val_loss: 0.0021\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0204 - val_loss: 0.0021\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0203 - val_loss: 0.0021\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0203 - val_loss: 0.0021\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0202 - val_loss: 0.0021\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0202 - val_loss: 0.0021\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0021\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.0021\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0200 - val_loss: 0.0021\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0200 - val_loss: 0.0021\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0021\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0020\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0020\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0198 - val_loss: 0.0020\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0197 - val_loss: 0.0020\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0197 - val_loss: 0.0020\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0020\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0020\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0195 - val_loss: 0.0020\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0195 - val_loss: 0.0020\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0020\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0020\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0193 - val_loss: 0.0020\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0193 - val_loss: 0.0020\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0192 - val_loss: 0.0020\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0192 - val_loss: 0.0020\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0191 - val_loss: 0.0020\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0191 - val_loss: 0.0020\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0190 - val_loss: 0.0019\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0190 - val_loss: 0.0019\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0189 - val_loss: 0.0019\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0189 - val_loss: 0.0019\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0188 - val_loss: 0.0019\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0188 - val_loss: 0.0019\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0187 - val_loss: 0.0019\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0187 - val_loss: 0.0019\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0186 - val_loss: 0.0019\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0186 - val_loss: 0.0019\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0185 - val_loss: 0.0019\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0019\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0184 - val_loss: 0.0019\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0019\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0019\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0182 - val_loss: 0.0018\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0182 - val_loss: 0.0018\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0181 - val_loss: 0.0018\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0181 - val_loss: 0.0018\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0018\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0180 - val_loss: 0.0018\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0179 - val_loss: 0.0018\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0179 - val_loss: 0.0018\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0178 - val_loss: 0.0018\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0178 - val_loss: 0.0018\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0178 - val_loss: 0.0018\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 0.0018\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0177 - val_loss: 0.0018\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0018\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0176 - val_loss: 0.0018\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0175 - val_loss: 0.0018\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0175 - val_loss: 0.0018\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0174 - val_loss: 0.0018\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0174 - val_loss: 0.0018\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0018\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0017\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0017\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0017\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0171 - val_loss: 0.0017\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0171 - val_loss: 0.0017\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0171 - val_loss: 0.0017\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0017\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0170 - val_loss: 0.0017\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0169 - val_loss: 0.0017\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0169 - val_loss: 0.0017\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0168 - val_loss: 0.0017\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0168 - val_loss: 0.0017\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0167 - val_loss: 0.0017\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0167 - val_loss: 0.0017\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0017\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0017\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0165 - val_loss: 0.0017\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0165 - val_loss: 0.0017\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0165 - val_loss: 0.0016\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0016\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0016\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0016\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0016\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0162 - val_loss: 0.0016\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0162 - val_loss: 0.0016\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0161 - val_loss: 0.0016\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0161 - val_loss: 0.0016\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0161 - val_loss: 0.0016\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0016\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0160 - val_loss: 0.0016\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0016\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0016\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0158 - val_loss: 0.0016\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0158 - val_loss: 0.0016\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0158 - val_loss: 0.0016\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0157 - val_loss: 0.0016\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0016\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0156 - val_loss: 0.0016\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0156 - val_loss: 0.0016\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0155 - val_loss: 0.0015\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0015\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0015\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0015\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0015\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0153 - val_loss: 0.0015\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0015\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0152 - val_loss: 0.0015\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0152 - val_loss: 0.0015\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0152 - val_loss: 0.0015\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0151 - val_loss: 0.0015\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.0015\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0150 - val_loss: 0.0015\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0150 - val_loss: 0.0015\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0150 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0015\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0015\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0148 - val_loss: 0.0015\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.0015\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0147 - val_loss: 0.0015\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0147 - val_loss: 0.0015\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0015\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0015\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0145 - val_loss: 0.0015\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.0014\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0145 - val_loss: 0.0014\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0144 - val_loss: 0.0014\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.0014\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0143 - val_loss: 0.0014\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0143 - val_loss: 0.0014\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0143 - val_loss: 0.0014\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0014\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0014\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0014\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0141 - val_loss: 0.0014\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0141 - val_loss: 0.0014\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0140 - val_loss: 0.0014\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0014\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0014\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0014\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0014\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0138 - val_loss: 0.0014\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0138 - val_loss: 0.0014\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0137 - val_loss: 0.0013\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0137 - val_loss: 0.0013\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0137 - val_loss: 0.0013\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0136 - val_loss: 0.0013\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0013\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0136 - val_loss: 0.0013\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0135 - val_loss: 0.0013\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0135 - val_loss: 0.0013\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0134 - val_loss: 0.0013\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0013\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0134 - val_loss: 0.0013\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0133 - val_loss: 0.0013\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0013\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0132 - val_loss: 0.0013\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0132 - val_loss: 0.0013\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0132 - val_loss: 0.0013\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0131 - val_loss: 0.0013\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0013\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0013\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.0013\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0130 - val_loss: 0.0013\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0013\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0129 - val_loss: 0.0013\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0129 - val_loss: 0.0013\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0013\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0128 - val_loss: 0.0013\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0013\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0127 - val_loss: 0.0013\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0012\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0012\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0126 - val_loss: 0.0012\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0126 - val_loss: 0.0012\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0125 - val_loss: 0.0012\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0012\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0012\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0012\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0124 - val_loss: 0.0012\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0012\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0123 - val_loss: 0.0012\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0012\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0123 - val_loss: 0.0012\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0012\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0012\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0121 - val_loss: 0.0012\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0121 - val_loss: 0.0012\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0121 - val_loss: 0.0012\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0012\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0120 - val_loss: 0.0012\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0012\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0119 - val_loss: 0.0012\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0012\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0118 - val_loss: 0.0012\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0012\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0011\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.0011\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0117 - val_loss: 0.0011\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0011\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0011\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0011\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0011\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0011\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0011\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0011\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0114 - val_loss: 0.0011\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0114 - val_loss: 0.0011\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0114 - val_loss: 0.0011\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0011\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0011\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0113 - val_loss: 0.0011\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0112 - val_loss: 0.0011\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0011\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0112 - val_loss: 0.0011\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0011\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0111 - val_loss: 0.0011\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0011\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0011\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0011\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0011\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0011\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0011\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0010\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0108 - val_loss: 0.0010\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0108 - val_loss: 0.0010\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0010\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0107 - val_loss: 0.0010\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0107 - val_loss: 0.0010\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0010\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0010\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0010\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0010\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0010\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0105 - val_loss: 0.0010\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0105 - val_loss: 0.0010\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0105 - val_loss: 0.0010\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0010\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0010\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0010\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 9.9900e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0103 - val_loss: 9.9395e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0103 - val_loss: 9.8978e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 9.8582e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0102 - val_loss: 9.8202e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0102 - val_loss: 9.7829e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 9.7469e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0101 - val_loss: 9.7134e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 9.6825e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0101 - val_loss: 9.6553e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 9.6343e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0100 - val_loss: 9.6028e-04\n",
      "0.003058450762182474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.42163548,  0.6059354 , -0.13677222, -0.7906114 , -1.0763352 ],\n",
       "        [ 0.06679168, -0.099337  ,  0.13898559,  0.4687319 , -0.6448089 ],\n",
       "        [ 1.1090984 ,  0.76668227, -1.0195371 ,  0.24008453,  0.34601167]],\n",
       "       dtype=float32),\n",
       " array([0.30799362, 0.02783361, 0.66396666, 0.03773048, 0.0559358 ],\n",
       "       dtype=float32),\n",
       " array([[-0.9165243 ,  0.2261486 ,  0.32673386, -0.48637864, -0.6373677 ,\n",
       "         -0.8992517 ,  0.2156669 ,  0.03149367, -0.79693466, -0.24251527],\n",
       "        [-0.40337026, -0.6321553 ,  0.34297574, -0.39571565, -1.0525458 ,\n",
       "         -0.49060795,  0.25851688,  0.07842402, -0.20690078, -0.47556716],\n",
       "        [ 0.14176187, -0.45519263, -0.37924442, -0.29292473, -0.48043913,\n",
       "         -0.2172279 ,  0.5907631 ,  0.6649517 , -0.8225569 , -0.07844837],\n",
       "        [-0.9881642 , -0.22664726, -0.4131226 , -1.0239978 , -0.41835934,\n",
       "         -0.67992914,  0.4540248 ,  0.44805092, -0.6062681 , -0.6785382 ],\n",
       "        [-0.92873305, -0.3588898 ,  0.4486165 , -0.254987  , -0.12026184,\n",
       "          0.1608415 ,  0.10062832, -0.3972919 , -0.29592985, -0.25551084]],\n",
       "       dtype=float32),\n",
       " array([-0.03447893,  0.        ,  1.5861638 , -0.646702  , -0.61407864,\n",
       "        -0.52073497,  1.3917123 ,  1.4022272 , -0.44682497, -0.39641556],\n",
       "       dtype=float32),\n",
       " array([[ 0.4431456 ],\n",
       "        [-0.3933502 ],\n",
       "        [ 1.0254554 ],\n",
       "        [ 0.2944183 ],\n",
       "        [-0.06351371],\n",
       "        [-0.03017952],\n",
       "        [ 0.6144934 ],\n",
       "        [ 0.79540944],\n",
       "        [ 0.22766812],\n",
       "        [ 0.43123633]], dtype=float32),\n",
       " array([1.2370973], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_relu(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_relu_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 32.3310 - val_loss: 28.9262\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 29.1628 - val_loss: 25.1389\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2352 - val_loss: 21.1784\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 21.1413 - val_loss: 17.3245\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.1891 - val_loss: 13.7418\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 13.5249 - val_loss: 10.4903\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.2107 - val_loss: 7.6017\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2845 - val_loss: 5.1137\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7945 - val_loss: 3.0780\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7942 - val_loss: 1.5476\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3278 - val_loss: 0.5531\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4152 - val_loss: 0.0859\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0383 - val_loss: 0.0812\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1214 - val_loss: 0.4073\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.5233 - val_loss: 0.8905\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0663 - val_loss: 1.3657\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5860 - val_loss: 1.7141\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9662 - val_loss: 1.8744\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1462 - val_loss: 1.8370\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1147 - val_loss: 1.6316\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.8986 - val_loss: 1.3142\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5527 - val_loss: 0.9528\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1478 - val_loss: 0.6121\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7563 - val_loss: 0.3382\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4337 - val_loss: 0.1507\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2063 - val_loss: 0.0456\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0727 - val_loss: 0.0047\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0067\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0328\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0320 - val_loss: 0.0693\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0684 - val_loss: 0.1070\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1070 - val_loss: 0.1403\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1414 - val_loss: 0.1663\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1682 - val_loss: 0.1835\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1861 - val_loss: 0.1917\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1948 - val_loss: 0.1916\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1949 - val_loss: 0.1842\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1876 - val_loss: 0.1709\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1744 - val_loss: 0.1534\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1568 - val_loss: 0.1332\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1365 - val_loss: 0.1118\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1149 - val_loss: 0.0904\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0934 - val_loss: 0.0702\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0729 - val_loss: 0.0520\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0544 - val_loss: 0.0363\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0385 - val_loss: 0.0236\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0138\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0068\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 4.9901e-04\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0372e-04\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5559e-04 - val_loss: 0.0015\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0088\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0114\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0139 - val_loss: 0.0160\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.3721e-04\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3555e-04 - val_loss: 3.7654e-04\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6809e-04 - val_loss: 1.7965e-04\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5554e-04 - val_loss: 1.1351e-04\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6444e-04 - val_loss: 1.4413e-04\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6070e-04 - val_loss: 2.3911e-04\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1186e-04 - val_loss: 3.6923e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8893e-04 - val_loss: 5.0981e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6748e-04 - val_loss: 6.4141e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.4995e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 8.2659e-04\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.6724e-04\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 8.7183e-04\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 8.4344e-04\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.8745e-04\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.1064e-04\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.2040e-04\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 0.0011 - val_loss: 5.2406e-04\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.7951e-04 - val_loss: 4.2833e-04\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 8.5905e-04 - val_loss: 3.3889e-04\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.4301e-04 - val_loss: 2.6021e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.3650e-04 - val_loss: 1.9533e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.4316e-04 - val_loss: 1.4597e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6521e-04 - val_loss: 1.1254e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0361e-04 - val_loss: 9.4381e-05\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5813e-04 - val_loss: 8.9951e-05\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2765e-04 - val_loss: 9.7095e-05\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1031e-04 - val_loss: 1.1324e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0387e-04 - val_loss: 1.3566e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0581e-04 - val_loss: 1.6169e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1363e-04 - val_loss: 1.8886e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2499e-04 - val_loss: 2.1501e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3776e-04 - val_loss: 2.3840e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5023e-04 - val_loss: 2.5776e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6107e-04 - val_loss: 2.7223e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6935e-04 - val_loss: 2.8143e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7456e-04 - val_loss: 2.8528e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7650e-04 - val_loss: 2.8413e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7530e-04 - val_loss: 2.7848e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7131e-04 - val_loss: 2.6904e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.6501e-04 - val_loss: 2.5661e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.5700e-04 - val_loss: 2.4201e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.4788e-04 - val_loss: 2.2606e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3826e-04 - val_loss: 2.0951e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 3.2868e-04 - val_loss: 1.9298e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1957e-04 - val_loss: 1.7705e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1131e-04 - val_loss: 1.6210e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0412e-04 - val_loss: 1.4843e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9813e-04 - val_loss: 1.3620e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9339e-04 - val_loss: 1.2551e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8986e-04 - val_loss: 1.1635e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8742e-04 - val_loss: 1.0862e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8590e-04 - val_loss: 1.0223e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8516e-04 - val_loss: 9.7028e-05\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8496e-04 - val_loss: 9.2857e-05\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8515e-04 - val_loss: 8.9566e-05\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8553e-04 - val_loss: 8.7001e-05\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 2.8597e-04 - val_loss: 8.5047e-05\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8635e-04 - val_loss: 8.3578e-05\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8657e-04 - val_loss: 8.2524e-05\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8657e-04 - val_loss: 8.1806e-05\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8634e-04 - val_loss: 8.1390e-05\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8586e-04 - val_loss: 8.1234e-05\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8516e-04 - val_loss: 8.1310e-05\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8427e-04 - val_loss: 8.1617e-05\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8322e-04 - val_loss: 8.2133e-05\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8207e-04 - val_loss: 8.2858e-05\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8086e-04 - val_loss: 8.3771e-05\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7964e-04 - val_loss: 8.4864e-05\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7844e-04 - val_loss: 8.6109e-05\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7730e-04 - val_loss: 8.7485e-05\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.7623e-04 - val_loss: 8.8955e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7526e-04 - val_loss: 9.0482e-05\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7439e-04 - val_loss: 9.2040e-05\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7361e-04 - val_loss: 9.3592e-05\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7293e-04 - val_loss: 9.5090e-05\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7233e-04 - val_loss: 9.6504e-05\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7180e-04 - val_loss: 9.7806e-05\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7132e-04 - val_loss: 9.8972e-05\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7088e-04 - val_loss: 9.9977e-05\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7047e-04 - val_loss: 1.0080e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7006e-04 - val_loss: 1.0144e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6965e-04 - val_loss: 1.0187e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6925e-04 - val_loss: 1.0213e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6882e-04 - val_loss: 1.0220e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6839e-04 - val_loss: 1.0210e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6794e-04 - val_loss: 1.0184e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6747e-04 - val_loss: 1.0144e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6699e-04 - val_loss: 1.0091e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6650e-04 - val_loss: 1.0029e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6600e-04 - val_loss: 9.9574e-05\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6550e-04 - val_loss: 9.8800e-05\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6500e-04 - val_loss: 9.7975e-05\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6450e-04 - val_loss: 9.7132e-05\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6401e-04 - val_loss: 9.6269e-05\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6353e-04 - val_loss: 9.5416e-05\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6305e-04 - val_loss: 9.4577e-05\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6258e-04 - val_loss: 9.3760e-05\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6213e-04 - val_loss: 9.2986e-05\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6168e-04 - val_loss: 9.2246e-05\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6124e-04 - val_loss: 9.1563e-05\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6082e-04 - val_loss: 9.0924e-05\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6040e-04 - val_loss: 9.0346e-05\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5998e-04 - val_loss: 8.9821e-05\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5957e-04 - val_loss: 8.9350e-05\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.5917e-04 - val_loss: 8.8933e-05\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5876e-04 - val_loss: 8.8566e-05\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5836e-04 - val_loss: 8.8256e-05\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5795e-04 - val_loss: 8.8000e-05\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5755e-04 - val_loss: 8.7783e-05\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5715e-04 - val_loss: 8.7604e-05\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5675e-04 - val_loss: 8.7465e-05\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5635e-04 - val_loss: 8.7360e-05\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5595e-04 - val_loss: 8.7281e-05\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5556e-04 - val_loss: 8.7230e-05\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.5516e-04 - val_loss: 8.7195e-05\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5477e-04 - val_loss: 8.7180e-05\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5438e-04 - val_loss: 8.7180e-05\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5399e-04 - val_loss: 8.7184e-05\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5360e-04 - val_loss: 8.7187e-05\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5322e-04 - val_loss: 8.7193e-05\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5284e-04 - val_loss: 8.7200e-05\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5246e-04 - val_loss: 8.7203e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5208e-04 - val_loss: 8.7195e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5171e-04 - val_loss: 8.7180e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5133e-04 - val_loss: 8.7151e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5096e-04 - val_loss: 8.7118e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.5060e-04 - val_loss: 8.7067e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5023e-04 - val_loss: 8.7005e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4987e-04 - val_loss: 8.6926e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4951e-04 - val_loss: 8.6829e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4914e-04 - val_loss: 8.6724e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4878e-04 - val_loss: 8.6608e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4843e-04 - val_loss: 8.6483e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4807e-04 - val_loss: 8.6345e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4771e-04 - val_loss: 8.6196e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4737e-04 - val_loss: 8.6043e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4701e-04 - val_loss: 8.5881e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4666e-04 - val_loss: 8.5704e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4631e-04 - val_loss: 8.5537e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4597e-04 - val_loss: 8.5359e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4562e-04 - val_loss: 8.5181e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4527e-04 - val_loss: 8.5002e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4493e-04 - val_loss: 8.4824e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4459e-04 - val_loss: 8.4646e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4425e-04 - val_loss: 8.4472e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4391e-04 - val_loss: 8.4300e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4358e-04 - val_loss: 8.4132e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4324e-04 - val_loss: 8.3965e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4290e-04 - val_loss: 8.3803e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4257e-04 - val_loss: 8.3648e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4224e-04 - val_loss: 8.3494e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4191e-04 - val_loss: 8.3351e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4158e-04 - val_loss: 8.3208e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4125e-04 - val_loss: 8.3071e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4092e-04 - val_loss: 8.2943e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4060e-04 - val_loss: 8.2814e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4028e-04 - val_loss: 8.2690e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3995e-04 - val_loss: 8.2576e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.3963e-04 - val_loss: 8.2459e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.3931e-04 - val_loss: 8.2349e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 2.3899e-04 - val_loss: 8.2239e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.3867e-04 - val_loss: 8.2133e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3836e-04 - val_loss: 8.2032e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3804e-04 - val_loss: 8.1932e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3772e-04 - val_loss: 8.1837e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3740e-04 - val_loss: 8.1742e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3710e-04 - val_loss: 8.1641e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3678e-04 - val_loss: 8.1546e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3647e-04 - val_loss: 8.1446e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.3616e-04 - val_loss: 8.1346e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3585e-04 - val_loss: 8.1257e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3554e-04 - val_loss: 8.1159e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3524e-04 - val_loss: 8.1063e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3494e-04 - val_loss: 8.0964e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3463e-04 - val_loss: 8.0866e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3433e-04 - val_loss: 8.0766e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3403e-04 - val_loss: 8.0668e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3372e-04 - val_loss: 8.0565e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3342e-04 - val_loss: 8.0469e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3312e-04 - val_loss: 8.0371e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3282e-04 - val_loss: 8.0264e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3252e-04 - val_loss: 8.0166e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3223e-04 - val_loss: 8.0059e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3193e-04 - val_loss: 7.9959e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3164e-04 - val_loss: 7.9853e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3134e-04 - val_loss: 7.9757e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3105e-04 - val_loss: 7.9653e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3075e-04 - val_loss: 7.9550e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3046e-04 - val_loss: 7.9448e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3017e-04 - val_loss: 7.9347e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2988e-04 - val_loss: 7.9245e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2959e-04 - val_loss: 7.9146e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2930e-04 - val_loss: 7.9044e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2901e-04 - val_loss: 7.8947e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2873e-04 - val_loss: 7.8846e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2844e-04 - val_loss: 7.8754e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.2816e-04 - val_loss: 7.8656e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2788e-04 - val_loss: 7.8561e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2759e-04 - val_loss: 7.8468e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2731e-04 - val_loss: 7.8366e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2702e-04 - val_loss: 7.8274e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2674e-04 - val_loss: 7.8180e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2646e-04 - val_loss: 7.8089e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2618e-04 - val_loss: 7.7996e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2590e-04 - val_loss: 7.7903e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2562e-04 - val_loss: 7.7815e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2535e-04 - val_loss: 7.7722e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2507e-04 - val_loss: 7.7633e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2479e-04 - val_loss: 7.7546e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2452e-04 - val_loss: 7.7457e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2424e-04 - val_loss: 7.7368e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2397e-04 - val_loss: 7.7284e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2369e-04 - val_loss: 7.7199e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2342e-04 - val_loss: 7.7114e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2315e-04 - val_loss: 7.7023e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.2288e-04 - val_loss: 7.6937e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2261e-04 - val_loss: 7.6851e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2234e-04 - val_loss: 7.6766e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2206e-04 - val_loss: 7.6681e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2179e-04 - val_loss: 7.6598e-05\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2153e-04 - val_loss: 7.6517e-05\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2126e-04 - val_loss: 7.6428e-05\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2100e-04 - val_loss: 7.6343e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.2073e-04 - val_loss: 7.6263e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2046e-04 - val_loss: 7.6173e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2019e-04 - val_loss: 7.6094e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1993e-04 - val_loss: 7.6011e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1967e-04 - val_loss: 7.5929e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1940e-04 - val_loss: 7.5843e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1914e-04 - val_loss: 7.5761e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1888e-04 - val_loss: 7.5681e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1861e-04 - val_loss: 7.5596e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1835e-04 - val_loss: 7.5517e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1809e-04 - val_loss: 7.5432e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1784e-04 - val_loss: 7.5357e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1758e-04 - val_loss: 7.5269e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1732e-04 - val_loss: 7.5196e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1706e-04 - val_loss: 7.5109e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1680e-04 - val_loss: 7.5026e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1654e-04 - val_loss: 7.4950e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1629e-04 - val_loss: 7.4869e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1603e-04 - val_loss: 7.4785e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1578e-04 - val_loss: 7.4710e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1552e-04 - val_loss: 7.4628e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1527e-04 - val_loss: 7.4550e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1502e-04 - val_loss: 7.4467e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1476e-04 - val_loss: 7.4389e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1451e-04 - val_loss: 7.4316e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1426e-04 - val_loss: 7.4233e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1401e-04 - val_loss: 7.4161e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1376e-04 - val_loss: 7.4083e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.1350e-04 - val_loss: 7.4006e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1325e-04 - val_loss: 7.3929e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1301e-04 - val_loss: 7.3854e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1275e-04 - val_loss: 7.3774e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1251e-04 - val_loss: 7.3692e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1226e-04 - val_loss: 7.3620e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.1201e-04 - val_loss: 7.3541e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1177e-04 - val_loss: 7.3465e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1152e-04 - val_loss: 7.3391e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1127e-04 - val_loss: 7.3320e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1103e-04 - val_loss: 7.3242e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1078e-04 - val_loss: 7.3170e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1054e-04 - val_loss: 7.3093e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1030e-04 - val_loss: 7.3023e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1005e-04 - val_loss: 7.2946e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0981e-04 - val_loss: 7.2875e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0957e-04 - val_loss: 7.2797e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0932e-04 - val_loss: 7.2727e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.0908e-04 - val_loss: 7.2650e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 2.0884e-04 - val_loss: 7.2573e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0860e-04 - val_loss: 7.2500e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0835e-04 - val_loss: 7.2428e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0812e-04 - val_loss: 7.2356e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0788e-04 - val_loss: 7.2283e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0764e-04 - val_loss: 7.2211e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0740e-04 - val_loss: 7.2139e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0716e-04 - val_loss: 7.2066e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0692e-04 - val_loss: 7.1992e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0668e-04 - val_loss: 7.1920e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0645e-04 - val_loss: 7.1850e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0621e-04 - val_loss: 7.1777e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0598e-04 - val_loss: 7.1706e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0574e-04 - val_loss: 7.1637e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0550e-04 - val_loss: 7.1559e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0527e-04 - val_loss: 7.1489e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0504e-04 - val_loss: 7.1418e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.0481e-04 - val_loss: 7.1348e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0457e-04 - val_loss: 7.1277e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0434e-04 - val_loss: 7.1208e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0411e-04 - val_loss: 7.1134e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 2.0387e-04 - val_loss: 7.1065e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0364e-04 - val_loss: 7.0991e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0341e-04 - val_loss: 7.0922e-05\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0318e-04 - val_loss: 7.0853e-05\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0295e-04 - val_loss: 7.0785e-05\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0272e-04 - val_loss: 7.0715e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0249e-04 - val_loss: 7.0650e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0226e-04 - val_loss: 7.0579e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0203e-04 - val_loss: 7.0512e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0180e-04 - val_loss: 7.0445e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0158e-04 - val_loss: 7.0377e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0135e-04 - val_loss: 7.0312e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0112e-04 - val_loss: 7.0237e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0089e-04 - val_loss: 7.0166e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 2.0067e-04 - val_loss: 7.0097e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0044e-04 - val_loss: 7.0029e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0021e-04 - val_loss: 6.9958e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9999e-04 - val_loss: 6.9891e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9976e-04 - val_loss: 6.9823e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9954e-04 - val_loss: 6.9753e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9931e-04 - val_loss: 6.9687e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9909e-04 - val_loss: 6.9621e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9887e-04 - val_loss: 6.9552e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9864e-04 - val_loss: 6.9485e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9842e-04 - val_loss: 6.9417e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9820e-04 - val_loss: 6.9353e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9797e-04 - val_loss: 6.9290e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9776e-04 - val_loss: 6.9223e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9754e-04 - val_loss: 6.9156e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9731e-04 - val_loss: 6.9084e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9709e-04 - val_loss: 6.9016e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9687e-04 - val_loss: 6.8950e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9665e-04 - val_loss: 6.8889e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9643e-04 - val_loss: 6.8819e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9622e-04 - val_loss: 6.8754e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9600e-04 - val_loss: 6.8684e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9577e-04 - val_loss: 6.8620e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9556e-04 - val_loss: 6.8553e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9534e-04 - val_loss: 6.8487e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9512e-04 - val_loss: 6.8418e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9490e-04 - val_loss: 6.8360e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9469e-04 - val_loss: 6.8293e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9448e-04 - val_loss: 6.8228e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9426e-04 - val_loss: 6.8166e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9404e-04 - val_loss: 6.8098e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9383e-04 - val_loss: 6.8031e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.9361e-04 - val_loss: 6.7970e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9340e-04 - val_loss: 6.7905e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9318e-04 - val_loss: 6.7840e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9297e-04 - val_loss: 6.7776e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9276e-04 - val_loss: 6.7711e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9254e-04 - val_loss: 6.7648e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9233e-04 - val_loss: 6.7585e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9212e-04 - val_loss: 6.7512e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9190e-04 - val_loss: 6.7453e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9170e-04 - val_loss: 6.7388e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9148e-04 - val_loss: 6.7323e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9127e-04 - val_loss: 6.7265e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9106e-04 - val_loss: 6.7198e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9085e-04 - val_loss: 6.7134e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9064e-04 - val_loss: 6.7068e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9043e-04 - val_loss: 6.7009e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9022e-04 - val_loss: 6.6947e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9001e-04 - val_loss: 6.6880e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8980e-04 - val_loss: 6.6816e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.8959e-04 - val_loss: 6.6756e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 1.8939e-04 - val_loss: 6.6694e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8918e-04 - val_loss: 6.6631e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8897e-04 - val_loss: 6.6567e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8877e-04 - val_loss: 6.6508e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8856e-04 - val_loss: 6.6443e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8835e-04 - val_loss: 6.6378e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8814e-04 - val_loss: 6.6315e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8794e-04 - val_loss: 6.6252e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8773e-04 - val_loss: 6.6191e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8752e-04 - val_loss: 6.6129e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8732e-04 - val_loss: 6.6069e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8711e-04 - val_loss: 6.6002e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8691e-04 - val_loss: 6.5939e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8671e-04 - val_loss: 6.5878e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8650e-04 - val_loss: 6.5818e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8630e-04 - val_loss: 6.5753e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8610e-04 - val_loss: 6.5690e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8590e-04 - val_loss: 6.5633e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8570e-04 - val_loss: 6.5572e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8549e-04 - val_loss: 6.5510e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8529e-04 - val_loss: 6.5447e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8509e-04 - val_loss: 6.5390e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8488e-04 - val_loss: 6.5331e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8468e-04 - val_loss: 6.5269e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8449e-04 - val_loss: 6.5206e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8428e-04 - val_loss: 6.5150e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8408e-04 - val_loss: 6.5090e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8388e-04 - val_loss: 6.5024e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8368e-04 - val_loss: 6.4966e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8349e-04 - val_loss: 6.4904e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8329e-04 - val_loss: 6.4843e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8309e-04 - val_loss: 6.4784e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8289e-04 - val_loss: 6.4718e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8269e-04 - val_loss: 6.4661e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8249e-04 - val_loss: 6.4598e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8229e-04 - val_loss: 6.4539e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.8209e-04 - val_loss: 6.4480e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8190e-04 - val_loss: 6.4420e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8170e-04 - val_loss: 6.4358e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8150e-04 - val_loss: 6.4298e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8131e-04 - val_loss: 6.4237e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8111e-04 - val_loss: 6.4177e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8092e-04 - val_loss: 6.4117e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8072e-04 - val_loss: 6.4062e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.8053e-04 - val_loss: 6.4004e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8034e-04 - val_loss: 6.3948e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8014e-04 - val_loss: 6.3887e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7995e-04 - val_loss: 6.3829e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7975e-04 - val_loss: 6.3765e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7956e-04 - val_loss: 6.3707e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7937e-04 - val_loss: 6.3647e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7917e-04 - val_loss: 6.3590e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7898e-04 - val_loss: 6.3530e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7879e-04 - val_loss: 6.3475e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7859e-04 - val_loss: 6.3409e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7840e-04 - val_loss: 6.3355e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7821e-04 - val_loss: 6.3296e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7802e-04 - val_loss: 6.3237e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7783e-04 - val_loss: 6.3174e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7763e-04 - val_loss: 6.3115e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7745e-04 - val_loss: 6.3058e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7726e-04 - val_loss: 6.3003e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7707e-04 - val_loss: 6.2942e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7688e-04 - val_loss: 6.2880e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7669e-04 - val_loss: 6.2827e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7650e-04 - val_loss: 6.2772e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.7631e-04 - val_loss: 6.2714e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7612e-04 - val_loss: 6.2654e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7593e-04 - val_loss: 6.2599e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7575e-04 - val_loss: 6.2544e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7556e-04 - val_loss: 6.2480e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7537e-04 - val_loss: 6.2426e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7518e-04 - val_loss: 6.2367e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7500e-04 - val_loss: 6.2305e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7481e-04 - val_loss: 6.2250e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7462e-04 - val_loss: 6.2192e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7444e-04 - val_loss: 6.2134e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7425e-04 - val_loss: 6.2079e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7406e-04 - val_loss: 6.2021e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7388e-04 - val_loss: 6.1965e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7370e-04 - val_loss: 6.1903e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7350e-04 - val_loss: 6.1851e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7333e-04 - val_loss: 6.1794e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7314e-04 - val_loss: 6.1738e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7296e-04 - val_loss: 6.1679e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7277e-04 - val_loss: 6.1626e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7259e-04 - val_loss: 6.1567e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7240e-04 - val_loss: 6.1512e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7222e-04 - val_loss: 6.1456e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7204e-04 - val_loss: 6.1400e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7186e-04 - val_loss: 6.1341e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7167e-04 - val_loss: 6.1283e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7149e-04 - val_loss: 6.1222e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7131e-04 - val_loss: 6.1173e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 1.7113e-04 - val_loss: 6.1115e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7095e-04 - val_loss: 6.1059e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7077e-04 - val_loss: 6.1001e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7059e-04 - val_loss: 6.0948e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7040e-04 - val_loss: 6.0889e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7022e-04 - val_loss: 6.0841e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7004e-04 - val_loss: 6.0781e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6987e-04 - val_loss: 6.0729e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6969e-04 - val_loss: 6.0669e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6951e-04 - val_loss: 6.0616e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6933e-04 - val_loss: 6.0558e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6915e-04 - val_loss: 6.0504e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6897e-04 - val_loss: 6.0448e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6879e-04 - val_loss: 6.0392e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6861e-04 - val_loss: 6.0336e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.6843e-04 - val_loss: 6.0282e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6826e-04 - val_loss: 6.0229e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6808e-04 - val_loss: 6.0172e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6790e-04 - val_loss: 6.0118e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6772e-04 - val_loss: 6.0060e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6755e-04 - val_loss: 6.0004e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6737e-04 - val_loss: 5.9951e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6720e-04 - val_loss: 5.9892e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6702e-04 - val_loss: 5.9838e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6684e-04 - val_loss: 5.9788e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6667e-04 - val_loss: 5.9730e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6650e-04 - val_loss: 5.9677e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6632e-04 - val_loss: 5.9620e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6615e-04 - val_loss: 5.9564e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6597e-04 - val_loss: 5.9513e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6580e-04 - val_loss: 5.9461e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6562e-04 - val_loss: 5.9406e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6545e-04 - val_loss: 5.9355e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6528e-04 - val_loss: 5.9300e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6510e-04 - val_loss: 5.9245e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6493e-04 - val_loss: 5.9192e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6476e-04 - val_loss: 5.9138e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6458e-04 - val_loss: 5.9085e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6441e-04 - val_loss: 5.9029e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6424e-04 - val_loss: 5.8978e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6407e-04 - val_loss: 5.8922e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6390e-04 - val_loss: 5.8869e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6372e-04 - val_loss: 5.8817e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6355e-04 - val_loss: 5.8762e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6338e-04 - val_loss: 5.8709e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6321e-04 - val_loss: 5.8657e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6304e-04 - val_loss: 5.8605e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6287e-04 - val_loss: 5.8546e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6270e-04 - val_loss: 5.8493e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6253e-04 - val_loss: 5.8439e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6236e-04 - val_loss: 5.8386e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6220e-04 - val_loss: 5.8335e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6202e-04 - val_loss: 5.8281e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6186e-04 - val_loss: 5.8230e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6169e-04 - val_loss: 5.8173e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6152e-04 - val_loss: 5.8120e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6135e-04 - val_loss: 5.8067e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6118e-04 - val_loss: 5.8018e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6101e-04 - val_loss: 5.7967e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6085e-04 - val_loss: 5.7911e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6068e-04 - val_loss: 5.7863e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6051e-04 - val_loss: 5.7809e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6034e-04 - val_loss: 5.7754e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6018e-04 - val_loss: 5.7701e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6001e-04 - val_loss: 5.7648e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5984e-04 - val_loss: 5.7598e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5968e-04 - val_loss: 5.7547e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5951e-04 - val_loss: 5.7497e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5935e-04 - val_loss: 5.7442e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5918e-04 - val_loss: 5.7388e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5901e-04 - val_loss: 5.7336e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5885e-04 - val_loss: 5.7283e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5869e-04 - val_loss: 5.7232e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5852e-04 - val_loss: 5.7148e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5835e-04 - val_loss: 5.7033e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5817e-04 - val_loss: 5.6906e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5799e-04 - val_loss: 5.6777e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5780e-04 - val_loss: 5.6643e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5762e-04 - val_loss: 5.6509e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5743e-04 - val_loss: 5.6370e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5724e-04 - val_loss: 5.6231e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5705e-04 - val_loss: 5.6091e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.5686e-04 - val_loss: 5.5950e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5667e-04 - val_loss: 5.5809e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5648e-04 - val_loss: 5.5665e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5629e-04 - val_loss: 5.5517e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5609e-04 - val_loss: 5.5372e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5590e-04 - val_loss: 5.5228e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5571e-04 - val_loss: 5.5084e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5552e-04 - val_loss: 5.4936e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5532e-04 - val_loss: 5.4789e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5513e-04 - val_loss: 5.4649e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5494e-04 - val_loss: 5.4500e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5474e-04 - val_loss: 5.4354e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5454e-04 - val_loss: 5.4207e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5435e-04 - val_loss: 5.4068e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5416e-04 - val_loss: 5.3923e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5396e-04 - val_loss: 5.3777e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5377e-04 - val_loss: 5.3635e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5358e-04 - val_loss: 5.3493e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5339e-04 - val_loss: 5.3347e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5319e-04 - val_loss: 5.3208e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5300e-04 - val_loss: 5.3068e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5281e-04 - val_loss: 5.2928e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5262e-04 - val_loss: 5.2781e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5243e-04 - val_loss: 5.2642e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5224e-04 - val_loss: 5.2501e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5205e-04 - val_loss: 5.2364e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5186e-04 - val_loss: 5.2222e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5167e-04 - val_loss: 5.2086e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.5148e-04 - val_loss: 5.1943e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5129e-04 - val_loss: 5.1806e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5110e-04 - val_loss: 5.1667e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5091e-04 - val_loss: 5.1532e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5072e-04 - val_loss: 5.1397e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5054e-04 - val_loss: 5.1263e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5035e-04 - val_loss: 5.1129e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5017e-04 - val_loss: 5.0991e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4998e-04 - val_loss: 5.0859e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4979e-04 - val_loss: 5.0724e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4961e-04 - val_loss: 5.0588e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4942e-04 - val_loss: 5.0457e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4924e-04 - val_loss: 5.0329e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4906e-04 - val_loss: 5.0197e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4887e-04 - val_loss: 5.0066e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4869e-04 - val_loss: 4.9937e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4850e-04 - val_loss: 4.9806e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4832e-04 - val_loss: 4.9677e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 1.4814e-04 - val_loss: 4.9555e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4796e-04 - val_loss: 4.9425e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4778e-04 - val_loss: 4.9299e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4760e-04 - val_loss: 4.9174e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4742e-04 - val_loss: 4.9050e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4724e-04 - val_loss: 4.8926e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4706e-04 - val_loss: 4.8804e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4688e-04 - val_loss: 4.8682e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4670e-04 - val_loss: 4.8561e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4653e-04 - val_loss: 4.8440e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4634e-04 - val_loss: 4.8319e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4617e-04 - val_loss: 4.8198e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4599e-04 - val_loss: 4.8075e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4581e-04 - val_loss: 4.7956e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4564e-04 - val_loss: 4.7840e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4546e-04 - val_loss: 4.7724e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4528e-04 - val_loss: 4.7607e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4511e-04 - val_loss: 4.7489e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4493e-04 - val_loss: 4.7374e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4476e-04 - val_loss: 4.7256e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4458e-04 - val_loss: 4.7141e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4441e-04 - val_loss: 4.7025e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4424e-04 - val_loss: 4.6911e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4406e-04 - val_loss: 4.6797e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4389e-04 - val_loss: 4.6678e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4372e-04 - val_loss: 4.6565e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4355e-04 - val_loss: 4.6454e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4338e-04 - val_loss: 4.6342e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4320e-04 - val_loss: 4.6229e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4304e-04 - val_loss: 4.6120e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4286e-04 - val_loss: 4.6010e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4269e-04 - val_loss: 4.5900e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4252e-04 - val_loss: 4.5792e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4235e-04 - val_loss: 4.5677e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4218e-04 - val_loss: 4.5573e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4201e-04 - val_loss: 4.5465e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 1.4185e-04 - val_loss: 4.5360e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4168e-04 - val_loss: 4.5253e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4151e-04 - val_loss: 4.5147e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4134e-04 - val_loss: 4.5044e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4118e-04 - val_loss: 4.4936e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4101e-04 - val_loss: 4.4834e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4084e-04 - val_loss: 4.4730e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4068e-04 - val_loss: 4.4627e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4051e-04 - val_loss: 4.4525e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4034e-04 - val_loss: 4.4423e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4018e-04 - val_loss: 4.4314e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4001e-04 - val_loss: 4.4214e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3985e-04 - val_loss: 4.4111e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3969e-04 - val_loss: 4.4014e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3952e-04 - val_loss: 4.3910e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3936e-04 - val_loss: 4.3807e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3920e-04 - val_loss: 4.3704e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3903e-04 - val_loss: 4.3606e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3887e-04 - val_loss: 4.3502e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3871e-04 - val_loss: 4.3403e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3855e-04 - val_loss: 4.3307e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3838e-04 - val_loss: 4.3208e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3822e-04 - val_loss: 4.3110e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3806e-04 - val_loss: 4.3010e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3790e-04 - val_loss: 4.2915e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3774e-04 - val_loss: 4.2818e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3758e-04 - val_loss: 4.2720e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3742e-04 - val_loss: 4.2624e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3726e-04 - val_loss: 4.2527e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3710e-04 - val_loss: 4.2437e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3694e-04 - val_loss: 4.2343e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3679e-04 - val_loss: 4.2248e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3663e-04 - val_loss: 4.2155e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3647e-04 - val_loss: 4.2064e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3631e-04 - val_loss: 4.1967e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3615e-04 - val_loss: 4.1880e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3600e-04 - val_loss: 4.1789e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3584e-04 - val_loss: 4.1698e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3569e-04 - val_loss: 4.1610e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3555e-04 - val_loss: 4.1521e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3539e-04 - val_loss: 4.1432e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3524e-04 - val_loss: 4.1349e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3510e-04 - val_loss: 4.1262e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3494e-04 - val_loss: 4.1180e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3480e-04 - val_loss: 4.1095e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3465e-04 - val_loss: 4.1007e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3450e-04 - val_loss: 4.0925e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3435e-04 - val_loss: 4.0844e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3421e-04 - val_loss: 4.0761e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3406e-04 - val_loss: 4.0681e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3391e-04 - val_loss: 4.0599e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3376e-04 - val_loss: 4.0520e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3362e-04 - val_loss: 4.0441e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3347e-04 - val_loss: 4.0363e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3333e-04 - val_loss: 4.0284e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3318e-04 - val_loss: 4.0205e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3303e-04 - val_loss: 4.0126e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3289e-04 - val_loss: 4.0052e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3275e-04 - val_loss: 3.9972e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.3260e-04 - val_loss: 3.9901e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3246e-04 - val_loss: 3.9824e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3231e-04 - val_loss: 3.9747e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3217e-04 - val_loss: 3.9673e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3203e-04 - val_loss: 3.9600e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3189e-04 - val_loss: 3.9521e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3175e-04 - val_loss: 3.9449e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3161e-04 - val_loss: 3.9372e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3146e-04 - val_loss: 3.9298e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3132e-04 - val_loss: 3.9222e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3118e-04 - val_loss: 3.9150e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3104e-04 - val_loss: 3.9074e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3090e-04 - val_loss: 3.9002e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3075e-04 - val_loss: 3.8930e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3062e-04 - val_loss: 3.8861e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3047e-04 - val_loss: 3.8784e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3033e-04 - val_loss: 3.8711e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3019e-04 - val_loss: 3.8639e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3005e-04 - val_loss: 3.8567e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2991e-04 - val_loss: 3.8495e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2977e-04 - val_loss: 3.8428e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2963e-04 - val_loss: 3.8353e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2949e-04 - val_loss: 3.8283e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2936e-04 - val_loss: 3.8210e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2922e-04 - val_loss: 3.8137e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2908e-04 - val_loss: 3.8068e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2894e-04 - val_loss: 3.7995e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2880e-04 - val_loss: 3.7927e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2867e-04 - val_loss: 3.7855e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2853e-04 - val_loss: 3.7784e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2839e-04 - val_loss: 3.7715e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2825e-04 - val_loss: 3.7644e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2812e-04 - val_loss: 3.7570e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2798e-04 - val_loss: 3.7506e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2784e-04 - val_loss: 3.7433e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2770e-04 - val_loss: 3.7362e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2754e-04 - val_loss: 3.7284e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2738e-04 - val_loss: 3.7202e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2721e-04 - val_loss: 3.7123e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2704e-04 - val_loss: 3.7037e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2687e-04 - val_loss: 3.6957e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2670e-04 - val_loss: 3.6871e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2653e-04 - val_loss: 3.6789e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2635e-04 - val_loss: 3.6703e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2617e-04 - val_loss: 3.6618e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2599e-04 - val_loss: 3.6529e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2581e-04 - val_loss: 3.6446e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2563e-04 - val_loss: 3.6362e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2545e-04 - val_loss: 3.6278e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2527e-04 - val_loss: 3.6195e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2509e-04 - val_loss: 3.6114e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.2491e-04 - val_loss: 3.6034e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2473e-04 - val_loss: 3.5955e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2455e-04 - val_loss: 3.5875e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2436e-04 - val_loss: 3.5795e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2418e-04 - val_loss: 3.5716e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2400e-04 - val_loss: 3.5637e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2382e-04 - val_loss: 3.5563e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2364e-04 - val_loss: 3.5488e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2346e-04 - val_loss: 3.5411e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2328e-04 - val_loss: 3.5331e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2310e-04 - val_loss: 3.5257e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2292e-04 - val_loss: 3.5182e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2274e-04 - val_loss: 3.5106e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2256e-04 - val_loss: 3.5029e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2238e-04 - val_loss: 3.4953e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2220e-04 - val_loss: 3.4878e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2203e-04 - val_loss: 3.4805e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2185e-04 - val_loss: 3.4730e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2168e-04 - val_loss: 3.4653e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2150e-04 - val_loss: 3.4577e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2133e-04 - val_loss: 3.4501e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2115e-04 - val_loss: 3.4424e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2097e-04 - val_loss: 3.4351e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2080e-04 - val_loss: 3.4276e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2063e-04 - val_loss: 3.4204e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2045e-04 - val_loss: 3.4129e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2028e-04 - val_loss: 3.4056e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2011e-04 - val_loss: 3.3983e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1994e-04 - val_loss: 3.3906e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1977e-04 - val_loss: 3.3833e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1960e-04 - val_loss: 3.3761e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1943e-04 - val_loss: 3.3692e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1926e-04 - val_loss: 3.3622e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1910e-04 - val_loss: 3.3549e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1892e-04 - val_loss: 3.3482e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1876e-04 - val_loss: 3.3412e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1859e-04 - val_loss: 3.3342e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1843e-04 - val_loss: 3.3273e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1826e-04 - val_loss: 3.3204e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1809e-04 - val_loss: 3.3136e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1793e-04 - val_loss: 3.3071e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1776e-04 - val_loss: 3.3003e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1760e-04 - val_loss: 3.2937e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1744e-04 - val_loss: 3.2874e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1727e-04 - val_loss: 3.2806e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1711e-04 - val_loss: 3.2743e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1695e-04 - val_loss: 3.2679e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1679e-04 - val_loss: 3.2617e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1663e-04 - val_loss: 3.2555e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1647e-04 - val_loss: 3.2489e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1631e-04 - val_loss: 3.2432e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1615e-04 - val_loss: 3.2367e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1599e-04 - val_loss: 3.2304e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1583e-04 - val_loss: 3.2245e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1567e-04 - val_loss: 3.2182e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1551e-04 - val_loss: 3.2120e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1536e-04 - val_loss: 3.2061e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1520e-04 - val_loss: 3.1996e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1504e-04 - val_loss: 3.1936e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1489e-04 - val_loss: 3.1875e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1473e-04 - val_loss: 3.1818e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1457e-04 - val_loss: 3.1756e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1442e-04 - val_loss: 3.1692e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1426e-04 - val_loss: 3.1633e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1411e-04 - val_loss: 3.1575e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1395e-04 - val_loss: 3.1516e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1380e-04 - val_loss: 3.1455e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1365e-04 - val_loss: 3.1398e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1350e-04 - val_loss: 3.1341e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1335e-04 - val_loss: 3.1285e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1319e-04 - val_loss: 3.1226e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1304e-04 - val_loss: 3.1168e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1289e-04 - val_loss: 3.1113e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1274e-04 - val_loss: 3.1058e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1259e-04 - val_loss: 3.0999e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1244e-04 - val_loss: 3.0941e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1229e-04 - val_loss: 3.0887e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1214e-04 - val_loss: 3.0832e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1199e-04 - val_loss: 3.0773e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1184e-04 - val_loss: 3.0720e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1170e-04 - val_loss: 3.0664e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1155e-04 - val_loss: 3.0606e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1140e-04 - val_loss: 3.0552e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1125e-04 - val_loss: 3.0494e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1110e-04 - val_loss: 3.0442e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1096e-04 - val_loss: 3.0388e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1081e-04 - val_loss: 3.0334e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1067e-04 - val_loss: 3.0279e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1052e-04 - val_loss: 3.0225e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1038e-04 - val_loss: 3.0173e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1023e-04 - val_loss: 3.0120e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1009e-04 - val_loss: 3.0068e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0995e-04 - val_loss: 3.0018e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0980e-04 - val_loss: 2.9964e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0966e-04 - val_loss: 2.9910e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0951e-04 - val_loss: 2.9858e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0937e-04 - val_loss: 2.9806e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0923e-04 - val_loss: 2.9755e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0909e-04 - val_loss: 2.9706e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0895e-04 - val_loss: 2.9655e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0881e-04 - val_loss: 2.9608e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0866e-04 - val_loss: 2.9555e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0852e-04 - val_loss: 2.9504e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0838e-04 - val_loss: 2.9457e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0824e-04 - val_loss: 2.9403e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0810e-04 - val_loss: 2.9354e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0796e-04 - val_loss: 2.9305e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0782e-04 - val_loss: 2.9256e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0768e-04 - val_loss: 2.9204e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0755e-04 - val_loss: 2.9156e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0740e-04 - val_loss: 2.9102e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0727e-04 - val_loss: 2.9053e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0713e-04 - val_loss: 2.9005e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.0699e-04 - val_loss: 2.8957e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0686e-04 - val_loss: 2.8905e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0672e-04 - val_loss: 2.8858e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0658e-04 - val_loss: 2.8808e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0644e-04 - val_loss: 2.8762e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0631e-04 - val_loss: 2.8712e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0617e-04 - val_loss: 2.8663e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0604e-04 - val_loss: 2.8618e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0590e-04 - val_loss: 2.8571e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0577e-04 - val_loss: 2.8523e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0563e-04 - val_loss: 2.8477e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0550e-04 - val_loss: 2.8430e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0536e-04 - val_loss: 2.8385e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0523e-04 - val_loss: 2.8337e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0510e-04 - val_loss: 2.8289e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0496e-04 - val_loss: 2.8241e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0483e-04 - val_loss: 2.8195e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0470e-04 - val_loss: 2.8151e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.0456e-04 - val_loss: 2.8104e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0443e-04 - val_loss: 2.8058e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0430e-04 - val_loss: 2.8012e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0417e-04 - val_loss: 2.7970e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0404e-04 - val_loss: 2.7922e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0390e-04 - val_loss: 2.7875e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0377e-04 - val_loss: 2.7832e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0365e-04 - val_loss: 2.7787e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0351e-04 - val_loss: 2.7743e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0339e-04 - val_loss: 2.7696e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0325e-04 - val_loss: 2.7648e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0312e-04 - val_loss: 2.7607e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0300e-04 - val_loss: 2.7561e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0287e-04 - val_loss: 2.7516e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.0274e-04 - val_loss: 2.7473e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0261e-04 - val_loss: 2.7425e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0248e-04 - val_loss: 2.7385e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0235e-04 - val_loss: 2.7339e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0222e-04 - val_loss: 2.7298e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0210e-04 - val_loss: 2.7253e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0197e-04 - val_loss: 2.7208e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0184e-04 - val_loss: 2.7164e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0171e-04 - val_loss: 2.7122e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0159e-04 - val_loss: 2.7077e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0146e-04 - val_loss: 2.7038e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0133e-04 - val_loss: 2.6995e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0121e-04 - val_loss: 2.6950e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0108e-04 - val_loss: 2.6907e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0095e-04 - val_loss: 2.6865e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0083e-04 - val_loss: 2.6822e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0070e-04 - val_loss: 2.6779e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0058e-04 - val_loss: 2.6737e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0045e-04 - val_loss: 2.6699e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0033e-04 - val_loss: 2.6658e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0021e-04 - val_loss: 2.6614e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0008e-04 - val_loss: 2.6570e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9956e-05 - val_loss: 2.6531e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9833e-05 - val_loss: 2.6489e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.9710e-05 - val_loss: 2.6448e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9587e-05 - val_loss: 2.6405e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9465e-05 - val_loss: 2.6363e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9340e-05 - val_loss: 2.6322e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9218e-05 - val_loss: 2.6280e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9096e-05 - val_loss: 2.6238e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8975e-05 - val_loss: 2.6198e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8854e-05 - val_loss: 2.6157e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8732e-05 - val_loss: 2.6113e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.8608e-05 - val_loss: 2.6074e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8488e-05 - val_loss: 2.6033e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8367e-05 - val_loss: 2.5994e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8246e-05 - val_loss: 2.5954e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8126e-05 - val_loss: 2.5912e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8008e-05 - val_loss: 2.5872e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7886e-05 - val_loss: 2.5832e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7768e-05 - val_loss: 2.5792e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7644e-05 - val_loss: 2.5753e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7527e-05 - val_loss: 2.5717e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7409e-05 - val_loss: 2.5674e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7290e-05 - val_loss: 2.5637e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7171e-05 - val_loss: 2.5596e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7053e-05 - val_loss: 2.5557e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6933e-05 - val_loss: 2.5516e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6815e-05 - val_loss: 2.5478e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6697e-05 - val_loss: 2.5439e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6581e-05 - val_loss: 2.5401e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6462e-05 - val_loss: 2.5363e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6344e-05 - val_loss: 2.5325e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6226e-05 - val_loss: 2.5286e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6108e-05 - val_loss: 2.5250e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5995e-05 - val_loss: 2.5212e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5876e-05 - val_loss: 2.5173e-05\n",
      "1.9709159460035153e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.4298675 ,  0.27644145, -1.0566635 ,  0.76622355,  1.2594548 ],\n",
       "        [ 1.5312579 ,  0.28291023,  0.56972045,  0.3950509 , -1.5730925 ],\n",
       "        [-1.1497428 , -0.0331588 ,  1.2893088 , -1.3861564 ,  1.4841046 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.91897225, -0.40965942,  0.9855153 ,  0.77317923,  0.929807  ],\n",
       "       dtype=float32),\n",
       " array([[ 1.5253696 , -0.9903142 ,  1.2872907 , -1.0487838 ,  1.1133215 ,\n",
       "         -0.09579836, -0.63780516, -0.45755273,  1.0521785 , -1.2494339 ],\n",
       "        [ 0.2478209 , -0.1601973 ,  0.6521437 , -0.43222526,  0.82868105,\n",
       "         -0.5875431 , -0.43301854, -0.2727186 ,  0.8543918 , -0.19751884],\n",
       "        [ 1.1773201 , -1.3230765 ,  1.5512339 , -1.25831   ,  0.8945974 ,\n",
       "         -1.2736075 , -0.51824325, -0.2846994 ,  0.49638823, -0.9217735 ],\n",
       "        [ 0.6837311 , -0.40257525,  1.1845977 , -0.964068  ,  1.3107548 ,\n",
       "         -1.3150781 , -1.2971549 , -0.4043555 ,  0.5077204 , -0.27377632],\n",
       "        [ 1.32261   , -1.044327  ,  1.5472919 , -0.53706264,  0.72398233,\n",
       "         -0.37616712, -1.0454702 , -0.64737326,  1.0589968 , -0.797986  ]],\n",
       "       dtype=float32),\n",
       " array([ 0.9618385 , -0.70275587,  0.94936454, -0.8138389 ,  1.0976657 ,\n",
       "        -0.57017064, -0.8333438 , -0.38549358,  1.0370754 , -0.8124668 ],\n",
       "       dtype=float32),\n",
       " array([[1.3251548 ],\n",
       "        [0.5841499 ],\n",
       "        [1.4901459 ],\n",
       "        [0.5995455 ],\n",
       "        [0.9420651 ],\n",
       "        [0.45684287],\n",
       "        [0.53402936],\n",
       "        [0.4332102 ],\n",
       "        [1.3530775 ],\n",
       "        [0.4256086 ]], dtype=float32),\n",
       " array([0.8556544], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_sigmoid(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sigmoid_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 28.9306 - val_loss: 23.7474\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 23.3094 - val_loss: 17.0626\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16.5003 - val_loss: 10.7583\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9941 - val_loss: 5.7432\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8841 - val_loss: 2.4486\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7563 - val_loss: 0.8070\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5527 - val_loss: 0.6163\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7995 - val_loss: 1.3045\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7161 - val_loss: 2.0745\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5159 - val_loss: 2.4408\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8110 - val_loss: 2.3261\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5974 - val_loss: 1.8678\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0458 - val_loss: 1.2594\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3627 - val_loss: 0.6758\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7267 - val_loss: 0.2435\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2618 - val_loss: 0.0274\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0286\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0302 - val_loss: 0.1920\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2003 - val_loss: 0.4284\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.4466 - val_loss: 0.6453\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.6723 - val_loss: 0.7757\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8077 - val_loss: 0.7919\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8244 - val_loss: 0.7034\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7326 - val_loss: 0.5444\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5682 - val_loss: 0.3596\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3770 - val_loss: 0.1909\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2022 - val_loss: 0.0688\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0750 - val_loss: 0.0078\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0478\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0458 - val_loss: 0.1111\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1082 - val_loss: 0.1727\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1694 - val_loss: 0.2147\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2112 - val_loss: 0.2278\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2241 - val_loss: 0.2115\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2079 - val_loss: 0.1728\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1693 - val_loss: 0.1227\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1194 - val_loss: 0.0727\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0701 - val_loss: 0.0327\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0081\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0073 - val_loss: 3.9392e-05\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1163e-04 - val_loss: 0.0058\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0200\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0226 - val_loss: 0.0364\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0398 - val_loss: 0.0497\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0536 - val_loss: 0.0562\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0604 - val_loss: 0.0550\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0591 - val_loss: 0.0471\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0509 - val_loss: 0.0351\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0383 - val_loss: 0.0220\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.0107\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0031\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 1.1294e-04\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5763e-04 - val_loss: 0.0012\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0099\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0091 - val_loss: 0.0144\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0172\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.5322e-04\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8057e-04 - val_loss: 2.2810e-05\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9706e-04 - val_loss: 4.7010e-04\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6468e-04 - val_loss: 0.0015\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 5.1754e-04\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6918e-04 - val_loss: 1.1023e-04\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3422e-04 - val_loss: 3.4090e-05\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4060e-04 - val_loss: 2.3571e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4095e-04 - val_loss: 6.0563e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2965e-04 - val_loss: 0.0010\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7874e-04 - val_loss: 0.0013\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.3425e-04\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4319e-04 - val_loss: 4.3384e-04\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9173e-04 - val_loss: 2.0505e-04\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1450e-04 - val_loss: 7.0504e-05\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3060e-04 - val_loss: 2.7478e-05\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3408e-04 - val_loss: 5.3714e-05\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0000e-04 - val_loss: 1.1676e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9389e-04 - val_loss: 1.8382e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8176e-04 - val_loss: 2.2976e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3805e-04 - val_loss: 2.4155e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5016e-04 - val_loss: 2.1898e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1894e-04 - val_loss: 1.7199e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5597e-04 - val_loss: 1.1608e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7865e-04 - val_loss: 6.7092e-05\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0491e-04 - val_loss: 3.7005e-05\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4875e-04 - val_loss: 3.1408e-05\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1760e-04 - val_loss: 4.9019e-05\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1173e-04 - val_loss: 8.2990e-05\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2547e-04 - val_loss: 1.2341e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4975e-04 - val_loss: 1.6012e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7481e-04 - val_loss: 1.8506e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9277e-04 - val_loss: 1.9389e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9906e-04 - val_loss: 1.8628e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9295e-04 - val_loss: 1.6536e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7697e-04 - val_loss: 1.3643e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5568e-04 - val_loss: 1.0541e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3416e-04 - val_loss: 7.7395e-05\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1668e-04 - val_loss: 5.5802e-05\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0581e-04 - val_loss: 4.1946e-05\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0212e-04 - val_loss: 3.5258e-05\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0438e-04 - val_loss: 3.3867e-05\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1023e-04 - val_loss: 3.5374e-05\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1693e-04 - val_loss: 3.7569e-05\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.2209e-04 - val_loss: 3.8938e-05\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2423e-04 - val_loss: 3.8871e-05\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2287e-04 - val_loss: 3.7627e-05\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1854e-04 - val_loss: 3.6019e-05\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1244e-04 - val_loss: 3.5038e-05\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0595e-04 - val_loss: 3.5519e-05\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0038e-04 - val_loss: 3.7876e-05\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9654e-04 - val_loss: 4.2006e-05\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9472e-04 - val_loss: 4.7332e-05\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9466e-04 - val_loss: 5.2999e-05\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9576e-04 - val_loss: 5.8077e-05\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9725e-04 - val_loss: 6.1779e-05\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9843e-04 - val_loss: 6.3640e-05\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9882e-04 - val_loss: 6.3513e-05\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9824e-04 - val_loss: 6.1629e-05\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.9679e-04 - val_loss: 5.8444e-05\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9478e-04 - val_loss: 5.4552e-05\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9259e-04 - val_loss: 5.0521e-05\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9060e-04 - val_loss: 4.6824e-05\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.8907e-04 - val_loss: 4.3741e-05\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8810e-04 - val_loss: 4.1405e-05\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.8765e-04 - val_loss: 3.9787e-05\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.8756e-04 - val_loss: 3.8771e-05\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8761e-04 - val_loss: 3.8208e-05\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.8761e-04 - val_loss: 3.7967e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8741e-04 - val_loss: 3.7963e-05\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8693e-04 - val_loss: 3.8158e-05\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8621e-04 - val_loss: 3.8555e-05\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8532e-04 - val_loss: 3.9166e-05\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8436e-04 - val_loss: 3.9997e-05\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8344e-04 - val_loss: 4.1016e-05\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8265e-04 - val_loss: 4.2174e-05\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8202e-04 - val_loss: 4.3372e-05\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8154e-04 - val_loss: 4.4499e-05\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8117e-04 - val_loss: 4.5446e-05\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8084e-04 - val_loss: 4.6126e-05\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8052e-04 - val_loss: 4.6490e-05\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8014e-04 - val_loss: 4.6516e-05\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7968e-04 - val_loss: 4.6246e-05\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7916e-04 - val_loss: 4.5726e-05\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7858e-04 - val_loss: 4.5029e-05\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7799e-04 - val_loss: 4.4251e-05\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7741e-04 - val_loss: 4.3455e-05\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7687e-04 - val_loss: 4.2708e-05\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7636e-04 - val_loss: 4.2043e-05\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7591e-04 - val_loss: 4.1500e-05\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7548e-04 - val_loss: 4.1080e-05\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7508e-04 - val_loss: 4.0784e-05\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 1.7468e-04 - val_loss: 4.0610e-05\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 1.7426e-04 - val_loss: 4.0539e-05\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7382e-04 - val_loss: 4.0568e-05\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7337e-04 - val_loss: 4.0684e-05\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7290e-04 - val_loss: 4.0865e-05\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7243e-04 - val_loss: 4.1102e-05\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7196e-04 - val_loss: 4.1368e-05\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7150e-04 - val_loss: 4.1649e-05\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7106e-04 - val_loss: 4.1914e-05\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7063e-04 - val_loss: 4.2150e-05\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7021e-04 - val_loss: 4.2332e-05\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6980e-04 - val_loss: 4.2451e-05\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6939e-04 - val_loss: 4.2491e-05\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6898e-04 - val_loss: 4.2461e-05\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6856e-04 - val_loss: 4.2365e-05\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6815e-04 - val_loss: 4.2210e-05\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6773e-04 - val_loss: 4.2016e-05\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6730e-04 - val_loss: 4.1794e-05\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6688e-04 - val_loss: 4.1563e-05\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6647e-04 - val_loss: 4.1331e-05\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6606e-04 - val_loss: 4.1116e-05\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6565e-04 - val_loss: 4.0927e-05\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6526e-04 - val_loss: 4.0762e-05\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6486e-04 - val_loss: 4.0633e-05\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6446e-04 - val_loss: 4.0537e-05\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6406e-04 - val_loss: 4.0472e-05\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6367e-04 - val_loss: 4.0436e-05\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6328e-04 - val_loss: 4.0426e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6288e-04 - val_loss: 4.0438e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6249e-04 - val_loss: 4.0463e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6210e-04 - val_loss: 4.0498e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6171e-04 - val_loss: 4.0529e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.6133e-04 - val_loss: 4.0558e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6094e-04 - val_loss: 4.0573e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6056e-04 - val_loss: 4.0576e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6018e-04 - val_loss: 4.0563e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5981e-04 - val_loss: 4.0528e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5943e-04 - val_loss: 4.0476e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5906e-04 - val_loss: 4.0408e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5868e-04 - val_loss: 4.0322e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5831e-04 - val_loss: 4.0231e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5794e-04 - val_loss: 4.0131e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5757e-04 - val_loss: 4.0025e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5720e-04 - val_loss: 3.9926e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.5684e-04 - val_loss: 3.9825e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5647e-04 - val_loss: 3.9735e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5611e-04 - val_loss: 3.9649e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 1.5575e-04 - val_loss: 3.9572e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5539e-04 - val_loss: 3.9507e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5503e-04 - val_loss: 3.9450e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5468e-04 - val_loss: 3.9403e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5433e-04 - val_loss: 3.9359e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5397e-04 - val_loss: 3.9320e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5363e-04 - val_loss: 3.9287e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.5327e-04 - val_loss: 3.9257e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5292e-04 - val_loss: 3.9223e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5257e-04 - val_loss: 3.9190e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5223e-04 - val_loss: 3.9154e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5188e-04 - val_loss: 3.9111e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5154e-04 - val_loss: 3.9067e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5120e-04 - val_loss: 3.9017e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5086e-04 - val_loss: 3.8964e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 1.5052e-04 - val_loss: 3.8905e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5018e-04 - val_loss: 3.8841e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4985e-04 - val_loss: 3.8775e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4951e-04 - val_loss: 3.8710e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4918e-04 - val_loss: 3.8643e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4885e-04 - val_loss: 3.8575e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4852e-04 - val_loss: 3.8512e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4819e-04 - val_loss: 3.8449e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4786e-04 - val_loss: 3.8387e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4753e-04 - val_loss: 3.8329e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4721e-04 - val_loss: 3.8272e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4688e-04 - val_loss: 3.8217e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4656e-04 - val_loss: 3.8168e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4624e-04 - val_loss: 3.8121e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4592e-04 - val_loss: 3.8073e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4560e-04 - val_loss: 3.8024e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4528e-04 - val_loss: 3.7980e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4497e-04 - val_loss: 3.7935e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4465e-04 - val_loss: 3.7885e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4434e-04 - val_loss: 3.7842e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4403e-04 - val_loss: 3.7791e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4371e-04 - val_loss: 3.7740e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4341e-04 - val_loss: 3.7689e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4309e-04 - val_loss: 3.7639e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4278e-04 - val_loss: 3.7585e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4248e-04 - val_loss: 3.7531e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4217e-04 - val_loss: 3.7478e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4187e-04 - val_loss: 3.7426e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4157e-04 - val_loss: 3.7373e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4127e-04 - val_loss: 3.7317e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4096e-04 - val_loss: 3.7266e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4067e-04 - val_loss: 3.7214e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4037e-04 - val_loss: 3.7161e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4007e-04 - val_loss: 3.7111e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3977e-04 - val_loss: 3.7062e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3948e-04 - val_loss: 3.7012e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3918e-04 - val_loss: 3.6961e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3889e-04 - val_loss: 3.6914e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3860e-04 - val_loss: 3.6869e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3831e-04 - val_loss: 3.6821e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3802e-04 - val_loss: 3.6774e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3773e-04 - val_loss: 3.6730e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3744e-04 - val_loss: 3.6682e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3715e-04 - val_loss: 3.6635e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3687e-04 - val_loss: 3.6588e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3659e-04 - val_loss: 3.6543e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3631e-04 - val_loss: 3.6497e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3602e-04 - val_loss: 3.6445e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3574e-04 - val_loss: 3.6402e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3546e-04 - val_loss: 3.6354e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3518e-04 - val_loss: 3.6308e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3491e-04 - val_loss: 3.6259e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.3463e-04 - val_loss: 3.6215e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3435e-04 - val_loss: 3.6167e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3407e-04 - val_loss: 3.6122e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3380e-04 - val_loss: 3.6076e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3353e-04 - val_loss: 3.6030e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3326e-04 - val_loss: 3.5984e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3299e-04 - val_loss: 3.5941e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3272e-04 - val_loss: 3.5895e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3245e-04 - val_loss: 3.5849e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3218e-04 - val_loss: 3.5809e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3191e-04 - val_loss: 3.5764e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3165e-04 - val_loss: 3.5721e-05\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.3138e-04 - val_loss: 3.5676e-05\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3112e-04 - val_loss: 3.5634e-05\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3086e-04 - val_loss: 3.5591e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3060e-04 - val_loss: 3.5548e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3033e-04 - val_loss: 3.5505e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3007e-04 - val_loss: 3.5464e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2982e-04 - val_loss: 3.5421e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2956e-04 - val_loss: 3.5379e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2930e-04 - val_loss: 3.5337e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2904e-04 - val_loss: 3.5296e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2878e-04 - val_loss: 3.5254e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2853e-04 - val_loss: 3.5213e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2828e-04 - val_loss: 3.5170e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2803e-04 - val_loss: 3.5129e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2777e-04 - val_loss: 3.5085e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2752e-04 - val_loss: 3.5044e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2727e-04 - val_loss: 3.5003e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2702e-04 - val_loss: 3.4965e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2677e-04 - val_loss: 3.4926e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2653e-04 - val_loss: 3.4881e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.2628e-04 - val_loss: 3.4843e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2603e-04 - val_loss: 3.4805e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 1.2579e-04 - val_loss: 3.4767e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2554e-04 - val_loss: 3.4725e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2530e-04 - val_loss: 3.4687e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2506e-04 - val_loss: 3.4648e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2482e-04 - val_loss: 3.4612e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2457e-04 - val_loss: 3.4572e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2434e-04 - val_loss: 3.4534e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2410e-04 - val_loss: 3.4493e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2386e-04 - val_loss: 3.4455e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2362e-04 - val_loss: 3.4417e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2338e-04 - val_loss: 3.4380e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2315e-04 - val_loss: 3.4345e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2292e-04 - val_loss: 3.4304e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2268e-04 - val_loss: 3.4267e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2245e-04 - val_loss: 3.4229e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2221e-04 - val_loss: 3.4192e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2198e-04 - val_loss: 3.4157e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2175e-04 - val_loss: 3.4120e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2152e-04 - val_loss: 3.4081e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2129e-04 - val_loss: 3.4046e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2106e-04 - val_loss: 3.4009e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2083e-04 - val_loss: 3.3973e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2060e-04 - val_loss: 3.3937e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2038e-04 - val_loss: 3.3902e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2015e-04 - val_loss: 3.3866e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1993e-04 - val_loss: 3.3832e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1971e-04 - val_loss: 3.3795e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1948e-04 - val_loss: 3.3761e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1926e-04 - val_loss: 3.3725e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1904e-04 - val_loss: 3.3691e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1882e-04 - val_loss: 3.3657e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1860e-04 - val_loss: 3.3622e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1837e-04 - val_loss: 3.3587e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1816e-04 - val_loss: 3.3555e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1794e-04 - val_loss: 3.3519e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1772e-04 - val_loss: 3.3487e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1750e-04 - val_loss: 3.3450e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1729e-04 - val_loss: 3.3418e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1707e-04 - val_loss: 3.3385e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1686e-04 - val_loss: 3.3354e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1664e-04 - val_loss: 3.3319e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1643e-04 - val_loss: 3.3287e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1622e-04 - val_loss: 3.3250e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1600e-04 - val_loss: 3.3220e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1579e-04 - val_loss: 3.3187e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1558e-04 - val_loss: 3.3156e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1537e-04 - val_loss: 3.3124e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1516e-04 - val_loss: 3.3093e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1495e-04 - val_loss: 3.3060e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1475e-04 - val_loss: 3.3027e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1454e-04 - val_loss: 3.2996e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1434e-04 - val_loss: 3.2964e-05\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1413e-04 - val_loss: 3.2934e-05\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1393e-04 - val_loss: 3.2904e-05\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1372e-04 - val_loss: 3.2869e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1352e-04 - val_loss: 3.2839e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1331e-04 - val_loss: 3.2809e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1311e-04 - val_loss: 3.2781e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1291e-04 - val_loss: 3.2746e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1271e-04 - val_loss: 3.2720e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1251e-04 - val_loss: 3.2688e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1231e-04 - val_loss: 3.2658e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1211e-04 - val_loss: 3.2629e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1191e-04 - val_loss: 3.2595e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1171e-04 - val_loss: 3.2568e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1151e-04 - val_loss: 3.2536e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1132e-04 - val_loss: 3.2510e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1112e-04 - val_loss: 3.2480e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1092e-04 - val_loss: 3.2451e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1073e-04 - val_loss: 3.2425e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1054e-04 - val_loss: 3.2393e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1034e-04 - val_loss: 3.2365e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1015e-04 - val_loss: 3.2336e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0996e-04 - val_loss: 3.2307e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0976e-04 - val_loss: 3.2279e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0958e-04 - val_loss: 3.2250e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0938e-04 - val_loss: 3.2222e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0919e-04 - val_loss: 3.2193e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0900e-04 - val_loss: 3.2167e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0882e-04 - val_loss: 3.2138e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0863e-04 - val_loss: 3.2109e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0844e-04 - val_loss: 3.2086e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0825e-04 - val_loss: 3.2055e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0806e-04 - val_loss: 3.2029e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0788e-04 - val_loss: 3.2002e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0769e-04 - val_loss: 3.1971e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0751e-04 - val_loss: 3.1948e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0733e-04 - val_loss: 3.1922e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0714e-04 - val_loss: 3.1894e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0696e-04 - val_loss: 3.1866e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.0678e-04 - val_loss: 3.1839e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0659e-04 - val_loss: 3.1814e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0641e-04 - val_loss: 3.1789e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.0623e-04 - val_loss: 3.1765e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0605e-04 - val_loss: 3.1736e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0587e-04 - val_loss: 3.1713e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0569e-04 - val_loss: 3.1685e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0552e-04 - val_loss: 3.1655e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0534e-04 - val_loss: 3.1632e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0516e-04 - val_loss: 3.1608e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0498e-04 - val_loss: 3.1585e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0481e-04 - val_loss: 3.1559e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0463e-04 - val_loss: 3.1532e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0445e-04 - val_loss: 3.1508e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0428e-04 - val_loss: 3.1482e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0411e-04 - val_loss: 3.1460e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0393e-04 - val_loss: 3.1432e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0376e-04 - val_loss: 3.1410e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0359e-04 - val_loss: 3.1385e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0341e-04 - val_loss: 3.1359e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0324e-04 - val_loss: 3.1337e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0307e-04 - val_loss: 3.1311e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0290e-04 - val_loss: 3.1289e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0273e-04 - val_loss: 3.1261e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0256e-04 - val_loss: 3.1238e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0239e-04 - val_loss: 3.1219e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0222e-04 - val_loss: 3.1192e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0205e-04 - val_loss: 3.1170e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0189e-04 - val_loss: 3.1146e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0172e-04 - val_loss: 3.1122e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0155e-04 - val_loss: 3.1100e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0139e-04 - val_loss: 3.1074e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0122e-04 - val_loss: 3.1054e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0105e-04 - val_loss: 3.1031e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0089e-04 - val_loss: 3.1008e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0073e-04 - val_loss: 3.0985e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0056e-04 - val_loss: 3.0962e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0040e-04 - val_loss: 3.0943e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0024e-04 - val_loss: 3.0921e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0007e-04 - val_loss: 3.0897e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9915e-05 - val_loss: 3.0877e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9754e-05 - val_loss: 3.0852e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9595e-05 - val_loss: 3.0831e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9434e-05 - val_loss: 3.0805e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.9273e-05 - val_loss: 3.0786e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.9111e-05 - val_loss: 3.0765e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8951e-05 - val_loss: 3.0744e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.8796e-05 - val_loss: 3.0722e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.8638e-05 - val_loss: 3.0699e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.8481e-05 - val_loss: 3.0680e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8324e-05 - val_loss: 3.0655e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8166e-05 - val_loss: 3.0634e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8010e-05 - val_loss: 3.0613e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7854e-05 - val_loss: 3.0594e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7700e-05 - val_loss: 3.0573e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7546e-05 - val_loss: 3.0553e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7392e-05 - val_loss: 3.0531e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7237e-05 - val_loss: 3.0509e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7084e-05 - val_loss: 3.0491e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6932e-05 - val_loss: 3.0470e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6778e-05 - val_loss: 3.0451e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6627e-05 - val_loss: 3.0432e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6472e-05 - val_loss: 3.0410e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6325e-05 - val_loss: 3.0391e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6171e-05 - val_loss: 3.0372e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6021e-05 - val_loss: 3.0354e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5872e-05 - val_loss: 3.0333e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.5724e-05 - val_loss: 3.0310e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5574e-05 - val_loss: 3.0290e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5423e-05 - val_loss: 3.0272e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5277e-05 - val_loss: 3.0252e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5128e-05 - val_loss: 3.0232e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4983e-05 - val_loss: 3.0212e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4834e-05 - val_loss: 3.0195e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4689e-05 - val_loss: 3.0176e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4542e-05 - val_loss: 3.0162e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.4397e-05 - val_loss: 3.0141e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4252e-05 - val_loss: 3.0119e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4105e-05 - val_loss: 3.0101e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3964e-05 - val_loss: 3.0083e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3817e-05 - val_loss: 3.0062e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3672e-05 - val_loss: 3.0046e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3531e-05 - val_loss: 3.0027e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3389e-05 - val_loss: 3.0010e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3247e-05 - val_loss: 2.9992e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.3106e-05 - val_loss: 2.9972e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2962e-05 - val_loss: 2.9956e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2820e-05 - val_loss: 2.9939e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2682e-05 - val_loss: 2.9919e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2540e-05 - val_loss: 2.9903e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2403e-05 - val_loss: 2.9884e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2263e-05 - val_loss: 2.9867e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2121e-05 - val_loss: 2.9848e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1981e-05 - val_loss: 2.9831e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1844e-05 - val_loss: 2.9813e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1706e-05 - val_loss: 2.9795e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1568e-05 - val_loss: 2.9778e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1431e-05 - val_loss: 2.9762e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1293e-05 - val_loss: 2.9743e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1159e-05 - val_loss: 2.9725e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1020e-05 - val_loss: 2.9712e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0886e-05 - val_loss: 2.9692e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0752e-05 - val_loss: 2.9675e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0617e-05 - val_loss: 2.9659e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0480e-05 - val_loss: 2.9644e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0346e-05 - val_loss: 2.9625e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0210e-05 - val_loss: 2.9609e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0081e-05 - val_loss: 2.9592e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9947e-05 - val_loss: 2.9578e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9812e-05 - val_loss: 2.9562e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9682e-05 - val_loss: 2.9545e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9551e-05 - val_loss: 2.9530e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9417e-05 - val_loss: 2.9515e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9286e-05 - val_loss: 2.9496e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9156e-05 - val_loss: 2.9481e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9025e-05 - val_loss: 2.9464e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8894e-05 - val_loss: 2.9450e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8766e-05 - val_loss: 2.9433e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8635e-05 - val_loss: 2.9418e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 8.8509e-05 - val_loss: 2.9403e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8380e-05 - val_loss: 2.9386e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8248e-05 - val_loss: 2.9369e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8119e-05 - val_loss: 2.9356e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7995e-05 - val_loss: 2.9340e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7865e-05 - val_loss: 2.9325e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7740e-05 - val_loss: 2.9312e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7612e-05 - val_loss: 2.9296e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7487e-05 - val_loss: 2.9280e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7358e-05 - val_loss: 2.9266e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7234e-05 - val_loss: 2.9251e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7109e-05 - val_loss: 2.9238e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.6986e-05 - val_loss: 2.9222e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6860e-05 - val_loss: 2.9207e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6734e-05 - val_loss: 2.9193e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6611e-05 - val_loss: 2.9178e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6487e-05 - val_loss: 2.9163e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 8.6364e-05 - val_loss: 2.9148e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6239e-05 - val_loss: 2.9134e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6119e-05 - val_loss: 2.9118e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5997e-05 - val_loss: 2.9107e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5874e-05 - val_loss: 2.9092e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5754e-05 - val_loss: 2.9077e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5631e-05 - val_loss: 2.9061e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5511e-05 - val_loss: 2.9049e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5389e-05 - val_loss: 2.9034e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5270e-05 - val_loss: 2.9020e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.5150e-05 - val_loss: 2.9009e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5028e-05 - val_loss: 2.8995e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4912e-05 - val_loss: 2.8982e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4791e-05 - val_loss: 2.8968e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4672e-05 - val_loss: 2.8951e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4556e-05 - val_loss: 2.8942e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4438e-05 - val_loss: 2.8928e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 8.4317e-05 - val_loss: 2.8913e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4202e-05 - val_loss: 2.8899e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4085e-05 - val_loss: 2.8887e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3966e-05 - val_loss: 2.8875e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3851e-05 - val_loss: 2.8859e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3734e-05 - val_loss: 2.8846e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3617e-05 - val_loss: 2.8837e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3503e-05 - val_loss: 2.8822e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3387e-05 - val_loss: 2.8808e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3272e-05 - val_loss: 2.8796e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3159e-05 - val_loss: 2.8781e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3041e-05 - val_loss: 2.8770e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2929e-05 - val_loss: 2.8758e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2814e-05 - val_loss: 2.8744e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2699e-05 - val_loss: 2.8731e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2588e-05 - val_loss: 2.8720e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 204us/step - loss: 8.2475e-05 - val_loss: 2.8705e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2363e-05 - val_loss: 2.8696e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2251e-05 - val_loss: 2.8684e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2137e-05 - val_loss: 2.8671e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2027e-05 - val_loss: 2.8658e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1917e-05 - val_loss: 2.8645e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1802e-05 - val_loss: 2.8633e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1692e-05 - val_loss: 2.8622e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.1583e-05 - val_loss: 2.8613e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1474e-05 - val_loss: 2.8598e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1363e-05 - val_loss: 2.8586e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1255e-05 - val_loss: 2.8574e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1141e-05 - val_loss: 2.8565e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1034e-05 - val_loss: 2.8550e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0926e-05 - val_loss: 2.8541e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0818e-05 - val_loss: 2.8527e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0711e-05 - val_loss: 2.8518e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0601e-05 - val_loss: 2.8505e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0494e-05 - val_loss: 2.8496e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0386e-05 - val_loss: 2.8482e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0278e-05 - val_loss: 2.8473e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0172e-05 - val_loss: 2.8459e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0066e-05 - val_loss: 2.8450e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9959e-05 - val_loss: 2.8437e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9852e-05 - val_loss: 2.8428e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9749e-05 - val_loss: 2.8414e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9642e-05 - val_loss: 2.8403e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9537e-05 - val_loss: 2.8391e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9432e-05 - val_loss: 2.8386e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9326e-05 - val_loss: 2.8372e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9223e-05 - val_loss: 2.8361e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9115e-05 - val_loss: 2.8350e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9014e-05 - val_loss: 2.8341e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8913e-05 - val_loss: 2.8328e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8808e-05 - val_loss: 2.8319e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8704e-05 - val_loss: 2.8307e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8601e-05 - val_loss: 2.8299e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8499e-05 - val_loss: 2.8283e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8395e-05 - val_loss: 2.8278e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8294e-05 - val_loss: 2.8265e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8193e-05 - val_loss: 2.8256e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8091e-05 - val_loss: 2.8243e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7989e-05 - val_loss: 2.8236e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7886e-05 - val_loss: 2.8223e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7789e-05 - val_loss: 2.8215e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7689e-05 - val_loss: 2.8201e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7586e-05 - val_loss: 2.8197e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7488e-05 - val_loss: 2.8186e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7389e-05 - val_loss: 2.8175e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.7287e-05 - val_loss: 2.8165e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.7191e-05 - val_loss: 2.8157e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7091e-05 - val_loss: 2.8149e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6992e-05 - val_loss: 2.8136e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.6892e-05 - val_loss: 2.8125e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6796e-05 - val_loss: 2.8118e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6697e-05 - val_loss: 2.8108e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.6599e-05 - val_loss: 2.8097e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6501e-05 - val_loss: 2.8090e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6404e-05 - val_loss: 2.8077e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6306e-05 - val_loss: 2.8067e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6211e-05 - val_loss: 2.8058e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6111e-05 - val_loss: 2.8050e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6017e-05 - val_loss: 2.8044e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5922e-05 - val_loss: 2.8032e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5825e-05 - val_loss: 2.8023e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5730e-05 - val_loss: 2.8014e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5634e-05 - val_loss: 2.8004e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5543e-05 - val_loss: 2.7996e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5449e-05 - val_loss: 2.7989e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5351e-05 - val_loss: 2.7977e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5257e-05 - val_loss: 2.7968e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5163e-05 - val_loss: 2.7961e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5070e-05 - val_loss: 2.7952e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4975e-05 - val_loss: 2.7942e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4882e-05 - val_loss: 2.7932e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4790e-05 - val_loss: 2.7923e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4695e-05 - val_loss: 2.7917e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4603e-05 - val_loss: 2.7908e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4511e-05 - val_loss: 2.7899e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4417e-05 - val_loss: 2.7890e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4327e-05 - val_loss: 2.7882e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4234e-05 - val_loss: 2.7874e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4141e-05 - val_loss: 2.7864e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4049e-05 - val_loss: 2.7857e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3958e-05 - val_loss: 2.7851e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.3869e-05 - val_loss: 2.7839e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3777e-05 - val_loss: 2.7830e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3689e-05 - val_loss: 2.7826e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.3596e-05 - val_loss: 2.7815e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3511e-05 - val_loss: 2.7808e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3418e-05 - val_loss: 2.7801e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3329e-05 - val_loss: 2.7790e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3241e-05 - val_loss: 2.7783e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3151e-05 - val_loss: 2.7774e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3063e-05 - val_loss: 2.7766e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2973e-05 - val_loss: 2.7759e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2883e-05 - val_loss: 2.7751e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2795e-05 - val_loss: 2.7744e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2708e-05 - val_loss: 2.7735e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2619e-05 - val_loss: 2.7729e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2533e-05 - val_loss: 2.7722e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2445e-05 - val_loss: 2.7712e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2358e-05 - val_loss: 2.7704e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2271e-05 - val_loss: 2.7699e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2183e-05 - val_loss: 2.7692e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2096e-05 - val_loss: 2.7682e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2013e-05 - val_loss: 2.7674e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.1924e-05 - val_loss: 2.7669e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1838e-05 - val_loss: 2.7661e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1752e-05 - val_loss: 2.7650e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1666e-05 - val_loss: 2.7645e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1583e-05 - val_loss: 2.7637e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.1497e-05 - val_loss: 2.7631e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1412e-05 - val_loss: 2.7623e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1329e-05 - val_loss: 2.7616e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1243e-05 - val_loss: 2.7612e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1160e-05 - val_loss: 2.7603e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1076e-05 - val_loss: 2.7597e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0990e-05 - val_loss: 2.7589e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0908e-05 - val_loss: 2.7582e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0825e-05 - val_loss: 2.7576e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0739e-05 - val_loss: 2.7568e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0658e-05 - val_loss: 2.7564e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0576e-05 - val_loss: 2.7554e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0493e-05 - val_loss: 2.7548e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0412e-05 - val_loss: 2.7543e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0327e-05 - val_loss: 2.7535e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0244e-05 - val_loss: 2.7527e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0162e-05 - val_loss: 2.7521e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0080e-05 - val_loss: 2.7514e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.0001e-05 - val_loss: 2.7509e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9916e-05 - val_loss: 2.7501e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9838e-05 - val_loss: 2.7494e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9757e-05 - val_loss: 2.7490e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9676e-05 - val_loss: 2.7486e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9596e-05 - val_loss: 2.7474e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9516e-05 - val_loss: 2.7468e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9435e-05 - val_loss: 2.7465e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9357e-05 - val_loss: 2.7455e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9276e-05 - val_loss: 2.7449e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9196e-05 - val_loss: 2.7445e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9117e-05 - val_loss: 2.7439e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.9040e-05 - val_loss: 2.7432e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8959e-05 - val_loss: 2.7427e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8881e-05 - val_loss: 2.7422e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8802e-05 - val_loss: 2.7415e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8724e-05 - val_loss: 2.7408e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8643e-05 - val_loss: 2.7401e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8565e-05 - val_loss: 2.7397e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8489e-05 - val_loss: 2.7390e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8411e-05 - val_loss: 2.7385e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8334e-05 - val_loss: 2.7378e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8257e-05 - val_loss: 2.7373e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8180e-05 - val_loss: 2.7368e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8101e-05 - val_loss: 2.7361e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8024e-05 - val_loss: 2.7357e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7950e-05 - val_loss: 2.7348e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7870e-05 - val_loss: 2.7344e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7796e-05 - val_loss: 2.7338e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7719e-05 - val_loss: 2.7334e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7645e-05 - val_loss: 2.7330e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7571e-05 - val_loss: 2.7322e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7492e-05 - val_loss: 2.7316e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7418e-05 - val_loss: 2.7311e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7341e-05 - val_loss: 2.7305e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7267e-05 - val_loss: 2.7300e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7191e-05 - val_loss: 2.7294e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7119e-05 - val_loss: 2.7286e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7044e-05 - val_loss: 2.7282e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6968e-05 - val_loss: 2.7280e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6895e-05 - val_loss: 2.7273e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.6819e-05 - val_loss: 2.7266e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6745e-05 - val_loss: 2.7263e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6672e-05 - val_loss: 2.7259e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6598e-05 - val_loss: 2.7252e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6526e-05 - val_loss: 2.7248e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6453e-05 - val_loss: 2.7245e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6381e-05 - val_loss: 2.7237e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6308e-05 - val_loss: 2.7231e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6234e-05 - val_loss: 2.7228e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 6.6163e-05 - val_loss: 2.7224e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.6089e-05 - val_loss: 2.7219e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6016e-05 - val_loss: 2.7212e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5946e-05 - val_loss: 2.7207e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5873e-05 - val_loss: 2.7203e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5803e-05 - val_loss: 2.7196e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5731e-05 - val_loss: 2.7189e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5660e-05 - val_loss: 2.7186e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5591e-05 - val_loss: 2.7182e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5518e-05 - val_loss: 2.7178e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5446e-05 - val_loss: 2.7175e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.5376e-05 - val_loss: 2.7168e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5305e-05 - val_loss: 2.7165e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5235e-05 - val_loss: 2.7160e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5163e-05 - val_loss: 2.7155e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5095e-05 - val_loss: 2.7154e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5026e-05 - val_loss: 2.7146e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4959e-05 - val_loss: 2.7141e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4886e-05 - val_loss: 2.7140e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4817e-05 - val_loss: 2.7134e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4747e-05 - val_loss: 2.7130e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4679e-05 - val_loss: 2.7122e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4608e-05 - val_loss: 2.7121e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4542e-05 - val_loss: 2.7119e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4472e-05 - val_loss: 2.7114e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.4405e-05 - val_loss: 2.7108e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4335e-05 - val_loss: 2.7105e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4266e-05 - val_loss: 2.7100e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 6.4198e-05 - val_loss: 2.7096e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4131e-05 - val_loss: 2.7090e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4062e-05 - val_loss: 2.7086e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3995e-05 - val_loss: 2.7081e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3927e-05 - val_loss: 2.7080e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3860e-05 - val_loss: 2.7076e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3794e-05 - val_loss: 2.7070e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3727e-05 - val_loss: 2.7068e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3660e-05 - val_loss: 2.7064e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3594e-05 - val_loss: 2.7060e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3525e-05 - val_loss: 2.7054e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3461e-05 - val_loss: 2.7048e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3392e-05 - val_loss: 2.7046e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3326e-05 - val_loss: 2.7046e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3261e-05 - val_loss: 2.7041e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3197e-05 - val_loss: 2.7037e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3130e-05 - val_loss: 2.7030e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3065e-05 - val_loss: 2.7027e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2999e-05 - val_loss: 2.7023e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2935e-05 - val_loss: 2.7021e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2867e-05 - val_loss: 2.7017e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2803e-05 - val_loss: 2.7014e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2740e-05 - val_loss: 2.7010e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2674e-05 - val_loss: 2.7007e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2611e-05 - val_loss: 2.7002e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2546e-05 - val_loss: 2.7001e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2484e-05 - val_loss: 2.6995e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2416e-05 - val_loss: 2.6992e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2353e-05 - val_loss: 2.6988e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2289e-05 - val_loss: 2.6985e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2225e-05 - val_loss: 2.6982e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2163e-05 - val_loss: 2.6979e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2098e-05 - val_loss: 2.6975e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2035e-05 - val_loss: 2.6972e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.1973e-05 - val_loss: 2.6967e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1909e-05 - val_loss: 2.6968e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1845e-05 - val_loss: 2.6964e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1783e-05 - val_loss: 2.6960e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1724e-05 - val_loss: 2.6956e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1661e-05 - val_loss: 2.6952e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1596e-05 - val_loss: 2.6949e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1535e-05 - val_loss: 2.6943e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1472e-05 - val_loss: 2.6944e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1412e-05 - val_loss: 2.6940e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1349e-05 - val_loss: 2.6938e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1288e-05 - val_loss: 2.6935e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1225e-05 - val_loss: 2.6933e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1166e-05 - val_loss: 2.6927e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1104e-05 - val_loss: 2.6924e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1043e-05 - val_loss: 2.6921e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 6.0980e-05 - val_loss: 2.6919e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0922e-05 - val_loss: 2.6913e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0859e-05 - val_loss: 2.6912e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0800e-05 - val_loss: 2.6910e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0740e-05 - val_loss: 2.6906e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0679e-05 - val_loss: 2.6903e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0617e-05 - val_loss: 2.6901e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0557e-05 - val_loss: 2.6898e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0499e-05 - val_loss: 2.6895e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0438e-05 - val_loss: 2.6894e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0379e-05 - val_loss: 2.6890e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0316e-05 - val_loss: 2.6890e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0260e-05 - val_loss: 2.6884e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0200e-05 - val_loss: 2.6882e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0142e-05 - val_loss: 2.6877e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0081e-05 - val_loss: 2.6878e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0023e-05 - val_loss: 2.6874e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9966e-05 - val_loss: 2.6872e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9906e-05 - val_loss: 2.6869e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9847e-05 - val_loss: 2.6866e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9789e-05 - val_loss: 2.6862e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9729e-05 - val_loss: 2.6862e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9671e-05 - val_loss: 2.6857e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9614e-05 - val_loss: 2.6856e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9556e-05 - val_loss: 2.6854e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9496e-05 - val_loss: 2.6851e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9441e-05 - val_loss: 2.6852e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9383e-05 - val_loss: 2.6847e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9326e-05 - val_loss: 2.6844e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9268e-05 - val_loss: 2.6843e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9211e-05 - val_loss: 2.6837e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9154e-05 - val_loss: 2.6837e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9097e-05 - val_loss: 2.6834e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9038e-05 - val_loss: 2.6834e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8983e-05 - val_loss: 2.6832e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8928e-05 - val_loss: 2.6829e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8870e-05 - val_loss: 2.6825e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8812e-05 - val_loss: 2.6823e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8757e-05 - val_loss: 2.6822e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8703e-05 - val_loss: 2.6821e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.8645e-05 - val_loss: 2.6817e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8587e-05 - val_loss: 2.6818e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8532e-05 - val_loss: 2.6814e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8478e-05 - val_loss: 2.6812e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8422e-05 - val_loss: 2.6810e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8365e-05 - val_loss: 2.6808e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8310e-05 - val_loss: 2.6809e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8256e-05 - val_loss: 2.6804e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8201e-05 - val_loss: 2.6801e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8145e-05 - val_loss: 2.6800e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.8088e-05 - val_loss: 2.6796e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8035e-05 - val_loss: 2.6795e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7981e-05 - val_loss: 2.6794e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7927e-05 - val_loss: 2.6792e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7872e-05 - val_loss: 2.6788e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7816e-05 - val_loss: 2.6787e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7763e-05 - val_loss: 2.6786e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7709e-05 - val_loss: 2.6784e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7654e-05 - val_loss: 2.6783e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7601e-05 - val_loss: 2.6782e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7548e-05 - val_loss: 2.6780e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7493e-05 - val_loss: 2.6776e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7439e-05 - val_loss: 2.6774e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7385e-05 - val_loss: 2.6775e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7334e-05 - val_loss: 2.6775e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7280e-05 - val_loss: 2.6770e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7227e-05 - val_loss: 2.6771e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7175e-05 - val_loss: 2.6765e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7120e-05 - val_loss: 2.6765e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7067e-05 - val_loss: 2.6764e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7014e-05 - val_loss: 2.6763e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6961e-05 - val_loss: 2.6761e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6909e-05 - val_loss: 2.6757e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6858e-05 - val_loss: 2.6759e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6805e-05 - val_loss: 2.6756e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6753e-05 - val_loss: 2.6754e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6701e-05 - val_loss: 2.6755e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6651e-05 - val_loss: 2.6752e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6597e-05 - val_loss: 2.6749e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6546e-05 - val_loss: 2.6751e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.6493e-05 - val_loss: 2.6745e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6442e-05 - val_loss: 2.6747e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6391e-05 - val_loss: 2.6745e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6338e-05 - val_loss: 2.6743e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6286e-05 - val_loss: 2.6744e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6237e-05 - val_loss: 2.6740e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6183e-05 - val_loss: 2.6740e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6134e-05 - val_loss: 2.6738e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6084e-05 - val_loss: 2.6737e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6031e-05 - val_loss: 2.6735e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5981e-05 - val_loss: 2.6735e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5930e-05 - val_loss: 2.6733e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5881e-05 - val_loss: 2.6732e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5830e-05 - val_loss: 2.6731e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5778e-05 - val_loss: 2.6728e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5729e-05 - val_loss: 2.6729e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5679e-05 - val_loss: 2.6727e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5628e-05 - val_loss: 2.6727e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5578e-05 - val_loss: 2.6724e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5529e-05 - val_loss: 2.6725e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5477e-05 - val_loss: 2.6725e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5429e-05 - val_loss: 2.6723e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5378e-05 - val_loss: 2.6721e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5329e-05 - val_loss: 2.6721e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5282e-05 - val_loss: 2.6720e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5231e-05 - val_loss: 2.6718e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.5182e-05 - val_loss: 2.6717e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5133e-05 - val_loss: 2.6715e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5083e-05 - val_loss: 2.6715e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5035e-05 - val_loss: 2.6712e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4985e-05 - val_loss: 2.6713e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4938e-05 - val_loss: 2.6712e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4890e-05 - val_loss: 2.6709e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4839e-05 - val_loss: 2.6711e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 5.4792e-05 - val_loss: 2.6708e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.4743e-05 - val_loss: 2.6712e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4695e-05 - val_loss: 2.6709e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4647e-05 - val_loss: 2.6709e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4600e-05 - val_loss: 2.6705e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4550e-05 - val_loss: 2.6706e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4505e-05 - val_loss: 2.6703e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4455e-05 - val_loss: 2.6705e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4407e-05 - val_loss: 2.6703e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4359e-05 - val_loss: 2.6705e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4314e-05 - val_loss: 2.6703e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4266e-05 - val_loss: 2.6701e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4217e-05 - val_loss: 2.6700e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4172e-05 - val_loss: 2.6702e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4125e-05 - val_loss: 2.6700e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4075e-05 - val_loss: 2.6700e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4028e-05 - val_loss: 2.6699e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3981e-05 - val_loss: 2.6698e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3936e-05 - val_loss: 2.6695e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3890e-05 - val_loss: 2.6698e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3842e-05 - val_loss: 2.6694e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3794e-05 - val_loss: 2.6697e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3751e-05 - val_loss: 2.6695e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3702e-05 - val_loss: 2.6694e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3656e-05 - val_loss: 2.6693e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3610e-05 - val_loss: 2.6693e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3566e-05 - val_loss: 2.6691e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3516e-05 - val_loss: 2.6693e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3473e-05 - val_loss: 2.6692e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3425e-05 - val_loss: 2.6694e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3378e-05 - val_loss: 2.6690e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3333e-05 - val_loss: 2.6693e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3288e-05 - val_loss: 2.6688e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3242e-05 - val_loss: 2.6689e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3196e-05 - val_loss: 2.6689e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3154e-05 - val_loss: 2.6690e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3105e-05 - val_loss: 2.6690e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3063e-05 - val_loss: 2.6690e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3016e-05 - val_loss: 2.6689e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2971e-05 - val_loss: 2.6686e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2926e-05 - val_loss: 2.6687e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2880e-05 - val_loss: 2.6689e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.2838e-05 - val_loss: 2.6687e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2792e-05 - val_loss: 2.6689e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2749e-05 - val_loss: 2.6686e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2701e-05 - val_loss: 2.6687e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2657e-05 - val_loss: 2.6687e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2614e-05 - val_loss: 2.6685e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2569e-05 - val_loss: 2.6685e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2525e-05 - val_loss: 2.6685e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2480e-05 - val_loss: 2.6685e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2436e-05 - val_loss: 2.6688e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2394e-05 - val_loss: 2.6686e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2348e-05 - val_loss: 2.6685e-05\n",
      "5.773789234808646e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.4418993 , -0.9924778 ,  1.4855046 , -0.43957102, -0.5873704 ],\n",
       "        [-0.45432314,  1.2622943 , -1.1151009 , -1.2847834 ,  1.2202035 ],\n",
       "        [ 0.62762415,  1.3228725 , -1.1606499 , -1.1440914 , -1.077212  ]],\n",
       "       dtype=float32),\n",
       " array([-0.05569606,  0.7148598 ,  0.6447647 ,  0.68643385,  0.7162877 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.0668627 , -0.5749267 ,  0.37502658,  0.49871224,  0.22313769,\n",
       "          0.19043618,  1.0259385 , -1.0016663 , -0.38766634,  0.66892064],\n",
       "        [ 0.97462857, -1.2066432 ,  0.29968235,  0.69233644,  1.2295597 ,\n",
       "          0.03709182,  0.5549572 , -1.3321874 , -0.12321477,  0.9630039 ],\n",
       "        [ 0.07031487, -0.5737888 ,  0.12287904,  1.2244643 ,  1.1991793 ,\n",
       "          0.8922235 ,  0.9619157 , -1.0768243 , -1.1684618 ,  0.39470005],\n",
       "        [ 1.1648592 , -1.0305548 ,  1.1416585 ,  0.02360647,  0.9867999 ,\n",
       "          1.0824572 ,  1.1180915 , -0.1762995 , -1.2231485 ,  0.43959427],\n",
       "        [ 0.9803563 , -1.2821087 ,  0.7161241 ,  1.3432412 ,  0.5715303 ,\n",
       "          0.17113972,  1.1225955 , -0.112302  ,  0.04671755,  1.3241861 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.6897019 , -0.65718174,  0.6746932 ,  0.6955936 ,  0.70203704,\n",
       "         0.6632917 ,  0.61442035, -0.66918236, -0.65354455,  0.6785558 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.8441122 ],\n",
       "        [-1.1460018 ],\n",
       "        [-0.18374425],\n",
       "        [ 0.8996802 ],\n",
       "        [ 0.72308296],\n",
       "        [-0.27777392],\n",
       "        [ 0.34846866],\n",
       "        [-0.96375847],\n",
       "        [-0.30251756],\n",
       "        [ 0.7290776 ]], dtype=float32),\n",
       " array([0.5126575], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_tanh(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_tanh_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
