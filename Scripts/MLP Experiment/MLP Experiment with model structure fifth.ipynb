{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_1(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_2(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_3(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_4(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_5(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_6(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 418us/step - loss: 15340.0154 - val_loss: 14898.4771\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13328.0442 - val_loss: 10958.5904\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7610.9040 - val_loss: 4140.2437\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 1937.6251 - val_loss: 474.5551\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 145.2830 - val_loss: 34.6837\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 30.5874 - val_loss: 27.6731\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.3466 - val_loss: 25.2280\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.8197 - val_loss: 24.8380\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3988 - val_loss: 24.7776\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2699 - val_loss: 25.0457\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4221 - val_loss: 25.3338\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2256 - val_loss: 25.0205\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1578 - val_loss: 25.5947\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2244 - val_loss: 25.1205\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2462 - val_loss: 25.2902\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0585 - val_loss: 25.0619\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9881 - val_loss: 25.0743\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1838 - val_loss: 25.2948\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0436 - val_loss: 25.0950\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1254 - val_loss: 25.1740\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1858 - val_loss: 25.7418\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1173 - val_loss: 25.1894\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0876 - val_loss: 25.3321\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3720 - val_loss: 26.1429\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3905 - val_loss: 25.3059\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0684 - val_loss: 25.2898\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2255 - val_loss: 25.2365\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1402 - val_loss: 25.8752\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1011 - val_loss: 25.5677\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9501 - val_loss: 25.5524\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0463 - val_loss: 25.1967\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2978 - val_loss: 25.2930\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9717 - val_loss: 25.2925\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0791 - val_loss: 25.6319\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2163 - val_loss: 25.4755\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0026 - val_loss: 25.2558\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2294 - val_loss: 25.2100\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9345 - val_loss: 25.3119\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2706 - val_loss: 25.1962\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1446 - val_loss: 25.8020\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3183 - val_loss: 25.9056\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3123 - val_loss: 25.2908\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2302 - val_loss: 25.0274\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1023 - val_loss: 25.2156\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0480 - val_loss: 25.2179\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.5103 - val_loss: 25.3565\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9428 - val_loss: 25.5142\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1548 - val_loss: 25.8628\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.7749 - val_loss: 26.6071\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3244 - val_loss: 26.1561\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8247 - val_loss: 25.6273\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9455 - val_loss: 25.7813\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0426 - val_loss: 25.8419\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9089 - val_loss: 25.7152\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7814 - val_loss: 25.3317\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3418 - val_loss: 26.3373\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2059 - val_loss: 25.8281\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1115 - val_loss: 26.7817\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0650 - val_loss: 26.9703\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2966 - val_loss: 26.1808\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7939 - val_loss: 26.0678\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0553 - val_loss: 26.1274\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0481 - val_loss: 25.6034\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8481 - val_loss: 25.9390\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1620 - val_loss: 26.7928\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9570 - val_loss: 25.3172\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2472 - val_loss: 25.4114\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8745 - val_loss: 25.5100\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2060 - val_loss: 26.4694\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5756 - val_loss: 26.3196\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1771 - val_loss: 26.2568\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.9521 - val_loss: 25.9692\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8533 - val_loss: 25.5797\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6015 - val_loss: 26.4048\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7177 - val_loss: 25.4431\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0750 - val_loss: 25.4638\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8317 - val_loss: 26.7142\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9718 - val_loss: 25.7543\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9417 - val_loss: 26.2319\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0826 - val_loss: 26.1748\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1598 - val_loss: 26.0262\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0005 - val_loss: 25.8647\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7634 - val_loss: 26.0827\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.8796 - val_loss: 25.5837\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7771 - val_loss: 26.0964\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8168 - val_loss: 25.7124\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9220 - val_loss: 26.5995\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3593 - val_loss: 25.9467\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9673 - val_loss: 25.5394\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4771 - val_loss: 26.4902\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.5583 - val_loss: 28.2140\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0522 - val_loss: 26.2398\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1792 - val_loss: 25.9883\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1208 - val_loss: 26.0296\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2681 - val_loss: 26.7423\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.7930 - val_loss: 25.8713\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1643 - val_loss: 25.3729\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5240 - val_loss: 26.6016\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0169 - val_loss: 26.7461\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.9475 - val_loss: 25.3284\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.7335 - val_loss: 25.8808\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3343 - val_loss: 25.4304\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2114 - val_loss: 25.6224\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3259 - val_loss: 25.6882\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2497 - val_loss: 26.0559\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.3954 - val_loss: 25.7550\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4703 - val_loss: 27.9938\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3654 - val_loss: 25.2507\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1948 - val_loss: 25.6087\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.5515 - val_loss: 25.2287\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9642 - val_loss: 26.1175\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7024 - val_loss: 26.0874\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8173 - val_loss: 26.3271\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2490 - val_loss: 25.5277\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1425 - val_loss: 26.7571\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2411 - val_loss: 26.1699\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 21.7824 - val_loss: 27.8606\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 23.0505 - val_loss: 25.7267\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0229 - val_loss: 26.5882\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1952 - val_loss: 25.5172\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.4630 - val_loss: 25.7352\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 23.3153 - val_loss: 26.3232\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0460 - val_loss: 25.8791\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.7067 - val_loss: 25.7512\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5320 - val_loss: 27.2664\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1774 - val_loss: 26.2261\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5910 - val_loss: 25.5255\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6427 - val_loss: 26.2381\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3977 - val_loss: 26.4848\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3984 - val_loss: 25.9614\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3288 - val_loss: 27.3083\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.4860 - val_loss: 26.4528\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9697 - val_loss: 26.6205\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8419 - val_loss: 25.4381\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1742 - val_loss: 26.7336\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4844 - val_loss: 28.1721\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6012 - val_loss: 26.2295\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.6303 - val_loss: 26.1554\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.7516 - val_loss: 25.7452\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.0295 - val_loss: 25.9537\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9681 - val_loss: 27.4006\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.7482 - val_loss: 25.7903\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9564 - val_loss: 25.6262\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1678 - val_loss: 26.7575\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1091 - val_loss: 27.0167\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8499 - val_loss: 25.4047\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3900 - val_loss: 25.5879\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7447 - val_loss: 25.8411\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1101 - val_loss: 26.4906\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.6540 - val_loss: 26.3708\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1265 - val_loss: 26.1856\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.0632 - val_loss: 25.4761\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.5273 - val_loss: 27.2261\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.0374 - val_loss: 26.1391\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9612 - val_loss: 28.3464\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.4324 - val_loss: 25.8579\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2252 - val_loss: 25.6979\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8870 - val_loss: 28.5094\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6746 - val_loss: 27.1166\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7047 - val_loss: 26.2259\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.7326 - val_loss: 26.0865\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6206 - val_loss: 27.5851\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0555 - val_loss: 25.4634\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3569 - val_loss: 26.9471\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9734 - val_loss: 26.4869\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9568 - val_loss: 26.8085\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0299 - val_loss: 26.6572\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1116 - val_loss: 25.7282\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8626 - val_loss: 26.4940\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1420 - val_loss: 25.4732\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1675 - val_loss: 25.8846\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4068 - val_loss: 25.5770\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1215 - val_loss: 26.8003\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5419 - val_loss: 25.3060\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0172 - val_loss: 28.1784\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.1792 - val_loss: 30.0549\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9981 - val_loss: 25.4623\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0575 - val_loss: 26.6897\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8816 - val_loss: 25.6880\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3765 - val_loss: 26.2436\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3351 - val_loss: 25.7257\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.1394 - val_loss: 25.6442\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2969 - val_loss: 25.8596\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0259 - val_loss: 25.4957\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9356 - val_loss: 25.3429\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9814 - val_loss: 24.9636\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.3845 - val_loss: 26.1590\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0470 - val_loss: 26.5910\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0403 - val_loss: 25.4193\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9035 - val_loss: 25.4092\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3605 - val_loss: 25.6999\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.7903 - val_loss: 26.6177\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.8525 - val_loss: 26.4435\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.9162 - val_loss: 24.5602\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.6439 - val_loss: 24.2078\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.3707 - val_loss: 26.3593\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.5366 - val_loss: 24.3989\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.5275 - val_loss: 25.5730\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5304 - val_loss: 25.4528\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.1722 - val_loss: 24.1580\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.3836 - val_loss: 23.9322\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.7555 - val_loss: 23.3283\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.1249 - val_loss: 23.8238\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.4812 - val_loss: 25.3708\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1664 - val_loss: 23.5365\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0091 - val_loss: 22.9329\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.5044 - val_loss: 24.5967\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7776 - val_loss: 24.6523\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6451 - val_loss: 23.0747\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8978 - val_loss: 22.5596\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6223 - val_loss: 21.9734\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0386 - val_loss: 22.4454\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0974 - val_loss: 21.1148\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4190 - val_loss: 21.5403\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9116 - val_loss: 20.6253\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8488 - val_loss: 20.9252\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6877 - val_loss: 20.5600\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0774 - val_loss: 21.3712\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2449 - val_loss: 20.3562\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2031 - val_loss: 20.6044\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3925 - val_loss: 22.3830\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3409 - val_loss: 19.7210\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.1068 - val_loss: 19.9370\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5047 - val_loss: 21.2851\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5730 - val_loss: 19.9859\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.7263 - val_loss: 22.2655\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1388 - val_loss: 19.0502\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.6393 - val_loss: 19.8765\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3339 - val_loss: 19.3257\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.6628 - val_loss: 19.6376\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.3484 - val_loss: 19.7227\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2867 - val_loss: 18.7658\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.3186 - val_loss: 18.7264\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.6257 - val_loss: 18.0331\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2132 - val_loss: 18.7282\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.9719 - val_loss: 18.1225\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.9214 - val_loss: 19.2548\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.0704 - val_loss: 21.1939\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5906 - val_loss: 20.5114\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.6650 - val_loss: 17.7822\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.1511 - val_loss: 18.8593\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.9102 - val_loss: 18.7676\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.4123 - val_loss: 18.5671\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.6200 - val_loss: 19.6993\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.2700 - val_loss: 18.1220\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.1503 - val_loss: 18.4427\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8760 - val_loss: 18.3839\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3744 - val_loss: 18.3648\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1585 - val_loss: 18.7847\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.4921 - val_loss: 17.1891\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.2029 - val_loss: 17.3521\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9296 - val_loss: 19.1104\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.1488 - val_loss: 17.9016\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8464 - val_loss: 18.4034\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.5605 - val_loss: 17.7280\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3614 - val_loss: 19.3402\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9623 - val_loss: 17.7714\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4889 - val_loss: 17.1366\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3487 - val_loss: 16.5943\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5859 - val_loss: 22.2540\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7237 - val_loss: 18.4015\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8181 - val_loss: 16.5951\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9892 - val_loss: 18.8444\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4484 - val_loss: 17.1812\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4121 - val_loss: 16.5808\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8449 - val_loss: 18.1444\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8171 - val_loss: 16.1515\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9657 - val_loss: 20.3908\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8525 - val_loss: 17.1581\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5964 - val_loss: 16.2604\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4748 - val_loss: 15.8775\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7720 - val_loss: 16.4669\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0306 - val_loss: 17.9600\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9024 - val_loss: 16.8245\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0596 - val_loss: 16.1940\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2174 - val_loss: 17.3253\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.4126 - val_loss: 17.6359\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9660 - val_loss: 16.5970\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9473 - val_loss: 17.2319\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7217 - val_loss: 17.5861\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4677 - val_loss: 19.1252\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.5292 - val_loss: 16.9305\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9146 - val_loss: 15.5511\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9828 - val_loss: 16.8186\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 12.8819 - val_loss: 15.7246\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.3619 - val_loss: 15.1199\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.8018 - val_loss: 14.9913\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.3281 - val_loss: 16.1653\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3868 - val_loss: 16.0612\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9856 - val_loss: 14.8705\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2136 - val_loss: 16.0879\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4297 - val_loss: 15.2907\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3315 - val_loss: 15.5563\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.4003 - val_loss: 15.9444\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1429 - val_loss: 14.4451\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4516 - val_loss: 15.6875\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5920 - val_loss: 17.0516\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0080 - val_loss: 15.2817\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9545 - val_loss: 14.9650\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1822 - val_loss: 16.1087\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3936 - val_loss: 14.9667\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7143 - val_loss: 15.2929\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9373 - val_loss: 15.3649\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6072 - val_loss: 14.5120\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9797 - val_loss: 13.8378\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0808 - val_loss: 15.0162\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2611 - val_loss: 15.3085\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0131 - val_loss: 14.0701\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7512 - val_loss: 13.8597\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3111 - val_loss: 14.7567\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3717 - val_loss: 13.6814\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0415 - val_loss: 17.1071\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2593 - val_loss: 13.4068\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.9000 - val_loss: 14.1753\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6858 - val_loss: 14.5230\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0484 - val_loss: 13.8870\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.7459 - val_loss: 15.9420\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5534 - val_loss: 13.9940\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4596 - val_loss: 13.6769\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.8517 - val_loss: 14.5116\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0501 - val_loss: 13.7138\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2104 - val_loss: 13.2784\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7397 - val_loss: 13.4693\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8296 - val_loss: 13.7167\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5539 - val_loss: 12.7952\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6300 - val_loss: 13.0275\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2560 - val_loss: 12.8344\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1726 - val_loss: 12.1698\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1365 - val_loss: 13.0206\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2179 - val_loss: 14.7935\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4223 - val_loss: 12.6970\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5362 - val_loss: 13.9241\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9210 - val_loss: 13.6230\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9414 - val_loss: 12.4075\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6370 - val_loss: 17.7335\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6933 - val_loss: 12.4169\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0234 - val_loss: 13.6927\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3050 - val_loss: 13.0680\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0209 - val_loss: 12.0296\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7334 - val_loss: 14.0080\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1388 - val_loss: 12.9773\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7205 - val_loss: 12.6716\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9650 - val_loss: 12.1941\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1341 - val_loss: 13.8841\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9071 - val_loss: 13.4997\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6341 - val_loss: 12.6370\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6438 - val_loss: 13.1859\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8200 - val_loss: 13.1067\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2369 - val_loss: 13.9623\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1171 - val_loss: 11.7962\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4690 - val_loss: 11.8388\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7704 - val_loss: 11.8752\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6338 - val_loss: 11.9305\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8395 - val_loss: 12.0270\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2026 - val_loss: 12.6281\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6903 - val_loss: 12.8695\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8783 - val_loss: 14.0433\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1279 - val_loss: 11.8146\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6226 - val_loss: 12.3389\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2052 - val_loss: 11.6647\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8895 - val_loss: 13.6758\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5013 - val_loss: 12.6335\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2968 - val_loss: 11.4878\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3654 - val_loss: 11.4991\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7852 - val_loss: 12.1750\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9100 - val_loss: 12.5634\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9238 - val_loss: 11.6412\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7224 - val_loss: 12.5134\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8955 - val_loss: 12.0441\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6820 - val_loss: 11.2135\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6546 - val_loss: 12.2725\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5354 - val_loss: 14.8214\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9068 - val_loss: 11.2539\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0297 - val_loss: 12.0218\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5712 - val_loss: 11.2236\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4758 - val_loss: 12.2669\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2440 - val_loss: 11.4499\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3850 - val_loss: 11.1655\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3531 - val_loss: 13.3756\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9491 - val_loss: 12.9073\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1152 - val_loss: 12.2362\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5400 - val_loss: 13.9932\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2178 - val_loss: 11.9710\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3327 - val_loss: 11.1517\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0976 - val_loss: 11.4141\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1652 - val_loss: 11.4622\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3718 - val_loss: 11.1476\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0907 - val_loss: 11.3218\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.3882 - val_loss: 11.2588\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0873 - val_loss: 11.1393\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0920 - val_loss: 12.1692\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2177 - val_loss: 11.0599\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0954 - val_loss: 11.4409\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0882 - val_loss: 13.2858\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2596 - val_loss: 11.1101\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4336 - val_loss: 12.5590\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4983 - val_loss: 11.5422\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2449 - val_loss: 12.0825\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5475 - val_loss: 11.2551\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4322 - val_loss: 11.4289\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4781 - val_loss: 11.1783\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0543 - val_loss: 12.3415\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6492 - val_loss: 12.2332\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0281 - val_loss: 11.4536\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5682 - val_loss: 10.9073\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3964 - val_loss: 11.2213\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1973 - val_loss: 10.8911\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2758 - val_loss: 11.8624\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0754 - val_loss: 10.8604\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7499 - val_loss: 11.3691\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5922 - val_loss: 12.7979\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2659 - val_loss: 11.0926\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1644 - val_loss: 11.6147\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3491 - val_loss: 13.0160\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3425 - val_loss: 12.2407\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4926 - val_loss: 11.7885\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2489 - val_loss: 11.1284\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9541 - val_loss: 11.0008\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1310 - val_loss: 12.6135\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3782 - val_loss: 11.4864\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1189 - val_loss: 10.8685\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7825 - val_loss: 12.9468\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2944 - val_loss: 10.9961\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8695 - val_loss: 11.2895\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1458 - val_loss: 11.8183\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9696 - val_loss: 12.1354\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0144 - val_loss: 11.1886\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2972 - val_loss: 11.1148\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0954 - val_loss: 11.6031\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2122 - val_loss: 11.6198\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3266 - val_loss: 11.2051\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8660 - val_loss: 10.8306\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0383 - val_loss: 11.7010\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6528 - val_loss: 11.6932\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1990 - val_loss: 10.7788\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0689 - val_loss: 11.4690\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9465 - val_loss: 11.1777\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2961 - val_loss: 14.1547\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3951 - val_loss: 11.4972\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1641 - val_loss: 10.7977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6115 - val_loss: 12.8455\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1888 - val_loss: 11.3816\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2746 - val_loss: 11.2484\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1577 - val_loss: 11.2052\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5356 - val_loss: 12.6711\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0584 - val_loss: 11.6983\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2399 - val_loss: 12.3744\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0848 - val_loss: 10.9121\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0218 - val_loss: 10.8469\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2668 - val_loss: 11.5653\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3162 - val_loss: 10.8568\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0949 - val_loss: 11.8187\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5728 - val_loss: 11.6405\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.7425 - val_loss: 10.9173\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.9711 - val_loss: 11.2697\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.6407 - val_loss: 11.8210\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2330 - val_loss: 11.0879\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1578 - val_loss: 11.5813\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0870 - val_loss: 11.4878\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0175 - val_loss: 11.3562\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4586 - val_loss: 11.2300\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1319 - val_loss: 11.0707\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4101 - val_loss: 11.2109\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1423 - val_loss: 11.2572\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9594 - val_loss: 11.0969\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3939 - val_loss: 11.2630\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9278 - val_loss: 11.2545\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4965 - val_loss: 13.5265\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3754 - val_loss: 11.8529\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4871 - val_loss: 11.8251\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4617 - val_loss: 12.9208\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4743 - val_loss: 11.3523\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8226 - val_loss: 11.8218\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5720 - val_loss: 12.6587\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8307 - val_loss: 11.1495\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2040 - val_loss: 12.2572\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0267 - val_loss: 11.2875\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2363 - val_loss: 11.1223\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3389 - val_loss: 11.4607\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1128 - val_loss: 11.7002\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5377 - val_loss: 12.2474\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0711 - val_loss: 11.8535\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9452 - val_loss: 11.5869\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3022 - val_loss: 11.1351\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1336 - val_loss: 11.1069\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2167 - val_loss: 11.8485\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0485 - val_loss: 11.5303\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0960 - val_loss: 11.7898\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3146 - val_loss: 10.9572\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9693 - val_loss: 11.0475\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0988 - val_loss: 11.0329\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0678 - val_loss: 11.7487\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4017 - val_loss: 14.0118\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2502 - val_loss: 12.0534\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1163 - val_loss: 11.0868\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2461 - val_loss: 10.9627\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9448 - val_loss: 10.8674\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5216 - val_loss: 11.8745\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3568 - val_loss: 13.0730\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2658 - val_loss: 11.7780\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9433 - val_loss: 11.8499\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2110 - val_loss: 12.6340\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2437 - val_loss: 10.8153\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4078 - val_loss: 11.8678\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7716 - val_loss: 11.6556\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8333 - val_loss: 11.7212\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8879 - val_loss: 11.1311\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1540 - val_loss: 13.7368\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1520 - val_loss: 11.2308\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0453 - val_loss: 11.8172\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3291 - val_loss: 12.9521\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8380 - val_loss: 12.3943\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5501 - val_loss: 11.2826\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1350 - val_loss: 10.9360\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9642 - val_loss: 11.1711\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2816 - val_loss: 11.4108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9894 - val_loss: 11.1601\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4918 - val_loss: 10.9214\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3032 - val_loss: 11.2336\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1683 - val_loss: 10.6217\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7339 - val_loss: 11.2961\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9958 - val_loss: 11.4467\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0571 - val_loss: 11.8354\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3754 - val_loss: 11.0701\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0774 - val_loss: 11.5330\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1651 - val_loss: 11.3082\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9752 - val_loss: 10.7797\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3612 - val_loss: 12.5560\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9724 - val_loss: 11.7030\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2877 - val_loss: 11.1575\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8532 - val_loss: 11.3979\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2458 - val_loss: 10.8623\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5091 - val_loss: 11.3777\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3784 - val_loss: 11.6933\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3225 - val_loss: 11.0736\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0797 - val_loss: 10.9156\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8919 - val_loss: 11.0756\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0930 - val_loss: 11.8752\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2403 - val_loss: 10.8087\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4431 - val_loss: 11.1112\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0802 - val_loss: 11.4165\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9070 - val_loss: 11.0567\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8839 - val_loss: 11.8916\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8033 - val_loss: 11.7465\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7608 - val_loss: 11.5960\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9698 - val_loss: 11.2820\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9579 - val_loss: 12.0712\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8760 - val_loss: 11.1107\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0085 - val_loss: 10.8714\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9305 - val_loss: 11.0571\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4931 - val_loss: 12.5668\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5870 - val_loss: 10.9335\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5650 - val_loss: 11.5140\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9761 - val_loss: 11.5185\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9134 - val_loss: 11.1256\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1398 - val_loss: 10.9134\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1188 - val_loss: 10.9261\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0639 - val_loss: 12.7991\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2572 - val_loss: 11.4479\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9229 - val_loss: 12.3614\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0935 - val_loss: 10.6377\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0436 - val_loss: 11.1211\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3066 - val_loss: 11.0879\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9917 - val_loss: 10.6538\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0761 - val_loss: 10.6324\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0631 - val_loss: 11.6865\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1267 - val_loss: 11.3172\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4815 - val_loss: 11.2540\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6815 - val_loss: 11.4227\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2528 - val_loss: 12.1719\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2367 - val_loss: 12.0556\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8111 - val_loss: 11.4848\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8586 - val_loss: 11.2742\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0492 - val_loss: 12.1023\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9073 - val_loss: 10.7483\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1600 - val_loss: 11.8899\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3235 - val_loss: 11.1743\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3240 - val_loss: 13.7271\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2714 - val_loss: 10.7831\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9465 - val_loss: 11.7120\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3305 - val_loss: 11.1271\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1873 - val_loss: 10.8570\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1287 - val_loss: 11.9950\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4739 - val_loss: 11.5430\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0428 - val_loss: 11.0647\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2227 - val_loss: 10.8364\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2831 - val_loss: 11.6313\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8722 - val_loss: 11.5504\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6666 - val_loss: 12.3020\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9102 - val_loss: 11.1282\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1487 - val_loss: 12.3905\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2239 - val_loss: 11.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9780 - val_loss: 11.6947\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0554 - val_loss: 10.9289\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8635 - val_loss: 12.4877\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2437 - val_loss: 11.4585\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2397 - val_loss: 12.0629\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6951 - val_loss: 12.7502\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1042 - val_loss: 13.1528\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8251 - val_loss: 11.2018\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4194 - val_loss: 11.1222\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1131 - val_loss: 11.2411\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4081 - val_loss: 11.1873\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0635 - val_loss: 11.5243\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1797 - val_loss: 12.8277\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1696 - val_loss: 12.5150\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1746 - val_loss: 11.7030\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0349 - val_loss: 12.2291\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8940 - val_loss: 11.7280\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0348 - val_loss: 10.9579\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1028 - val_loss: 10.8024\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7142 - val_loss: 11.3640\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1940 - val_loss: 11.1886\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9332 - val_loss: 11.8328\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2282 - val_loss: 11.8335\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9483 - val_loss: 11.2893\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0966 - val_loss: 11.7156\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1124 - val_loss: 11.3622\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0562 - val_loss: 10.9531\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2777 - val_loss: 11.3880\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5005 - val_loss: 10.9427\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8965 - val_loss: 11.0110\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0309 - val_loss: 11.5129\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0676 - val_loss: 10.9633\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7202 - val_loss: 11.9307\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1121 - val_loss: 10.7696\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0113 - val_loss: 10.6839\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.8781 - val_loss: 11.3714\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0953 - val_loss: 11.8572\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1883 - val_loss: 11.1272\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0293 - val_loss: 12.9411\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4046 - val_loss: 10.7984\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7938 - val_loss: 11.0859\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0458 - val_loss: 11.2122\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3063 - val_loss: 10.9898\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2095 - val_loss: 12.2597\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0336 - val_loss: 11.0971\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9082 - val_loss: 13.0153\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8174 - val_loss: 11.3035\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9508 - val_loss: 11.8522\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3557 - val_loss: 13.4044\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3797 - val_loss: 11.4103\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7583 - val_loss: 11.1778\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1053 - val_loss: 11.3666\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6379 - val_loss: 10.8783\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8209 - val_loss: 10.8456\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2934 - val_loss: 11.2758\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1142 - val_loss: 10.6921\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0711 - val_loss: 11.4857\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0201 - val_loss: 12.5967\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2371 - val_loss: 10.6785\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1708 - val_loss: 10.7583\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1264 - val_loss: 14.0671\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2570 - val_loss: 11.1193\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0908 - val_loss: 10.6453\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7875 - val_loss: 13.1580\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0634 - val_loss: 10.7605\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2938 - val_loss: 10.7473\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7589 - val_loss: 10.7601\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9300 - val_loss: 10.6384\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2789 - val_loss: 11.3806\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0764 - val_loss: 11.4752\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1195 - val_loss: 11.2637\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9232 - val_loss: 10.9409\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0193 - val_loss: 12.3392\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2924 - val_loss: 10.6666\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1830 - val_loss: 10.9771\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7073 - val_loss: 10.6288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8963 - val_loss: 11.0478\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2784 - val_loss: 11.6970\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2714 - val_loss: 10.9369\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0990 - val_loss: 11.4049\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6954 - val_loss: 11.0241\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7794 - val_loss: 11.1146\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1263 - val_loss: 11.1096\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8430 - val_loss: 13.0646\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5301 - val_loss: 10.8274\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2065 - val_loss: 11.3937\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9671 - val_loss: 11.1228\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3983 - val_loss: 12.2049\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6030 - val_loss: 10.8161\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9499 - val_loss: 11.1522\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9702 - val_loss: 10.9323\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6457 - val_loss: 11.1239\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0683 - val_loss: 10.7797\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1581 - val_loss: 12.8242\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1486 - val_loss: 12.4687\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0056 - val_loss: 11.0321\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8527 - val_loss: 11.3486\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8688 - val_loss: 14.3009\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0801 - val_loss: 10.8736\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9325 - val_loss: 11.0229\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6924 - val_loss: 12.5240\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8841 - val_loss: 11.3155\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2212 - val_loss: 11.9322\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0264 - val_loss: 11.0123\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0312 - val_loss: 11.6777\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1402 - val_loss: 14.1856\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2084 - val_loss: 10.9568\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0379 - val_loss: 10.5754\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8220 - val_loss: 10.7346\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9415 - val_loss: 11.3001\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0616 - val_loss: 10.8084\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7480 - val_loss: 11.4623\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0215 - val_loss: 10.8744\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9615 - val_loss: 11.4767\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7374 - val_loss: 10.6794\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7052 - val_loss: 11.6267\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0306 - val_loss: 10.9870\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8187 - val_loss: 11.1315\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5396 - val_loss: 11.4934\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3502 - val_loss: 10.7867\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9139 - val_loss: 10.6556\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7010 - val_loss: 11.0030\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8889 - val_loss: 11.4335\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0790 - val_loss: 10.6123\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9778 - val_loss: 11.1674\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9698 - val_loss: 11.1513\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2953 - val_loss: 11.8584\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3563 - val_loss: 12.1169\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9648 - val_loss: 11.4405\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2029 - val_loss: 10.8949\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2880 - val_loss: 11.2230\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3075 - val_loss: 11.0831\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1387 - val_loss: 11.6760\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2819 - val_loss: 10.7047\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7225 - val_loss: 10.5097\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8788 - val_loss: 10.6779\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7807 - val_loss: 10.5707\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9606 - val_loss: 10.9120\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9212 - val_loss: 12.4611\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1090 - val_loss: 12.3468\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8882 - val_loss: 11.8514\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7689 - val_loss: 11.5696\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8507 - val_loss: 11.9494\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9293 - val_loss: 11.1328\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9705 - val_loss: 10.5784\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2843 - val_loss: 10.3541\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7580 - val_loss: 10.9197\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7839 - val_loss: 12.4192\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9190 - val_loss: 13.1962\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8636 - val_loss: 11.0279\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9562 - val_loss: 10.7395\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0028 - val_loss: 10.5309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8618 - val_loss: 10.9666\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0664 - val_loss: 11.7266\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0457 - val_loss: 11.1659\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2393 - val_loss: 10.5296\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9308 - val_loss: 10.4935\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1356 - val_loss: 11.2305\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3260 - val_loss: 12.1757\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2201 - val_loss: 10.7167\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7640 - val_loss: 10.8122\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8563 - val_loss: 11.0061\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9257 - val_loss: 11.2853\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7876 - val_loss: 10.5588\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1295 - val_loss: 11.5359\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0680 - val_loss: 10.5687\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0751 - val_loss: 10.9125\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8832 - val_loss: 10.8690\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8528 - val_loss: 11.0538\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2301 - val_loss: 11.1178\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0196 - val_loss: 11.0596\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2242 - val_loss: 10.6461\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7436 - val_loss: 10.3880\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6441 - val_loss: 10.4814\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1693 - val_loss: 11.0289\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8935 - val_loss: 10.5532\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8400 - val_loss: 10.3798\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9677 - val_loss: 11.4948\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0723 - val_loss: 11.4705\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1774 - val_loss: 10.5575\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1326 - val_loss: 11.9488\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8004 - val_loss: 10.5552\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9565 - val_loss: 12.2054\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0356 - val_loss: 11.2847\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7156 - val_loss: 11.0839\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7927 - val_loss: 11.8882\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8363 - val_loss: 10.5610\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9031 - val_loss: 10.5542\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6991 - val_loss: 12.1831\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0836 - val_loss: 12.9783\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0438 - val_loss: 10.9562\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8283 - val_loss: 10.3110\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9499 - val_loss: 10.7452\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1063 - val_loss: 10.6891\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8107 - val_loss: 10.5359\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0588 - val_loss: 11.1792\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2102 - val_loss: 11.2675\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1108 - val_loss: 10.7791\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9559 - val_loss: 10.8504\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3211 - val_loss: 11.3752\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4217 - val_loss: 13.3108\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1026 - val_loss: 12.2036\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0693 - val_loss: 10.5549\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1658 - val_loss: 10.6053\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9630 - val_loss: 10.7741\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8098 - val_loss: 10.9216\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9336 - val_loss: 12.4513\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.7249 - val_loss: 11.6674\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0133 - val_loss: 11.8373\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1333 - val_loss: 11.5416\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0955 - val_loss: 10.2956\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6846 - val_loss: 10.7946\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6170 - val_loss: 11.4401\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4069 - val_loss: 10.2823\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8328 - val_loss: 10.8375\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9100 - val_loss: 11.8687\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6691 - val_loss: 10.6224\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8109 - val_loss: 10.5412\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7515 - val_loss: 10.7987\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5899 - val_loss: 10.9654\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6680 - val_loss: 11.2210\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0307 - val_loss: 11.7639\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2818 - val_loss: 11.2647\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2471 - val_loss: 10.5798\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6400 - val_loss: 10.4983\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7070 - val_loss: 10.6160\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7629 - val_loss: 10.1664\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7613 - val_loss: 10.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2534 - val_loss: 10.6141\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9088 - val_loss: 10.4848\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9322 - val_loss: 11.1810\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0754 - val_loss: 10.7780\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7747 - val_loss: 11.1674\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7940 - val_loss: 10.7899\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0669 - val_loss: 11.6913\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7825 - val_loss: 10.7337\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6826 - val_loss: 10.6795\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3244 - val_loss: 11.0212\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8467 - val_loss: 10.4418\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7495 - val_loss: 11.4388\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9583 - val_loss: 10.3670\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9672 - val_loss: 10.2297\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0060 - val_loss: 10.6976\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2044 - val_loss: 10.1468\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7720 - val_loss: 10.7903\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7165 - val_loss: 10.8854\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3557 - val_loss: 11.2275\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9543 - val_loss: 11.7470\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6584 - val_loss: 10.5778\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7502 - val_loss: 10.4626\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7552 - val_loss: 10.4769\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8340 - val_loss: 10.4577\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1545 - val_loss: 10.9229\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7564 - val_loss: 10.7851\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7722 - val_loss: 10.9476\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1783 - val_loss: 11.0143\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8932 - val_loss: 10.8141\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8706 - val_loss: 10.8696\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9081 - val_loss: 10.4394\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9114 - val_loss: 10.6423\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6288 - val_loss: 10.8228\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0811 - val_loss: 12.0617\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1012 - val_loss: 10.2950\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7843 - val_loss: 10.5069\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8770 - val_loss: 11.3716\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9136 - val_loss: 11.0110\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7505 - val_loss: 10.8528\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6885 - val_loss: 10.1695\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4291 - val_loss: 10.6504\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2673 - val_loss: 10.4726\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6730 - val_loss: 10.6784\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9195 - val_loss: 10.2636\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8655 - val_loss: 10.7991\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6823 - val_loss: 11.4530\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5910 - val_loss: 10.5715\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4705 - val_loss: 10.6822\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9963 - val_loss: 10.5513\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9501 - val_loss: 11.0884\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3835 - val_loss: 12.8889\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0591 - val_loss: 10.2815\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8187 - val_loss: 10.4570\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8255 - val_loss: 11.6621\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1229 - val_loss: 10.8973\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4534 - val_loss: 10.2030\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0408 - val_loss: 11.7811\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7718 - val_loss: 12.0720\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0370 - val_loss: 10.9484\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7513 - val_loss: 10.5118\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0149 - val_loss: 10.6573\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9158 - val_loss: 13.8929\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2782 - val_loss: 10.7080\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7563 - val_loss: 10.1243\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9805 - val_loss: 10.3316\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9991 - val_loss: 11.9105\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1524 - val_loss: 10.4753\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7567 - val_loss: 10.8964\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8709 - val_loss: 10.1961\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5573 - val_loss: 10.4062\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9965 - val_loss: 11.9466\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9123 - val_loss: 10.1523\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9915 - val_loss: 10.4334\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4867 - val_loss: 11.0560\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1136 - val_loss: 11.2886\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9756 - val_loss: 10.8566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0179 - val_loss: 11.0638\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3357 - val_loss: 11.5366\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1380 - val_loss: 10.4415\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8946 - val_loss: 10.6532\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5577 - val_loss: 10.3589\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8486 - val_loss: 10.4589\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0346 - val_loss: 9.9388\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5843 - val_loss: 10.4917\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6255 - val_loss: 10.7084\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6425 - val_loss: 10.4750\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7059 - val_loss: 10.2050\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7549 - val_loss: 10.8353\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8843 - val_loss: 10.5666\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7106 - val_loss: 11.6242\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6484 - val_loss: 10.4342\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7157 - val_loss: 11.1234\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1006 - val_loss: 11.5570\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4391 - val_loss: 10.3568\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8855 - val_loss: 10.7129\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7502 - val_loss: 10.3031\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6823 - val_loss: 11.7991\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7237 - val_loss: 13.3533\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5313 - val_loss: 12.3148\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8506 - val_loss: 10.2507\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1851 - val_loss: 10.3404\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7510 - val_loss: 10.3111\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5813 - val_loss: 10.9570\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1620 - val_loss: 10.8752\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9121 - val_loss: 10.8302\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7715 - val_loss: 11.2154\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1669 - val_loss: 10.7976\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6156 - val_loss: 10.0055\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6472 - val_loss: 10.2587\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6740 - val_loss: 11.7605\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8047 - val_loss: 10.9994\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1068 - val_loss: 11.0961\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5192 - val_loss: 10.3241\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1262 - val_loss: 10.6818\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8048 - val_loss: 11.3520\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7384 - val_loss: 10.1479\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4936 - val_loss: 10.4357\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0081 - val_loss: 10.5564\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5404 - val_loss: 11.1369\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7883 - val_loss: 10.5917\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8298 - val_loss: 10.1654\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4534 - val_loss: 11.0958\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1655 - val_loss: 10.2831\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8707 - val_loss: 10.9552\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7337 - val_loss: 10.4040\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6289 - val_loss: 10.2592\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6815 - val_loss: 10.3537\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7401 - val_loss: 11.6321\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5665 - val_loss: 10.3202\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6709 - val_loss: 10.1822\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5947 - val_loss: 10.1442\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7104 - val_loss: 11.0236\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0610 - val_loss: 10.6835\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4159 - val_loss: 10.6472\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8178 - val_loss: 10.5558\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9824 - val_loss: 10.0290\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7325 - val_loss: 10.4061\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6550 - val_loss: 10.1975\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7562 - val_loss: 10.2295\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5911 - val_loss: 10.3544\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9643 - val_loss: 11.1877\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6124 - val_loss: 10.7435\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7710 - val_loss: 12.4932\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3408 - val_loss: 10.0205\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0278 - val_loss: 10.1490\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6262 - val_loss: 10.2487\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9042 - val_loss: 10.1616\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4467 - val_loss: 11.5912\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8461 - val_loss: 10.1881\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1368 - val_loss: 10.3370\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1377 - val_loss: 10.8222\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1230 - val_loss: 10.8965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6753 - val_loss: 10.6563\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7951 - val_loss: 10.3352\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6902 - val_loss: 11.4051\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8574 - val_loss: 10.1648\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7651 - val_loss: 10.0015\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6447 - val_loss: 11.4058\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7364 - val_loss: 10.3301\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7514 - val_loss: 11.6658\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8862 - val_loss: 11.1894\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9212 - val_loss: 11.0116\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2692 - val_loss: 10.1189\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9177 - val_loss: 10.7042\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3767 - val_loss: 10.4238\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.7340 - val_loss: 10.1191\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5245 - val_loss: 10.2639\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7442 - val_loss: 9.8099\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7552 - val_loss: 10.8134\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8532 - val_loss: 11.0671\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0698 - val_loss: 10.2949\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1499 - val_loss: 10.2578\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5117 - val_loss: 11.7917\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8513 - val_loss: 11.6305\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9295 - val_loss: 11.1601\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6112 - val_loss: 10.3359\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0141 - val_loss: 10.7059\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9336 - val_loss: 10.2553\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5524 - val_loss: 10.0113\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7802 - val_loss: 10.2951\n",
      "9.015815083431987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.1028473 , -0.18292013, -3.8349018 , -1.5870104 ,  3.814878  ],\n",
       "        [-0.13712819, -0.2612418 ,  0.32714096,  0.35182697, -0.08928601],\n",
       "        [-0.3918271 , -0.34844434, -0.5450464 ,  0.28817612, -0.074275  ],\n",
       "        [ 0.10039558,  0.09183448,  0.16906567,  0.07121518, -0.07979812],\n",
       "        [-1.0957295 , -0.21084051, -0.45275334, -0.18003482,  2.3101661 ]],\n",
       "       dtype=float32),\n",
       " array([-3.041849  , -0.20409858, -4.772107  , -1.2570957 ,  5.236213  ],\n",
       "       dtype=float32),\n",
       " array([[ 2.8811598 ,  1.933249  , -2.2385168 ,  1.9186612 , -2.9452496 ],\n",
       "        [-1.7918831 , -1.0472606 ,  0.5667873 , -1.836486  ,  1.3318132 ],\n",
       "        [ 3.2278888 ,  2.5148187 , -2.7223623 ,  2.6507337 , -3.2211773 ],\n",
       "        [-1.4626925 , -0.67815995,  1.6746815 , -0.9251087 ,  0.37785146],\n",
       "        [-1.8383002 , -2.7416701 ,  2.0179338 , -2.8827069 ,  1.9486701 ]],\n",
       "       dtype=float32),\n",
       " array([-2.3521082, -2.5822237,  2.24171  , -2.1694663,  2.1959887],\n",
       "       dtype=float32),\n",
       " array([[-2.5036724],\n",
       "        [-2.3743   ],\n",
       "        [ 2.7961814],\n",
       "        [-3.1468685],\n",
       "        [ 3.1081364]], dtype=float32),\n",
       " array([2.0290163], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_1(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure1_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 200us/step - loss: 7791.2709 - val_loss: 664.1791\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 214.8925 - val_loss: 79.1624\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 59.3235 - val_loss: 42.2021\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 39.3088 - val_loss: 33.1251\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 32.7026 - val_loss: 29.6676\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 29.4712 - val_loss: 27.7788\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 27.8105 - val_loss: 27.7127\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 26.6247 - val_loss: 27.3857\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 25.8451 - val_loss: 27.0336\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 25.3645 - val_loss: 27.1277\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.9117 - val_loss: 26.8210\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.6316 - val_loss: 26.9208\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.1674 - val_loss: 26.4132\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 23.9968 - val_loss: 27.5830\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.4114 - val_loss: 26.3336\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 23.0710 - val_loss: 27.5590\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.5495 - val_loss: 26.5014\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8184 - val_loss: 26.3841\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.2570 - val_loss: 26.1615\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.8891 - val_loss: 26.2747\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.4601 - val_loss: 26.4398\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.1747 - val_loss: 25.7137\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.7256 - val_loss: 25.4434\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.5011 - val_loss: 25.0975\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3992 - val_loss: 25.0457\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.2871 - val_loss: 25.1086\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.0567 - val_loss: 24.6699\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0209 - val_loss: 24.6288\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.7643 - val_loss: 24.7902\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.7529 - val_loss: 24.4928\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7667 - val_loss: 24.6353\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.9753 - val_loss: 24.4991\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5868 - val_loss: 24.1413\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5064 - val_loss: 24.2725\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.5459 - val_loss: 24.3069\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2882 - val_loss: 23.7214\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3292 - val_loss: 23.7218\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1217 - val_loss: 23.7044\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1022 - val_loss: 23.3668\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1370 - val_loss: 23.2801\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0600 - val_loss: 23.4493\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8580 - val_loss: 23.1429\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.6648 - val_loss: 22.8022\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.7726 - val_loss: 22.8673\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5975 - val_loss: 22.5218\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5330 - val_loss: 22.4026\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3548 - val_loss: 22.5388\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7505 - val_loss: 22.7066\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4380 - val_loss: 22.0743\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2984 - val_loss: 22.3073\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2242 - val_loss: 21.0135\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0316 - val_loss: 21.4265\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0660 - val_loss: 20.9165\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1207 - val_loss: 21.0438\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.7874 - val_loss: 21.0240\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7539 - val_loss: 20.9476\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6404 - val_loss: 20.3377\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.5858 - val_loss: 20.3622\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.6070 - val_loss: 20.2157\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.6279 - val_loss: 20.2059\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.5184 - val_loss: 20.1550\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3900 - val_loss: 20.1540\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 15.71 - 0s 87us/step - loss: 16.3154 - val_loss: 20.1578\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2391 - val_loss: 20.4117\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3622 - val_loss: 20.6957\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.1428 - val_loss: 19.4971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.2089 - val_loss: 19.5075\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.1242 - val_loss: 19.3416\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.8350 - val_loss: 19.9958\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.1248 - val_loss: 19.3492\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.8564 - val_loss: 19.3934\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.7702 - val_loss: 19.3287\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9922 - val_loss: 19.0708\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.5568 - val_loss: 18.9046\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.5847 - val_loss: 18.9612\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.6686 - val_loss: 18.8195\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.2448 - val_loss: 18.7073\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.6083 - val_loss: 20.0358\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3808 - val_loss: 19.0606\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3220 - val_loss: 18.4323\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.2727 - val_loss: 18.6749\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0801 - val_loss: 18.5625\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1720 - val_loss: 20.9193\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3005 - val_loss: 18.1990\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.0897 - val_loss: 17.9573\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9180 - val_loss: 17.9460\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.3844 - val_loss: 19.4274\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.2164 - val_loss: 19.1109\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8511 - val_loss: 17.6954\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7389 - val_loss: 17.8001\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8458 - val_loss: 19.1145\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7929 - val_loss: 17.8426\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7890 - val_loss: 17.4377\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7805 - val_loss: 17.3782\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5404 - val_loss: 18.3803\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9437 - val_loss: 17.5212\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6569 - val_loss: 17.4018\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1551 - val_loss: 17.6598\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7966 - val_loss: 17.8184\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2420 - val_loss: 20.4774\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4219 - val_loss: 17.7073\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3347 - val_loss: 20.4904\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3062 - val_loss: 17.6585\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.0995 - val_loss: 17.1037\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2373 - val_loss: 17.9072\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5440 - val_loss: 16.6305\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4946 - val_loss: 17.6600\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3673 - val_loss: 16.7856\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7474 - val_loss: 17.3708\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5296 - val_loss: 16.6978\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0546 - val_loss: 18.2584\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9179 - val_loss: 17.6049\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6887 - val_loss: 16.9673\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7184 - val_loss: 16.9012\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3293 - val_loss: 18.1795\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8918 - val_loss: 17.5981\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3039 - val_loss: 16.3648\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6555 - val_loss: 18.3489\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.2296 - val_loss: 16.0244\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.6582 - val_loss: 15.8535\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 13.3803 - val_loss: 16.6183\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.2127 - val_loss: 16.6682\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.8772 - val_loss: 15.6844\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.8758 - val_loss: 17.3110\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.3817 - val_loss: 16.2250\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.6205 - val_loss: 16.5029\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4390 - val_loss: 15.4592\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.5620 - val_loss: 19.5660\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.3141 - val_loss: 15.7767\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7278 - val_loss: 15.6436\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1479 - val_loss: 15.0593\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4359 - val_loss: 16.2576\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6417 - val_loss: 16.2773\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2985 - val_loss: 17.1010\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7737 - val_loss: 15.5860\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6369 - val_loss: 14.9072\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0893 - val_loss: 15.7193\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0605 - val_loss: 17.9321\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.9158 - val_loss: 16.0084\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0765 - val_loss: 14.6765\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8826 - val_loss: 14.5003\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5284 - val_loss: 14.9906\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0965 - val_loss: 15.4005\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9670 - val_loss: 15.9512\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7337 - val_loss: 15.4522\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3155 - val_loss: 15.1765\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0572 - val_loss: 13.3775\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3576 - val_loss: 14.8059\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4022 - val_loss: 14.4417\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1558 - val_loss: 13.9098\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.5313 - val_loss: 14.1454\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0166 - val_loss: 13.3055\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2640 - val_loss: 13.3250\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6520 - val_loss: 15.2700\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4685 - val_loss: 15.6300\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2033 - val_loss: 17.0945\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7886 - val_loss: 13.0292\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8678 - val_loss: 12.7643\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.6354 - val_loss: 14.6837\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1054 - val_loss: 13.7679\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9741 - val_loss: 12.9754\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8192 - val_loss: 13.8917\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4582 - val_loss: 13.3492\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6567 - val_loss: 12.5917\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2003 - val_loss: 14.4737\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4131 - val_loss: 13.2349\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.8866 - val_loss: 14.5025\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8201 - val_loss: 13.5091\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7110 - val_loss: 12.8157\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6865 - val_loss: 12.9298\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.7390 - val_loss: 12.7682\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4965 - val_loss: 12.5878\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3592 - val_loss: 13.1145\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1791 - val_loss: 12.3723\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7580 - val_loss: 13.4174\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.5249 - val_loss: 14.0783\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2877 - val_loss: 12.4688\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8514 - val_loss: 12.6672\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0447 - val_loss: 12.4334\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7884 - val_loss: 12.9442\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2910 - val_loss: 12.5471\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7728 - val_loss: 11.9781\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1886 - val_loss: 12.6686\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9029 - val_loss: 12.1000\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1700 - val_loss: 13.4661\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4294 - val_loss: 13.0375\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7667 - val_loss: 12.7922\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0988 - val_loss: 13.8244\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5655 - val_loss: 12.0933\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6709 - val_loss: 13.8516\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1016 - val_loss: 11.4717\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7639 - val_loss: 12.5919\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6518 - val_loss: 12.9632\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7200 - val_loss: 13.7143\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7755 - val_loss: 13.6073\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4565 - val_loss: 12.0798\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4456 - val_loss: 12.3487\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5748 - val_loss: 11.5637\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9547 - val_loss: 11.6171\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5694 - val_loss: 11.8021\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3015 - val_loss: 11.3353\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2562 - val_loss: 11.9979\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7928 - val_loss: 12.6188\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.5860 - val_loss: 11.4832\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3003 - val_loss: 11.3222\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8826 - val_loss: 12.0907\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4465 - val_loss: 12.8057\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6645 - val_loss: 11.3988\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6096 - val_loss: 12.0226\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7775 - val_loss: 11.2680\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7212 - val_loss: 13.1226\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4850 - val_loss: 12.2455\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1550 - val_loss: 12.5694\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3519 - val_loss: 11.8294\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0924 - val_loss: 11.4929\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2760 - val_loss: 11.8090\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9282 - val_loss: 11.4515\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5887 - val_loss: 11.0881\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5339 - val_loss: 11.8305\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2742 - val_loss: 11.3637\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2541 - val_loss: 11.6974\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1088 - val_loss: 11.1504\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1133 - val_loss: 12.6126\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1025 - val_loss: 14.4692\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2018 - val_loss: 11.3706\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2747 - val_loss: 11.2246\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3086 - val_loss: 14.5252\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2654 - val_loss: 12.1313\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2136 - val_loss: 12.1165\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5206 - val_loss: 10.9845\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0715 - val_loss: 11.4124\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9607 - val_loss: 13.7799\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2180 - val_loss: 10.7715\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0490 - val_loss: 11.2150\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1667 - val_loss: 11.3885\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3146 - val_loss: 12.4541\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6472 - val_loss: 11.7457\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9627 - val_loss: 11.1881\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0985 - val_loss: 11.4540\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2095 - val_loss: 11.2401\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2572 - val_loss: 10.8146\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9097 - val_loss: 10.8991\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0592 - val_loss: 11.1593\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1091 - val_loss: 12.0332\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1057 - val_loss: 11.0975\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7438 - val_loss: 12.3706\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7885 - val_loss: 12.0364\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1094 - val_loss: 11.3034\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0143 - val_loss: 10.7539\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8843 - val_loss: 10.3811\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0852 - val_loss: 11.3837\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9465 - val_loss: 11.7021\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1848 - val_loss: 10.5730\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6736 - val_loss: 10.7383\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9724 - val_loss: 10.8273\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3415 - val_loss: 12.1630\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8782 - val_loss: 12.5368\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8896 - val_loss: 11.3424\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0832 - val_loss: 11.7401\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4732 - val_loss: 12.2740\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4588 - val_loss: 11.6004\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4879 - val_loss: 12.4015\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2352 - val_loss: 10.5792\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8589 - val_loss: 11.2896\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8465 - val_loss: 11.9685\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8230 - val_loss: 10.4497\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8390 - val_loss: 11.1255\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8543 - val_loss: 12.1264\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1860 - val_loss: 10.3325\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9058 - val_loss: 10.5721\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6507 - val_loss: 10.3100\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6593 - val_loss: 10.2066\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7417 - val_loss: 10.6333\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4920 - val_loss: 11.1794\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0038 - val_loss: 11.5546\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8829 - val_loss: 10.4917\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7375 - val_loss: 10.5581\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6032 - val_loss: 10.3688\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5696 - val_loss: 10.9772\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4194 - val_loss: 11.0265\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6787 - val_loss: 10.9628\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1178 - val_loss: 10.4842\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0412 - val_loss: 11.0130\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9284 - val_loss: 10.2285\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6574 - val_loss: 10.6272\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9052 - val_loss: 11.5850\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.8789 - val_loss: 11.5990\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.7226 - val_loss: 11.2841\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5405 - val_loss: 10.3401\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5572 - val_loss: 11.5455\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7231 - val_loss: 11.2262\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7189 - val_loss: 11.0832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8695 - val_loss: 11.6694\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9787 - val_loss: 11.0406\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.7906 - val_loss: 11.3081\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6202 - val_loss: 10.1370\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8161 - val_loss: 10.2948\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4550 - val_loss: 12.3072\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6703 - val_loss: 11.8946\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7988 - val_loss: 10.6615\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6494 - val_loss: 12.4365\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7608 - val_loss: 10.7870\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6443 - val_loss: 10.3440\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8416 - val_loss: 10.6027\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9051 - val_loss: 11.2678\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0403 - val_loss: 10.5009\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3947 - val_loss: 11.5884\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4739 - val_loss: 10.2456\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4456 - val_loss: 10.7643\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6353 - val_loss: 11.1908\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7490 - val_loss: 10.9841\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6953 - val_loss: 10.6545\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5089 - val_loss: 10.4021\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9414 - val_loss: 10.3912\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5679 - val_loss: 11.5279\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7303 - val_loss: 12.6128\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7702 - val_loss: 10.5489\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0282 - val_loss: 11.0311\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4903 - val_loss: 10.1564\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7232 - val_loss: 10.7752\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1216 - val_loss: 10.9193\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5260 - val_loss: 9.8762\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3446 - val_loss: 10.0404\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5965 - val_loss: 10.0028\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8129 - val_loss: 10.2594\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4605 - val_loss: 9.8391\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5649 - val_loss: 10.7298\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4867 - val_loss: 10.5466\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6311 - val_loss: 10.5042\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7576 - val_loss: 11.4229\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3351 - val_loss: 12.6854\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2775 - val_loss: 12.0543\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9000 - val_loss: 12.2202\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7518 - val_loss: 10.2743\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7501 - val_loss: 11.0268\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4191 - val_loss: 10.1671\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6653 - val_loss: 10.9910\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6314 - val_loss: 10.3376\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5134 - val_loss: 9.9920\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4526 - val_loss: 11.0632\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6075 - val_loss: 11.5225\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6740 - val_loss: 9.8078\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8676 - val_loss: 10.2177\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9560 - val_loss: 10.9218\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1838 - val_loss: 11.0690\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8577 - val_loss: 10.2213\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4947 - val_loss: 10.9640\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5264 - val_loss: 10.1086\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6045 - val_loss: 15.0712\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2768 - val_loss: 10.5100\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7210 - val_loss: 11.1331\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8258 - val_loss: 10.3148\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5854 - val_loss: 11.5225\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4082 - val_loss: 10.9610\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6246 - val_loss: 10.3836\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3808 - val_loss: 10.2956\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9177 - val_loss: 10.8435\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9221 - val_loss: 11.8007\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7452 - val_loss: 10.1811\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6782 - val_loss: 11.1296\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5792 - val_loss: 10.0120\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5353 - val_loss: 10.6187\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5194 - val_loss: 10.0469\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8001 - val_loss: 10.0113\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4720 - val_loss: 10.7697\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5725 - val_loss: 10.8578\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4461 - val_loss: 11.5056\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6609 - val_loss: 10.1937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1305 - val_loss: 9.8596\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7237 - val_loss: 9.9310\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3906 - val_loss: 10.7419\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4564 - val_loss: 10.8027\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5709 - val_loss: 10.9531\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4291 - val_loss: 11.3977\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4539 - val_loss: 10.2123\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5673 - val_loss: 9.9970\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5083 - val_loss: 10.5293\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5957 - val_loss: 10.8036\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2556 - val_loss: 11.1817\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4434 - val_loss: 10.0980\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5930 - val_loss: 9.7407\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3545 - val_loss: 9.6984\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4837 - val_loss: 10.0994\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6088 - val_loss: 9.9632\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3072 - val_loss: 10.6814\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8121 - val_loss: 10.9462\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7608 - val_loss: 10.1532\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6203 - val_loss: 11.3262\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4006 - val_loss: 10.3471\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3010 - val_loss: 11.1013\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3784 - val_loss: 11.3113\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6995 - val_loss: 10.3771\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9351 - val_loss: 9.7220\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4265 - val_loss: 9.6965\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2465 - val_loss: 10.4007\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2463 - val_loss: 9.8741\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8895 - val_loss: 11.8545\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4301 - val_loss: 9.5996\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3710 - val_loss: 9.8192\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5278 - val_loss: 9.7723\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2922 - val_loss: 9.9116\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9388 - val_loss: 12.2590\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6584 - val_loss: 9.8917\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7279 - val_loss: 10.5789\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7226 - val_loss: 10.5466\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3938 - val_loss: 10.4328\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4259 - val_loss: 9.7875\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4622 - val_loss: 10.7172\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7712 - val_loss: 11.3718\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8324 - val_loss: 10.4904\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3424 - val_loss: 9.7254\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5505 - val_loss: 11.6058\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4737 - val_loss: 9.5997\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3462 - val_loss: 10.8770\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4604 - val_loss: 10.4613\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6487 - val_loss: 11.0199\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8169 - val_loss: 11.0974\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5624 - val_loss: 9.8004\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3286 - val_loss: 10.5262\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3047 - val_loss: 9.6783\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6684 - val_loss: 10.9820\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3409 - val_loss: 10.1805\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3808 - val_loss: 10.4070\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2855 - val_loss: 10.7821\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6194 - val_loss: 10.4502\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6040 - val_loss: 10.7540\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4068 - val_loss: 10.2635\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2955 - val_loss: 9.7138\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3459 - val_loss: 10.4005\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6899 - val_loss: 9.8493\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3017 - val_loss: 10.4705\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3927 - val_loss: 9.4386\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6446 - val_loss: 10.3335\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4206 - val_loss: 10.0536\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6469 - val_loss: 11.3975\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7846 - val_loss: 10.6777\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4795 - val_loss: 9.4110\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6253 - val_loss: 9.8782\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8428 - val_loss: 10.3359\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0521 - val_loss: 10.8684\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3456 - val_loss: 9.3163\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3705 - val_loss: 11.0981\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5036 - val_loss: 10.3704\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6075 - val_loss: 11.0275\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3459 - val_loss: 11.5790\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5695 - val_loss: 10.1269\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1589 - val_loss: 10.3765\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5736 - val_loss: 9.6207\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4383 - val_loss: 9.8880\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2995 - val_loss: 9.4070\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4095 - val_loss: 10.2786\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5986 - val_loss: 10.1568\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2047 - val_loss: 10.0763\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6810 - val_loss: 9.8081\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5233 - val_loss: 11.3785\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6677 - val_loss: 9.8500\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3379 - val_loss: 10.8114\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5320 - val_loss: 9.5154\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3523 - val_loss: 11.0917\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5437 - val_loss: 9.3975\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2365 - val_loss: 9.6710\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4023 - val_loss: 10.3943\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1170 - val_loss: 10.5649\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4838 - val_loss: 10.1041\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5749 - val_loss: 10.1982\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5046 - val_loss: 9.5783\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1184 - val_loss: 9.4118\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2908 - val_loss: 10.3538\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5583 - val_loss: 10.5116\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7909 - val_loss: 9.5389\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2927 - val_loss: 11.0942\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1391 - val_loss: 9.3288\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3459 - val_loss: 9.6913\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7927 - val_loss: 10.0158\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5110 - val_loss: 10.3214\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7275 - val_loss: 10.0521\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3694 - val_loss: 9.6766\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3170 - val_loss: 9.6112\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2223 - val_loss: 9.7941\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8093 - val_loss: 11.2980\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6236 - val_loss: 10.6087\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7556 - val_loss: 9.6203\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4519 - val_loss: 10.0893\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4761 - val_loss: 9.8743\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4050 - val_loss: 9.4544\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2773 - val_loss: 9.4901\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1698 - val_loss: 10.2026\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6363 - val_loss: 11.1742\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7028 - val_loss: 12.6687\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6996 - val_loss: 9.7953\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8221 - val_loss: 9.8101\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1918 - val_loss: 9.5134\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3277 - val_loss: 11.1141\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3258 - val_loss: 12.3834\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8844 - val_loss: 10.2000\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6490 - val_loss: 9.6124\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7425 - val_loss: 9.4621\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4612 - val_loss: 11.3187\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2473 - val_loss: 10.2916\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2578 - val_loss: 9.9987\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3574 - val_loss: 12.2238\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5890 - val_loss: 9.7057\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2037 - val_loss: 9.7499\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3297 - val_loss: 10.2887\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3059 - val_loss: 9.7359\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2936 - val_loss: 9.4120\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5790 - val_loss: 9.4670\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6914 - val_loss: 11.9192\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2364 - val_loss: 9.3551\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2222 - val_loss: 10.4154\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1699 - val_loss: 11.2920\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6130 - val_loss: 10.7306\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8974 - val_loss: 13.1068\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6681 - val_loss: 9.9207\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5111 - val_loss: 10.3679\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1276 - val_loss: 10.1734\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4515 - val_loss: 9.8582\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3978 - val_loss: 10.7294\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3470 - val_loss: 10.1257\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3474 - val_loss: 10.2219\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5472 - val_loss: 13.2745\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3982 - val_loss: 11.0394\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4430 - val_loss: 10.2112\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3987 - val_loss: 9.7907\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5043 - val_loss: 9.8159\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0445 - val_loss: 9.7888\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2717 - val_loss: 10.3883\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5665 - val_loss: 10.0476\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5480 - val_loss: 10.8174\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5108 - val_loss: 10.0646\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3353 - val_loss: 9.8016\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1059 - val_loss: 9.3806\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2169 - val_loss: 9.7169\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2098 - val_loss: 9.7020\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4809 - val_loss: 11.2547\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9803 - val_loss: 10.6832\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1651 - val_loss: 9.4909\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2043 - val_loss: 9.6706\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3118 - val_loss: 10.5462\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2828 - val_loss: 9.2058\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2625 - val_loss: 9.6631\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3157 - val_loss: 9.5273\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4729 - val_loss: 9.4817\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6673 - val_loss: 9.5273\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8004 - val_loss: 9.1102\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3739 - val_loss: 10.3108\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4598 - val_loss: 9.3635\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2502 - val_loss: 11.1284\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3493 - val_loss: 10.0667\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3586 - val_loss: 10.0636\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3059 - val_loss: 9.5949\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1946 - val_loss: 9.1911\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5009 - val_loss: 9.6894\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8038 - val_loss: 9.2570\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2142 - val_loss: 9.6648\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7611 - val_loss: 10.8218\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9365 - val_loss: 10.3464\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4192 - val_loss: 9.9338\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2974 - val_loss: 10.2156\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2793 - val_loss: 10.0659\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2114 - val_loss: 9.9979\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1878 - val_loss: 10.1319\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0893 - val_loss: 10.0525\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2332 - val_loss: 9.3936\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2705 - val_loss: 10.0756\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8459 - val_loss: 9.3589\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3893 - val_loss: 10.1450\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1876 - val_loss: 9.6775\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4464 - val_loss: 11.1614\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2103 - val_loss: 11.9032\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4181 - val_loss: 9.3647\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2829 - val_loss: 9.7848\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5485 - val_loss: 9.9113\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5462 - val_loss: 9.6451\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3746 - val_loss: 10.0453\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2738 - val_loss: 9.2052\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2795 - val_loss: 10.4865\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3334 - val_loss: 11.0188\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2624 - val_loss: 9.5543\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4608 - val_loss: 12.5800\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1683 - val_loss: 10.0153\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6645 - val_loss: 9.3403\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2716 - val_loss: 9.1572\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4567 - val_loss: 10.8731\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2526 - val_loss: 10.5636\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4994 - val_loss: 10.3873\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1977 - val_loss: 9.6405\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2838 - val_loss: 10.0288\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5224 - val_loss: 9.7924\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3931 - val_loss: 10.6132\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1320 - val_loss: 10.2867\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1602 - val_loss: 9.8639\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9182 - val_loss: 9.7729\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0378 - val_loss: 10.6806\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3954 - val_loss: 11.2264\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0287 - val_loss: 9.6044\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4429 - val_loss: 9.5741\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2615 - val_loss: 9.3240\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0860 - val_loss: 9.3686\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0592 - val_loss: 9.7000\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1323 - val_loss: 9.1249\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4002 - val_loss: 9.6043\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3914 - val_loss: 10.5714\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0419 - val_loss: 9.9112\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4512 - val_loss: 9.4555\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4007 - val_loss: 9.2736\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1554 - val_loss: 9.9031\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1226 - val_loss: 9.2810\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9832 - val_loss: 9.4700\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3916 - val_loss: 10.4684\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1888 - val_loss: 9.4574\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1069 - val_loss: 9.6173\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2734 - val_loss: 9.2472\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3480 - val_loss: 11.4784\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2678 - val_loss: 9.5331\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0244 - val_loss: 9.3400\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7363 - val_loss: 9.7667\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2273 - val_loss: 9.9419\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.6172 - val_loss: 10.6030\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2470 - val_loss: 11.7853\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2108 - val_loss: 9.7199\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4775 - val_loss: 9.5819\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2069 - val_loss: 11.6803\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4415 - val_loss: 9.4049\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1833 - val_loss: 9.2618\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1516 - val_loss: 9.7336\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2473 - val_loss: 10.0816\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7020 - val_loss: 10.3862\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6886 - val_loss: 9.3031\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5273 - val_loss: 9.3426\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3112 - val_loss: 9.4029\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6292 - val_loss: 9.6945\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3580 - val_loss: 9.1375\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8866 - val_loss: 9.7433\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3886 - val_loss: 9.0258\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1598 - val_loss: 9.3858\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6360 - val_loss: 9.6731\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2860 - val_loss: 9.6695\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1788 - val_loss: 9.2477\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0985 - val_loss: 9.3578\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2820 - val_loss: 10.2133\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2239 - val_loss: 10.4232\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1742 - val_loss: 9.3793\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3653 - val_loss: 9.4943\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1775 - val_loss: 9.9900\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0368 - val_loss: 11.0115\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4778 - val_loss: 9.9396\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4310 - val_loss: 9.6039\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6507 - val_loss: 10.8062\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3542 - val_loss: 9.1526\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0593 - val_loss: 9.9704\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2150 - val_loss: 10.5933\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1726 - val_loss: 9.8629\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9299 - val_loss: 9.3377\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2327 - val_loss: 9.7411\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4075 - val_loss: 10.5378\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5319 - val_loss: 9.6861\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0593 - val_loss: 9.4586\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9544 - val_loss: 9.1767\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1385 - val_loss: 9.8303\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9978 - val_loss: 11.6269\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2166 - val_loss: 9.1536\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9807 - val_loss: 9.2339\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0916 - val_loss: 9.4928\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3518 - val_loss: 11.8836\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2324 - val_loss: 10.0750\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6133 - val_loss: 9.3951\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1578 - val_loss: 9.3314\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4913 - val_loss: 11.3295\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6360 - val_loss: 10.2818\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6092 - val_loss: 9.0424\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0231 - val_loss: 11.4999\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1677 - val_loss: 11.4140\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5307 - val_loss: 9.2374\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0909 - val_loss: 8.9845\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4653 - val_loss: 11.2535\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2415 - val_loss: 9.2720\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1446 - val_loss: 10.1952\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8746 - val_loss: 9.2435\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4006 - val_loss: 9.1049\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5703 - val_loss: 9.2024\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1288 - val_loss: 10.1770\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3060 - val_loss: 10.9713\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5116 - val_loss: 9.3677\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6364 - val_loss: 10.4843\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2266 - val_loss: 9.7942\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0299 - val_loss: 9.7621\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6899 - val_loss: 9.9087\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7772 - val_loss: 9.2297\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0817 - val_loss: 9.4524\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0502 - val_loss: 11.1349\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3665 - val_loss: 9.8112\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2903 - val_loss: 9.9459\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8283 - val_loss: 9.3985\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2011 - val_loss: 10.5144\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0205 - val_loss: 9.4436\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4169 - val_loss: 9.6083\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1552 - val_loss: 12.2024\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3631 - val_loss: 9.2993\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3362 - val_loss: 9.2668\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6540 - val_loss: 9.0524\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2139 - val_loss: 10.6440\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4481 - val_loss: 9.5289\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4140 - val_loss: 10.1542\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0083 - val_loss: 9.0263\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7731 - val_loss: 9.2379\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2330 - val_loss: 9.2115\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7736 - val_loss: 9.5127\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7168 - val_loss: 10.0837\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2552 - val_loss: 9.4960\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1181 - val_loss: 9.6839\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3575 - val_loss: 9.9797\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4761 - val_loss: 10.6279\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2294 - val_loss: 10.8285\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6429 - val_loss: 10.6230\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5556 - val_loss: 10.0632\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5546 - val_loss: 9.5231\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0657 - val_loss: 9.3855\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1258 - val_loss: 12.1492\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6674 - val_loss: 9.4991\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4391 - val_loss: 11.2302\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4527 - val_loss: 9.1832\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2587 - val_loss: 9.5439\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3486 - val_loss: 9.2091\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1035 - val_loss: 9.6611\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2531 - val_loss: 11.0692\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3424 - val_loss: 9.8079\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1481 - val_loss: 9.6377\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1902 - val_loss: 11.7288\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2364 - val_loss: 10.0598\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3610 - val_loss: 9.5284\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2947 - val_loss: 9.5103\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2190 - val_loss: 9.1689\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4331 - val_loss: 12.2793\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2429 - val_loss: 8.9887\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3434 - val_loss: 10.4084\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5207 - val_loss: 10.1354\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4125 - val_loss: 9.2511\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2485 - val_loss: 9.5399\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1604 - val_loss: 9.2302\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2558 - val_loss: 9.6367\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0703 - val_loss: 9.2316\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1557 - val_loss: 9.4503\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6595 - val_loss: 9.6833\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8661 - val_loss: 10.5294\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4877 - val_loss: 9.3300\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3674 - val_loss: 9.6027\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4244 - val_loss: 10.4346\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1442 - val_loss: 9.5745\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9472 - val_loss: 9.3691\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3311 - val_loss: 9.5828\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3583 - val_loss: 9.4184\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4324 - val_loss: 10.5045\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0602 - val_loss: 9.2007\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2558 - val_loss: 10.4497\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3087 - val_loss: 10.7226\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0889 - val_loss: 9.1242\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9229 - val_loss: 11.0394\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2742 - val_loss: 9.5105\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2177 - val_loss: 12.7751\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7315 - val_loss: 9.6954\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6743 - val_loss: 10.2011\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5472 - val_loss: 12.6342\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8500 - val_loss: 9.3533\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1832 - val_loss: 10.4945\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4613 - val_loss: 11.8618\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5281 - val_loss: 9.1638\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7214 - val_loss: 9.4235\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7060 - val_loss: 9.2560\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1944 - val_loss: 10.3080\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6537 - val_loss: 9.4024\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3366 - val_loss: 9.1773\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2628 - val_loss: 10.3860\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1192 - val_loss: 11.3389\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2589 - val_loss: 11.5142\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4746 - val_loss: 8.9748\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3586 - val_loss: 9.4899\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4105 - val_loss: 9.4754\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0435 - val_loss: 10.2807\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0524 - val_loss: 10.5857\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1641 - val_loss: 9.0421\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1369 - val_loss: 9.3596\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0735 - val_loss: 9.1943\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4406 - val_loss: 11.2832\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.3352 - val_loss: 10.9518\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1681 - val_loss: 10.2342\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.2870 - val_loss: 8.9710\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.1956 - val_loss: 9.7588\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1854 - val_loss: 10.0721\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.3637 - val_loss: 9.2687\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.5366 - val_loss: 9.4216\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4213 - val_loss: 9.9473\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0878 - val_loss: 9.4890\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2470 - val_loss: 9.9365\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0456 - val_loss: 9.1222\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3202 - val_loss: 9.9137\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2200 - val_loss: 9.1069\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0798 - val_loss: 9.5983\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0104 - val_loss: 9.2440\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2489 - val_loss: 10.3055\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6321 - val_loss: 9.8329\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2670 - val_loss: 9.9688\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2289 - val_loss: 9.8410\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4099 - val_loss: 12.5869\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4405 - val_loss: 9.4099\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0811 - val_loss: 10.3354\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1259 - val_loss: 9.5174\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1054 - val_loss: 9.5620\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2535 - val_loss: 10.4619\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1907 - val_loss: 10.4537\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6166 - val_loss: 9.8793\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4735 - val_loss: 9.2720\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1328 - val_loss: 10.1981\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1996 - val_loss: 9.8741\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0713 - val_loss: 9.6386\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2372 - val_loss: 9.9742\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4757 - val_loss: 10.8484\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4459 - val_loss: 9.8228\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0313 - val_loss: 9.4238\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3765 - val_loss: 10.2918\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4524 - val_loss: 9.1073\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3168 - val_loss: 9.2925\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1893 - val_loss: 9.8871\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1504 - val_loss: 10.2595\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4505 - val_loss: 9.1828\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4558 - val_loss: 10.2113\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2693 - val_loss: 9.1801\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9276 - val_loss: 9.7640\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2973 - val_loss: 11.4217\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9439 - val_loss: 9.4929\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1451 - val_loss: 9.6973\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4184 - val_loss: 10.0119\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4431 - val_loss: 9.3794\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2147 - val_loss: 11.5057\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5948 - val_loss: 9.6214\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6757 - val_loss: 11.3718\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2659 - val_loss: 9.7511\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3014 - val_loss: 9.7286\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3620 - val_loss: 9.6472\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0200 - val_loss: 10.0194\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0611 - val_loss: 11.1703\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4933 - val_loss: 9.4598\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2481 - val_loss: 9.8245\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2872 - val_loss: 9.1588\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2767 - val_loss: 9.8135\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3264 - val_loss: 9.1037\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1761 - val_loss: 9.0106\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0116 - val_loss: 9.3538\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5482 - val_loss: 9.0256\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0520 - val_loss: 11.8033\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3205 - val_loss: 9.2251\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5479 - val_loss: 9.2841\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0899 - val_loss: 8.9697\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9706 - val_loss: 9.4152\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2040 - val_loss: 10.0805\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1734 - val_loss: 9.8815\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1571 - val_loss: 9.0403\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2328 - val_loss: 11.7359\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0369 - val_loss: 9.5580\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2591 - val_loss: 9.5962\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0036 - val_loss: 9.4947\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3197 - val_loss: 9.4408\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3989 - val_loss: 9.1875\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2155 - val_loss: 10.6208\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3221 - val_loss: 10.6992\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6621 - val_loss: 9.3433\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2348 - val_loss: 9.3522\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0777 - val_loss: 10.8626\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4140 - val_loss: 9.2996\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1362 - val_loss: 9.7102\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4300 - val_loss: 9.5612\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5595 - val_loss: 10.7493\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1814 - val_loss: 10.3780\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2557 - val_loss: 9.2695\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0513 - val_loss: 8.9896\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0593 - val_loss: 9.3164\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9711 - val_loss: 9.0145\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1108 - val_loss: 10.4807\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1886 - val_loss: 9.0060\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1424 - val_loss: 8.9840\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8956 - val_loss: 8.8556\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3737 - val_loss: 9.6756\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0820 - val_loss: 9.1357\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9903 - val_loss: 10.3846\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6483 - val_loss: 10.1681\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5608 - val_loss: 9.3936\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4107 - val_loss: 9.4672\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3396 - val_loss: 9.9110\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3644 - val_loss: 10.3145\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1764 - val_loss: 8.8642\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1949 - val_loss: 9.7370\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0921 - val_loss: 9.9615\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3086 - val_loss: 9.8114\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0956 - val_loss: 9.2357\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1693 - val_loss: 10.5090\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1652 - val_loss: 10.0404\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3715 - val_loss: 10.2308\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0738 - val_loss: 10.3170\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4208 - val_loss: 9.6618\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5208 - val_loss: 10.9537\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3787 - val_loss: 9.9284\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2148 - val_loss: 9.3546\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1507 - val_loss: 9.8372\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0400 - val_loss: 9.6574\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5380 - val_loss: 9.4051\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7230 - val_loss: 9.6156\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2375 - val_loss: 9.1159\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7191 - val_loss: 9.9844\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6392 - val_loss: 10.3952\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1678 - val_loss: 9.0004\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8708 - val_loss: 9.1563\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0314 - val_loss: 10.9815\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5184 - val_loss: 9.3072\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3343 - val_loss: 9.6352\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3228 - val_loss: 11.1145\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2853 - val_loss: 9.7267\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4175 - val_loss: 9.8116\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4808 - val_loss: 10.2056\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2738 - val_loss: 9.2392\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9957 - val_loss: 9.6910\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2053 - val_loss: 9.4502\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8184 - val_loss: 9.3751\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1741 - val_loss: 10.0664\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4173 - val_loss: 9.0593\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1822 - val_loss: 9.8499\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0797 - val_loss: 9.0175\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2320 - val_loss: 9.5329\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3463 - val_loss: 9.8008\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1523 - val_loss: 9.0222\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0370 - val_loss: 9.4476\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0763 - val_loss: 8.9244\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1811 - val_loss: 9.1020\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0205 - val_loss: 9.0287\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0743 - val_loss: 9.6344\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2786 - val_loss: 10.5666\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6097 - val_loss: 9.2527\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1499 - val_loss: 9.4358\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0074 - val_loss: 9.6487\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6450 - val_loss: 9.3354\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2744 - val_loss: 10.6822\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5671 - val_loss: 9.4020\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0720 - val_loss: 8.9829\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1139 - val_loss: 10.3955\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4680 - val_loss: 9.5347\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6823 - val_loss: 8.9541\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3563 - val_loss: 8.9404\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1759 - val_loss: 9.2297\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2116 - val_loss: 9.4871\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2433 - val_loss: 9.3187\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9407 - val_loss: 9.9908\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2019 - val_loss: 8.9897\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2724 - val_loss: 12.7073\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4066 - val_loss: 12.4682\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3768 - val_loss: 9.4643\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1955 - val_loss: 9.3174\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.1187 - val_loss: 9.1264\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1569 - val_loss: 12.4363\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0232 - val_loss: 10.0941\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8183 - val_loss: 11.3047\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8939 - val_loss: 9.1313\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2973 - val_loss: 8.8914\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2847 - val_loss: 9.3802\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4552 - val_loss: 9.3046\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0517 - val_loss: 9.2502\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0523 - val_loss: 10.7580\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1738 - val_loss: 9.3897\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4279 - val_loss: 9.4293\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9498 - val_loss: 9.7778\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1435 - val_loss: 9.0919\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1056 - val_loss: 9.6777\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4108 - val_loss: 9.0632\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2527 - val_loss: 9.3788\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3265 - val_loss: 9.3735\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2582 - val_loss: 10.4674\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0833 - val_loss: 9.4236\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1839 - val_loss: 9.5786\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2019 - val_loss: 8.9538\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3417 - val_loss: 11.4980\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4635 - val_loss: 8.8463\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6397 - val_loss: 10.1211\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7474 - val_loss: 10.2284\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4928 - val_loss: 9.2731\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9202 - val_loss: 9.6228\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0156 - val_loss: 9.6599\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0822 - val_loss: 9.8731\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9591 - val_loss: 9.4250\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0600 - val_loss: 9.0800\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3484 - val_loss: 9.3854\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3467 - val_loss: 8.8681\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9137 - val_loss: 9.7279\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7950 - val_loss: 9.8733\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2069 - val_loss: 9.2724\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4769 - val_loss: 9.0890\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0841 - val_loss: 9.7211\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2135 - val_loss: 9.3551\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2841 - val_loss: 9.1215\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0043 - val_loss: 10.1810\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2475 - val_loss: 9.6970\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2729 - val_loss: 10.1936\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9450 - val_loss: 10.3874\n",
      "8.37053843726099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.7677883 ,  3.3786387 ,  1.8246051 ,  0.1774328 , -4.090878  ],\n",
       "        [-1.5376334 , -0.1165167 , -0.49760297,  0.1743749 ,  0.23387308],\n",
       "        [-1.6489935 , -0.01073588, -0.422408  ,  0.26362455, -0.7587081 ],\n",
       "        [ 0.27092138, -0.05603147, -0.01877734, -0.12452704,  0.1712811 ],\n",
       "        [ 0.38842356,  2.4592583 ,  0.30092913,  0.14813006, -0.33776888]],\n",
       "       dtype=float32),\n",
       " array([-0.71774656,  4.8482175 ,  1.3255492 , -1.3909711 , -4.9423018 ],\n",
       "       dtype=float32),\n",
       " array([[-0.49358094, -0.80332774, -0.6153615 , -0.5802122 ,  0.16576518,\n",
       "          0.5420509 , -0.21803573, -0.27171144,  0.30409363, -0.46186498],\n",
       "        [-1.7936229 , -1.1690708 , -1.2502135 , -1.2135376 ,  1.396115  ,\n",
       "          1.8445383 ,  0.7554351 , -1.9695513 , -2.0240016 , -2.0544276 ],\n",
       "        [ 0.69083965,  1.0306183 ,  0.16364534,  0.28036234, -1.1024816 ,\n",
       "          0.00622307, -0.7980508 ,  0.7393603 ,  0.57989544,  1.0012525 ],\n",
       "        [ 1.1746765 ,  1.8081229 ,  1.8896163 ,  1.8406764 , -1.1784774 ,\n",
       "         -2.3764746 , -1.5848624 ,  2.2299476 ,  1.9615242 ,  1.1943647 ],\n",
       "        [ 2.4512684 ,  1.8985122 ,  2.11294   ,  1.6412964 , -1.2264504 ,\n",
       "         -2.5887232 , -1.600354  ,  2.5215688 ,  1.9787439 ,  1.5285423 ]],\n",
       "       dtype=float32),\n",
       " array([-2.2733393, -2.2874277, -2.310883 , -2.0847042,  1.0314039,\n",
       "         2.3512263,  2.081537 , -2.3465917, -2.3223236, -2.2681954],\n",
       "       dtype=float32),\n",
       " array([[-1.7247857],\n",
       "        [-1.80235  ],\n",
       "        [-1.9023492],\n",
       "        [-1.48626  ],\n",
       "        [ 0.8934774],\n",
       "        [ 2.3188405],\n",
       "        [ 1.3216571],\n",
       "        [-2.3100808],\n",
       "        [-2.230333 ],\n",
       "        [-1.8166717]], dtype=float32),\n",
       " array([2.4616568], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_2(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure2_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 136\n",
      "Trainable params: 136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 207us/step - loss: 7571.0139 - val_loss: 371.3410\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 151.2914 - val_loss: 50.8228\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 39.0354 - val_loss: 31.3228\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 32.7595 - val_loss: 28.6751\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 30.4431 - val_loss: 27.4069\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 29.1534 - val_loss: 26.7640\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 28.2407 - val_loss: 26.0428\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 27.8465 - val_loss: 26.1491\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 27.1901 - val_loss: 25.8627\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 26.3930 - val_loss: 25.4471\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 26.0368 - val_loss: 25.3904\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 25.8965 - val_loss: 25.6239\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 25.7439 - val_loss: 25.2047\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 25.4568 - val_loss: 25.6959\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 25.1690 - val_loss: 25.2308\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 25.3140 - val_loss: 25.5301\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 24.7887 - val_loss: 25.2167\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 24.6908 - val_loss: 25.6053\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 24.5397 - val_loss: 25.8849\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 24.3608 - val_loss: 25.1568\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.3527 - val_loss: 25.8264\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.5154 - val_loss: 25.3511\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.0406 - val_loss: 25.5653\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.8577 - val_loss: 25.8881\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 24.0848 - val_loss: 26.0788\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.8093 - val_loss: 25.3657\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.5188 - val_loss: 25.5092\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.8402 - val_loss: 26.0159\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 24.0851 - val_loss: 25.9431\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.2574 - val_loss: 25.5721\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.1110 - val_loss: 25.7149\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.0467 - val_loss: 26.0541\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.1059 - val_loss: 25.7615\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.6956 - val_loss: 25.7763\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.2616 - val_loss: 25.6787\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.5891 - val_loss: 25.6150\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2307 - val_loss: 25.5202\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.1238 - val_loss: 25.4340\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8570 - val_loss: 25.4850\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.8465 - val_loss: 25.4889\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9251 - val_loss: 25.5347\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8664 - val_loss: 25.5405\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3079 - val_loss: 26.6812\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6754 - val_loss: 25.5142\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.0307 - val_loss: 26.2708\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7085 - val_loss: 28.3538\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6691 - val_loss: 25.1568\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.6623 - val_loss: 25.1803\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.8042 - val_loss: 24.7734\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.3028 - val_loss: 25.6688\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8238 - val_loss: 24.5951\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.8223 - val_loss: 24.4294\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4785 - val_loss: 24.6988\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.2076 - val_loss: 24.0256\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.9237 - val_loss: 23.9727\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7387 - val_loss: 23.8307\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5288 - val_loss: 23.5921\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2679 - val_loss: 24.0054\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3673 - val_loss: 23.6451\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4540 - val_loss: 23.4493\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0841 - val_loss: 22.9712\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4271 - val_loss: 22.8439\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9681 - val_loss: 22.9144\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9611 - val_loss: 22.7304\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9807 - val_loss: 22.6567\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9986 - val_loss: 23.1248\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1843 - val_loss: 22.7289\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7216 - val_loss: 23.1541\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6177 - val_loss: 22.7922\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2479 - val_loss: 22.9738\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8131 - val_loss: 21.7531\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3771 - val_loss: 21.3585\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1085 - val_loss: 20.9554\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9563 - val_loss: 21.0343\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4295 - val_loss: 20.7376\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8588 - val_loss: 20.1890\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0717 - val_loss: 21.1640\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.4138 - val_loss: 20.1900\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2357 - val_loss: 19.7533\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.3343 - val_loss: 19.0932\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.2042 - val_loss: 18.9664\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.9006 - val_loss: 19.0284\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.7422 - val_loss: 18.8809\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.7170 - val_loss: 18.4895\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.4757 - val_loss: 18.1417\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4464 - val_loss: 18.9627\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.5629 - val_loss: 17.8983\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.7447 - val_loss: 18.9627\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1120 - val_loss: 18.9798\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4920 - val_loss: 17.3824\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5342 - val_loss: 18.0115\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4348 - val_loss: 17.3457\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3976 - val_loss: 17.7179\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0367 - val_loss: 17.8124\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1855 - val_loss: 18.3336\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8548 - val_loss: 17.5119\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6765 - val_loss: 16.6852\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7657 - val_loss: 16.8640\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5521 - val_loss: 17.1381\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4041 - val_loss: 16.6643\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7229 - val_loss: 16.9372\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7436 - val_loss: 16.3641\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9880 - val_loss: 16.8877\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3317 - val_loss: 16.0552\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1125 - val_loss: 17.1752\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1748 - val_loss: 15.8543\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.1604 - val_loss: 16.3904\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.9003 - val_loss: 16.6321\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 13.4175 - val_loss: 15.7259\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.8731 - val_loss: 17.0271\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.2491 - val_loss: 15.6846\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.5537 - val_loss: 15.9237\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.7011 - val_loss: 16.0049\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.1075 - val_loss: 16.5404\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.9629 - val_loss: 16.1658\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6033 - val_loss: 16.1061\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6607 - val_loss: 17.3223\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1486 - val_loss: 16.4602\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6311 - val_loss: 16.2753\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6991 - val_loss: 15.3288\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5165 - val_loss: 16.4905\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.2680 - val_loss: 19.5893\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.2986 - val_loss: 16.3456\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7868 - val_loss: 15.9972\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8324 - val_loss: 18.6986\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5127 - val_loss: 17.0571\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4037 - val_loss: 17.9275\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.8616 - val_loss: 15.6418\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.7444 - val_loss: 16.6175\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4086 - val_loss: 16.3446\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0403 - val_loss: 15.2139\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3875 - val_loss: 17.2586\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9291 - val_loss: 16.1795\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5200 - val_loss: 15.5906\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7217 - val_loss: 14.9416\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5694 - val_loss: 16.4953\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0729 - val_loss: 15.4684\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0120 - val_loss: 16.2031\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2072 - val_loss: 17.0037\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2636 - val_loss: 15.4178\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8688 - val_loss: 15.1972\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7576 - val_loss: 15.1400\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6885 - val_loss: 14.6653\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2718 - val_loss: 16.5572\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3299 - val_loss: 15.7089\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9266 - val_loss: 15.4064\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2261 - val_loss: 14.6092\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9968 - val_loss: 15.1510\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1297 - val_loss: 16.6617\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1237 - val_loss: 14.9859\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7737 - val_loss: 15.4921\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.2651 - val_loss: 14.6113\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9094 - val_loss: 14.7153\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6275 - val_loss: 14.3459\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5929 - val_loss: 15.0258\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5456 - val_loss: 14.9122\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3735 - val_loss: 14.7842\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0357 - val_loss: 14.8283\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4870 - val_loss: 15.3069\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6134 - val_loss: 15.6189\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0287 - val_loss: 13.9235\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0203 - val_loss: 15.0622\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9725 - val_loss: 14.9346\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.2606 - val_loss: 15.8771\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5519 - val_loss: 14.5218\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9404 - val_loss: 15.2446\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4872 - val_loss: 13.9978\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4238 - val_loss: 14.9891\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8892 - val_loss: 14.9020\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1077 - val_loss: 17.2489\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5025 - val_loss: 14.2150\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0060 - val_loss: 14.3259\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1071 - val_loss: 14.4315\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5838 - val_loss: 13.2258\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1825 - val_loss: 15.2885\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4069 - val_loss: 13.8387\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7382 - val_loss: 14.2193\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0358 - val_loss: 14.7799\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1556 - val_loss: 13.3702\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.1065 - val_loss: 15.7154\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0657 - val_loss: 13.3037\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9051 - val_loss: 13.0267\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2492 - val_loss: 13.1966\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7507 - val_loss: 14.2235\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5207 - val_loss: 15.9887\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9058 - val_loss: 12.9851\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.9937 - val_loss: 14.3566\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.8776 - val_loss: 13.0244\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3506 - val_loss: 13.8773\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0998 - val_loss: 13.1268\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3499 - val_loss: 13.8686\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2766 - val_loss: 17.1586\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.2746 - val_loss: 14.9601\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3535 - val_loss: 15.5562\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3791 - val_loss: 14.6083\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0198 - val_loss: 12.6745\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4642 - val_loss: 13.3343\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6564 - val_loss: 14.4121\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2195 - val_loss: 12.0771\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9115 - val_loss: 12.9438\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7949 - val_loss: 14.1460\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1519 - val_loss: 13.5555\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6055 - val_loss: 12.6821\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5967 - val_loss: 12.6093\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4795 - val_loss: 14.0551\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.7304 - val_loss: 12.4808\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7792 - val_loss: 14.8878\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2998 - val_loss: 12.3646\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1064 - val_loss: 14.0880\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5857 - val_loss: 13.6278\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.8952 - val_loss: 12.7590\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8956 - val_loss: 13.8904\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4037 - val_loss: 13.0231\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.8053 - val_loss: 16.5836\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0918 - val_loss: 12.3885\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1661 - val_loss: 12.2340\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8273 - val_loss: 13.1882\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4429 - val_loss: 12.4635\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1425 - val_loss: 12.5670\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1676 - val_loss: 12.2626\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4106 - val_loss: 12.6423\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2805 - val_loss: 14.1350\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6726 - val_loss: 12.3569\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0013 - val_loss: 12.2160\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8769 - val_loss: 12.3370\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4573 - val_loss: 12.1619\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6327 - val_loss: 12.9489\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7428 - val_loss: 14.9920\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2424 - val_loss: 13.2755\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3587 - val_loss: 12.3111\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4536 - val_loss: 12.4108\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7061 - val_loss: 11.5112\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8432 - val_loss: 11.9443\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3958 - val_loss: 11.9599\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8107 - val_loss: 12.7804\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6569 - val_loss: 11.6597\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8044 - val_loss: 12.1969\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3598 - val_loss: 12.2344\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7002 - val_loss: 15.0291\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1220 - val_loss: 11.8623\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9975 - val_loss: 11.9062\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.9221 - val_loss: 12.6806\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8080 - val_loss: 12.3680\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7347 - val_loss: 12.4236\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5744 - val_loss: 11.9805\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1928 - val_loss: 11.9392\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.7381 - val_loss: 12.0122\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.2957 - val_loss: 14.3874\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0326 - val_loss: 13.6649\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3605 - val_loss: 11.6441\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8846 - val_loss: 11.2876\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5587 - val_loss: 12.2959\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8015 - val_loss: 12.0188\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4977 - val_loss: 15.7526\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2542 - val_loss: 11.0482\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1254 - val_loss: 12.6331\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4194 - val_loss: 11.6291\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7714 - val_loss: 12.6679\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2493 - val_loss: 12.9836\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9781 - val_loss: 12.4322\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6902 - val_loss: 11.2181\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3239 - val_loss: 12.5266\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6562 - val_loss: 11.5409\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3528 - val_loss: 11.6488\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2923 - val_loss: 11.6767\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8088 - val_loss: 11.2152\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9007 - val_loss: 13.8033\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8918 - val_loss: 11.0181\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.3526 - val_loss: 13.2454\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4490 - val_loss: 12.7951\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6087 - val_loss: 12.1435\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5381 - val_loss: 11.5753\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5089 - val_loss: 11.2321\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1622 - val_loss: 11.4822\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.7990 - val_loss: 11.5294\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2235 - val_loss: 10.9899\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3984 - val_loss: 11.5196\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.4018 - val_loss: 11.4187\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4096 - val_loss: 14.2232\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5697 - val_loss: 11.7215\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2093 - val_loss: 11.5694\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1880 - val_loss: 13.3909\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4514 - val_loss: 11.1574\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0750 - val_loss: 11.8575\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4612 - val_loss: 11.4266\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3124 - val_loss: 10.8484\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9277 - val_loss: 10.2872\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0400 - val_loss: 11.0033\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3872 - val_loss: 12.7422\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6974 - val_loss: 11.2867\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7082 - val_loss: 10.9648\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8969 - val_loss: 10.6155\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5505 - val_loss: 11.1827\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7440 - val_loss: 10.8157\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7084 - val_loss: 11.6913\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3142 - val_loss: 11.8004\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5012 - val_loss: 11.6024\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1396 - val_loss: 10.8516\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5360 - val_loss: 11.3700\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0050 - val_loss: 9.9258\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5678 - val_loss: 10.5103\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5658 - val_loss: 10.4418\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5220 - val_loss: 10.1472\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2938 - val_loss: 11.6051\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0702 - val_loss: 10.0577\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3834 - val_loss: 9.8616\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5580 - val_loss: 11.1546\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4277 - val_loss: 9.8191\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6713 - val_loss: 11.0288\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3361 - val_loss: 10.5015\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7264 - val_loss: 10.6254\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8449 - val_loss: 9.7961\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3894 - val_loss: 9.4308\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3178 - val_loss: 10.5897\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3420 - val_loss: 10.3061\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4059 - val_loss: 9.9369\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5144 - val_loss: 9.4210\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2588 - val_loss: 11.3990\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4405 - val_loss: 9.3361\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7403 - val_loss: 9.8212\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3691 - val_loss: 9.7879\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7757 - val_loss: 10.8996\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2059 - val_loss: 10.2904\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7586 - val_loss: 9.9272\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3925 - val_loss: 11.6251\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3299 - val_loss: 9.5293\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0878 - val_loss: 9.8460\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6288 - val_loss: 9.3972\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2142 - val_loss: 9.7743\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1082 - val_loss: 9.2274\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1507 - val_loss: 9.9084\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5256 - val_loss: 9.4967\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2016 - val_loss: 9.1754\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8974 - val_loss: 10.2825\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0334 - val_loss: 9.5240\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7360 - val_loss: 9.7809\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4686 - val_loss: 11.0667\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7604 - val_loss: 11.2459\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6770 - val_loss: 9.6107\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0217 - val_loss: 9.0626\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2966 - val_loss: 9.5127\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9201 - val_loss: 9.8339\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3229 - val_loss: 9.1518\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4016 - val_loss: 11.0879\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7523 - val_loss: 9.2651\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6923 - val_loss: 9.7693\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9511 - val_loss: 10.0446\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2061 - val_loss: 10.8059\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1649 - val_loss: 10.7498\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1687 - val_loss: 9.4044\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0244 - val_loss: 9.4853\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3308 - val_loss: 9.7123\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7767 - val_loss: 9.5181\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.8426 - val_loss: 9.8295\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6968 - val_loss: 9.4779\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9130 - val_loss: 9.0749\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8048 - val_loss: 9.0433\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9005 - val_loss: 9.0980\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9038 - val_loss: 9.4690\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3583 - val_loss: 8.9250\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0866 - val_loss: 9.2834\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0088 - val_loss: 9.8725\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0624 - val_loss: 9.3752\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8454 - val_loss: 9.4995\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1174 - val_loss: 9.2235\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8736 - val_loss: 8.9203\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7912 - val_loss: 9.2475\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2847 - val_loss: 10.1589\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9227 - val_loss: 9.9905\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1342 - val_loss: 11.8716\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2523 - val_loss: 8.9919\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5307 - val_loss: 9.2813\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7111 - val_loss: 9.2683\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8192 - val_loss: 9.3338\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7393 - val_loss: 9.1655\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9177 - val_loss: 10.4288\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6378 - val_loss: 10.0374\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0764 - val_loss: 9.0820\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7209 - val_loss: 9.3773\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4427 - val_loss: 9.7278\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5265 - val_loss: 11.6332\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7950 - val_loss: 9.2145\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6665 - val_loss: 8.8585\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9701 - val_loss: 8.7671\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8756 - val_loss: 10.2541\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9299 - val_loss: 9.6602\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6841 - val_loss: 8.8830\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1413 - val_loss: 9.4212\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8529 - val_loss: 9.2478\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7358 - val_loss: 9.8400\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6285 - val_loss: 9.0180\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8177 - val_loss: 9.7276\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6841 - val_loss: 9.0411\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9930 - val_loss: 8.6823\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9946 - val_loss: 8.7701\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1462 - val_loss: 12.2733\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9545 - val_loss: 8.9291\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6593 - val_loss: 9.6263\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6783 - val_loss: 8.9269\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7022 - val_loss: 10.6602\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8355 - val_loss: 9.7132\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6684 - val_loss: 10.2303\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9156 - val_loss: 9.1415\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9622 - val_loss: 9.2009\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6472 - val_loss: 9.3277\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6121 - val_loss: 8.8767\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4932 - val_loss: 9.9191\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9352 - val_loss: 9.2038\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8290 - val_loss: 9.5692\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3604 - val_loss: 9.5509\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5532 - val_loss: 9.8936\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8018 - val_loss: 9.1354\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8314 - val_loss: 9.1719\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2521 - val_loss: 8.9174\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7129 - val_loss: 10.0682\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5502 - val_loss: 10.2699\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0681 - val_loss: 9.5174\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4485 - val_loss: 8.7632\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1465 - val_loss: 9.0484\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9995 - val_loss: 10.1065\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4083 - val_loss: 8.9790\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8649 - val_loss: 9.3739\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3284 - val_loss: 9.2322\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5846 - val_loss: 9.4600\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4587 - val_loss: 8.7723\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7361 - val_loss: 9.9756\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5540 - val_loss: 10.0282\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5800 - val_loss: 8.8481\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8773 - val_loss: 9.7543\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7565 - val_loss: 9.1865\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7691 - val_loss: 10.1019\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6970 - val_loss: 9.2051\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9909 - val_loss: 9.1513\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7362 - val_loss: 10.8324\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8909 - val_loss: 10.0483\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0298 - val_loss: 9.5874\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6876 - val_loss: 10.2546\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9060 - val_loss: 10.3882\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.7323 - val_loss: 9.2047\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7132 - val_loss: 10.3312\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5516 - val_loss: 8.4693\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7108 - val_loss: 9.6498\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7722 - val_loss: 8.9618\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5615 - val_loss: 9.5032\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5634 - val_loss: 9.5002\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5005 - val_loss: 8.9081\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7897 - val_loss: 8.8549\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9415 - val_loss: 9.3061\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8826 - val_loss: 9.3039\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0378 - val_loss: 8.6756\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6238 - val_loss: 9.4770\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4781 - val_loss: 10.3450\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5373 - val_loss: 12.3056\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9715 - val_loss: 9.9314\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2912 - val_loss: 9.5418\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0643 - val_loss: 8.9685\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5051 - val_loss: 9.9386\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9309 - val_loss: 9.6460\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8917 - val_loss: 8.9677\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8885 - val_loss: 9.2480\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9407 - val_loss: 10.7684\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7032 - val_loss: 8.9969\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4702 - val_loss: 8.5839\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6726 - val_loss: 9.3760\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0575 - val_loss: 12.0839\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1533 - val_loss: 9.6719\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5707 - val_loss: 8.7344\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6381 - val_loss: 8.5962\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5879 - val_loss: 9.3726\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4094 - val_loss: 9.7011\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8954 - val_loss: 9.9061\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9181 - val_loss: 9.6143\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0016 - val_loss: 8.9680\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6620 - val_loss: 9.5242\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6161 - val_loss: 9.1129\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6950 - val_loss: 9.8086\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6370 - val_loss: 8.8257\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5179 - val_loss: 8.5538\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1119 - val_loss: 8.5923\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9090 - val_loss: 9.0204\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8156 - val_loss: 9.5677\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5762 - val_loss: 9.8437\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6266 - val_loss: 9.0854\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4099 - val_loss: 9.9198\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9737 - val_loss: 8.9956\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4129 - val_loss: 8.6953\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3056 - val_loss: 9.0303\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4777 - val_loss: 8.9857\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4907 - val_loss: 9.4257\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6911 - val_loss: 8.9962\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5967 - val_loss: 8.9128\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4125 - val_loss: 11.3779\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2782 - val_loss: 10.1818\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0687 - val_loss: 8.7979\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4794 - val_loss: 9.4443\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8711 - val_loss: 9.4294\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4779 - val_loss: 8.8603\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0083 - val_loss: 9.7210\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.7925 - val_loss: 10.4482\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9148 - val_loss: 8.8974\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5179 - val_loss: 8.8204\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8085 - val_loss: 9.0869\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7316 - val_loss: 9.4120\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0074 - val_loss: 9.2310\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5257 - val_loss: 8.4286\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8039 - val_loss: 9.0267\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2278 - val_loss: 9.3100\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3461 - val_loss: 8.8635\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7953 - val_loss: 10.3010\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3163 - val_loss: 10.4338\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8875 - val_loss: 9.4694\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7961 - val_loss: 10.2578\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8241 - val_loss: 9.4116\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 7.8568 - val_loss: 10.3584\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.4691 - val_loss: 8.9289\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5370 - val_loss: 9.1023\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6966 - val_loss: 10.2054\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7667 - val_loss: 11.5665\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0824 - val_loss: 9.5219\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5277 - val_loss: 10.1230\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7223 - val_loss: 8.8530\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7092 - val_loss: 9.5066\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1265 - val_loss: 9.5113\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 8.1073 - val_loss: 9.4838\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 158us/step - loss: 7.0486 - val_loss: 9.4815\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 153us/step - loss: 8.2884 - val_loss: 9.6245\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 144us/step - loss: 7.8240 - val_loss: 9.2728\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 7.8845 - val_loss: 9.0563\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1921 - val_loss: 9.0259\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.2355 - val_loss: 9.6139\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 228us/step - loss: 7.8389 - val_loss: 9.7335\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 155us/step - loss: 7.5716 - val_loss: 8.8550\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6880 - val_loss: 9.3365\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7219 - val_loss: 9.2764\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5597 - val_loss: 9.7006\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8633 - val_loss: 9.0477\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.0053 - val_loss: 11.6309\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0318 - val_loss: 9.4961\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5464 - val_loss: 9.4214\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6953 - val_loss: 8.9385\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.5558 - val_loss: 10.2720\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.7555 - val_loss: 8.9759\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0546 - val_loss: 9.8722\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9745 - val_loss: 8.6697\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 7.8641 - val_loss: 9.0583\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.4204 - val_loss: 9.9978\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8925 - val_loss: 8.4225\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.4991 - val_loss: 9.0051\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9228 - val_loss: 8.6751\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.7831 - val_loss: 8.6585\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4395 - val_loss: 8.6957\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2816 - val_loss: 8.6843\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4676 - val_loss: 8.5550\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6018 - val_loss: 8.5206\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5173 - val_loss: 9.2515\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0248 - val_loss: 8.5613\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4627 - val_loss: 9.3162\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7028 - val_loss: 8.7866\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7298 - val_loss: 9.9526\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.2995 - val_loss: 9.4313\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 132us/step - loss: 7.6677 - val_loss: 8.9215\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 122us/step - loss: 7.7242 - val_loss: 9.5825\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 7.9921 - val_loss: 8.4702\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3892 - val_loss: 8.8501\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4356 - val_loss: 8.6609\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6979 - val_loss: 9.6941\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5727 - val_loss: 8.9556\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6075 - val_loss: 9.1989\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6689 - val_loss: 8.5329\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3240 - val_loss: 9.0830\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5925 - val_loss: 8.9081\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3999 - val_loss: 9.5917\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2869 - val_loss: 8.7171\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2914 - val_loss: 9.2364\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3878 - val_loss: 8.8587\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1130 - val_loss: 9.0561\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5754 - val_loss: 10.3748\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.6857 - val_loss: 9.8483\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1182 - val_loss: 9.0425\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8543 - val_loss: 8.4588\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7517 - val_loss: 8.5782\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2286 - val_loss: 9.7340\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0811 - val_loss: 11.8601\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.6135 - val_loss: 10.2910\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.1515 - val_loss: 8.8610\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 7.4239 - val_loss: 9.0833\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.8757 - val_loss: 8.6214\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4345 - val_loss: 10.0287\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0224 - val_loss: 8.6994\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3876 - val_loss: 9.7307\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0550 - val_loss: 9.4533\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 7.4854 - val_loss: 8.4489\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.8974 - val_loss: 9.4620\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 8.0395 - val_loss: 9.5163\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 155us/step - loss: 7.9128 - val_loss: 8.5677\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 121us/step - loss: 7.3600 - val_loss: 8.7327\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 126us/step - loss: 7.9231 - val_loss: 10.1790\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.3692 - val_loss: 8.6484\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 7.2872 - val_loss: 9.1656\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.5625 - val_loss: 8.6203\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4133 - val_loss: 11.2940\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6337 - val_loss: 9.8868\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.0261 - val_loss: 9.2992\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5139 - val_loss: 8.5495\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3920 - val_loss: 9.5652\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.6922 - val_loss: 9.3151\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8505 - val_loss: 9.7610\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.7160 - val_loss: 9.1682\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.4859 - val_loss: 8.6830\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.3487 - val_loss: 9.0246\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.1861 - val_loss: 9.2826\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.7908 - val_loss: 10.6069\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1621 - val_loss: 10.2500\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.7519 - val_loss: 9.2743\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.5049 - val_loss: 9.1170\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5612 - val_loss: 9.0466\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3751 - val_loss: 8.8974\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6383 - val_loss: 9.3478\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5667 - val_loss: 9.9846\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9113 - val_loss: 8.9294\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.3555 - val_loss: 8.8096\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7321 - val_loss: 9.9445\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7224 - val_loss: 9.4478\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0290 - val_loss: 10.1576\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6496 - val_loss: 8.6285\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7550 - val_loss: 10.1454\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.7173 - val_loss: 9.2480\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0471 - val_loss: 9.2648\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6828 - val_loss: 8.6325\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6662 - val_loss: 9.8336\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1306 - val_loss: 9.3211\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5932 - val_loss: 9.0096\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.7526 - val_loss: 9.5744\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5672 - val_loss: 8.3607\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.2750 - val_loss: 8.4929\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7187 - val_loss: 8.5046\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.1125 - val_loss: 9.3776\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6144 - val_loss: 9.6880\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3614 - val_loss: 8.8017\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6456 - val_loss: 8.6832\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5447 - val_loss: 8.6969\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.7531 - val_loss: 8.6069\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0358 - val_loss: 9.2922\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8653 - val_loss: 8.4186\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.1061 - val_loss: 11.0445\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.5106 - val_loss: 9.0740\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.5630 - val_loss: 8.7982\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.3354 - val_loss: 8.5485\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.4419 - val_loss: 8.9830\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.6489 - val_loss: 10.6055\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 7.9994 - val_loss: 9.3337\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.2791 - val_loss: 10.6624\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.1225 - val_loss: 9.4261\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.4717 - val_loss: 9.1106\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.4731 - val_loss: 9.6590\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3678 - val_loss: 8.9321\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.7679 - val_loss: 8.5679\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.6337 - val_loss: 9.2000\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.0418 - val_loss: 8.7633\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 8.3364 - val_loss: 9.1038\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 7.5742 - val_loss: 9.2864\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5885 - val_loss: 8.2211\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3874 - val_loss: 8.8024\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7919 - val_loss: 8.7501\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1264 - val_loss: 8.7910\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6398 - val_loss: 9.5899\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6073 - val_loss: 9.1099\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 8s 7ms/step - loss: 7.6174 - val_loss: 9.0341\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4732 - val_loss: 9.8276\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8803 - val_loss: 8.4680\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3798 - val_loss: 9.2975\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5955 - val_loss: 8.5633\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2019 - val_loss: 9.3670\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6527 - val_loss: 8.4002\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6860 - val_loss: 8.8688\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1531 - val_loss: 11.4489\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7648 - val_loss: 8.3455\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8659 - val_loss: 10.1701\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5121 - val_loss: 8.5415\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.1417 - val_loss: 8.8956\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.4387 - val_loss: 9.3583\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.5744 - val_loss: 9.3102\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4584 - val_loss: 9.1040\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6204 - val_loss: 9.3515\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4552 - val_loss: 9.8251\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0989 - val_loss: 9.1586\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6734 - val_loss: 10.4526\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.7588 - val_loss: 9.2689\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.6257 - val_loss: 8.7119\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.5377 - val_loss: 8.8110\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.5818 - val_loss: 8.8466\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.6129 - val_loss: 8.7794\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.0022 - val_loss: 8.8902\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.8388 - val_loss: 9.5905\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 7.4576 - val_loss: 9.4210\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.5923 - val_loss: 9.8073\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.7459 - val_loss: 8.7201\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.6353 - val_loss: 9.3877\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.4315 - val_loss: 8.9207\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.6896 - val_loss: 9.8229\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 131us/step - loss: 9.3321 - val_loss: 8.7475\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.9475 - val_loss: 8.9528\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.3847 - val_loss: 8.5798\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.4722 - val_loss: 8.7714\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.4994 - val_loss: 9.8129\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.7508 - val_loss: 10.0150\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 8.0691 - val_loss: 9.4122\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.0375 - val_loss: 9.6809\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.6969 - val_loss: 9.3141\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 7.6424 - val_loss: 8.6229\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.0467 - val_loss: 8.9173\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.797 - 0s 119us/step - loss: 7.6762 - val_loss: 9.3449\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.2725 - val_loss: 8.8505\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.4343 - val_loss: 8.9106\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.4990 - val_loss: 8.3280\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.5461 - val_loss: 9.7402\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.6019 - val_loss: 9.5684\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.2418 - val_loss: 9.2792\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.9484 - val_loss: 9.5206\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.4560 - val_loss: 10.2629\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.4907 - val_loss: 9.6162\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.6618 - val_loss: 8.6277\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.5796 - val_loss: 9.0641\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.4411 - val_loss: 9.1788\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.3347 - val_loss: 8.3433\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6857 - val_loss: 9.2130\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.0433 - val_loss: 8.5015\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.6902 - val_loss: 9.7791\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 121us/step - loss: 7.6459 - val_loss: 8.3917\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 7.1760 - val_loss: 9.1207\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.1086 - val_loss: 13.2867\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.2543 - val_loss: 9.4863\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.7439 - val_loss: 8.4423\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 7.7768 - val_loss: 9.3988\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 131us/step - loss: 7.5008 - val_loss: 8.5234\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 7.5224 - val_loss: 10.1316\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 138us/step - loss: 7.7012 - val_loss: 8.5192\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 7.4211 - val_loss: 9.4825\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 7.5728 - val_loss: 8.8530\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 138us/step - loss: 7.5130 - val_loss: 8.3767\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.4673 - val_loss: 11.3125\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.0366 - val_loss: 10.2705\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 8.2173 - val_loss: 8.8127\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 7.6957 - val_loss: 8.8605\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3901 - val_loss: 8.7615\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 7.5353 - val_loss: 8.6813\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.4139 - val_loss: 9.0580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.2463 - val_loss: 8.3448\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.5172 - val_loss: 10.4147\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.5253 - val_loss: 8.6133\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5140 - val_loss: 8.2844\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.3435 - val_loss: 8.8620\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.6129 - val_loss: 9.0153\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.4127 - val_loss: 9.7274\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.5087 - val_loss: 9.7952\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.7269 - val_loss: 8.4787\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7537 - val_loss: 9.2293\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6011 - val_loss: 8.6554\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9724 - val_loss: 9.4561\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5242 - val_loss: 8.4021\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4418 - val_loss: 8.6123\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4017 - val_loss: 9.8166\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.8625 - val_loss: 8.9084\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3818 - val_loss: 8.7828\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4743 - val_loss: 9.0610\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7791 - val_loss: 10.1945\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8907 - val_loss: 11.9616\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7543 - val_loss: 9.2723\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.2233 - val_loss: 9.6964\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4073 - val_loss: 8.5613\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6298 - val_loss: 8.8743\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.4214 - val_loss: 8.1548\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.6692 - val_loss: 8.8962\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0364 - val_loss: 8.3591\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2493 - val_loss: 8.9987\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5674 - val_loss: 9.3365\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4281 - val_loss: 8.5799\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1753 - val_loss: 8.6828\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2288 - val_loss: 8.8652\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4476 - val_loss: 10.4545\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0444 - val_loss: 10.6508\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.8075 - val_loss: 9.2024\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3221 - val_loss: 8.9639\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.3621 - val_loss: 8.7458\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1537 - val_loss: 9.5497\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9206 - val_loss: 8.4220\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.4906 - val_loss: 9.5550\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4561 - val_loss: 8.4803\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.3884 - val_loss: 8.5924\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.9840 - val_loss: 8.7747\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1554 - val_loss: 12.4836\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6262 - val_loss: 9.0697\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.6488 - val_loss: 11.1721\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.7542 - val_loss: 8.4318\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4837 - val_loss: 8.8600\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4824 - val_loss: 8.3908\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1683 - val_loss: 11.0848\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5470 - val_loss: 8.6746\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1659 - val_loss: 9.6273\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4673 - val_loss: 8.5545\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8067 - val_loss: 8.4683\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.2896 - val_loss: 8.9339\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.6582 - val_loss: 8.7278\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4102 - val_loss: 8.8165\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4719 - val_loss: 8.9812\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3493 - val_loss: 9.1834\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.7233 - val_loss: 8.5065\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7524 - val_loss: 8.2618\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4255 - val_loss: 8.3445\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6228 - val_loss: 9.0608\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.9116 - val_loss: 8.6103\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5725 - val_loss: 8.3951\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6292 - val_loss: 10.3337\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.8781 - val_loss: 8.5414\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7628 - val_loss: 10.1315\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3315 - val_loss: 8.2883\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5336 - val_loss: 8.3735\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3753 - val_loss: 9.4022\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7779 - val_loss: 8.9097\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3918 - val_loss: 8.8718\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5449 - val_loss: 10.2176\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4106 - val_loss: 10.7298\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1533 - val_loss: 8.4293\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4117 - val_loss: 8.5260\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4787 - val_loss: 9.2301\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6561 - val_loss: 8.7214\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4885 - val_loss: 8.4450\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8054 - val_loss: 8.3886\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4378 - val_loss: 9.2095\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6798 - val_loss: 9.9837\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4680 - val_loss: 8.8883\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5110 - val_loss: 8.5835\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5541 - val_loss: 9.3002\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6373 - val_loss: 9.2625\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7937 - val_loss: 8.8176\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5473 - val_loss: 9.0603\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2811 - val_loss: 8.2129\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4612 - val_loss: 8.9465\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4141 - val_loss: 9.0506\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5502 - val_loss: 9.7612\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.7036 - val_loss: 8.5294\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5016 - val_loss: 9.3689\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5230 - val_loss: 9.0084\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6117 - val_loss: 8.8142\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3283 - val_loss: 8.5624\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.3210 - val_loss: 9.0763\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3998 - val_loss: 8.2321\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.2786 - val_loss: 8.7098\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5518 - val_loss: 8.4235\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3199 - val_loss: 8.5651\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9326 - val_loss: 10.7582\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3401 - val_loss: 8.3569\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2783 - val_loss: 8.8736\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.5683 - val_loss: 11.2527\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5172 - val_loss: 8.5780\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4814 - val_loss: 9.0731\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3627 - val_loss: 10.8111\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6137 - val_loss: 9.9195\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3598 - val_loss: 8.1002\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8193 - val_loss: 10.1702\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7203 - val_loss: 8.4600\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6190 - val_loss: 8.7065\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3817 - val_loss: 8.7088\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5713 - val_loss: 9.0201\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4768 - val_loss: 8.3514\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7026 - val_loss: 8.5028\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.6940 - val_loss: 8.2861\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.5171 - val_loss: 8.1879\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2421 - val_loss: 9.1906\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8362 - val_loss: 9.3402\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5215 - val_loss: 8.5944\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.6648 - val_loss: 9.2235\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.2666 - val_loss: 8.2944\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8100 - val_loss: 9.6433\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1371 - val_loss: 9.6160\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4966 - val_loss: 8.6539\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.5096 - val_loss: 12.5010\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3047 - val_loss: 10.5370\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.3613 - val_loss: 8.5737\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 7.8688 - val_loss: 8.5429\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.4528 - val_loss: 8.5535\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.6024 - val_loss: 8.5132\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.7166 - val_loss: 9.1473\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.6359 - val_loss: 9.0518\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.5764 - val_loss: 8.1992\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 135us/step - loss: 7.2739 - val_loss: 8.7164\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.5799 - val_loss: 8.2906\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.8369 - val_loss: 9.5220\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0340 - val_loss: 8.9736\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2446 - val_loss: 8.6697\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8955 - val_loss: 9.3988\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3001 - val_loss: 9.1690\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.3774 - val_loss: 9.1748\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5697 - val_loss: 9.0765\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.6716 - val_loss: 8.9839\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8195 - val_loss: 8.4010\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.3803 - val_loss: 10.3887\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2197 - val_loss: 8.7876\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3808 - val_loss: 8.6927\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8042 - val_loss: 9.2207\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.5773 - val_loss: 9.2835\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4531 - val_loss: 9.0779\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5015 - val_loss: 8.4642\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6467 - val_loss: 10.5129\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5275 - val_loss: 9.4706\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8789 - val_loss: 9.3211\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4020 - val_loss: 8.3284\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8567 - val_loss: 8.8059\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5869 - val_loss: 9.5949\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5057 - val_loss: 9.0015\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0787 - val_loss: 8.6363\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7893 - val_loss: 9.3335\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3239 - val_loss: 8.9819\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.3327 - val_loss: 8.5056\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4206 - val_loss: 8.5101\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9442 - val_loss: 8.4812\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9323 - val_loss: 8.5436\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6704 - val_loss: 8.8174\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3790 - val_loss: 8.9672\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3319 - val_loss: 8.7210\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9828 - val_loss: 9.2920\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5857 - val_loss: 8.4700\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9180 - val_loss: 9.3717\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.4448 - val_loss: 9.5751\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5114 - val_loss: 11.3688\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4342 - val_loss: 8.8723\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4547 - val_loss: 9.5585\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.8731 - val_loss: 8.3766\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5682 - val_loss: 8.4773\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4566 - val_loss: 8.7657\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6314 - val_loss: 10.2326\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.4004 - val_loss: 8.6669\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 7.5735 - val_loss: 8.7470\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3298 - val_loss: 8.9064\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.2705 - val_loss: 8.6561\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9873 - val_loss: 9.3642\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.7556 - val_loss: 8.9052\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3888 - val_loss: 9.5007\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7390 - val_loss: 8.8356\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4887 - val_loss: 9.4467\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4362 - val_loss: 8.5174\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.2869 - val_loss: 8.6348\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5298 - val_loss: 8.6164\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0819 - val_loss: 9.2137\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1400 - val_loss: 8.6068\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3284 - val_loss: 9.1346\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2591 - val_loss: 8.6802\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3246 - val_loss: 8.5320\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2960 - val_loss: 8.6064\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5813 - val_loss: 8.3503\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4248 - val_loss: 8.7040\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.9306 - val_loss: 8.2461\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5076 - val_loss: 8.9730\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5660 - val_loss: 9.5280\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3471 - val_loss: 8.5588\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9314 - val_loss: 8.7625\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.4155 - val_loss: 8.4093\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.9230 - val_loss: 8.4030\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5230 - val_loss: 9.4000\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5870 - val_loss: 8.3812\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7089 - val_loss: 8.7627\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5870 - val_loss: 9.3330\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6259 - val_loss: 9.2728\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5730 - val_loss: 8.9300\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8048 - val_loss: 9.4051\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.1299 - val_loss: 8.9351\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4667 - val_loss: 8.4206\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3749 - val_loss: 12.8830\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.3359 - val_loss: 9.4702\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2440 - val_loss: 9.4491\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.7895 - val_loss: 8.7018\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.7394 - val_loss: 8.5796\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6059 - val_loss: 8.5470\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3754 - val_loss: 9.1304\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0913 - val_loss: 9.4597\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.1814 - val_loss: 8.6680\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5533 - val_loss: 8.6027\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.6335 - val_loss: 8.4866\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.7869 - val_loss: 8.7380\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.4681 - val_loss: 8.8813\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.5728 - val_loss: 10.8663\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.2116 - val_loss: 9.0210\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.7486 - val_loss: 9.4328\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.9881 - val_loss: 8.6522\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.9088 - val_loss: 9.6845\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.8577 - val_loss: 8.9206\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.2773 - val_loss: 8.6957\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5005 - val_loss: 9.8897\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3264 - val_loss: 9.1222\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3516 - val_loss: 8.2071\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.3000 - val_loss: 8.3819\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.2619 - val_loss: 9.1231\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.4940 - val_loss: 8.4043\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0097 - val_loss: 8.8320\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2970 - val_loss: 8.9061\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5853 - val_loss: 9.0509\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.4575 - val_loss: 8.1770\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.7977 - val_loss: 9.1455\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.0347 - val_loss: 8.9810\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4629 - val_loss: 8.6991\n",
      "6.89828661796266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.7919672 ,  2.1022475 , -0.17914449, -3.173222  , -0.5609557 ],\n",
       "        [ 0.25407743,  0.09484929, -0.2519919 ,  0.15588671, -0.26156175],\n",
       "        [ 0.15325333,  0.0568601 , -0.62885857, -0.97730666,  0.60064954],\n",
       "        [ 0.12000665, -0.08048029,  0.09868743,  0.13511463,  0.0538561 ],\n",
       "        [-0.25885865,  1.4075347 , -0.10699441, -0.157861  , -1.0371504 ]],\n",
       "       dtype=float32),\n",
       " array([-1.5383961,  3.1506953, -0.2629808, -4.4808993, -1.0722444],\n",
       "       dtype=float32),\n",
       " array([[-0.09233887,  0.481585  , -0.36302447,  0.00980702, -0.40432152,\n",
       "          0.37571558, -0.654326  ,  0.4271522 ,  0.23243321, -0.39100522,\n",
       "         -0.42023462,  0.6639396 , -0.8765567 ,  0.39006215, -0.28157026],\n",
       "        [-1.0166435 ,  1.8106722 , -2.1201212 , -1.1487098 , -2.1342962 ,\n",
       "          1.4021574 , -1.7075852 ,  1.2510626 ,  1.784408  , -1.3969655 ,\n",
       "         -1.4233822 ,  1.5004185 , -2.2376816 ,  1.9360279 , -1.6135662 ],\n",
       "        [-0.18518306,  0.35424858, -1.0290703 , -0.53976727, -0.86087614,\n",
       "          0.93118304, -1.2524363 ,  0.18752144,  0.5712115 , -0.11559038,\n",
       "         -0.44861504,  1.155791  , -0.9364561 ,  0.28388667, -0.8392524 ],\n",
       "        [ 1.5076213 , -1.57572   ,  1.8217641 ,  1.401756  ,  2.108999  ,\n",
       "         -1.4179431 ,  1.4558295 , -2.0046449 , -2.1245372 ,  1.4235528 ,\n",
       "          1.9692063 , -2.0341861 ,  2.3104312 , -2.056918  ,  1.5270793 ],\n",
       "        [-0.69085836, -0.4965013 , -0.47901905, -0.07791085,  0.18118173,\n",
       "          0.05702275, -0.62400264,  0.63869894,  0.16249415, -0.6092114 ,\n",
       "          0.27809092,  0.5232473 , -0.42695498,  0.6066106 , -0.28733996]],\n",
       "       dtype=float32),\n",
       " array([-2.1833158,  1.8854189, -2.336365 , -2.223617 , -2.3589287,\n",
       "         2.318967 , -2.33232  ,  2.245432 ,  2.337506 , -2.1775334,\n",
       "        -2.2829142,  2.304492 , -2.3596795,  2.2841272, -2.3384037],\n",
       "       dtype=float32),\n",
       " array([[-1.1982055],\n",
       "        [ 1.254533 ],\n",
       "        [-1.6827941],\n",
       "        [-1.421341 ],\n",
       "        [-1.8629618],\n",
       "        [ 1.8106916],\n",
       "        [-1.7862612],\n",
       "        [ 1.3611984],\n",
       "        [ 1.689381 ],\n",
       "        [-1.2104155],\n",
       "        [-1.5282568],\n",
       "        [ 1.5197862],\n",
       "        [-2.035165 ],\n",
       "        [ 1.5358232],\n",
       "        [-1.8725696]], dtype=float32),\n",
       " array([2.467388], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_3(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure3_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 271us/step - loss: 8255.0172 - val_loss: 994.4898\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 199.1649 - val_loss: 44.0001\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 32.2267 - val_loss: 30.2602\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 26.2481 - val_loss: 27.5073\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 23.1028 - val_loss: 25.7107\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 21.2252 - val_loss: 24.9312\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 20.2284 - val_loss: 25.2935\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 19.6550 - val_loss: 24.5684\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 19.2819 - val_loss: 24.2453\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 18.8455 - val_loss: 24.1436\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 18.5810 - val_loss: 24.2996\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 18.4625 - val_loss: 23.2837\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 18.3355 - val_loss: 23.3928\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 126us/step - loss: 18.0489 - val_loss: 23.0883\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 17.8360 - val_loss: 22.8137\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.6246 - val_loss: 23.5524\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.7952 - val_loss: 22.3385\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5631 - val_loss: 22.5274\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 17.2753 - val_loss: 22.4716\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 17.2870 - val_loss: 22.8614\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 17.2102 - val_loss: 21.6690\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 17.0049 - val_loss: 21.3639\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 17.0275 - val_loss: 21.4073\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 16.8691 - val_loss: 21.0715\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 16.8168 - val_loss: 21.4448\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 16.7611 - val_loss: 21.7080\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 16.6622 - val_loss: 20.5730\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 16.5236 - val_loss: 20.3843\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.3572 - val_loss: 20.2482\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.6034 - val_loss: 21.1147\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.4151 - val_loss: 21.3834\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.2620 - val_loss: 20.2441\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.1651 - val_loss: 20.5687\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.2268 - val_loss: 19.9729\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.9980 - val_loss: 20.1906\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.0034 - val_loss: 19.9633\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.9279 - val_loss: 19.5837\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.8446 - val_loss: 19.2779\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.8900 - val_loss: 19.2143\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.7849 - val_loss: 19.2529\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.7328 - val_loss: 19.0929\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.5845 - val_loss: 19.2751\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.4320 - val_loss: 18.9032\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 15.6319 - val_loss: 18.8323\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.6040 - val_loss: 18.3157\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.4925 - val_loss: 18.4719\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.5845 - val_loss: 19.8918\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.3311 - val_loss: 18.1868\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4073 - val_loss: 19.6749\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2679 - val_loss: 17.8840\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1971 - val_loss: 18.4492\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.1624 - val_loss: 18.0117\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0412 - val_loss: 18.6541\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.7755 - val_loss: 17.6316\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7158 - val_loss: 17.4035\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 14.6379 - val_loss: 18.3862\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 14.6136 - val_loss: 17.2585\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.5656 - val_loss: 18.1735\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7784 - val_loss: 17.9704\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7329 - val_loss: 17.8347\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5131 - val_loss: 17.3753\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.3402 - val_loss: 19.3462\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.4957 - val_loss: 18.5475\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1018 - val_loss: 17.5389\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6091 - val_loss: 18.1630\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0919 - val_loss: 17.2066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.8016 - val_loss: 17.1959\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3545 - val_loss: 17.5371\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1172 - val_loss: 18.5883\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6832 - val_loss: 16.7790\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8717 - val_loss: 17.2605\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9937 - val_loss: 16.6543\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0193 - val_loss: 17.0900\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9492 - val_loss: 16.6109\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0715 - val_loss: 18.9898\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9785 - val_loss: 16.7828\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5573 - val_loss: 18.0520\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0085 - val_loss: 16.7786\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.76 - 0s 89us/step - loss: 13.7877 - val_loss: 16.5983\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.7425 - val_loss: 17.4528\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5950 - val_loss: 16.6457\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4595 - val_loss: 17.4841\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1859 - val_loss: 17.1995\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.6245 - val_loss: 17.2137\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.9479 - val_loss: 17.0919\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.3488 - val_loss: 16.5161\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.3436 - val_loss: 17.0656\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.4876 - val_loss: 17.0050\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.6137 - val_loss: 18.7163\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.0628 - val_loss: 16.2766\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.7065 - val_loss: 16.1752\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.4826 - val_loss: 15.4461\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.8364 - val_loss: 15.6522\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.3259 - val_loss: 15.6228\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.6804 - val_loss: 15.4048\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.4026 - val_loss: 15.3879\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6036 - val_loss: 15.8968\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2515 - val_loss: 15.4794\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9084 - val_loss: 16.1257\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.7917 - val_loss: 14.8827\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6342 - val_loss: 14.5559\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.0741 - val_loss: 14.6580\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.0881 - val_loss: 14.2932\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.5403 - val_loss: 14.8472\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.1261 - val_loss: 14.8355\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 11.4927 - val_loss: 14.3327\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.7139 - val_loss: 13.2355\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.8045 - val_loss: 13.5557\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.4717 - val_loss: 13.5700\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.8024 - val_loss: 12.9401\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5993 - val_loss: 13.0160\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 10.8837 - val_loss: 12.5701\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 10.3710 - val_loss: 12.9367\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9549 - val_loss: 13.4036\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.7025 - val_loss: 13.3247\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.8981 - val_loss: 11.8992\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.1882 - val_loss: 14.5564\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.9455 - val_loss: 11.9104\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7225 - val_loss: 12.4344\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.0447 - val_loss: 11.3491\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4056 - val_loss: 11.4068\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.3424 - val_loss: 11.6944\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.5269 - val_loss: 11.6019\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3086 - val_loss: 12.0034\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1930 - val_loss: 11.7081\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.5065 - val_loss: 11.3145\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5942 - val_loss: 12.1843\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4349 - val_loss: 11.8352\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.3607 - val_loss: 13.3855\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3495 - val_loss: 11.0783\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4087 - val_loss: 11.6693\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.2289 - val_loss: 13.6352\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.7094 - val_loss: 11.3860\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3481 - val_loss: 11.0945\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3289 - val_loss: 11.3248\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4153 - val_loss: 11.3900\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9213 - val_loss: 11.7483\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9773 - val_loss: 10.7633\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7523 - val_loss: 12.3487\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8742 - val_loss: 11.7813\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9878 - val_loss: 11.3177\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.0468 - val_loss: 10.5769\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5358 - val_loss: 11.8217\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4388 - val_loss: 10.6753\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1331 - val_loss: 10.9796\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2609 - val_loss: 14.0050\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.7291 - val_loss: 10.8654\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.6340 - val_loss: 11.4448\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0129 - val_loss: 10.7142\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9461 - val_loss: 11.7913\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.2560 - val_loss: 11.5896\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.1431 - val_loss: 10.6237\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.0489 - val_loss: 12.0671\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.3781 - val_loss: 10.5529\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.0337 - val_loss: 10.7267\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2415 - val_loss: 11.3715\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.9892 - val_loss: 10.4803\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2249 - val_loss: 11.1112\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6592 - val_loss: 10.8417\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6962 - val_loss: 12.5710\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.4663 - val_loss: 10.1077\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0849 - val_loss: 10.6000\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0529 - val_loss: 11.3548\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0299 - val_loss: 10.2036\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9320 - val_loss: 10.1657\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.3983 - val_loss: 12.2645\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1843 - val_loss: 11.2866\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7492 - val_loss: 11.2523\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0495 - val_loss: 10.8105\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8466 - val_loss: 11.7141\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6559 - val_loss: 11.0914\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.7250 - val_loss: 10.5802\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9105 - val_loss: 12.4678\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4331 - val_loss: 10.8921\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.2165 - val_loss: 14.0368\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 9.1524 - val_loss: 10.4346\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.8631 - val_loss: 9.7870\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.4979 - val_loss: 11.0338\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.6277 - val_loss: 11.4037\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 134us/step - loss: 8.5124 - val_loss: 10.3522\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 8.6262 - val_loss: 11.0884\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.9565 - val_loss: 10.4563\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8385 - val_loss: 11.5438\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1480 - val_loss: 10.6927\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6999 - val_loss: 10.0673\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5710 - val_loss: 10.5026\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5771 - val_loss: 10.9040\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2165 - val_loss: 9.8600\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6948 - val_loss: 9.9596\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4188 - val_loss: 11.3850\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0276 - val_loss: 10.0931\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4305 - val_loss: 10.6703\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5814 - val_loss: 12.1288\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7909 - val_loss: 12.2450\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7606 - val_loss: 9.9099\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6390 - val_loss: 11.3977\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8293 - val_loss: 11.1967\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9957 - val_loss: 10.0525\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5932 - val_loss: 10.5669\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2650 - val_loss: 10.5055\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5789 - val_loss: 10.3624\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4470 - val_loss: 10.9639\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5148 - val_loss: 10.1378\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7737 - val_loss: 10.2471\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4828 - val_loss: 9.6193\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8491 - val_loss: 10.3493\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0485 - val_loss: 9.9657\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3793 - val_loss: 9.5423\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.3867 - val_loss: 9.8511\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4802 - val_loss: 10.8326\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5031 - val_loss: 10.5255\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5357 - val_loss: 10.2182\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0942 - val_loss: 11.8385\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5998 - val_loss: 9.8895\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7343 - val_loss: 10.0215\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5072 - val_loss: 10.2127\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6952 - val_loss: 10.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3345 - val_loss: 10.9767\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8747 - val_loss: 10.1683\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7544 - val_loss: 12.7143\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4841 - val_loss: 9.9189\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4391 - val_loss: 9.2719\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5362 - val_loss: 10.2245\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5384 - val_loss: 9.1879\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4060 - val_loss: 9.5169\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3757 - val_loss: 11.2890\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2437 - val_loss: 9.2927\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9272 - val_loss: 9.4769\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7169 - val_loss: 9.7065\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5184 - val_loss: 13.3517\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1487 - val_loss: 9.6440\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1635 - val_loss: 10.1994\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2648 - val_loss: 9.8217\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0998 - val_loss: 10.5089\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.8359 - val_loss: 9.2027\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9532 - val_loss: 10.9684\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2481 - val_loss: 9.6880\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.3529 - val_loss: 9.4176\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5172 - val_loss: 9.3087\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2325 - val_loss: 9.5594\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3010 - val_loss: 10.5033\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3084 - val_loss: 9.6670\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4314 - val_loss: 10.4678\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4015 - val_loss: 9.2729\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1982 - val_loss: 10.0126\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3090 - val_loss: 10.8406\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0503 - val_loss: 9.0818\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2836 - val_loss: 9.7595\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1148 - val_loss: 9.3954\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1049 - val_loss: 9.1333\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1813 - val_loss: 9.0832\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1782 - val_loss: 9.3339\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.0081 - val_loss: 9.6067\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7881 - val_loss: 8.9349\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0324 - val_loss: 9.3974\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1064 - val_loss: 9.8570\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0978 - val_loss: 9.2241\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2418 - val_loss: 9.5107\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0562 - val_loss: 8.9536\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1499 - val_loss: 9.3550\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2520 - val_loss: 9.8028\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7647 - val_loss: 9.0854\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2080 - val_loss: 9.7146\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1628 - val_loss: 9.5965\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2152 - val_loss: 9.4531\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4075 - val_loss: 9.6536\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1277 - val_loss: 10.4367\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.5157 - val_loss: 9.0008\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1008 - val_loss: 8.7902\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6128 - val_loss: 10.6764\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0766 - val_loss: 9.2837\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9796 - val_loss: 8.9176\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.9675 - val_loss: 12.6783\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4794 - val_loss: 10.1279\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0771 - val_loss: 9.8409\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9604 - val_loss: 9.2731\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.8067 - val_loss: 9.0465\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1673 - val_loss: 9.3641\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8793 - val_loss: 8.9651\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.3037 - val_loss: 10.3590\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9563 - val_loss: 8.5354\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8462 - val_loss: 8.5695\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9644 - val_loss: 10.9221\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0591 - val_loss: 8.5992\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2545 - val_loss: 9.9219\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1161 - val_loss: 10.4132\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2120 - val_loss: 8.9152\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9635 - val_loss: 9.7417\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.4312 - val_loss: 9.7921\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.9884 - val_loss: 8.5516\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6354 - val_loss: 9.2330\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6517 - val_loss: 8.8102\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.4178 - val_loss: 9.2902\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7331 - val_loss: 8.6574\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2278 - val_loss: 8.8947\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.8008 - val_loss: 8.5826\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.7309 - val_loss: 9.7491\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9939 - val_loss: 9.0477\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9800 - val_loss: 9.0669\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9495 - val_loss: 9.1045\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9753 - val_loss: 8.5519\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.9961 - val_loss: 9.4728\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8832 - val_loss: 8.4002\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1750 - val_loss: 8.6626\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4423 - val_loss: 9.0329\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1467 - val_loss: 9.3301\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9973 - val_loss: 10.1241\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0029 - val_loss: 9.7323\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4440 - val_loss: 10.2783\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 7.9290 - val_loss: 10.4065\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9047 - val_loss: 8.9448\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9393 - val_loss: 8.5804\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4520 - val_loss: 9.5929\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7714 - val_loss: 8.4322\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5468 - val_loss: 8.5983\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7543 - val_loss: 8.8345\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9201 - val_loss: 9.0539\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1693 - val_loss: 8.5708\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6921 - val_loss: 8.4697\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8104 - val_loss: 8.9034\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6176 - val_loss: 8.5358\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8779 - val_loss: 8.1864\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8511 - val_loss: 10.0217\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8523 - val_loss: 9.1859\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0317 - val_loss: 8.3319\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.0232 - val_loss: 9.1322\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7504 - val_loss: 8.6296\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9144 - val_loss: 11.0862\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8174 - val_loss: 8.8556\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.1504 - val_loss: 9.6252\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.6443 - val_loss: 9.7288\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8358 - val_loss: 9.0580\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5027 - val_loss: 8.6188\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5751 - val_loss: 10.5570\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.6995 - val_loss: 8.5254\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 128us/step - loss: 7.6933 - val_loss: 8.2594\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7220 - val_loss: 8.4367\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4939 - val_loss: 9.3843\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9250 - val_loss: 8.4887\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6655 - val_loss: 8.5668\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8340 - val_loss: 10.5097\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6071 - val_loss: 9.2062\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5115 - val_loss: 8.5271\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9425 - val_loss: 10.0765\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7211 - val_loss: 8.1595\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 8.1670 - val_loss: 12.0774\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2468 - val_loss: 8.1082\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8140 - val_loss: 8.7190\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6699 - val_loss: 8.5386\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4717 - val_loss: 8.1023\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5951 - val_loss: 10.4754\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9809 - val_loss: 7.9596\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4814 - val_loss: 8.6970\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6881 - val_loss: 8.1240\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7423 - val_loss: 8.3335\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.5898 - val_loss: 8.8391\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5937 - val_loss: 8.7713\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9563 - val_loss: 8.7446\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7179 - val_loss: 8.5061\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6991 - val_loss: 9.3787\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3709 - val_loss: 8.4492\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6623 - val_loss: 8.5687\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6844 - val_loss: 9.6900\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6468 - val_loss: 8.1962\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5614 - val_loss: 8.0500\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3482 - val_loss: 8.6339\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7631 - val_loss: 9.4600\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5641 - val_loss: 8.8122\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3692 - val_loss: 9.2042\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3995 - val_loss: 8.1327\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5317 - val_loss: 9.3071\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6796 - val_loss: 8.3458\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3184 - val_loss: 8.5830\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5504 - val_loss: 7.9282\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4316 - val_loss: 9.7895\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3933 - val_loss: 8.9294\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5381 - val_loss: 8.6169\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5904 - val_loss: 9.3190\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8276 - val_loss: 8.8492\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2689 - val_loss: 8.4290\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4462 - val_loss: 10.6125\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9779 - val_loss: 8.2740\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2901 - val_loss: 8.0291\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3468 - val_loss: 7.9100\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3715 - val_loss: 9.2941\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4048 - val_loss: 7.5931\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5707 - val_loss: 8.6924\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3523 - val_loss: 8.6342\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6413 - val_loss: 8.4771\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5004 - val_loss: 8.5355\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6303 - val_loss: 8.0711\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9979 - val_loss: 9.1657\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3917 - val_loss: 8.8993\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3480 - val_loss: 8.1300\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4202 - val_loss: 8.2385\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0869 - val_loss: 8.5313\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5009 - val_loss: 8.2345\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8210 - val_loss: 8.4793\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3709 - val_loss: 9.7387\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2939 - val_loss: 9.0548\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2840 - val_loss: 8.3530\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2727 - val_loss: 7.7864\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8642 - val_loss: 8.3404\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3485 - val_loss: 8.6281\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4077 - val_loss: 8.1341\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4490 - val_loss: 7.9163\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4008 - val_loss: 7.5166\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0183 - val_loss: 9.0061\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0320 - val_loss: 8.0576\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1108 - val_loss: 8.8111\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2906 - val_loss: 8.6454\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1083 - val_loss: 9.4127\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0329 - val_loss: 9.2647\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3171 - val_loss: 8.4193\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1106 - val_loss: 8.4720\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2681 - val_loss: 8.2951\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7210 - val_loss: 7.7200\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8201 - val_loss: 8.1117\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1358 - val_loss: 10.6815\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5470 - val_loss: 8.1330\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7169 - val_loss: 9.7526\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5457 - val_loss: 8.6938\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2399 - val_loss: 8.6236\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9646 - val_loss: 9.8739\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.0626 - val_loss: 7.6071\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8160 - val_loss: 8.4750\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0140 - val_loss: 7.9455\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.7807 - val_loss: 8.0318\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9627 - val_loss: 7.8389\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8656 - val_loss: 8.9282\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0925 - val_loss: 8.0553\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8568 - val_loss: 7.8776\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.8383 - val_loss: 8.2203\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8451 - val_loss: 8.5380\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9033 - val_loss: 9.2078\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6818 - val_loss: 7.5690\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2442 - val_loss: 8.7490\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8425 - val_loss: 7.9110\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6078 - val_loss: 7.9510\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8912 - val_loss: 8.2143\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5204 - val_loss: 7.6497\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5378 - val_loss: 8.0508\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4907 - val_loss: 8.0399\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3852 - val_loss: 7.9148\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6447 - val_loss: 7.1985\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2898 - val_loss: 7.6841\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4492 - val_loss: 7.7242\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4591 - val_loss: 7.0674\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1597 - val_loss: 7.2008\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2417 - val_loss: 8.0412\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0250 - val_loss: 6.8256\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0131 - val_loss: 6.9625\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9355 - val_loss: 7.0387\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2129 - val_loss: 6.7235\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2679 - val_loss: 9.8109\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3514 - val_loss: 6.8613\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1452 - val_loss: 6.4611\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0800 - val_loss: 6.2151\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8528 - val_loss: 6.2861\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0202 - val_loss: 7.2563\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8786 - val_loss: 7.4659\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8755 - val_loss: 7.0833\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9089 - val_loss: 7.3001\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9918 - val_loss: 5.9965\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7372 - val_loss: 6.1925\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6438 - val_loss: 6.0456\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8608 - val_loss: 6.3016\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8979 - val_loss: 6.6519\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0069 - val_loss: 5.9097\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2991 - val_loss: 7.0406\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2915 - val_loss: 6.8813\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7347 - val_loss: 6.4356\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8792 - val_loss: 6.3353\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7294 - val_loss: 5.7847\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6443 - val_loss: 6.5553\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5870 - val_loss: 6.3812\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7181 - val_loss: 5.9093\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7278 - val_loss: 6.1857\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0495 - val_loss: 7.5058\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6982 - val_loss: 6.0267\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5598 - val_loss: 5.9248\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8081 - val_loss: 6.6425\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7682 - val_loss: 6.5704\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9054 - val_loss: 5.8038\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5887 - val_loss: 6.2589\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9168 - val_loss: 5.7360\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8806 - val_loss: 8.4343\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5258 - val_loss: 7.1477\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8189 - val_loss: 6.0955\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9038 - val_loss: 5.8843\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7636 - val_loss: 7.6460\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.9486 - val_loss: 5.9934\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.7916 - val_loss: 5.7667\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6901 - val_loss: 5.7681\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5747 - val_loss: 6.1397\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.9056 - val_loss: 5.5656\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.8872 - val_loss: 5.6952\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9041 - val_loss: 6.8634\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4385 - val_loss: 5.9124\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4018 - val_loss: 5.8392\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5226 - val_loss: 5.6508\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8461 - val_loss: 5.7143\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0476 - val_loss: 5.6616\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7036 - val_loss: 5.6806\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7327 - val_loss: 6.7801\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6365 - val_loss: 5.9871\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8391 - val_loss: 8.4639\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9130 - val_loss: 5.6859\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5439 - val_loss: 5.8743\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.9402 - val_loss: 5.8663\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7802 - val_loss: 5.8909\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9034 - val_loss: 6.5131\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5879 - val_loss: 5.6437\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7347 - val_loss: 5.7012\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7726 - val_loss: 6.7250\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7387 - val_loss: 6.2298\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7263 - val_loss: 5.8697\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4662 - val_loss: 5.9223\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4304 - val_loss: 5.8226\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4617 - val_loss: 6.0430\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7045 - val_loss: 9.0529\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8716 - val_loss: 6.0883\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6443 - val_loss: 5.8026\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5555 - val_loss: 5.9465\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9013 - val_loss: 5.7982\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5998 - val_loss: 7.0707\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1001 - val_loss: 5.6787\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6519 - val_loss: 6.1458\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6253 - val_loss: 6.4694\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4615 - val_loss: 5.9638\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1261 - val_loss: 5.8522\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4879 - val_loss: 5.5048\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5127 - val_loss: 5.8628\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0795 - val_loss: 7.1234\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1714 - val_loss: 6.1526\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6882 - val_loss: 5.8628\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7709 - val_loss: 6.8960\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0929 - val_loss: 6.5651\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8521 - val_loss: 6.3643\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3647 - val_loss: 5.8030\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5673 - val_loss: 5.6489\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5078 - val_loss: 5.9274\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3311 - val_loss: 6.7524\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8536 - val_loss: 5.7827\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6743 - val_loss: 6.0143\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4667 - val_loss: 5.8632\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6701 - val_loss: 6.7042\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8886 - val_loss: 6.3639\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8297 - val_loss: 5.9180\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3814 - val_loss: 6.6239\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1285 - val_loss: 6.2745\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5508 - val_loss: 6.2797\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5224 - val_loss: 5.4368\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3205 - val_loss: 5.8164\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7776 - val_loss: 6.2309\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7785 - val_loss: 6.3669\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7271 - val_loss: 6.5089\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8839 - val_loss: 5.8970\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4781 - val_loss: 6.0937\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7509 - val_loss: 8.2950\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6839 - val_loss: 5.4979\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5112 - val_loss: 6.2580\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4934 - val_loss: 5.9828\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5496 - val_loss: 6.4337\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6701 - val_loss: 6.0673\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3906 - val_loss: 5.6014\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5416 - val_loss: 6.7361\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5252 - val_loss: 6.7263\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9227 - val_loss: 5.5842\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7036 - val_loss: 6.4378\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5078 - val_loss: 5.5934\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5106 - val_loss: 5.4199\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7523 - val_loss: 7.1361\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7162 - val_loss: 5.5424\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6003 - val_loss: 5.6907\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4611 - val_loss: 6.5089\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6821 - val_loss: 5.9563\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6238 - val_loss: 6.9319\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4924 - val_loss: 5.7949\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7601 - val_loss: 6.6281\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5798 - val_loss: 5.5563\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4971 - val_loss: 5.4610\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4224 - val_loss: 6.9065\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0778 - val_loss: 5.7204\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3164 - val_loss: 6.1021\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2932 - val_loss: 5.6795\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4239 - val_loss: 5.7967\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7892 - val_loss: 6.5331\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6865 - val_loss: 5.9953\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5271 - val_loss: 5.7448\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3884 - val_loss: 6.1961\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4344 - val_loss: 5.6259\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7231 - val_loss: 5.5258\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6095 - val_loss: 6.0022\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3399 - val_loss: 5.5143\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4176 - val_loss: 5.9023\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4622 - val_loss: 5.4978\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4611 - val_loss: 5.8981\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6866 - val_loss: 5.9404\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4790 - val_loss: 6.1290\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6697 - val_loss: 6.2218\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3923 - val_loss: 5.6235\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3669 - val_loss: 5.7954\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3144 - val_loss: 5.8439\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5654 - val_loss: 5.6604\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7491 - val_loss: 5.7203\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6970 - val_loss: 5.5816\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4327 - val_loss: 5.6806\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5067 - val_loss: 6.0670\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3159 - val_loss: 5.9318\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5601 - val_loss: 8.6995\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3672 - val_loss: 5.4506\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8059 - val_loss: 5.7181\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4162 - val_loss: 6.3923\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8564 - val_loss: 5.6922\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5581 - val_loss: 6.0720\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6360 - val_loss: 7.3261\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5666 - val_loss: 6.9954\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5839 - val_loss: 5.9595\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9257 - val_loss: 7.1180\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5630 - val_loss: 5.6603\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2997 - val_loss: 5.4967\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3819 - val_loss: 5.7176\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3530 - val_loss: 5.7557\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5585 - val_loss: 6.4673\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4910 - val_loss: 6.3779\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3340 - val_loss: 5.4993\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6860 - val_loss: 5.8557\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7194 - val_loss: 5.9435\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6673 - val_loss: 6.6684\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4905 - val_loss: 5.4294\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4341 - val_loss: 5.7104\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6101 - val_loss: 5.8465\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5745 - val_loss: 6.0061\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4870 - val_loss: 5.6963\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4884 - val_loss: 5.8585\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6627 - val_loss: 5.5313\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4191 - val_loss: 5.6543\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2886 - val_loss: 5.4690\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4561 - val_loss: 5.6620\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2841 - val_loss: 5.5726\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2645 - val_loss: 6.2492\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2833 - val_loss: 5.5936\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3726 - val_loss: 5.9595\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2819 - val_loss: 5.9511\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3563 - val_loss: 6.0594\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3609 - val_loss: 6.7943\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5293 - val_loss: 5.7226\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3479 - val_loss: 5.7293\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3818 - val_loss: 7.5651\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6907 - val_loss: 6.6892\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7381 - val_loss: 5.8622\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4404 - val_loss: 6.0384\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3233 - val_loss: 5.4488\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6938 - val_loss: 5.4846\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4762 - val_loss: 5.8830\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.5419 - val_loss: 5.4406\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6442 - val_loss: 5.7913\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0394 - val_loss: 5.4766\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6209 - val_loss: 5.8367\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4101 - val_loss: 5.5308\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6444 - val_loss: 5.5144\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4342 - val_loss: 5.3455\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4520 - val_loss: 5.9361\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3792 - val_loss: 5.8168\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3314 - val_loss: 5.9037\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4075 - val_loss: 5.9665\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3935 - val_loss: 5.8075\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4526 - val_loss: 5.8215\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7752 - val_loss: 5.9636\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5591 - val_loss: 5.4058\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5521 - val_loss: 6.7152\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4876 - val_loss: 5.4711\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3739 - val_loss: 5.5960\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4484 - val_loss: 5.3325\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3588 - val_loss: 6.0526\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4619 - val_loss: 5.8245\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2692 - val_loss: 5.6809\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4257 - val_loss: 5.6033\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6354 - val_loss: 5.8905\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4967 - val_loss: 5.5581\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4030 - val_loss: 5.4470\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4069 - val_loss: 6.1850\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6105 - val_loss: 5.9584\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3269 - val_loss: 5.7457\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3061 - val_loss: 5.5745\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4065 - val_loss: 5.8942\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9409 - val_loss: 5.7452\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6262 - val_loss: 6.4350\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4384 - val_loss: 5.7353\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9268 - val_loss: 6.5541\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3271 - val_loss: 5.6303\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6104 - val_loss: 5.8852\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4784 - val_loss: 5.6024\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3344 - val_loss: 6.2965\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3468 - val_loss: 5.7064\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.3222 - val_loss: 5.7030\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3443 - val_loss: 6.0651\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3864 - val_loss: 5.6818\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3943 - val_loss: 5.5183\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3386 - val_loss: 5.7371\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6081 - val_loss: 6.4337\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6276 - val_loss: 6.2116\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5668 - val_loss: 5.5324\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6061 - val_loss: 5.4485\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4586 - val_loss: 5.7487\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8092 - val_loss: 5.6190\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4568 - val_loss: 5.6556\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3592 - val_loss: 5.7782\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4706 - val_loss: 5.4710\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6219 - val_loss: 5.5203\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3333 - val_loss: 5.6545\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2283 - val_loss: 5.6421\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2941 - val_loss: 5.4246\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2727 - val_loss: 5.9076\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6588 - val_loss: 5.9422\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3813 - val_loss: 6.8780\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7993 - val_loss: 5.8527\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6380 - val_loss: 5.6972\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8471 - val_loss: 5.7737\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6568 - val_loss: 5.8995\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6741 - val_loss: 5.8324\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6508 - val_loss: 6.1608\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4733 - val_loss: 5.8138\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2370 - val_loss: 5.7491\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4558 - val_loss: 5.5289\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3271 - val_loss: 5.9680\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4619 - val_loss: 5.6846\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5977 - val_loss: 5.9162\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7403 - val_loss: 5.5396\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3314 - val_loss: 6.3615\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4194 - val_loss: 5.7930\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3082 - val_loss: 5.5361\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3632 - val_loss: 5.3823\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8263 - val_loss: 5.7948\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2304 - val_loss: 6.2632\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2324 - val_loss: 5.7609\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4270 - val_loss: 5.5722\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3543 - val_loss: 5.8541\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4987 - val_loss: 5.5785\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2272 - val_loss: 5.6363\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4455 - val_loss: 5.9143\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1928 - val_loss: 5.5864\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2512 - val_loss: 5.5020\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4526 - val_loss: 5.5184\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4299 - val_loss: 7.2882\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6385 - val_loss: 6.4014\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4782 - val_loss: 5.5909\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7536 - val_loss: 5.7291\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6640 - val_loss: 5.9682\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2768 - val_loss: 5.7192\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9467 - val_loss: 5.6364\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2271 - val_loss: 5.7632\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3973 - val_loss: 5.7137\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3436 - val_loss: 6.2496\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6521 - val_loss: 5.6294\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4230 - val_loss: 6.2438\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0556 - val_loss: 5.8860\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0998 - val_loss: 5.8450\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7812 - val_loss: 5.4299\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3251 - val_loss: 6.0069\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3795 - val_loss: 5.4365\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4667 - val_loss: 6.3961\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4427 - val_loss: 6.9121\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7069 - val_loss: 6.3637\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3735 - val_loss: 5.6014\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4331 - val_loss: 5.2536\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5038 - val_loss: 5.7971\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6027 - val_loss: 5.6884\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3014 - val_loss: 5.3741\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1578 - val_loss: 5.9321\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5189 - val_loss: 5.8810\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4552 - val_loss: 5.5440\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4684 - val_loss: 5.5449\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4377 - val_loss: 5.3814\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4612 - val_loss: 7.0215\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0265 - val_loss: 5.8254\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0429 - val_loss: 5.9431\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5757 - val_loss: 5.3425\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3624 - val_loss: 5.7736\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2598 - val_loss: 6.0279\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5209 - val_loss: 5.7520\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7146 - val_loss: 6.5998\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2808 - val_loss: 5.5732\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4418 - val_loss: 5.8283\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5911 - val_loss: 5.9341\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3746 - val_loss: 5.9373\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3179 - val_loss: 5.4600\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5671 - val_loss: 5.9001\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3809 - val_loss: 5.4012\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3127 - val_loss: 5.4124\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3489 - val_loss: 5.5714\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1784 - val_loss: 6.1864\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5255 - val_loss: 5.7787\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4565 - val_loss: 6.7773\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3896 - val_loss: 5.4663\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3085 - val_loss: 5.6134\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3733 - val_loss: 5.3803\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2305 - val_loss: 5.5267\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1616 - val_loss: 5.3047\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2036 - val_loss: 6.2070\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4820 - val_loss: 5.5926\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.3266 - val_loss: 5.6206\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2947 - val_loss: 5.8550\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3041 - val_loss: 5.4587\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2088 - val_loss: 5.3096\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2654 - val_loss: 5.6340\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5017 - val_loss: 5.5752\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3653 - val_loss: 5.5507\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3435 - val_loss: 6.3721\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6491 - val_loss: 6.0508\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2504 - val_loss: 5.4102\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3017 - val_loss: 5.6606\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2429 - val_loss: 7.4189\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3640 - val_loss: 5.3982\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3570 - val_loss: 5.6169\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8277 - val_loss: 5.3877\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4250 - val_loss: 5.6943\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3660 - val_loss: 5.6607\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5601 - val_loss: 7.5249\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8028 - val_loss: 5.5161\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.4324 - val_loss: 6.4719\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.2633 - val_loss: 5.2311\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.4771 - val_loss: 5.6966\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3312 - val_loss: 5.7764\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.3793 - val_loss: 5.5304\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.5942 - val_loss: 5.6998\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1631 - val_loss: 5.9722\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4127 - val_loss: 5.6684\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5884 - val_loss: 6.1954\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5132 - val_loss: 5.5394\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3598 - val_loss: 5.7114\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5755 - val_loss: 6.7227\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4682 - val_loss: 5.8544\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2699 - val_loss: 5.7341\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2488 - val_loss: 5.6045\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1623 - val_loss: 5.5551\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2514 - val_loss: 5.3724\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1341 - val_loss: 6.2158\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2367 - val_loss: 5.8029\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5578 - val_loss: 5.4251\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3524 - val_loss: 5.8586\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4863 - val_loss: 5.7648\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3747 - val_loss: 5.4139\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4753 - val_loss: 6.4972\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5161 - val_loss: 5.9212\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3991 - val_loss: 5.3204\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5887 - val_loss: 5.8869\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5882 - val_loss: 5.8468\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2966 - val_loss: 6.1094\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6336 - val_loss: 5.6903\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2349 - val_loss: 5.9954\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1754 - val_loss: 6.5843\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6648 - val_loss: 5.4240\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3014 - val_loss: 5.7455\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2356 - val_loss: 5.5616\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2774 - val_loss: 5.6212\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7741 - val_loss: 6.1117\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3379 - val_loss: 6.8269\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8839 - val_loss: 5.7990\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8509 - val_loss: 6.3215\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8047 - val_loss: 7.1761\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3972 - val_loss: 5.7014\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2313 - val_loss: 5.4991\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1460 - val_loss: 5.7353\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4091 - val_loss: 5.8209\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2750 - val_loss: 6.1155\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5023 - val_loss: 5.6913\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5471 - val_loss: 5.3668\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4466 - val_loss: 6.7527\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3176 - val_loss: 5.9971\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6468 - val_loss: 5.4073\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6043 - val_loss: 5.2785\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3457 - val_loss: 5.3816\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1792 - val_loss: 5.3470\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6337 - val_loss: 8.1154\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6465 - val_loss: 5.3607\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1819 - val_loss: 5.5099\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2469 - val_loss: 5.3368\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3896 - val_loss: 5.3385\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3896 - val_loss: 5.4738\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3531 - val_loss: 7.2275\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2864 - val_loss: 5.2071\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9322 - val_loss: 6.8360\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5730 - val_loss: 5.5209\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4459 - val_loss: 5.7077\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4302 - val_loss: 5.5106\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5004 - val_loss: 5.4111\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.1738 - val_loss: 6.6081\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5735 - val_loss: 5.7059\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4819 - val_loss: 5.4284\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3409 - val_loss: 5.7380\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9539 - val_loss: 5.5824\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3278 - val_loss: 5.7538\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6284 - val_loss: 5.5705\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1628 - val_loss: 5.2758\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1916 - val_loss: 6.0236\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8483 - val_loss: 5.9194\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4784 - val_loss: 5.2773\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.1280 - val_loss: 5.8805\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3993 - val_loss: 6.5290\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4539 - val_loss: 6.2745\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3615 - val_loss: 5.9619\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0660 - val_loss: 5.6818\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2269 - val_loss: 5.3865\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4698 - val_loss: 5.5678\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.1840 - val_loss: 6.7496\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4023 - val_loss: 5.2171\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2568 - val_loss: 5.8946\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5781 - val_loss: 5.4093\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2428 - val_loss: 5.3781\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2205 - val_loss: 6.7272\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5106 - val_loss: 5.4992\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2005 - val_loss: 5.4252\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1917 - val_loss: 6.3982\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4626 - val_loss: 6.3947\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5367 - val_loss: 5.7886\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6439 - val_loss: 5.9059\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2113 - val_loss: 5.9782\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7219 - val_loss: 7.3559\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5278 - val_loss: 5.3504\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.2513 - val_loss: 5.4741\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3788 - val_loss: 5.6111\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3459 - val_loss: 5.9082\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4337 - val_loss: 5.2956\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5195 - val_loss: 5.6529\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3662 - val_loss: 5.4140\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1465 - val_loss: 5.7507\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1350 - val_loss: 5.9673\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4559 - val_loss: 5.9459\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2563 - val_loss: 5.6146\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2160 - val_loss: 5.5310\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5011 - val_loss: 5.8093\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5363 - val_loss: 5.8573\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2920 - val_loss: 5.7897\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2623 - val_loss: 5.6232\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2587 - val_loss: 6.0030\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4905 - val_loss: 6.4156\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3971 - val_loss: 5.5803\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1026 - val_loss: 5.6719\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3393 - val_loss: 5.3730\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1755 - val_loss: 7.9539\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5073 - val_loss: 5.8190\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5737 - val_loss: 5.8117\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5022 - val_loss: 5.7532\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4997 - val_loss: 5.6883\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2216 - val_loss: 5.8126\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3771 - val_loss: 5.8098\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2311 - val_loss: 5.8328\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2693 - val_loss: 6.5684\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.3581 - val_loss: 5.7250\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1914 - val_loss: 5.6092\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.1248 - val_loss: 5.3570\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7050 - val_loss: 5.9444\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3150 - val_loss: 5.9342\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2348 - val_loss: 5.4953\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4715 - val_loss: 6.0641\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3339 - val_loss: 5.6531\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7003 - val_loss: 5.8339\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1010 - val_loss: 5.7187\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2706 - val_loss: 5.7490\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4397 - val_loss: 5.5898\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3088 - val_loss: 6.0762\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.3817 - val_loss: 5.3907\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5407 - val_loss: 5.9736\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3751 - val_loss: 5.5613\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3144 - val_loss: 5.3814\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1466 - val_loss: 5.5361\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3972 - val_loss: 6.1132\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3881 - val_loss: 5.4910\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3870 - val_loss: 5.4281\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4564 - val_loss: 5.4160\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4171 - val_loss: 5.5648\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2163 - val_loss: 5.4437\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9483 - val_loss: 5.4520\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3945 - val_loss: 5.7668\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4003 - val_loss: 5.4695\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2875 - val_loss: 5.8580\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1959 - val_loss: 5.4944\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1820 - val_loss: 5.6033\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0598 - val_loss: 5.4278\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2365 - val_loss: 5.7157\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1728 - val_loss: 6.0042\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2118 - val_loss: 5.4785\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3036 - val_loss: 5.8174\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.3772 - val_loss: 7.1044\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.4918 - val_loss: 6.2339\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3588 - val_loss: 5.3247\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1662 - val_loss: 7.6802\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3999 - val_loss: 5.5163\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2925 - val_loss: 6.6027\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8913 - val_loss: 6.0520\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.2210 - val_loss: 5.6432\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4792 - val_loss: 5.8119\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.2955 - val_loss: 5.4250\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2398 - val_loss: 5.9287\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3500 - val_loss: 5.6160\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0599 - val_loss: 5.6298\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5908 - val_loss: 5.5842\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4953 - val_loss: 5.3978\n",
      "5.681961152405865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.8788285 , -3.4316714 , -0.40708408, -0.158925  , -0.8343887 ,\n",
       "          0.12650158,  5.272518  , -4.6384478 , -0.4946385 , -4.1706696 ],\n",
       "        [ 0.33565846,  0.21593846, -0.4197381 , -0.27487323, -1.2772856 ,\n",
       "          0.14677253, -0.36620855, -0.81526196, -0.7610436 , -0.2665006 ],\n",
       "        [ 0.09765035, -0.10054585, -0.49387273, -1.823727  , -0.3966244 ,\n",
       "          0.16601782,  0.74108666, -3.4887586 , -2.2688293 , -0.05067521],\n",
       "        [ 0.11059216,  0.0581785 ,  0.67049825,  0.07663258,  0.3054783 ,\n",
       "         -0.10806639, -0.21898621,  0.24698038, -0.73153603, -0.3839056 ],\n",
       "        [-3.536333  , -0.4103085 , -0.3436026 , -0.01880508,  0.13174582,\n",
       "          0.13959658,  0.30670133, -0.28983793, -1.1406373 , -0.09629481]],\n",
       "       dtype=float32),\n",
       " array([-5.289814 , -1.8584602,  2.8561058, -1.4011571,  0.1072287,\n",
       "        -4.7049546,  6.2568574, -5.4900203,  6.7401867, -4.943392 ],\n",
       "       dtype=float32),\n",
       " array([[ 2.0303774 ,  1.42294   , -1.8294666 ,  2.1805906 , -1.5242388 ],\n",
       "        [-0.6138836 , -0.9821996 ,  0.38402662, -1.4447806 ,  1.2855768 ],\n",
       "        [-2.0723343 , -1.5150387 ,  1.2773912 , -1.7896613 ,  1.3617921 ],\n",
       "        [-1.0125014 , -0.9237311 ,  0.35900554, -1.2186426 ,  0.5885916 ],\n",
       "        [-0.44183797, -1.0639431 ,  0.31018692, -1.0566652 ,  0.68283314],\n",
       "        [ 2.4875686 ,  1.4641641 , -2.3457482 ,  2.175413  , -2.376582  ],\n",
       "        [-2.6699147 , -2.5678577 ,  2.5297968 , -2.3535311 ,  1.6208181 ],\n",
       "        [ 0.7679124 ,  0.64399153, -0.93374395,  0.97508985, -0.61886656],\n",
       "        [-2.4115317 , -2.0100195 ,  2.3309126 , -1.8581269 ,  1.7716249 ],\n",
       "        [ 2.296986  ,  1.8605462 , -1.2010336 ,  1.9780343 , -1.814759  ]],\n",
       "       dtype=float32),\n",
       " array([-2.2526786, -2.173384 ,  2.25954  , -2.2966287,  1.9244468],\n",
       "       dtype=float32),\n",
       " array([[-1.9275348],\n",
       "        [-1.5862573],\n",
       "        [ 1.840339 ],\n",
       "        [-2.0899167],\n",
       "        [ 1.4776416]], dtype=float32),\n",
       " array([2.4253972], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_4(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure4_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 238us/step - loss: 6809.1056 - val_loss: 440.5902\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 166.1197 - val_loss: 39.9000\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 29.1136 - val_loss: 26.7942\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 23.4232 - val_loss: 24.4907\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4807 - val_loss: 23.6474\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5392 - val_loss: 23.1648\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.0205 - val_loss: 22.8626\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.6892 - val_loss: 23.1119\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.1588 - val_loss: 23.1499\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9763 - val_loss: 22.5710\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.5874 - val_loss: 21.9626\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.3785 - val_loss: 21.6281\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9325 - val_loss: 21.6383\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.4836 - val_loss: 21.5393\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0657 - val_loss: 21.5389\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7785 - val_loss: 21.1478\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.5101 - val_loss: 20.8913\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2828 - val_loss: 21.0511\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.1797 - val_loss: 21.0899\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.8856 - val_loss: 20.5049\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.3678 - val_loss: 20.0762\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.0903 - val_loss: 19.8744\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.9852 - val_loss: 19.7914\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.8236 - val_loss: 19.3880\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.7045 - val_loss: 19.6282\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.4018 - val_loss: 19.1070\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2814 - val_loss: 18.8423\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.1177 - val_loss: 18.9541\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.2950 - val_loss: 18.9294\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.9422 - val_loss: 18.6360\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8408 - val_loss: 19.3303\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.9816 - val_loss: 18.7663\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5825 - val_loss: 18.3034\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5261 - val_loss: 18.1543\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.2145 - val_loss: 18.4499\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5990 - val_loss: 17.9862\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1115 - val_loss: 17.5121\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.1690 - val_loss: 17.5884\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9447 - val_loss: 17.8887\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.9854 - val_loss: 17.6409\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.0630 - val_loss: 17.4999\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5450 - val_loss: 17.7692\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.4549 - val_loss: 16.9504\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2527 - val_loss: 16.8091\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3368 - val_loss: 16.6764\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.4420 - val_loss: 16.6668\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9907 - val_loss: 16.4270\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1062 - val_loss: 16.4149\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7818 - val_loss: 16.5167\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.1142 - val_loss: 16.3865\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9467 - val_loss: 16.5877\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.9343 - val_loss: 16.3278\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.8104 - val_loss: 16.2280\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5896 - val_loss: 15.4091\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5515 - val_loss: 15.4577\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3238 - val_loss: 15.8420\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4351 - val_loss: 15.5682\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5057 - val_loss: 15.3153\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2426 - val_loss: 15.6960\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1096 - val_loss: 16.7117\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2431 - val_loss: 15.3658\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3788 - val_loss: 15.7142\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2008 - val_loss: 15.3930\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0781 - val_loss: 16.0583\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1497 - val_loss: 15.3328\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1845 - val_loss: 14.7381\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7095 - val_loss: 14.7149\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8009 - val_loss: 14.8064\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6260 - val_loss: 14.1438\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7583 - val_loss: 14.8345\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7645 - val_loss: 14.5577\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5882 - val_loss: 13.8161\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0859 - val_loss: 13.6802\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6901 - val_loss: 14.5072\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6655 - val_loss: 13.7796\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4740 - val_loss: 14.7363\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8137 - val_loss: 13.9395\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3853 - val_loss: 13.9371\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7741 - val_loss: 14.5158\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.1970 - val_loss: 13.5953\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1984 - val_loss: 14.1247\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4712 - val_loss: 13.5404\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6949 - val_loss: 13.9977\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2196 - val_loss: 14.0137\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1079 - val_loss: 13.0842\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1488 - val_loss: 14.9895\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3475 - val_loss: 13.2150\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0356 - val_loss: 13.5009\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9915 - val_loss: 13.1440\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2163 - val_loss: 13.5056\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0327 - val_loss: 13.1004\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.8337 - val_loss: 14.0017\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.9115 - val_loss: 13.6917\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2366 - val_loss: 14.1226\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2021 - val_loss: 13.4051\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.9483 - val_loss: 13.3387\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7663 - val_loss: 13.5844\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0034 - val_loss: 12.6651\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1549 - val_loss: 13.3239\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8625 - val_loss: 12.7755\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.8026 - val_loss: 13.6020\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2441 - val_loss: 12.3870\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.8478 - val_loss: 12.7958\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6826 - val_loss: 13.0923\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4672 - val_loss: 12.7908\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9002 - val_loss: 12.3876\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.7987 - val_loss: 12.9522\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3472 - val_loss: 12.4928\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8464 - val_loss: 12.2881\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6905 - val_loss: 13.3788\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4630 - val_loss: 12.7421\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3045 - val_loss: 15.0292\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7979 - val_loss: 12.6777\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7582 - val_loss: 12.9147\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9104 - val_loss: 14.4730\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4167 - val_loss: 12.4625\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6665 - val_loss: 12.3983\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7121 - val_loss: 13.2027\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5972 - val_loss: 12.6733\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5362 - val_loss: 14.3083\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 11.7362 - val_loss: 12.2667\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5899 - val_loss: 12.3639\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3606 - val_loss: 12.5830\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.9154 - val_loss: 12.4970\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3479 - val_loss: 11.8443\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3532 - val_loss: 12.7786\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9279 - val_loss: 11.9270\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0009 - val_loss: 13.9612\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7266 - val_loss: 14.1586\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0521 - val_loss: 12.5320\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.7708 - val_loss: 13.2944\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.2701 - val_loss: 11.9851\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4595 - val_loss: 13.2757\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2341 - val_loss: 12.6771\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7185 - val_loss: 13.8981\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7779 - val_loss: 13.3647\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9168 - val_loss: 12.0616\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7202 - val_loss: 12.9957\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2543 - val_loss: 13.5862\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4498 - val_loss: 12.1337\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9855 - val_loss: 11.9126\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8763 - val_loss: 12.5846\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.9826 - val_loss: 11.9624\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2659 - val_loss: 12.3516\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2281 - val_loss: 12.2626\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4506 - val_loss: 12.3083\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 10.0585 - val_loss: 12.4940\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.0458 - val_loss: 13.2706\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.3184 - val_loss: 12.3042\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.4121 - val_loss: 11.6312\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.1964 - val_loss: 12.6122\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2040 - val_loss: 12.0976\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0207 - val_loss: 13.7253\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5264 - val_loss: 11.4550\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4478 - val_loss: 13.2744\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1027 - val_loss: 12.4512\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9829 - val_loss: 11.4934\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.1432 - val_loss: 11.5525\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1534 - val_loss: 12.3527\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5664 - val_loss: 12.1062\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1042 - val_loss: 12.5213\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7433 - val_loss: 13.5870\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.3621 - val_loss: 12.2151\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3118 - val_loss: 12.4122\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0293 - val_loss: 11.3572\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4462 - val_loss: 13.2624\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4594 - val_loss: 13.4826\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3753 - val_loss: 11.3095\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0961 - val_loss: 11.9922\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8465 - val_loss: 11.3933\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3619 - val_loss: 11.6847\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2711 - val_loss: 12.9298\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0602 - val_loss: 13.7866\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9530 - val_loss: 11.3172\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9185 - val_loss: 11.6819\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6298 - val_loss: 12.0143\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5607 - val_loss: 11.1270\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1502 - val_loss: 11.6932\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6079 - val_loss: 11.8307\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9018 - val_loss: 11.8144\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7047 - val_loss: 12.9041\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1167 - val_loss: 13.4599\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7850 - val_loss: 12.7170\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5826 - val_loss: 11.5645\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9834 - val_loss: 11.9658\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6207 - val_loss: 11.7376\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1370 - val_loss: 12.3083\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.1053 - val_loss: 11.1566\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5580 - val_loss: 11.0596\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1759 - val_loss: 11.6973\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2536 - val_loss: 10.9910\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8149 - val_loss: 11.0550\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8892 - val_loss: 12.3155\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.6054 - val_loss: 11.6813\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6059 - val_loss: 12.5514\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2168 - val_loss: 11.1888\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4083 - val_loss: 11.3327\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3173 - val_loss: 11.5129\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6069 - val_loss: 10.9921\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.3080 - val_loss: 15.2750\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4258 - val_loss: 12.6264\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2255 - val_loss: 11.4170\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3104 - val_loss: 11.2882\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6818 - val_loss: 12.6670\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3501 - val_loss: 11.1413\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4375 - val_loss: 11.5034\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5382 - val_loss: 12.0932\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.9831 - val_loss: 13.1356\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7269 - val_loss: 11.9939\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6357 - val_loss: 11.3875\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6275 - val_loss: 10.8773\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1789 - val_loss: 11.8098\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0396 - val_loss: 12.8488\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3599 - val_loss: 12.9857\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1578 - val_loss: 11.0298\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7412 - val_loss: 10.8599\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8621 - val_loss: 11.7429\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5484 - val_loss: 11.6354\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5902 - val_loss: 11.7168\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9903 - val_loss: 11.0953\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4327 - val_loss: 15.9787\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2817 - val_loss: 11.0059\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6060 - val_loss: 11.0498\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2142 - val_loss: 11.1176\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8332 - val_loss: 11.8988\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5960 - val_loss: 11.8492\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3936 - val_loss: 11.1285\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2953 - val_loss: 11.7155\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8736 - val_loss: 13.7222\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2324 - val_loss: 11.4607\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5470 - val_loss: 14.1328\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1995 - val_loss: 10.5467\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2616 - val_loss: 10.9553\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9312 - val_loss: 13.1913\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6862 - val_loss: 12.2322\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1627 - val_loss: 10.4962\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3533 - val_loss: 10.8999\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0638 - val_loss: 12.5856\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3519 - val_loss: 11.2423\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3289 - val_loss: 10.6826\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0268 - val_loss: 11.8877\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3812 - val_loss: 13.5771\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1405 - val_loss: 11.8992\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3766 - val_loss: 10.7264\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1524 - val_loss: 12.4063\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4681 - val_loss: 10.9677\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1103 - val_loss: 11.2729\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1240 - val_loss: 12.6065\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1187 - val_loss: 10.8251\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2921 - val_loss: 12.1213\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8449 - val_loss: 10.5705\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2637 - val_loss: 11.7437\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9713 - val_loss: 10.6356\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6654 - val_loss: 12.1334\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3963 - val_loss: 10.8253\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7555 - val_loss: 10.9005\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1689 - val_loss: 11.0404\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0142 - val_loss: 10.6341\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5203 - val_loss: 11.4384\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5801 - val_loss: 11.6624\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0398 - val_loss: 11.3638\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1746 - val_loss: 10.6758\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7403 - val_loss: 10.9760\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3550 - val_loss: 12.2300\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9823 - val_loss: 12.4577\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7423 - val_loss: 11.3187\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6809 - val_loss: 10.6963\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8419 - val_loss: 11.5688\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3617 - val_loss: 10.9967\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0588 - val_loss: 10.1498\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2331 - val_loss: 12.3337\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3135 - val_loss: 10.2749\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9654 - val_loss: 11.3662\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9046 - val_loss: 11.0741\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4764 - val_loss: 10.4001\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3280 - val_loss: 10.9479\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2113 - val_loss: 10.2609\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6541 - val_loss: 10.2283\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8755 - val_loss: 11.0984\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3293 - val_loss: 10.3836\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9929 - val_loss: 11.9982\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1819 - val_loss: 10.4655\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7703 - val_loss: 10.0313\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0411 - val_loss: 10.8019\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9928 - val_loss: 11.6729\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5079 - val_loss: 10.9093\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8595 - val_loss: 10.0621\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2056 - val_loss: 11.1429\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2190 - val_loss: 10.7159\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0293 - val_loss: 10.7448\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4456 - val_loss: 11.0583\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1936 - val_loss: 11.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9815 - val_loss: 10.3232\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0984 - val_loss: 10.8483\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8233 - val_loss: 11.2258\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2386 - val_loss: 10.5179\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9391 - val_loss: 9.9734\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3930 - val_loss: 10.1805\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3429 - val_loss: 12.0277\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6542 - val_loss: 11.9974\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5079 - val_loss: 10.7628\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7262 - val_loss: 12.8870\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7586 - val_loss: 11.2202\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4782 - val_loss: 11.0679\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6610 - val_loss: 10.0797\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0321 - val_loss: 10.6333\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6432 - val_loss: 9.9176\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5329 - val_loss: 11.2823\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.6196 - val_loss: 10.8932\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0881 - val_loss: 12.2145\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4975 - val_loss: 10.6898\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8472 - val_loss: 9.8346\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6950 - val_loss: 10.5078\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6491 - val_loss: 10.1881\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0486 - val_loss: 12.1320\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7436 - val_loss: 10.0395\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5474 - val_loss: 9.7590\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7068 - val_loss: 10.0258\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3936 - val_loss: 10.5836\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5384 - val_loss: 9.7271\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4902 - val_loss: 9.6190\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6861 - val_loss: 11.5798\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7979 - val_loss: 10.1655\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6153 - val_loss: 10.3214\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4992 - val_loss: 10.9610\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1376 - val_loss: 10.5859\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1558 - val_loss: 10.2117\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8807 - val_loss: 10.7790\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0465 - val_loss: 9.7287\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8448 - val_loss: 14.5605\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7592 - val_loss: 10.7425\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9730 - val_loss: 9.3110\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1834 - val_loss: 10.5675\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0716 - val_loss: 9.1109\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8472 - val_loss: 9.3176\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8704 - val_loss: 9.9452\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6842 - val_loss: 11.0369\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7137 - val_loss: 9.2558\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5191 - val_loss: 8.9265\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5401 - val_loss: 9.2346\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7172 - val_loss: 9.7162\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1089 - val_loss: 9.5746\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0685 - val_loss: 8.8092\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5076 - val_loss: 9.3390\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6400 - val_loss: 9.4804\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9964 - val_loss: 8.8134\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4072 - val_loss: 8.8012\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6937 - val_loss: 9.8323\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1707 - val_loss: 8.7811\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0740 - val_loss: 8.5796\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3634 - val_loss: 9.1106\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0642 - val_loss: 8.5765\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0420 - val_loss: 8.4575\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1080 - val_loss: 8.3472\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8194 - val_loss: 8.5674\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6157 - val_loss: 8.4475\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3364 - val_loss: 8.8521\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1926 - val_loss: 8.1037\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9131 - val_loss: 9.2888\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3304 - val_loss: 8.1948\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1210 - val_loss: 8.8816\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0855 - val_loss: 7.8613\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9673 - val_loss: 8.0717\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.9490 - val_loss: 9.2719\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3950 - val_loss: 7.8422\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2153 - val_loss: 7.8680\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9140 - val_loss: 8.4853\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8841 - val_loss: 11.5253\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2478 - val_loss: 9.5728\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9799 - val_loss: 8.2539\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7372 - val_loss: 7.6624\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8350 - val_loss: 9.4153\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1003 - val_loss: 7.8168\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0008 - val_loss: 7.9960\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3891 - val_loss: 8.0059\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0321 - val_loss: 7.9908\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9623 - val_loss: 7.6125\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7174 - val_loss: 10.2948\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4647 - val_loss: 8.4862\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0724 - val_loss: 8.2333\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2229 - val_loss: 8.2051\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2250 - val_loss: 11.4455\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0653 - val_loss: 8.2119\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8253 - val_loss: 7.6876\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9567 - val_loss: 7.4959\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6870 - val_loss: 7.7310\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8699 - val_loss: 7.8484\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8602 - val_loss: 7.4080\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7750 - val_loss: 7.2487\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9767 - val_loss: 8.5932\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4053 - val_loss: 7.3465\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8262 - val_loss: 7.5398\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0702 - val_loss: 7.3581\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5816 - val_loss: 8.5283\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9149 - val_loss: 8.5057\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1259 - val_loss: 8.6542\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8806 - val_loss: 8.4475\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8296 - val_loss: 8.5647\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7416 - val_loss: 7.6743\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7279 - val_loss: 7.4880\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8996 - val_loss: 8.6987\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9745 - val_loss: 7.3047\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7251 - val_loss: 7.9881\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8088 - val_loss: 7.7853\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7717 - val_loss: 7.3188\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9792 - val_loss: 8.3972\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8023 - val_loss: 7.4370\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4790 - val_loss: 8.0791\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4615 - val_loss: 7.1773\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4415 - val_loss: 8.9709\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8798 - val_loss: 8.0118\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8353 - val_loss: 7.2344\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9264 - val_loss: 7.5472\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1089 - val_loss: 7.4764\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5309 - val_loss: 9.6512\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5762 - val_loss: 7.3153\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3621 - val_loss: 7.1493\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3898 - val_loss: 9.3899\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8536 - val_loss: 7.3010\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6989 - val_loss: 8.2479\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7622 - val_loss: 8.0058\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1407 - val_loss: 7.8352\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1317 - val_loss: 8.5608\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8868 - val_loss: 7.8419\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7807 - val_loss: 9.0834\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8066 - val_loss: 7.8759\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6151 - val_loss: 8.4598\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8185 - val_loss: 7.6278\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6621 - val_loss: 7.4935\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7522 - val_loss: 7.4153\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6255 - val_loss: 7.3789\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4950 - val_loss: 8.9342\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9513 - val_loss: 7.1639\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6445 - val_loss: 7.2584\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5688 - val_loss: 7.1953\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5220 - val_loss: 7.5573\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5680 - val_loss: 7.8870\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8320 - val_loss: 8.3693\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7393 - val_loss: 7.5953\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6479 - val_loss: 7.9304\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5886 - val_loss: 7.8120\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3347 - val_loss: 7.1622\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7483 - val_loss: 8.0701\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9043 - val_loss: 7.3297\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7665 - val_loss: 8.2748\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7269 - val_loss: 7.8198\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2996 - val_loss: 8.1301\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1406 - val_loss: 7.3085\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0118 - val_loss: 7.1223\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0106 - val_loss: 9.0885\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0975 - val_loss: 9.3108\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5938 - val_loss: 7.9684\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2719 - val_loss: 7.9414\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7013 - val_loss: 7.2370\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3602 - val_loss: 8.3948\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3224 - val_loss: 7.0618\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1060 - val_loss: 7.5206\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5478 - val_loss: 8.0197\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7493 - val_loss: 8.5897\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7886 - val_loss: 8.5622\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.6176 - val_loss: 7.1337\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3114 - val_loss: 8.1206\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6348 - val_loss: 6.9283\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7373 - val_loss: 7.7336\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7668 - val_loss: 8.9781\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8314 - val_loss: 8.1191\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7843 - val_loss: 8.0549\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9022 - val_loss: 7.0086\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3849 - val_loss: 8.6090\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7731 - val_loss: 6.9940\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3568 - val_loss: 8.0904\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0071 - val_loss: 6.6864\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6762 - val_loss: 7.9646\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5702 - val_loss: 8.0429\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5456 - val_loss: 7.5420\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.3475 - val_loss: 6.7144\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.8939 - val_loss: 8.3191\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.7824 - val_loss: 8.4630\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.6557 - val_loss: 7.0499\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.7432 - val_loss: 8.0718\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1115 - val_loss: 8.0571\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.6266 - val_loss: 7.3591\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 6.5333 - val_loss: 6.8115\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.6427 - val_loss: 7.9223\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5132 - val_loss: 7.2667\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4064 - val_loss: 6.9802\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4424 - val_loss: 7.2474\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2890 - val_loss: 7.7104\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9053 - val_loss: 7.5077\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5296 - val_loss: 7.3368\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.3830 - val_loss: 6.8268\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7351 - val_loss: 7.4161\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7826 - val_loss: 6.8516\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6219 - val_loss: 7.0571\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4648 - val_loss: 7.6691\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7891 - val_loss: 8.1338\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6733 - val_loss: 7.4747\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3530 - val_loss: 8.2133\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7927 - val_loss: 6.9024\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8476 - val_loss: 7.2506\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6478 - val_loss: 7.6284\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5965 - val_loss: 7.3464\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6048 - val_loss: 6.6795\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.3129 - val_loss: 6.6634\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4997 - val_loss: 7.2297\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8548 - val_loss: 8.1992\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8994 - val_loss: 8.1264\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4033 - val_loss: 8.3503\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5454 - val_loss: 7.5097\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4352 - val_loss: 6.7518\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4064 - val_loss: 7.3330\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3063 - val_loss: 7.8176\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3898 - val_loss: 6.7167\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.8184 - val_loss: 7.8678\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5772 - val_loss: 7.1163\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6021 - val_loss: 9.1293\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8901 - val_loss: 8.7900\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7296 - val_loss: 6.8276\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6247 - val_loss: 8.5506\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3760 - val_loss: 7.9456\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.3766 - val_loss: 7.4806\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3795 - val_loss: 7.3782\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3175 - val_loss: 9.6500\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5551 - val_loss: 7.3377\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2804 - val_loss: 7.0798\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2500 - val_loss: 7.0834\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8700 - val_loss: 7.1669\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5178 - val_loss: 7.5764\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4749 - val_loss: 6.7908\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3471 - val_loss: 7.9571\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5502 - val_loss: 6.7131\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1904 - val_loss: 7.2784\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2242 - val_loss: 6.6156\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4469 - val_loss: 7.1805\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7909 - val_loss: 7.0145\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4271 - val_loss: 7.7933\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6338 - val_loss: 6.8604\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2740 - val_loss: 7.2473\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3765 - val_loss: 7.3042\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6944 - val_loss: 8.7800\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8436 - val_loss: 7.7036\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2098 - val_loss: 8.1491\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4963 - val_loss: 7.5361\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9000 - val_loss: 7.3356\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5904 - val_loss: 7.5351\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4187 - val_loss: 6.9726\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3933 - val_loss: 7.6553\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4278 - val_loss: 6.9295\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4589 - val_loss: 9.2401\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8774 - val_loss: 9.0509\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1950 - val_loss: 7.0435\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5259 - val_loss: 7.3624\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5019 - val_loss: 6.6674\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7054 - val_loss: 8.2289\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4930 - val_loss: 6.7050\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3772 - val_loss: 7.2773\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2482 - val_loss: 6.9753\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2665 - val_loss: 8.1703\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1022 - val_loss: 6.6486\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3441 - val_loss: 6.7844\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4724 - val_loss: 8.2564\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0773 - val_loss: 7.6496\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6930 - val_loss: 7.0353\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2557 - val_loss: 7.1536\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2465 - val_loss: 6.7660\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4354 - val_loss: 7.3566\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4354 - val_loss: 6.9974\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4421 - val_loss: 8.4306\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8284 - val_loss: 9.1320\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6788 - val_loss: 8.0541\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0320 - val_loss: 9.5861\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7290 - val_loss: 6.8819\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4345 - val_loss: 9.6999\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0978 - val_loss: 7.0130\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6443 - val_loss: 6.8608\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3648 - val_loss: 6.8260\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5061 - val_loss: 7.1663\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3896 - val_loss: 6.8517\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9654 - val_loss: 7.1306\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1294 - val_loss: 7.3773\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4110 - val_loss: 6.4196\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6085 - val_loss: 7.1735\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7029 - val_loss: 7.6326\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4527 - val_loss: 7.0070\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5831 - val_loss: 7.5198\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9094 - val_loss: 10.3146\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0964 - val_loss: 7.7921\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5397 - val_loss: 7.9714\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3334 - val_loss: 7.0479\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2577 - val_loss: 6.7491\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5766 - val_loss: 7.5208\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7077 - val_loss: 7.5741\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6875 - val_loss: 7.6312\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2877 - val_loss: 6.8366\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.7526 - val_loss: 6.7840\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2280 - val_loss: 6.4556\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7375 - val_loss: 6.8018\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4082 - val_loss: 6.7213\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9480 - val_loss: 6.8835\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1298 - val_loss: 7.8578\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3970 - val_loss: 7.5761\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2626 - val_loss: 7.1409\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1147 - val_loss: 7.2174\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3660 - val_loss: 6.8397\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4626 - val_loss: 6.7404\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4917 - val_loss: 7.2374\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4506 - val_loss: 8.9214\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.5449 - val_loss: 6.9803\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3564 - val_loss: 6.8050\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2994 - val_loss: 6.8723\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7339 - val_loss: 7.4728\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2439 - val_loss: 6.8059\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1340 - val_loss: 6.5707\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1687 - val_loss: 6.5421\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5617 - val_loss: 7.1711\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4729 - val_loss: 6.8570\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2826 - val_loss: 6.5673\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2441 - val_loss: 6.7066\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3015 - val_loss: 6.8871\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3913 - val_loss: 6.5336\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6676 - val_loss: 7.0670\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2714 - val_loss: 7.1828\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6391 - val_loss: 7.0062\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3700 - val_loss: 8.1364\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3469 - val_loss: 6.8168\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2061 - val_loss: 8.1539\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6454 - val_loss: 6.5624\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4416 - val_loss: 7.1482\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1490 - val_loss: 6.8904\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2328 - val_loss: 6.4250\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3849 - val_loss: 6.5838\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2077 - val_loss: 6.2816\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2525 - val_loss: 9.0427\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3259 - val_loss: 7.2682\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8628 - val_loss: 6.4717\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6892 - val_loss: 6.3829\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6787 - val_loss: 6.5839\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7831 - val_loss: 6.8094\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2962 - val_loss: 7.3799\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6799 - val_loss: 7.1643\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2680 - val_loss: 7.2782\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1208 - val_loss: 9.6956\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2140 - val_loss: 6.5880\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0690 - val_loss: 6.0702\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.5668 - val_loss: 7.0642\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.3113 - val_loss: 6.8686\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8999 - val_loss: 6.6142\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.2491 - val_loss: 6.5019\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.4446 - val_loss: 6.6373\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.6140 - val_loss: 6.4318\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2896 - val_loss: 6.8560\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0801 - val_loss: 6.7879\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1395 - val_loss: 6.7198\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0308 - val_loss: 6.4343\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4251 - val_loss: 6.8250\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2470 - val_loss: 6.5023\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3034 - val_loss: 6.5119\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1490 - val_loss: 8.0052\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3157 - val_loss: 6.2381\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2175 - val_loss: 7.8084\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1731 - val_loss: 7.2156\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1136 - val_loss: 6.8589\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0952 - val_loss: 6.8116\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1524 - val_loss: 6.2854\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1394 - val_loss: 6.0535\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4826 - val_loss: 7.1248\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7190 - val_loss: 7.3010\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3045 - val_loss: 6.4200\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9695 - val_loss: 6.8878\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8482 - val_loss: 7.1507\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0557 - val_loss: 7.3838\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9893 - val_loss: 6.2016\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9935 - val_loss: 6.6373\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1857 - val_loss: 6.7646\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1103 - val_loss: 7.0524\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.5279 - val_loss: 6.6643\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0413 - val_loss: 6.0648\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3951 - val_loss: 6.4887\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1798 - val_loss: 6.6348\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4169 - val_loss: 6.2238\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3076 - val_loss: 7.6357\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9211 - val_loss: 6.2442\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3243 - val_loss: 6.7649\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1179 - val_loss: 7.6062\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2294 - val_loss: 6.5143\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1958 - val_loss: 6.7013\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1083 - val_loss: 6.5322\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9080 - val_loss: 6.9671\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1957 - val_loss: 6.5196\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0268 - val_loss: 6.3009\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1660 - val_loss: 6.6914\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7907 - val_loss: 6.2152\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9998 - val_loss: 6.4448\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1184 - val_loss: 7.7138\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2756 - val_loss: 5.9825\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9433 - val_loss: 6.6792\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9269 - val_loss: 6.6233\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7553 - val_loss: 7.2587\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0473 - val_loss: 7.7866\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7226 - val_loss: 6.1263\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0297 - val_loss: 6.3897\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6024 - val_loss: 6.3627\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1585 - val_loss: 6.0510\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7252 - val_loss: 6.9065\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6073 - val_loss: 6.1074\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0442 - val_loss: 6.7346\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6058 - val_loss: 8.6612\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7274 - val_loss: 6.3792\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1539 - val_loss: 6.4140\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6787 - val_loss: 7.3698\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1302 - val_loss: 7.0969\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2882 - val_loss: 7.1849\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2298 - val_loss: 6.0919\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0191 - val_loss: 6.3493\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9170 - val_loss: 6.1832\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8785 - val_loss: 7.0686\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6735 - val_loss: 7.2175\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.184 - 0s 93us/step - loss: 5.9254 - val_loss: 6.2495\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.3206 - val_loss: 6.7325\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0734 - val_loss: 7.7785\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8431 - val_loss: 6.7501\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7301 - val_loss: 6.2682\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6981 - val_loss: 6.0734\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7244 - val_loss: 6.5246\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0786 - val_loss: 6.1443\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8610 - val_loss: 8.0213\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1724 - val_loss: 6.0240\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8209 - val_loss: 5.9291\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7015 - val_loss: 6.2189\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0794 - val_loss: 6.6958\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8225 - val_loss: 6.0643\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9718 - val_loss: 6.7345\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1222 - val_loss: 5.8415\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7302 - val_loss: 5.8332\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7284 - val_loss: 6.0584\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6730 - val_loss: 6.9560\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6176 - val_loss: 6.7585\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1219 - val_loss: 6.4405\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6560 - val_loss: 6.5341\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7805 - val_loss: 5.8745\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0282 - val_loss: 5.8200\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8129 - val_loss: 7.0394\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9887 - val_loss: 5.9220\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1788 - val_loss: 6.5648\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6259 - val_loss: 7.5866\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8212 - val_loss: 8.2210\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8374 - val_loss: 6.3977\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1968 - val_loss: 6.3645\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0809 - val_loss: 7.5936\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2669 - val_loss: 6.0960\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7487 - val_loss: 6.1851\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6696 - val_loss: 6.2178\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8855 - val_loss: 6.1326\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0138 - val_loss: 7.1781\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8862 - val_loss: 6.9515\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7018 - val_loss: 6.9224\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0425 - val_loss: 6.5548\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8085 - val_loss: 6.0059\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5810 - val_loss: 6.5048\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9028 - val_loss: 6.1688\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5217 - val_loss: 6.0067\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7138 - val_loss: 6.8808\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1600 - val_loss: 6.2110\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2296 - val_loss: 6.4472\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4958 - val_loss: 6.1219\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0595 - val_loss: 6.1272\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0614 - val_loss: 6.2119\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9296 - val_loss: 6.6197\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7539 - val_loss: 7.2651\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0290 - val_loss: 6.2823\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2008 - val_loss: 5.9649\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0700 - val_loss: 5.7655\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8003 - val_loss: 6.2630\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6814 - val_loss: 7.2053\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8946 - val_loss: 7.1892\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1592 - val_loss: 6.2675\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6929 - val_loss: 6.2280\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6269 - val_loss: 5.8891\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5550 - val_loss: 5.9790\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5788 - val_loss: 6.1687\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8199 - val_loss: 6.4224\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8162 - val_loss: 7.0990\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0205 - val_loss: 6.1028\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6039 - val_loss: 5.8834\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6779 - val_loss: 6.3899\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8213 - val_loss: 5.9716\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9884 - val_loss: 7.3936\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7566 - val_loss: 6.0607\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7021 - val_loss: 6.1410\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5687 - val_loss: 6.6710\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9492 - val_loss: 6.0001\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7745 - val_loss: 6.1870\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5187 - val_loss: 6.4919\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9742 - val_loss: 6.4413\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6738 - val_loss: 5.6127\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3479 - val_loss: 6.9813\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1156 - val_loss: 7.2458\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3135 - val_loss: 8.4480\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2621 - val_loss: 6.7850\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6915 - val_loss: 7.0192\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8134 - val_loss: 6.1848\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3954 - val_loss: 6.0382\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6693 - val_loss: 6.0423\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7428 - val_loss: 6.2403\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7722 - val_loss: 5.6618\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4750 - val_loss: 6.5896\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5694 - val_loss: 5.7630\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4043 - val_loss: 5.8338\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5584 - val_loss: 5.7479\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 5.7726 - val_loss: 6.5975\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6467 - val_loss: 5.8037\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6105 - val_loss: 5.8844\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.4129 - val_loss: 5.8359\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7828 - val_loss: 6.8053\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7237 - val_loss: 6.4627\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5479 - val_loss: 6.2335\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0637 - val_loss: 6.5570\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9172 - val_loss: 7.0736\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6320 - val_loss: 6.3717\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4898 - val_loss: 5.8021\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5425 - val_loss: 6.1544\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2528 - val_loss: 5.7168\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7437 - val_loss: 7.9709\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8316 - val_loss: 5.9986\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6703 - val_loss: 6.8792\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5656 - val_loss: 6.3371\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5194 - val_loss: 7.3955\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6866 - val_loss: 6.0150\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5266 - val_loss: 7.1975\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5403 - val_loss: 5.4030\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4992 - val_loss: 5.9178\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4186 - val_loss: 6.9774\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4881 - val_loss: 6.1933\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3724 - val_loss: 5.6091\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7661 - val_loss: 6.6386\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6042 - val_loss: 7.1410\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7772 - val_loss: 5.8308\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6470 - val_loss: 6.6947\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0189 - val_loss: 5.5967\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0737 - val_loss: 6.0692\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5865 - val_loss: 5.8957\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5957 - val_loss: 5.5856\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3137 - val_loss: 5.9190\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6875 - val_loss: 8.3654\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9313 - val_loss: 6.3077\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7186 - val_loss: 5.9481\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3357 - val_loss: 5.8581\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4040 - val_loss: 5.8614\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9176 - val_loss: 5.7147\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8184 - val_loss: 5.4703\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6406 - val_loss: 5.6492\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3986 - val_loss: 5.6345\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7498 - val_loss: 5.9433\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4967 - val_loss: 6.3594\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5040 - val_loss: 6.7053\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5497 - val_loss: 5.9984\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7853 - val_loss: 5.8250\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4794 - val_loss: 5.9123\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4378 - val_loss: 5.9753\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5978 - val_loss: 5.9058\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4016 - val_loss: 5.5758\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6296 - val_loss: 6.2044\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4187 - val_loss: 6.6864\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5941 - val_loss: 5.4688\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8939 - val_loss: 8.4897\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8904 - val_loss: 9.3555\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6537 - val_loss: 6.0343\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5318 - val_loss: 5.4620\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2429 - val_loss: 5.6394\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7879 - val_loss: 7.5045\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7777 - val_loss: 5.8640\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7499 - val_loss: 5.8469\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6885 - val_loss: 5.7507\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8354 - val_loss: 6.3911\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6085 - val_loss: 6.4631\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2743 - val_loss: 6.8065\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6887 - val_loss: 5.7451\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6077 - val_loss: 5.4769\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3152 - val_loss: 5.6156\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6022 - val_loss: 5.5411\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6602 - val_loss: 6.1976\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5501 - val_loss: 6.4303\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8530 - val_loss: 5.9271\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3653 - val_loss: 5.5706\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6648 - val_loss: 5.9563\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2378 - val_loss: 5.5114\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4513 - val_loss: 5.5591\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6781 - val_loss: 8.5693\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8596 - val_loss: 6.0937\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7243 - val_loss: 5.4904\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6284 - val_loss: 7.0306\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4841 - val_loss: 5.9283\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7489 - val_loss: 5.5865\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4513 - val_loss: 5.8951\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2226 - val_loss: 5.7939\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7155 - val_loss: 6.3762\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7885 - val_loss: 5.5890\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7111 - val_loss: 6.0094\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6848 - val_loss: 5.9846\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3636 - val_loss: 5.4862\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3341 - val_loss: 6.8457\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6217 - val_loss: 6.0129\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6009 - val_loss: 5.9833\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5593 - val_loss: 5.2343\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8456 - val_loss: 6.2015\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3897 - val_loss: 5.5518\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.3835 - val_loss: 5.4066\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4156 - val_loss: 6.2510\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5316 - val_loss: 5.2734\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3116 - val_loss: 6.9046\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3699 - val_loss: 5.6182\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5828 - val_loss: 5.5089\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4070 - val_loss: 5.3436\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4068 - val_loss: 6.8275\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4983 - val_loss: 5.4320\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8411 - val_loss: 6.0981\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4623 - val_loss: 5.5499\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5302 - val_loss: 5.9676\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0822 - val_loss: 5.6598\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5335 - val_loss: 5.7116\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5567 - val_loss: 5.3211\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8440 - val_loss: 5.8413\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7450 - val_loss: 5.7937\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2862 - val_loss: 6.0036\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4206 - val_loss: 5.4327\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3137 - val_loss: 6.6138\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0211 - val_loss: 6.0080\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8239 - val_loss: 6.5176\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6945 - val_loss: 5.7730\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2292 - val_loss: 5.2432\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7752 - val_loss: 5.3037\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3094 - val_loss: 5.3841\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4700 - val_loss: 6.4693\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6793 - val_loss: 5.3879\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3099 - val_loss: 6.6882\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6537 - val_loss: 5.3905\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3032 - val_loss: 5.2998\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4815 - val_loss: 5.7605\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6378 - val_loss: 5.8334\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4868 - val_loss: 5.5662\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1615 - val_loss: 7.0835\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4075 - val_loss: 5.9606\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4792 - val_loss: 5.6751\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6174 - val_loss: 5.9614\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8003 - val_loss: 6.1299\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4421 - val_loss: 5.3011\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5738 - val_loss: 5.3241\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4248 - val_loss: 6.0821\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3967 - val_loss: 5.3752\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.5771 - val_loss: 5.4665\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9412 - val_loss: 5.3943\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9791 - val_loss: 5.2595\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5738 - val_loss: 5.5373\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1336 - val_loss: 5.1082\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3378 - val_loss: 5.7567\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4202 - val_loss: 5.5922\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3607 - val_loss: 5.3578\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4288 - val_loss: 6.0096\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4623 - val_loss: 5.4137\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4999 - val_loss: 6.4070\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6112 - val_loss: 5.8043\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3429 - val_loss: 5.9344\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9022 - val_loss: 6.1997\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8460 - val_loss: 5.2975\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2864 - val_loss: 5.3985\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1360 - val_loss: 5.3873\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2511 - val_loss: 9.2136\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3778 - val_loss: 5.3794\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2291 - val_loss: 5.3618\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4929 - val_loss: 5.3874\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3960 - val_loss: 5.4364\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3201 - val_loss: 5.3144\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5094 - val_loss: 6.1168\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1574 - val_loss: 5.9849\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9504 - val_loss: 6.8974\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.4706 - val_loss: 5.7488\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4564 - val_loss: 6.1120\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3532 - val_loss: 5.3122\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5566 - val_loss: 6.4867\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.3192 - val_loss: 5.2080\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3375 - val_loss: 5.8007\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7328 - val_loss: 5.6107\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6011 - val_loss: 5.6486\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2999 - val_loss: 5.4324\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3728 - val_loss: 6.9756\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3062 - val_loss: 6.0431\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1624 - val_loss: 6.3307\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3134 - val_loss: 5.3149\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2873 - val_loss: 5.2698\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4828 - val_loss: 5.3097\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3840 - val_loss: 6.2471\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2936 - val_loss: 5.0552\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1331 - val_loss: 5.2724\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3879 - val_loss: 6.2600\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2108 - val_loss: 5.2677\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3758 - val_loss: 5.2585\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4337 - val_loss: 5.5674\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1577 - val_loss: 5.5900\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1435 - val_loss: 5.6222\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4915 - val_loss: 6.5016\n",
      "5.185182373080633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5114426 ,  3.7540421 , -0.9258749 ,  3.9511173 , -2.8780782 ,\n",
       "          3.5148356 , -0.17075485, -0.21496631,  0.5896957 ,  0.37322915],\n",
       "        [ 1.1511277 ,  0.5803845 , -0.8427422 , -0.29231417,  0.13460119,\n",
       "         -0.10889622,  0.11545078, -0.7047312 ,  0.32383096, -0.5949959 ],\n",
       "        [ 1.8395011 ,  2.544752  , -0.34529173,  0.6556465 , -0.07748242,\n",
       "         -0.10527457, -0.41793054, -1.9265183 ,  0.5396208 , -2.7228565 ],\n",
       "        [ 0.26404285, -0.1661447 ,  0.3451975 , -0.1278867 ,  0.04879194,\n",
       "         -0.03528875,  0.27694777,  0.09411192, -0.8269575 , -0.17434831],\n",
       "        [ 0.64437515,  0.31596923, -1.2869954 ,  0.22923848, -0.24794689,\n",
       "          2.180064  , -1.2812476 ,  0.87846226,  0.8659223 ,  3.088846  ]],\n",
       "       dtype=float32),\n",
       " array([-5.344633  ,  4.3078933 , -0.37254304,  5.1133947 , -1.6516544 ,\n",
       "         4.539762  , -3.7096655 , -1.0651788 , -2.757848  , -5.13457   ],\n",
       "       dtype=float32),\n",
       " array([[ 0.9656323 ,  1.4725482 , -0.79799885,  1.4379953 ,  1.7076443 ,\n",
       "         -1.535236  , -1.8810906 ,  1.8494495 , -0.990873  ,  1.7544423 ],\n",
       "        [-0.6522312 ,  0.10614285, -0.0047328 , -0.5895409 , -0.96714425,\n",
       "          0.70227087,  0.7067221 , -0.4121528 ,  0.21391372, -0.9022221 ],\n",
       "        [-0.21872824, -0.44615173,  0.01513806, -0.4929602 , -0.7756128 ,\n",
       "          0.10180205,  0.7876226 , -0.12394873,  0.30151358, -0.8849182 ],\n",
       "        [-1.4373558 , -1.538662  ,  2.1822884 , -2.2550375 , -2.728381  ,\n",
       "          2.5490558 ,  2.0866666 , -2.672217  ,  1.7472897 , -2.675208  ],\n",
       "        [-0.4022934 , -0.42890587,  0.73848003, -1.029763  , -1.3695726 ,\n",
       "          1.153284  ,  0.49999496, -0.38216016,  0.4155021 , -1.3230127 ],\n",
       "        [-2.2511818 , -1.4024687 ,  1.5323862 , -1.8935783 , -2.1519496 ,\n",
       "          2.2711575 ,  2.3309324 , -2.4795554 ,  0.9775312 , -2.5940895 ],\n",
       "        [ 0.35959432,  1.448418  , -1.0855079 ,  1.0965194 ,  1.6398804 ,\n",
       "         -1.2819486 , -1.717112  ,  0.90482867, -0.74801993,  1.0249258 ],\n",
       "        [-0.84103346, -0.6315622 ,  0.57521653, -0.6807362 , -0.63109803,\n",
       "          0.14910154,  1.0527136 , -0.5141457 , -0.48445222, -0.41558176],\n",
       "        [ 0.41494393,  0.6099086 , -0.02750092,  0.03167812,  0.36330828,\n",
       "         -0.10714963, -0.90140396,  0.32448766, -0.04937581,  0.79268163],\n",
       "        [-0.16265105,  0.03795683, -0.22100301,  0.19465777,  0.69764596,\n",
       "         -0.41271794, -0.978368  ,  0.4518346 ,  0.2864624 , -0.07266244]],\n",
       "       dtype=float32),\n",
       " array([-1.5283858 , -1.6627955 ,  1.6137533 , -1.5053709 , -1.819081  ,\n",
       "         1.8021916 ,  1.846064  , -1.824101  ,  0.81347674, -1.8352424 ],\n",
       "       dtype=float32),\n",
       " array([[-0.8454777 ],\n",
       "        [-1.1049461 ],\n",
       "        [ 1.0325354 ],\n",
       "        [-1.1026993 ],\n",
       "        [-1.6371639 ],\n",
       "        [ 1.682911  ],\n",
       "        [ 1.791963  ],\n",
       "        [-1.7359393 ],\n",
       "        [ 0.54065484],\n",
       "        [-1.7093387 ]], dtype=float32),\n",
       " array([2.09722], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_5(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure5_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 249us/step - loss: 6687.9534 - val_loss: 599.8483\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 170.4263 - val_loss: 42.0623\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 30.9330 - val_loss: 27.7780\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 23.4163 - val_loss: 23.9673\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 20.9538 - val_loss: 22.7486\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3619 - val_loss: 22.2057\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5437 - val_loss: 22.4167\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7554 - val_loss: 21.8875\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4935 - val_loss: 21.7130\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.9348 - val_loss: 21.1150\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.7361 - val_loss: 21.3883\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.4271 - val_loss: 20.5617\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.3174 - val_loss: 20.3025\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.9335 - val_loss: 20.6963\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.2304 - val_loss: 19.5506\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.5518 - val_loss: 19.2494\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.1723 - val_loss: 19.1604\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.3390 - val_loss: 18.9344\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.6105 - val_loss: 18.6867\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8707 - val_loss: 18.2342\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6008 - val_loss: 18.3799\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.5899 - val_loss: 18.4800\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5707 - val_loss: 19.1565\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.5408 - val_loss: 17.7180\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.0502 - val_loss: 17.2451\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0316 - val_loss: 18.3495\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9482 - val_loss: 17.3704\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8961 - val_loss: 17.3012\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6311 - val_loss: 16.6751\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.4526 - val_loss: 16.8473\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.4946 - val_loss: 17.3251\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1119 - val_loss: 16.3044\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.8755 - val_loss: 16.1339\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8364 - val_loss: 15.9444\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.6265 - val_loss: 15.9562\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.4402 - val_loss: 15.2184\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0508 - val_loss: 14.9862\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.1538 - val_loss: 15.4751\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8850 - val_loss: 14.5291\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7797 - val_loss: 15.0216\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.6423 - val_loss: 14.2094\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6243 - val_loss: 14.1075\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5161 - val_loss: 14.1499\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.4390 - val_loss: 13.6785\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3396 - val_loss: 13.9596\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3005 - val_loss: 13.9364\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0102 - val_loss: 13.7809\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3463 - val_loss: 13.7862\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1217 - val_loss: 14.9716\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9751 - val_loss: 13.9117\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8071 - val_loss: 13.1493\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4074 - val_loss: 12.5940\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6477 - val_loss: 12.8199\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7988 - val_loss: 12.2207\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5270 - val_loss: 12.3517\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3868 - val_loss: 12.6555\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3478 - val_loss: 12.1549\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1254 - val_loss: 11.9238\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2077 - val_loss: 12.5611\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3680 - val_loss: 12.3597\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8565 - val_loss: 12.0336\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0193 - val_loss: 13.0048\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.1310 - val_loss: 11.6786\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8294 - val_loss: 11.9213\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.6329 - val_loss: 11.4916\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7517 - val_loss: 11.7503\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6231 - val_loss: 11.1200\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4627 - val_loss: 11.4531\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6741 - val_loss: 11.3956\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5182 - val_loss: 11.0879\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7236 - val_loss: 12.1863\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3603 - val_loss: 11.8632\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6664 - val_loss: 11.7720\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3992 - val_loss: 12.8155\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8723 - val_loss: 10.6586\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5439 - val_loss: 10.9981\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8064 - val_loss: 11.7810\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1377 - val_loss: 10.8047\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4851 - val_loss: 10.2949\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0128 - val_loss: 11.6315\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1150 - val_loss: 11.0929\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9804 - val_loss: 10.4804\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2867 - val_loss: 10.8741\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2466 - val_loss: 11.9859\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7589 - val_loss: 11.6929\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8613 - val_loss: 11.7839\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1991 - val_loss: 10.8255\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.6182 - val_loss: 11.0077\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2716 - val_loss: 11.0111\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8950 - val_loss: 10.6071\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8363 - val_loss: 10.4629\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7054 - val_loss: 10.4051\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6950 - val_loss: 10.3187\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9916 - val_loss: 10.6169\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8309 - val_loss: 11.7061\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7999 - val_loss: 10.7328\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9130 - val_loss: 10.8627\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0256 - val_loss: 10.4512\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0847 - val_loss: 14.5252\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9544 - val_loss: 10.1175\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7168 - val_loss: 12.0918\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6467 - val_loss: 10.8132\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6035 - val_loss: 10.5206\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6780 - val_loss: 10.2304\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6554 - val_loss: 10.3502\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4047 - val_loss: 11.7916\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0963 - val_loss: 10.5835\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4361 - val_loss: 11.5389\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8413 - val_loss: 12.0062\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7097 - val_loss: 10.2401\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4690 - val_loss: 10.4219\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7500 - val_loss: 11.2045\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7328 - val_loss: 10.4935\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0205 - val_loss: 10.6841\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0236 - val_loss: 13.7276\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8727 - val_loss: 11.9598\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6804 - val_loss: 11.2300\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6238 - val_loss: 10.2295\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3706 - val_loss: 10.0354\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3292 - val_loss: 10.6756\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2494 - val_loss: 11.3691\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8315 - val_loss: 11.4192\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5990 - val_loss: 11.7431\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0201 - val_loss: 10.3283\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4446 - val_loss: 10.2431\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9879 - val_loss: 10.8017\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1308 - val_loss: 11.4180\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7268 - val_loss: 11.5412\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2834 - val_loss: 9.4436\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1517 - val_loss: 9.2877\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0295 - val_loss: 10.3813\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2939 - val_loss: 10.1272\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0597 - val_loss: 9.6708\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3859 - val_loss: 10.4491\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3992 - val_loss: 9.1885\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4759 - val_loss: 11.2254\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6971 - val_loss: 9.0694\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6697 - val_loss: 9.8315\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5326 - val_loss: 10.3639\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3558 - val_loss: 9.4412\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1652 - val_loss: 10.7749\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9313 - val_loss: 9.6984\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7575 - val_loss: 9.5200\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5125 - val_loss: 8.9030\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2299 - val_loss: 8.8288\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2586 - val_loss: 9.6291\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3638 - val_loss: 9.8440\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1631 - val_loss: 10.1855\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6496 - val_loss: 9.1454\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8125 - val_loss: 9.1113\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7294 - val_loss: 9.4208\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8714 - val_loss: 10.0139\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8546 - val_loss: 9.9748\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8376 - val_loss: 8.5509\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0193 - val_loss: 8.6735\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9291 - val_loss: 8.9116\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9265 - val_loss: 9.9563\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6850 - val_loss: 8.9464\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9729 - val_loss: 10.9511\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0046 - val_loss: 8.7074\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7130 - val_loss: 9.9463\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0817 - val_loss: 8.6589\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9889 - val_loss: 9.5963\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8569 - val_loss: 14.9239\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7091 - val_loss: 9.9009\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7430 - val_loss: 9.5419\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9367 - val_loss: 9.3088\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0831 - val_loss: 10.5365\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8148 - val_loss: 11.2008\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7903 - val_loss: 9.9102\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9427 - val_loss: 9.1664\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4920 - val_loss: 8.7385\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0773 - val_loss: 8.2486\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5255 - val_loss: 8.6920\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9981 - val_loss: 8.3613\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9290 - val_loss: 8.1192\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7453 - val_loss: 8.2940\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8555 - val_loss: 9.4727\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2596 - val_loss: 8.9414\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6766 - val_loss: 11.5448\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4932 - val_loss: 10.0531\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5173 - val_loss: 9.4577\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6736 - val_loss: 9.2501\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3772 - val_loss: 9.5772\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5594 - val_loss: 8.0935\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6633 - val_loss: 9.6404\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6367 - val_loss: 8.3293\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2507 - val_loss: 7.9618\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5238 - val_loss: 10.2540\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1696 - val_loss: 8.3531\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.1967 - val_loss: 9.1201\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5558 - val_loss: 10.4011\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4932 - val_loss: 7.9518\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5104 - val_loss: 8.0955\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1382 - val_loss: 7.8350\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0592 - val_loss: 8.0281\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2578 - val_loss: 7.8199\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3485 - val_loss: 11.1762\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0218 - val_loss: 8.4065\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5460 - val_loss: 10.6819\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7414 - val_loss: 9.1937\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8020 - val_loss: 7.6074\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2896 - val_loss: 7.8930\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0872 - val_loss: 7.4607\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4137 - val_loss: 8.4376\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9566 - val_loss: 8.1525\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1736 - val_loss: 7.7568\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.7876 - val_loss: 8.4370\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0054 - val_loss: 7.8357\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2431 - val_loss: 8.7840\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9640 - val_loss: 7.2395\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8930 - val_loss: 7.1235\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9831 - val_loss: 9.2010\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2829 - val_loss: 8.4468\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1398 - val_loss: 9.1154\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7411 - val_loss: 7.6789\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5712 - val_loss: 7.7365\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7642 - val_loss: 9.1830\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9529 - val_loss: 7.5092\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2339 - val_loss: 7.4068\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5966 - val_loss: 9.9303\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6982 - val_loss: 7.5926\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8770 - val_loss: 7.6803\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7914 - val_loss: 7.7218\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9878 - val_loss: 8.4586\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3646 - val_loss: 8.5439\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5384 - val_loss: 8.5527\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7885 - val_loss: 8.1081\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2324 - val_loss: 8.0706\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8704 - val_loss: 7.5073\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9458 - val_loss: 7.3873\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9759 - val_loss: 8.4993\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8938 - val_loss: 9.3489\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9645 - val_loss: 7.7388\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7831 - val_loss: 7.6927\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1766 - val_loss: 7.8640\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3011 - val_loss: 8.1205\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7919 - val_loss: 8.1212\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6319 - val_loss: 7.3692\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8525 - val_loss: 7.4974\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0061 - val_loss: 7.3750\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4239 - val_loss: 8.8421\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6702 - val_loss: 6.8489\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8959 - val_loss: 7.1787\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7114 - val_loss: 8.4243\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6575 - val_loss: 7.4268\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3127 - val_loss: 9.6989\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5626 - val_loss: 7.2716\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5789 - val_loss: 6.9792\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.5470 - val_loss: 7.2673\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9766 - val_loss: 7.8955\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6282 - val_loss: 7.2260\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3220 - val_loss: 8.4624\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2961 - val_loss: 6.9319\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2919 - val_loss: 7.0914\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3612 - val_loss: 7.6496\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.3392 - val_loss: 7.8158\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3678 - val_loss: 9.6143\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0453 - val_loss: 7.4012\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8183 - val_loss: 7.3428\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2428 - val_loss: 6.9865\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4202 - val_loss: 6.8793\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.4182 - val_loss: 7.1782\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4554 - val_loss: 7.6618\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0994 - val_loss: 6.7684\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3410 - val_loss: 8.3575\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0508 - val_loss: 7.5385\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0528 - val_loss: 6.7736\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2396 - val_loss: 7.0942\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7960 - val_loss: 8.3192\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1641 - val_loss: 7.5296\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4080 - val_loss: 7.0977\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7690 - val_loss: 6.8382\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8046 - val_loss: 8.7302\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0342 - val_loss: 9.2042\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5429 - val_loss: 8.1077\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7190 - val_loss: 7.9507\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2753 - val_loss: 7.4692\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5339 - val_loss: 8.2179\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2767 - val_loss: 8.0744\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6214 - val_loss: 9.4900\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6404 - val_loss: 7.9298\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1951 - val_loss: 8.2899\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4017 - val_loss: 6.6758\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0091 - val_loss: 6.9670\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3228 - val_loss: 6.7784\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4353 - val_loss: 6.8621\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5393 - val_loss: 6.9952\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2464 - val_loss: 6.7468\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3569 - val_loss: 7.0600\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6120 - val_loss: 6.6999\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4444 - val_loss: 8.7027\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2423 - val_loss: 6.7959\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3480 - val_loss: 7.9060\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8134 - val_loss: 8.1978\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.2721 - val_loss: 8.0264\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.2424 - val_loss: 8.3317\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.5490 - val_loss: 7.0265\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8541 - val_loss: 7.0525\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2339 - val_loss: 6.9895\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.2688 - val_loss: 7.0183\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1968 - val_loss: 7.9423\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3431 - val_loss: 8.8257\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.5529 - val_loss: 8.0530\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2079 - val_loss: 7.8765\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0032 - val_loss: 7.5214\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2148 - val_loss: 6.5541\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7140 - val_loss: 6.9243\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.2570 - val_loss: 6.9796\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2186 - val_loss: 7.1194\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.8285 - val_loss: 6.6022\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2057 - val_loss: 7.1611\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0713 - val_loss: 7.8260\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6092 - val_loss: 7.7736\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6745 - val_loss: 7.4887\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3431 - val_loss: 6.9668\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4652 - val_loss: 7.2422\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3916 - val_loss: 6.8397\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2743 - val_loss: 8.0963\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2739 - val_loss: 6.8583\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5849 - val_loss: 8.1051\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4962 - val_loss: 7.6090\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7026 - val_loss: 8.5010\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2383 - val_loss: 7.0775\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4615 - val_loss: 9.3264\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3421 - val_loss: 7.3975\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1162 - val_loss: 6.9622\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1229 - val_loss: 7.4093\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5226 - val_loss: 7.3598\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8991 - val_loss: 8.6150\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5655 - val_loss: 9.1244\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6249 - val_loss: 6.6824\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4599 - val_loss: 8.3144\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0771 - val_loss: 6.8642\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0111 - val_loss: 7.6582\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9494 - val_loss: 7.8009\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3932 - val_loss: 8.1523\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2288 - val_loss: 6.9243\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0469 - val_loss: 6.9316\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.9719 - val_loss: 9.9267\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8604 - val_loss: 6.6198\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1953 - val_loss: 7.0729\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1579 - val_loss: 6.9393\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0987 - val_loss: 7.5175\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0109 - val_loss: 8.0630\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8305 - val_loss: 7.7196\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0927 - val_loss: 7.1586\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8006 - val_loss: 7.3395\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3512 - val_loss: 7.3580\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4492 - val_loss: 9.3431\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1880 - val_loss: 7.0563\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2053 - val_loss: 7.5056\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0733 - val_loss: 6.8621\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0292 - val_loss: 6.7115\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3938 - val_loss: 9.7856\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7022 - val_loss: 6.8958\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0162 - val_loss: 7.1295\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9655 - val_loss: 7.1362\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8062 - val_loss: 6.7903\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0519 - val_loss: 7.2441\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2210 - val_loss: 7.6927\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3773 - val_loss: 8.0969\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9131 - val_loss: 8.2393\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3416 - val_loss: 7.5205\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4789 - val_loss: 7.5942\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1642 - val_loss: 6.8685\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5870 - val_loss: 7.4675\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7392 - val_loss: 9.6960\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8031 - val_loss: 8.0245\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3362 - val_loss: 7.9148\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2461 - val_loss: 6.6865\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3993 - val_loss: 7.1442\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3883 - val_loss: 7.5328\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5752 - val_loss: 7.2397\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3249 - val_loss: 6.8624\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8897 - val_loss: 6.8342\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0245 - val_loss: 7.1035\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3926 - val_loss: 6.6855\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.8015 - val_loss: 9.9273\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5376 - val_loss: 6.8883\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.9429 - val_loss: 6.4108\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9390 - val_loss: 8.0079\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6975 - val_loss: 6.8569\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3256 - val_loss: 7.4309\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9430 - val_loss: 7.0478\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9764 - val_loss: 7.2752\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1853 - val_loss: 8.3656\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8936 - val_loss: 7.1209\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8198 - val_loss: 8.7446\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6650 - val_loss: 7.8242\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8854 - val_loss: 6.7980\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8659 - val_loss: 7.1677\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0921 - val_loss: 6.5253\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8219 - val_loss: 7.5089\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2245 - val_loss: 7.0757\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1410 - val_loss: 6.3625\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1056 - val_loss: 7.2074\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8657 - val_loss: 7.6709\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8776 - val_loss: 6.3456\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8296 - val_loss: 7.6329\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0602 - val_loss: 7.5549\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8924 - val_loss: 6.7508\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0429 - val_loss: 7.4530\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0826 - val_loss: 7.3753\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.5952 - val_loss: 6.9610\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.4855 - val_loss: 7.0072\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8956 - val_loss: 8.9804\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2758 - val_loss: 8.0727\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9225 - val_loss: 7.2566\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1488 - val_loss: 8.5954\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3865 - val_loss: 7.1871\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2722 - val_loss: 7.4242\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2450 - val_loss: 7.5174\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.9644 - val_loss: 6.5572\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0781 - val_loss: 8.0776\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1518 - val_loss: 7.2323\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2345 - val_loss: 6.5865\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0957 - val_loss: 7.6077\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5160 - val_loss: 8.6371\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4176 - val_loss: 7.2413\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5171 - val_loss: 6.6610\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1544 - val_loss: 6.5068\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.2189 - val_loss: 6.9201\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8636 - val_loss: 6.4749\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7234 - val_loss: 7.5000\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3676 - val_loss: 7.5776\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2288 - val_loss: 6.5956\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0811 - val_loss: 8.7419\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1503 - val_loss: 6.3263\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0642 - val_loss: 7.3091\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9948 - val_loss: 7.1497\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9237 - val_loss: 7.6040\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7733 - val_loss: 6.4634\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7881 - val_loss: 8.8822\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.5145 - val_loss: 6.7029\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8845 - val_loss: 6.5652\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1234 - val_loss: 6.9368\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8999 - val_loss: 6.7856\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9413 - val_loss: 6.8127\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3553 - val_loss: 7.4359\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8283 - val_loss: 7.0674\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1912 - val_loss: 7.1284\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8224 - val_loss: 7.4517\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8924 - val_loss: 6.9380\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0529 - val_loss: 7.0681\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5314 - val_loss: 6.9686\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1366 - val_loss: 6.9032\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1191 - val_loss: 6.6758\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0239 - val_loss: 8.2109\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0942 - val_loss: 7.4028\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0896 - val_loss: 6.9947\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8898 - val_loss: 9.6213\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2150 - val_loss: 6.3433\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5492 - val_loss: 6.7742\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0935 - val_loss: 7.3820\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2535 - val_loss: 7.3942\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3560 - val_loss: 6.5473\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9862 - val_loss: 7.8839\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.5069 - val_loss: 9.6354\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.0098 - val_loss: 6.7273\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.2523 - val_loss: 7.4179\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.7059 - val_loss: 6.6562\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0546 - val_loss: 7.1860\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0497 - val_loss: 7.6876\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.5781 - val_loss: 7.3243\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.4914 - val_loss: 10.8054\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.2910 - val_loss: 8.0039\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1016 - val_loss: 6.3136\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6688 - val_loss: 7.5405\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6200 - val_loss: 6.7149\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0888 - val_loss: 7.0196\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0958 - val_loss: 7.2370\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4592 - val_loss: 6.7522\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0827 - val_loss: 6.4915\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2266 - val_loss: 7.8521\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5382 - val_loss: 8.8605\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9370 - val_loss: 7.1855\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9093 - val_loss: 6.5767\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4222 - val_loss: 7.5351\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8667 - val_loss: 7.1139\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8606 - val_loss: 6.7786\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9233 - val_loss: 6.9664\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9232 - val_loss: 8.0391\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6123 - val_loss: 6.2956\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3045 - val_loss: 6.5543\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8713 - val_loss: 6.5769\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3005 - val_loss: 8.0091\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2480 - val_loss: 7.6016\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7967 - val_loss: 6.8866\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8329 - val_loss: 6.8342\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9029 - val_loss: 6.7154\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9633 - val_loss: 6.2402\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1961 - val_loss: 6.6220\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8499 - val_loss: 6.5662\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9327 - val_loss: 6.6337\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9418 - val_loss: 7.5489\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.2715 - val_loss: 6.5448\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7332 - val_loss: 6.9219\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1128 - val_loss: 6.4956\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8148 - val_loss: 7.3498\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0596 - val_loss: 6.6641\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1494 - val_loss: 7.3539\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0846 - val_loss: 7.3422\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0047 - val_loss: 7.1790\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6167 - val_loss: 7.0553\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9224 - val_loss: 7.8894\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0426 - val_loss: 7.2811\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1934 - val_loss: 7.8389\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9986 - val_loss: 8.6427\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9089 - val_loss: 7.6812\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6652 - val_loss: 6.9945\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.3858 - val_loss: 8.5636\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7970 - val_loss: 8.5203\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7377 - val_loss: 6.4914\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7992 - val_loss: 8.0002\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7696 - val_loss: 6.7723\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6666 - val_loss: 6.9935\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9107 - val_loss: 7.2863\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7584 - val_loss: 8.1178\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0805 - val_loss: 7.0939\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8876 - val_loss: 6.7621\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7396 - val_loss: 7.2604\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8709 - val_loss: 7.4384\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2111 - val_loss: 6.7271\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2357 - val_loss: 6.6092\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8193 - val_loss: 6.4402\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7426 - val_loss: 6.8933\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8681 - val_loss: 6.7035\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2533 - val_loss: 7.9855\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0542 - val_loss: 7.0371\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6211 - val_loss: 6.2826\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8094 - val_loss: 6.6797\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0516 - val_loss: 7.5336\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0658 - val_loss: 7.4760\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7097 - val_loss: 8.1730\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3980 - val_loss: 6.5273\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9055 - val_loss: 6.6807\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0781 - val_loss: 9.9052\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9967 - val_loss: 7.9475\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0598 - val_loss: 7.2762\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5948 - val_loss: 8.0036\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2288 - val_loss: 6.2003\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9481 - val_loss: 7.2951\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9486 - val_loss: 6.6910\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0220 - val_loss: 7.1481\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6097 - val_loss: 7.4474\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0726 - val_loss: 7.2030\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0471 - val_loss: 7.7522\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9049 - val_loss: 10.4562\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1715 - val_loss: 6.4120\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8532 - val_loss: 6.5999\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6858 - val_loss: 6.5504\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7460 - val_loss: 7.7897\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2215 - val_loss: 6.5458\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7283 - val_loss: 7.2783\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0986 - val_loss: 7.5411\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9919 - val_loss: 6.4645\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1092 - val_loss: 7.0904\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7417 - val_loss: 8.3914\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9506 - val_loss: 7.1478\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6735 - val_loss: 6.9302\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2707 - val_loss: 6.5059\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8326 - val_loss: 6.8638\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7615 - val_loss: 8.2125\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8654 - val_loss: 7.0820\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8330 - val_loss: 8.7074\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9760 - val_loss: 7.5151\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8067 - val_loss: 6.7197\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7746 - val_loss: 6.8510\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8388 - val_loss: 6.6742\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7463 - val_loss: 7.0806\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0137 - val_loss: 7.0766\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6876 - val_loss: 7.4783\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9879 - val_loss: 9.1390\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8307 - val_loss: 7.2918\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1511 - val_loss: 6.3924\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5159 - val_loss: 6.3234\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4349 - val_loss: 7.4119\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9936 - val_loss: 6.5929\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6255 - val_loss: 8.2269\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0679 - val_loss: 6.9508\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7547 - val_loss: 7.3853\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9875 - val_loss: 6.3948\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0889 - val_loss: 7.3055\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1516 - val_loss: 6.5531\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9771 - val_loss: 6.8325\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2015 - val_loss: 7.5720\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9399 - val_loss: 6.2233\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8065 - val_loss: 7.8186\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4137 - val_loss: 9.6312\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1261 - val_loss: 7.0254\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9401 - val_loss: 6.2472\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7109 - val_loss: 7.8209\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6664 - val_loss: 8.6364\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.1214 - val_loss: 9.3812\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2746 - val_loss: 6.6166\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7386 - val_loss: 7.9921\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3450 - val_loss: 7.4542\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0217 - val_loss: 6.7831\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3001 - val_loss: 6.5193\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7739 - val_loss: 8.7293\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1707 - val_loss: 7.3923\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6699 - val_loss: 7.3288\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2758 - val_loss: 8.2810\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2734 - val_loss: 9.2294\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7381 - val_loss: 7.0991\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9943 - val_loss: 7.2041\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7323 - val_loss: 6.4605\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1803 - val_loss: 6.3160\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.1376 - val_loss: 7.1720\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3243 - val_loss: 7.1630\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2834 - val_loss: 7.2282\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9025 - val_loss: 6.6359\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8786 - val_loss: 6.8513\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6873 - val_loss: 6.6719\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0332 - val_loss: 7.5079\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8636 - val_loss: 6.7874\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8273 - val_loss: 9.3860\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4959 - val_loss: 7.1533\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6209 - val_loss: 6.7909\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1907 - val_loss: 6.4562\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0129 - val_loss: 6.7100\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.7286 - val_loss: 6.6423\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.0757 - val_loss: 6.3222\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.3485 - val_loss: 8.4452\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8194 - val_loss: 6.9345\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.9153 - val_loss: 8.4506\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1031 - val_loss: 6.6687\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0184 - val_loss: 6.3123\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6235 - val_loss: 6.3945\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.6357 - val_loss: 6.5430\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7575 - val_loss: 6.2559\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6912 - val_loss: 6.2169\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5556 - val_loss: 6.7672\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4529 - val_loss: 6.8236\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4196 - val_loss: 6.5086\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7246 - val_loss: 6.4747\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6405 - val_loss: 7.5901\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9288 - val_loss: 6.8336\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5217 - val_loss: 6.4946\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9442 - val_loss: 6.8587\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6892 - val_loss: 6.8886\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5522 - val_loss: 7.5924\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3160 - val_loss: 6.9121\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9902 - val_loss: 6.2256\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8075 - val_loss: 6.5915\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9528 - val_loss: 6.7186\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8378 - val_loss: 7.7588\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0343 - val_loss: 9.1219\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6364 - val_loss: 6.8426\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9737 - val_loss: 6.3312\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9052 - val_loss: 6.9566\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6187 - val_loss: 7.3258\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6474 - val_loss: 8.5780\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0460 - val_loss: 6.7442\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0702 - val_loss: 6.1570\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7245 - val_loss: 6.6493\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9925 - val_loss: 7.7028\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8186 - val_loss: 6.2889\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9204 - val_loss: 6.7039\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0804 - val_loss: 6.3560\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7722 - val_loss: 6.5087\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0734 - val_loss: 9.0126\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0405 - val_loss: 7.6520\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7162 - val_loss: 6.6857\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2538 - val_loss: 7.2180\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7035 - val_loss: 7.5210\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5098 - val_loss: 6.5414\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0894 - val_loss: 7.9491\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6435 - val_loss: 8.0456\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9865 - val_loss: 8.4191\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8513 - val_loss: 8.5600\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4783 - val_loss: 9.0197\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7516 - val_loss: 6.5575\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5608 - val_loss: 6.1452\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3519 - val_loss: 6.5654\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0230 - val_loss: 6.2164\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6175 - val_loss: 6.3871\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7427 - val_loss: 8.1455\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8914 - val_loss: 7.9919\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6170 - val_loss: 7.4152\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6628 - val_loss: 6.5135\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7481 - val_loss: 7.4931\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8231 - val_loss: 6.9279\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8494 - val_loss: 7.1652\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8170 - val_loss: 6.2524\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7582 - val_loss: 6.1448\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9282 - val_loss: 6.8414\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5096 - val_loss: 6.2314\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1938 - val_loss: 6.5914\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6215 - val_loss: 6.4778\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6129 - val_loss: 7.3038\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2081 - val_loss: 6.8913\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6206 - val_loss: 7.4714\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9622 - val_loss: 8.6129\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2741 - val_loss: 6.1189\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9147 - val_loss: 10.7097\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0668 - val_loss: 8.0396\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7793 - val_loss: 7.8691\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6165 - val_loss: 6.2392\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7719 - val_loss: 7.0938\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7992 - val_loss: 6.3545\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6704 - val_loss: 6.8000\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4918 - val_loss: 6.4234\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9389 - val_loss: 7.8884\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7687 - val_loss: 8.1930\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0543 - val_loss: 8.0999\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9610 - val_loss: 6.7461\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0162 - val_loss: 6.8091\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5071 - val_loss: 6.3871\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7990 - val_loss: 7.6024\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6594 - val_loss: 6.7321\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5208 - val_loss: 7.9553\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7607 - val_loss: 6.5045\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7548 - val_loss: 7.4404\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0959 - val_loss: 6.1860\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6290 - val_loss: 6.3527\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0964 - val_loss: 6.4095\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7826 - val_loss: 7.2950\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6231 - val_loss: 7.0987\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0045 - val_loss: 8.5968\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9582 - val_loss: 8.7074\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0952 - val_loss: 8.4513\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1728 - val_loss: 7.8659\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6889 - val_loss: 6.6771\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2413 - val_loss: 8.1467\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9402 - val_loss: 6.4482\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6054 - val_loss: 6.2209\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7249 - val_loss: 6.6714\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5031 - val_loss: 6.2770\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7234 - val_loss: 6.3249\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7756 - val_loss: 6.8759\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7385 - val_loss: 6.2598\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8172 - val_loss: 6.8380\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5704 - val_loss: 6.4520\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7222 - val_loss: 7.6977\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7850 - val_loss: 6.7180\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4855 - val_loss: 6.8431\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7030 - val_loss: 6.4899\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8500 - val_loss: 7.0731\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8235 - val_loss: 7.2162\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3652 - val_loss: 6.8921\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2127 - val_loss: 6.2173\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6467 - val_loss: 7.6274\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7902 - val_loss: 6.4795\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7940 - val_loss: 7.4123\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6767 - val_loss: 7.1641\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5932 - val_loss: 6.3352\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6703 - val_loss: 7.2079\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9952 - val_loss: 7.4063\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.9877 - val_loss: 6.1677\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1202 - val_loss: 7.3664\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5588 - val_loss: 6.0737\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4794 - val_loss: 8.5081\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7465 - val_loss: 6.3786\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0567 - val_loss: 6.6653\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7259 - val_loss: 6.7777\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0373 - val_loss: 6.4517\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6524 - val_loss: 6.8236\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6229 - val_loss: 6.7580\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7061 - val_loss: 6.9720\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3158 - val_loss: 7.2210\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2017 - val_loss: 6.5010\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8239 - val_loss: 7.5660\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8986 - val_loss: 6.7830\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6097 - val_loss: 8.3457\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3276 - val_loss: 8.1721\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1587 - val_loss: 7.4188\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8048 - val_loss: 6.2583\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9921 - val_loss: 8.0402\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8091 - val_loss: 6.7507\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5226 - val_loss: 7.9590\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0613 - val_loss: 6.2895\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9785 - val_loss: 6.7521\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6362 - val_loss: 6.3096\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5553 - val_loss: 6.1074\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5880 - val_loss: 6.7301\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0068 - val_loss: 8.2020\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8950 - val_loss: 6.3064\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0163 - val_loss: 7.2823\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2732 - val_loss: 6.6509\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0517 - val_loss: 7.7067\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0430 - val_loss: 7.8225\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6377 - val_loss: 6.5087\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2269 - val_loss: 6.4109\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7504 - val_loss: 6.8246\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.5535 - val_loss: 7.2659\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6601 - val_loss: 7.1009\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0225 - val_loss: 7.6578\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8471 - val_loss: 6.2214\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6998 - val_loss: 6.4110\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.4038 - val_loss: 7.2932\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.1806 - val_loss: 6.8395\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.4483 - val_loss: 7.0137\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7728 - val_loss: 7.1232\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6026 - val_loss: 6.7318\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6324 - val_loss: 7.8785\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6888 - val_loss: 6.4114\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8020 - val_loss: 7.3685\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9273 - val_loss: 6.4086\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6531 - val_loss: 7.8021\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0115 - val_loss: 7.1964\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0622 - val_loss: 6.5524\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7990 - val_loss: 6.6199\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7556 - val_loss: 7.5491\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7325 - val_loss: 6.3331\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7804 - val_loss: 6.3250\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0846 - val_loss: 6.6135\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9165 - val_loss: 7.0077\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.5492 - val_loss: 7.1542\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1180 - val_loss: 6.8330\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4594 - val_loss: 6.5607\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7458 - val_loss: 6.2444\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8643 - val_loss: 6.1991\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7158 - val_loss: 6.5921\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8222 - val_loss: 6.6212\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.0726 - val_loss: 7.3701\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3603 - val_loss: 7.0139\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9923 - val_loss: 6.9927\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5929 - val_loss: 6.5036\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5879 - val_loss: 6.7655\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.9492 - val_loss: 7.1089\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7332 - val_loss: 6.5927\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9671 - val_loss: 6.3837\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6033 - val_loss: 6.2369\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5944 - val_loss: 6.2829\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9766 - val_loss: 6.6450\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6095 - val_loss: 6.0995\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1714 - val_loss: 7.0004\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5975 - val_loss: 6.8654\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6257 - val_loss: 6.4789\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6186 - val_loss: 7.6932\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0805 - val_loss: 7.5172\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6099 - val_loss: 6.6237\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6757 - val_loss: 6.7443\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8475 - val_loss: 9.1110\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5163 - val_loss: 6.8574\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0377 - val_loss: 6.1365\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8479 - val_loss: 6.2114\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1810 - val_loss: 7.8930\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7399 - val_loss: 6.7084\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6765 - val_loss: 6.6623\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0125 - val_loss: 6.6609\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9517 - val_loss: 6.4988\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7880 - val_loss: 7.3811\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6460 - val_loss: 6.6386\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9717 - val_loss: 6.8777\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7223 - val_loss: 7.3709\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8737 - val_loss: 6.9557\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6402 - val_loss: 6.8400\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6829 - val_loss: 6.4353\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7510 - val_loss: 6.3712\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6617 - val_loss: 6.6933\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8797 - val_loss: 6.1412\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5141 - val_loss: 7.0122\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2539 - val_loss: 6.7100\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7883 - val_loss: 6.9251\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5144 - val_loss: 7.3271\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0782 - val_loss: 7.9423\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6138 - val_loss: 6.8009\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8063 - val_loss: 6.9894\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7185 - val_loss: 6.3220\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8174 - val_loss: 7.9089\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8366 - val_loss: 6.4127\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5099 - val_loss: 6.3353\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6721 - val_loss: 7.2721\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6386 - val_loss: 7.3301\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5503 - val_loss: 8.3083\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9115 - val_loss: 6.4341\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8229 - val_loss: 5.9526\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0838 - val_loss: 7.3399\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1270 - val_loss: 6.1827\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6006 - val_loss: 7.8607\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5381 - val_loss: 6.0208\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8153 - val_loss: 6.9092\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7077 - val_loss: 6.2172\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0032 - val_loss: 6.5731\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6512 - val_loss: 7.3123\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6737 - val_loss: 6.3378\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2259 - val_loss: 7.1817\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1509 - val_loss: 7.1440\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7911 - val_loss: 6.4501\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6558 - val_loss: 6.2805\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5927 - val_loss: 6.2749\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6845 - val_loss: 6.3673\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6590 - val_loss: 6.5738\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8261 - val_loss: 5.9622\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2877 - val_loss: 6.2467\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7951 - val_loss: 7.5440\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7522 - val_loss: 7.3051\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7583 - val_loss: 6.2894\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5191 - val_loss: 7.1236\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5187 - val_loss: 6.2184\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7963 - val_loss: 6.2418\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1393 - val_loss: 6.8824\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6163 - val_loss: 7.9202\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3398 - val_loss: 7.3379\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9189 - val_loss: 7.7068\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6416 - val_loss: 6.5945\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6205 - val_loss: 6.8380\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0276 - val_loss: 6.0999\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6636 - val_loss: 6.5837\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8589 - val_loss: 9.4899\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9774 - val_loss: 8.5380\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9057 - val_loss: 7.7072\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9237 - val_loss: 6.8944\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5608 - val_loss: 7.3023\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9670 - val_loss: 6.7992\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0381 - val_loss: 6.8549\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6937 - val_loss: 6.4930\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6872 - val_loss: 6.6081\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.2184 - val_loss: 7.5138\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0112 - val_loss: 6.9088\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8707 - val_loss: 6.0999\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8810 - val_loss: 7.1084\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7625 - val_loss: 7.0019\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6481 - val_loss: 6.8599\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9420 - val_loss: 12.3888\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9788 - val_loss: 5.8827\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5504 - val_loss: 6.8949\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8382 - val_loss: 8.2705\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9986 - val_loss: 6.4469\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6723 - val_loss: 6.2612\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5530 - val_loss: 6.5308\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6621 - val_loss: 7.4949\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7319 - val_loss: 6.6586\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0732 - val_loss: 6.6586\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8349 - val_loss: 7.2389\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5419 - val_loss: 6.2326\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6346 - val_loss: 6.2481\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7663 - val_loss: 6.6263\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.012 - 0s 88us/step - loss: 5.5775 - val_loss: 6.6849\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5196 - val_loss: 6.1942\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7456 - val_loss: 7.3433\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5391 - val_loss: 6.9969\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7621 - val_loss: 6.4192\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6766 - val_loss: 7.6543\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5230 - val_loss: 6.9910\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4280 - val_loss: 7.3416\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4368 - val_loss: 6.7274\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7522 - val_loss: 6.2211\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9096 - val_loss: 6.3670\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4199 - val_loss: 6.1711\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6783 - val_loss: 6.1558\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6635 - val_loss: 6.5774\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5415 - val_loss: 7.4770\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7852 - val_loss: 6.3190\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0557 - val_loss: 6.4250\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1458 - val_loss: 5.9208\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.8038 - val_loss: 6.8683\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.7345 - val_loss: 7.3277\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.5075 - val_loss: 6.2820\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.6835 - val_loss: 8.0554\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5171 - val_loss: 7.0505\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.9209 - val_loss: 6.6450\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.9933 - val_loss: 6.6995\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0966 - val_loss: 6.2241\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6825 - val_loss: 6.5859\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6297 - val_loss: 8.1952\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9269 - val_loss: 6.6713\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.4244 - val_loss: 6.6728\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8726 - val_loss: 7.5391\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1194 - val_loss: 7.0811\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6335 - val_loss: 7.7004\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6458 - val_loss: 6.9596\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7620 - val_loss: 8.3837\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1532 - val_loss: 6.5791\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9931 - val_loss: 7.3921\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6488 - val_loss: 7.1257\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8624 - val_loss: 6.7907\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9461 - val_loss: 6.9189\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0155 - val_loss: 6.9058\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4939 - val_loss: 6.1975\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8804 - val_loss: 6.4471\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7291 - val_loss: 6.3800\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0762 - val_loss: 7.9038\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6206 - val_loss: 7.0365\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6095 - val_loss: 6.4658\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0972 - val_loss: 8.6863\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8244 - val_loss: 6.8086\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8845 - val_loss: 6.7872\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2246 - val_loss: 10.0308\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.5127 - val_loss: 9.2875\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7103 - val_loss: 7.5360\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7839 - val_loss: 10.0924\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4926 - val_loss: 6.7309\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7596 - val_loss: 6.9285\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0577 - val_loss: 9.0234\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6527 - val_loss: 6.1218\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4964 - val_loss: 6.7047\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6475 - val_loss: 6.3384\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9727 - val_loss: 6.9979\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7063 - val_loss: 7.0428\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5298 - val_loss: 6.4516\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4917 - val_loss: 6.6278\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6589 - val_loss: 6.0849\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6986 - val_loss: 6.3586\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5816 - val_loss: 6.2390\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9523 - val_loss: 6.8201\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9273 - val_loss: 7.6400\n",
      "5.4059844396810615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.15917177,  4.019571  , -0.4966733 , -0.35501915, -2.5954704 ,\n",
       "          0.2608817 , -4.930172  , -2.4686968 , -0.8906447 , -3.0119762 ],\n",
       "        [-0.19712326, -0.02506241, -0.73848444, -0.51074064,  2.0635738 ,\n",
       "          0.6605819 ,  0.34523457,  2.0927665 , -0.7253821 ,  0.02087061],\n",
       "        [ 0.62129486, -0.21315332, -0.9323829 , -0.25856674,  0.01871373,\n",
       "          2.0392547 , -0.0603885 , -0.07134196, -0.29165593, -0.9626695 ],\n",
       "        [ 0.23559852,  0.00578611,  0.44357622, -0.6246597 ,  5.006099  ,\n",
       "         -0.14556143,  0.08674883,  0.21636571,  0.37090892,  0.12875393],\n",
       "        [-0.9508229 ,  1.9738365 , -0.13214016,  0.15666112, -5.14663   ,\n",
       "         -0.74210525, -0.60973364, -0.15927906, -1.3166426 , -0.46851784]],\n",
       "       dtype=float32),\n",
       " array([ 2.1767712 ,  5.178756  ,  3.5349798 , -3.1752148 ,  0.15495494,\n",
       "         0.7801599 , -2.6150708 , -2.080281  , -0.41649815, -3.1530745 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.47484997,  0.83834696, -0.0726463 , -0.16832487,  0.7397636 ,\n",
       "         -0.547105  , -0.3820005 ,  1.0641905 ,  0.775042  , -0.53612965,\n",
       "         -0.700967  ,  0.6142498 , -0.3819884 ,  0.1893854 , -0.5349417 ],\n",
       "        [ 1.4162117 ,  1.9493392 , -1.6065655 , -1.9701822 ,  1.5414563 ,\n",
       "         -1.7871869 , -0.85733074,  1.3511965 ,  1.1017555 , -1.9886057 ,\n",
       "         -1.6848009 ,  1.7797732 , -1.7451699 ,  1.1896594 ,  0.61648333],\n",
       "        [ 1.2155511 ,  1.7424787 , -0.9049584 , -1.747358  ,  1.5315512 ,\n",
       "         -1.2764187 , -1.5180854 ,  1.9130114 ,  1.150132  , -1.8541703 ,\n",
       "         -1.8277745 ,  1.3502284 , -1.0859433 ,  1.332496  ,  0.14231677],\n",
       "        [-1.4484872 , -1.7642063 ,  1.1220455 ,  1.7974997 , -1.2072057 ,\n",
       "          1.3660668 ,  1.3421054 , -1.9559275 , -1.0925089 ,  1.4295665 ,\n",
       "          1.9501625 , -1.3631973 ,  1.5613457 , -1.4265158 , -0.5561297 ],\n",
       "        [ 0.15070547,  0.33712313,  0.14137428,  0.24085516,  0.08569284,\n",
       "          0.3212778 , -0.0281575 , -0.3729397 , -0.04466433, -0.01091168,\n",
       "          0.24512842,  0.29922277,  0.09321471, -0.18062751,  0.3648016 ],\n",
       "        [ 0.01088362, -0.33344752, -0.0066826 ,  0.4194598 , -0.4255347 ,\n",
       "          0.11854828,  0.50319767, -0.53586143, -0.3103331 ,  0.7550968 ,\n",
       "          0.40952328, -0.3806443 ,  0.40727365, -0.28987047,  0.03343472],\n",
       "        [ 0.32555357,  0.5822484 , -0.22522052, -0.5408404 ,  0.2347385 ,\n",
       "         -0.78523415, -0.79028964,  0.61124897,  0.533841  , -0.4052677 ,\n",
       "         -0.07868859,  0.5898476 , -0.53287804,  0.45421097,  0.4444178 ],\n",
       "        [-0.01091304,  0.09492375, -0.6326445 , -0.48384798, -0.02474694,\n",
       "         -0.4453227 , -0.6290072 ,  0.49876112,  0.539702  ,  0.18197837,\n",
       "          0.29748708,  0.42555743, -0.23993792,  0.46498433,  0.610237  ],\n",
       "        [ 0.3647821 ,  0.43725505, -0.25639546, -0.32898116,  0.3171998 ,\n",
       "         -0.9572445 , -0.5682774 ,  0.44965127,  0.28065532, -0.3680664 ,\n",
       "         -0.45657632,  0.20430881, -0.8852513 ,  0.29807663,  0.55936927],\n",
       "        [-1.5301019 , -0.9926612 ,  0.5149637 ,  0.94376415, -1.4671942 ,\n",
       "          1.5608462 ,  1.2057254 , -1.5006696 , -1.0306737 ,  1.0352939 ,\n",
       "          1.7306306 , -1.1415503 ,  1.3638991 , -0.642349  , -0.21620195]],\n",
       "       dtype=float32),\n",
       " array([ 2.064532 ,  2.0954437, -1.8268888, -2.1130304,  2.0739772,\n",
       "        -2.1082027, -1.8696207,  2.134775 ,  1.8917505, -2.1002364,\n",
       "        -2.1858957,  1.9607767, -2.0837169,  1.9126595,  1.2643831],\n",
       "       dtype=float32),\n",
       " array([[ 1.1569883 ],\n",
       "        [ 1.2817801 ],\n",
       "        [-0.69025356],\n",
       "        [-1.335824  ],\n",
       "        [ 1.1556791 ],\n",
       "        [-1.2431555 ],\n",
       "        [-0.7757846 ],\n",
       "        [ 1.3811742 ],\n",
       "        [ 0.7550549 ],\n",
       "        [-1.2687343 ],\n",
       "        [-1.6246736 ],\n",
       "        [ 0.95171994],\n",
       "        [-1.1724449 ],\n",
       "        [ 0.8449263 ],\n",
       "        [ 0.11941157]], dtype=float32),\n",
       " array([2.442122], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_6(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure6_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 740us/step - loss: 560.3367 - val_loss: 468.4248\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 332.2621 - val_loss: 180.4983\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 112.0297 - val_loss: 59.1428\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 46.0421 - val_loss: 30.4487\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 26.5736 - val_loss: 21.8680\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 23.2771 - val_loss: 20.0364\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 22.3452 - val_loss: 19.2243\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.5608 - val_loss: 17.4125\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 18.3058 - val_loss: 15.6812\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.2363 - val_loss: 14.4308\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.7208 - val_loss: 14.0497\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 14.6359 - val_loss: 13.8345\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.7341 - val_loss: 13.4638\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.8813 - val_loss: 13.2123\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.1997 - val_loss: 13.3812\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.5083 - val_loss: 13.5294\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.7670 - val_loss: 12.7439\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.3740 - val_loss: 13.0278\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.9148 - val_loss: 12.4571\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.6519 - val_loss: 11.8805\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.3848 - val_loss: 11.3377\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.1505 - val_loss: 10.7901\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9053 - val_loss: 10.4401\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.7107 - val_loss: 10.3878\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6565 - val_loss: 10.5748\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5106 - val_loss: 10.2208\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3950 - val_loss: 10.3584\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2678 - val_loss: 10.3358\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2498 - val_loss: 10.2392\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1279 - val_loss: 10.2436\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1030 - val_loss: 10.1075\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8854 - val_loss: 10.3279\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9526 - val_loss: 10.1547\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7731 - val_loss: 10.0959\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6281 - val_loss: 10.1228\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6232 - val_loss: 10.2087\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4918 - val_loss: 9.8817\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5503 - val_loss: 10.0466\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5556 - val_loss: 9.9637\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6960 - val_loss: 10.4435\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2579 - val_loss: 10.7072\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2988 - val_loss: 10.4018\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2762 - val_loss: 9.7260\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0848 - val_loss: 9.9776\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0893 - val_loss: 10.1640\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1446 - val_loss: 10.0919\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9707 - val_loss: 9.9197\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8601 - val_loss: 10.1462\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1436 - val_loss: 10.0481\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8336 - val_loss: 10.2498\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8546 - val_loss: 9.9559\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9308 - val_loss: 10.0228\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7741 - val_loss: 10.1106\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9926 - val_loss: 9.7964\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7157 - val_loss: 9.5362\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7665 - val_loss: 9.6087\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7048 - val_loss: 9.8697\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7097 - val_loss: 9.6000\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7138 - val_loss: 9.4208\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8019 - val_loss: 9.5387\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7733 - val_loss: 9.5247\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6195 - val_loss: 9.3056\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6385 - val_loss: 9.3660\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6474 - val_loss: 9.0431\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8344 - val_loss: 9.1102\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7727 - val_loss: 9.1579\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6785 - val_loss: 9.5246\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.7972 - val_loss: 9.0262\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6601 - val_loss: 9.1263\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5901 - val_loss: 9.0137\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5910 - val_loss: 9.2202\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5255 - val_loss: 9.0799\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5302 - val_loss: 8.8674\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5614 - val_loss: 8.8424\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4626 - val_loss: 9.1650\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5573 - val_loss: 9.0195\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5437 - val_loss: 9.0597\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5032 - val_loss: 8.9334\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4387 - val_loss: 8.5450\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4937 - val_loss: 8.7328\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5350 - val_loss: 8.7403\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4964 - val_loss: 8.7594\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4645 - val_loss: 8.7348\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4702 - val_loss: 8.7422\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7045 - val_loss: 8.9687\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.3912 - val_loss: 8.7335\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4724 - val_loss: 8.6861\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3507 - val_loss: 8.4432\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3739 - val_loss: 8.4924\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3578 - val_loss: 8.5663\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3526 - val_loss: 8.4298\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2993 - val_loss: 8.4061\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3766 - val_loss: 8.6093\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4516 - val_loss: 8.5830\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3975 - val_loss: 8.4540\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4468 - val_loss: 8.3533\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4981 - val_loss: 8.2207\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3622 - val_loss: 8.2498\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2874 - val_loss: 8.1969\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2703 - val_loss: 8.1973\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2293 - val_loss: 8.3901\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3754 - val_loss: 8.3948\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2493 - val_loss: 8.0382\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3563 - val_loss: 8.3747\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1903 - val_loss: 8.2283\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2153 - val_loss: 8.4603\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4657 - val_loss: 8.3277\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4448 - val_loss: 7.9129\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3307 - val_loss: 8.0721\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5436 - val_loss: 7.9568\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5449 - val_loss: 8.4048\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2888 - val_loss: 7.9290\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1778 - val_loss: 8.0005\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5178 - val_loss: 7.9170\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5270 - val_loss: 7.9389\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5493 - val_loss: 8.0291\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8917 - val_loss: 8.1377\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3653 - val_loss: 8.1526\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3153 - val_loss: 8.3020\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1197 - val_loss: 7.9455\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1085 - val_loss: 7.6046\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1194 - val_loss: 7.8952\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0603 - val_loss: 7.9666\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0727 - val_loss: 7.8974\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0514 - val_loss: 8.1430\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0606 - val_loss: 8.1939\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0876 - val_loss: 7.8275\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2607 - val_loss: 7.8723\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1181 - val_loss: 7.9619\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0818 - val_loss: 7.8284\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5036 - val_loss: 7.9085\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2918 - val_loss: 7.8278\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0269 - val_loss: 7.9159\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2447 - val_loss: 8.0301\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2440 - val_loss: 7.9704\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2446 - val_loss: 8.0349\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2195 - val_loss: 8.0359\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2563 - val_loss: 7.5395\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3539 - val_loss: 7.8292\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0335 - val_loss: 7.8934\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9935 - val_loss: 8.0795\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0315 - val_loss: 7.8443\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0913 - val_loss: 7.9191\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0051 - val_loss: 7.7529\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9624 - val_loss: 7.8157\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9661 - val_loss: 7.9377\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0142 - val_loss: 7.9213\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0088 - val_loss: 8.2575\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1194 - val_loss: 7.8335\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3031 - val_loss: 7.9709\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9377 - val_loss: 8.1810\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.1485 - val_loss: 7.7845\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.9583 - val_loss: 7.9133\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0836 - val_loss: 7.9301\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3345 - val_loss: 7.8068\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2634 - val_loss: 7.7360\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0782 - val_loss: 8.0531\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0655 - val_loss: 7.7926\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9328 - val_loss: 7.9793\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9762 - val_loss: 7.6993\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.1397 - val_loss: 7.8963\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9293 - val_loss: 7.7823\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1798 - val_loss: 8.2683\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9690 - val_loss: 7.9176\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9411 - val_loss: 7.8337\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8959 - val_loss: 7.6662\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8967 - val_loss: 7.8783\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9144 - val_loss: 8.0099\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9052 - val_loss: 7.9070\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9244 - val_loss: 8.2218\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1092 - val_loss: 7.9184\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1068 - val_loss: 7.9796\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8677 - val_loss: 7.8734\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8551 - val_loss: 7.7432\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8872 - val_loss: 7.6416\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9079 - val_loss: 8.0200\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8557 - val_loss: 7.7708\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9141 - val_loss: 7.4718\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8786 - val_loss: 7.6821\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8923 - val_loss: 7.9411\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8011 - val_loss: 7.8019\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0753 - val_loss: 8.0574\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8696 - val_loss: 7.8853\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9653 - val_loss: 7.8379\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8205 - val_loss: 7.9690\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8436 - val_loss: 7.7826\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8857 - val_loss: 7.6833\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9859 - val_loss: 8.1953\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0781 - val_loss: 7.5528\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8808 - val_loss: 7.5927\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8506 - val_loss: 7.7259\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9400 - val_loss: 7.9709\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8107 - val_loss: 8.2892\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0482 - val_loss: 7.7786\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0896 - val_loss: 7.6987\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0367 - val_loss: 8.0552\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0804 - val_loss: 7.6987\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9089 - val_loss: 7.4990\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7969 - val_loss: 7.9249\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9079 - val_loss: 7.9359\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0165 - val_loss: 7.7423\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7306 - val_loss: 8.2444\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8048 - val_loss: 7.7927\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8216 - val_loss: 7.8865\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7606 - val_loss: 7.7656\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7867 - val_loss: 7.7736\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7414 - val_loss: 8.0655\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7993 - val_loss: 7.6095\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7705 - val_loss: 7.8944\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8117 - val_loss: 7.9919\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8627 - val_loss: 7.9018\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7626 - val_loss: 7.7535\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7745 - val_loss: 8.1400\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7454 - val_loss: 7.7269\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8654 - val_loss: 8.0272\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.9056 - val_loss: 8.1564\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0895 - val_loss: 7.6340\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7339 - val_loss: 8.0900\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7416 - val_loss: 7.4798\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.9810 - val_loss: 7.7717\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8363 - val_loss: 7.5447\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9085 - val_loss: 7.8474\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8202 - val_loss: 7.7962\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7981 - val_loss: 7.8512\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7119 - val_loss: 7.8065\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7172 - val_loss: 7.9598\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8700 - val_loss: 7.6560\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9072 - val_loss: 7.9910\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9610 - val_loss: 7.8058\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7043 - val_loss: 7.9990\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8544 - val_loss: 7.9290\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7124 - val_loss: 7.7693\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7211 - val_loss: 7.5451\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7256 - val_loss: 7.6492\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7099 - val_loss: 7.7643\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7132 - val_loss: 8.0628\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6968 - val_loss: 7.9815\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7547 - val_loss: 7.6071\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8788 - val_loss: 7.9093\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8096 - val_loss: 7.6773\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7857 - val_loss: 8.0723\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7166 - val_loss: 7.8551\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7700 - val_loss: 8.0131\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7327 - val_loss: 7.7844\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8229 - val_loss: 7.7646\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6476 - val_loss: 8.1312\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8449 - val_loss: 7.7521\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0119 - val_loss: 7.7236\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7660 - val_loss: 7.5795\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7849 - val_loss: 8.5004\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7323 - val_loss: 7.8257\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7499 - val_loss: 8.0354\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7873 - val_loss: 7.8537\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8357 - val_loss: 7.9737\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7587 - val_loss: 7.8555\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6886 - val_loss: 7.8576\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6958 - val_loss: 8.0208\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7196 - val_loss: 8.0141\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7630 - val_loss: 8.0336\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7818 - val_loss: 7.6282\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6942 - val_loss: 7.6487\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6454 - val_loss: 8.2500\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6940 - val_loss: 7.7194\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7513 - val_loss: 8.1260\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8035 - val_loss: 7.9381\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7203 - val_loss: 7.9802\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6843 - val_loss: 7.7356\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6711 - val_loss: 8.0719\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7362 - val_loss: 7.7139\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6906 - val_loss: 7.9888\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7499 - val_loss: 7.8671\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6969 - val_loss: 7.7100\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6783 - val_loss: 7.9361\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6634 - val_loss: 7.7718\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7521 - val_loss: 7.9531\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7243 - val_loss: 7.9104\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6553 - val_loss: 7.7238\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8827 - val_loss: 8.5919\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2694 - val_loss: 7.5690\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0313 - val_loss: 7.8981\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9606 - val_loss: 8.0116\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8603 - val_loss: 7.9557\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8134 - val_loss: 8.1447\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6974 - val_loss: 7.9036\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6121 - val_loss: 8.2959\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6896 - val_loss: 7.8258\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6608 - val_loss: 7.7843\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6654 - val_loss: 7.7657\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6418 - val_loss: 7.9040\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7098 - val_loss: 7.8469\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8495 - val_loss: 7.8744\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5693 - val_loss: 8.4105\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6556 - val_loss: 7.8944\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6741 - val_loss: 8.0960\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6729 - val_loss: 7.8671\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6961 - val_loss: 8.2576\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7781 - val_loss: 8.1728\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7426 - val_loss: 7.5317\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8822 - val_loss: 7.8191\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.7305 - val_loss: 7.8792\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7339 - val_loss: 7.9981\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8406 - val_loss: 8.0055\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8985 - val_loss: 8.0487\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6647 - val_loss: 8.0797\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9165 - val_loss: 7.9003\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7585 - val_loss: 7.9099\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7898 - val_loss: 7.8538\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7659 - val_loss: 8.2309\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6131 - val_loss: 8.1419\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5937 - val_loss: 7.9925\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8752 - val_loss: 7.9537\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6091 - val_loss: 7.9555\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6105 - val_loss: 7.9071\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6144 - val_loss: 7.8819\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6491 - val_loss: 8.1165\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6413 - val_loss: 7.9470\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7287 - val_loss: 8.1017\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5925 - val_loss: 7.8081\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5621 - val_loss: 8.4019\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6281 - val_loss: 8.0650\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7031 - val_loss: 7.8674\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6509 - val_loss: 8.3401\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6908 - val_loss: 7.8845\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7312 - val_loss: 8.2558\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6453 - val_loss: 8.0403\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9635 - val_loss: 8.4094\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8324 - val_loss: 8.1519\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5572 - val_loss: 7.9141\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6172 - val_loss: 8.2816\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6432 - val_loss: 7.9203\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6232 - val_loss: 8.2186\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7271 - val_loss: 7.8722\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7198 - val_loss: 8.0172\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5833 - val_loss: 8.0822\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5642 - val_loss: 8.2499\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5836 - val_loss: 8.4244\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6075 - val_loss: 8.2697\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6515 - val_loss: 8.0435\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6751 - val_loss: 7.9645\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9344 - val_loss: 8.0081\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7552 - val_loss: 7.9481\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5591 - val_loss: 8.0929\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6409 - val_loss: 7.8843\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6199 - val_loss: 8.0660\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6601 - val_loss: 7.7384\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7483 - val_loss: 8.2378\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6449 - val_loss: 7.8292\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8922 - val_loss: 8.2782\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1271 - val_loss: 7.9323\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5682 - val_loss: 8.3636\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7160 - val_loss: 7.7147\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5787 - val_loss: 8.1480\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6383 - val_loss: 7.8736\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6251 - val_loss: 8.3006\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5998 - val_loss: 8.0566\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5967 - val_loss: 8.2891\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6287 - val_loss: 8.3083\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.6772 - val_loss: 8.0855\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5872 - val_loss: 7.9318\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6925 - val_loss: 8.3776\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6460 - val_loss: 8.1105\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6937 - val_loss: 7.7893\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6830 - val_loss: 8.1432\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5709 - val_loss: 8.4253\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5335 - val_loss: 8.2273\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5809 - val_loss: 8.4024\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5515 - val_loss: 7.9098\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5677 - val_loss: 8.1508\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6046 - val_loss: 8.1929\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5847 - val_loss: 7.9556\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6710 - val_loss: 7.9236\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6040 - val_loss: 8.0853\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5936 - val_loss: 8.1875\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5833 - val_loss: 8.3146\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5285 - val_loss: 8.0893\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6470 - val_loss: 8.1107\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.6509 - val_loss: 8.2448\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6039 - val_loss: 8.1811\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5922 - val_loss: 7.9603\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6011 - val_loss: 7.9844\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7744 - val_loss: 7.9956\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6166 - val_loss: 8.1451\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5928 - val_loss: 8.4683\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5368 - val_loss: 8.2925\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5463 - val_loss: 8.3042\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5895 - val_loss: 7.9285\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5331 - val_loss: 7.9937\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6483 - val_loss: 8.2165\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5453 - val_loss: 8.4032\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7265 - val_loss: 7.9263\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7077 - val_loss: 8.2447\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5794 - val_loss: 8.6482\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7223 - val_loss: 8.3350\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7455 - val_loss: 8.0654\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5857 - val_loss: 8.6074\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6443 - val_loss: 7.8481\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6085 - val_loss: 8.3148\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5587 - val_loss: 7.9928\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6822 - val_loss: 8.3119\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6344 - val_loss: 8.4296\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5390 - val_loss: 8.2570\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5905 - val_loss: 8.0393\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6235 - val_loss: 8.1719\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8179 - val_loss: 8.4931\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7232 - val_loss: 8.5042\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5874 - val_loss: 8.0955\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7696 - val_loss: 7.9104\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6619 - val_loss: 8.2567\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6884 - val_loss: 8.3342\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6171 - val_loss: 8.1710\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4693 - val_loss: 8.5917\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7016 - val_loss: 8.0900\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7565 - val_loss: 7.9363\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5937 - val_loss: 8.5885\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5670 - val_loss: 8.2177\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7194 - val_loss: 8.4442\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6556 - val_loss: 8.1694\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5020 - val_loss: 8.4660\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5609 - val_loss: 8.2948\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6038 - val_loss: 8.2244\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6976 - val_loss: 8.2096\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5181 - val_loss: 8.1947\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5832 - val_loss: 8.4564\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5352 - val_loss: 8.1124\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5481 - val_loss: 8.3251\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6556 - val_loss: 8.3026\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6045 - val_loss: 8.0743\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6022 - val_loss: 8.4890\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6156 - val_loss: 8.5360\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5471 - val_loss: 8.3091\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7395 - val_loss: 8.6058\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7640 - val_loss: 8.4127\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5443 - val_loss: 8.8339\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5587 - val_loss: 8.1062\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5594 - val_loss: 8.5342\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7260 - val_loss: 7.9972\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7690 - val_loss: 8.1872\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5313 - val_loss: 7.7799\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6986 - val_loss: 8.3662\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5383 - val_loss: 8.2238\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5596 - val_loss: 8.4825\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6157 - val_loss: 8.3813\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5468 - val_loss: 8.6657\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5157 - val_loss: 8.3198\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6150 - val_loss: 8.2864\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4794 - val_loss: 8.4836\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6090 - val_loss: 8.0076\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4461 - val_loss: 8.7839\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6050 - val_loss: 8.4650\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6348 - val_loss: 8.2417\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0050 - val_loss: 8.4615\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6990 - val_loss: 8.6699\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4984 - val_loss: 8.3655\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5517 - val_loss: 8.4063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5312 - val_loss: 8.5258\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6579 - val_loss: 8.1887\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6295 - val_loss: 8.0423\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7374 - val_loss: 7.9546\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7890 - val_loss: 8.2302\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4819 - val_loss: 8.1682\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5088 - val_loss: 8.4260\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5555 - val_loss: 8.7181\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4954 - val_loss: 8.4157\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.5638 - val_loss: 8.4380\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7810 - val_loss: 8.3067\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5551 - val_loss: 8.3255\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6271 - val_loss: 8.3356\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7512 - val_loss: 8.6048\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7465 - val_loss: 8.2648\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5992 - val_loss: 8.6640\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7734 - val_loss: 8.8977\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6610 - val_loss: 8.9138\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5884 - val_loss: 8.2587\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5792 - val_loss: 8.4516\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5404 - val_loss: 8.3361\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5135 - val_loss: 8.6759\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4128 - val_loss: 8.2684\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6939 - val_loss: 8.6973\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6650 - val_loss: 8.5336\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6645 - val_loss: 8.1760\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4230 - val_loss: 9.0398\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6694 - val_loss: 8.4031\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5147 - val_loss: 8.6368\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5826 - val_loss: 8.4129\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6526 - val_loss: 8.2905\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5096 - val_loss: 8.8032\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4956 - val_loss: 8.4514\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5453 - val_loss: 8.5525\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5572 - val_loss: 8.2889\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4731 - val_loss: 8.5717\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5621 - val_loss: 8.4428\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4847 - val_loss: 8.3413\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5588 - val_loss: 8.5398\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5557 - val_loss: 8.5824\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5944 - val_loss: 8.6696\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5397 - val_loss: 8.4573\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4877 - val_loss: 8.4872\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6037 - val_loss: 8.2626\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9675 - val_loss: 8.5263\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6570 - val_loss: 8.9366\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5183 - val_loss: 8.3477\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5241 - val_loss: 8.5667\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5927 - val_loss: 8.3780\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6723 - val_loss: 8.8037\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5498 - val_loss: 8.6004\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9115 - val_loss: 8.7155\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5010 - val_loss: 8.8369\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4756 - val_loss: 8.3522\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5531 - val_loss: 8.4585\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5092 - val_loss: 8.3654\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4886 - val_loss: 8.3376\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6659 - val_loss: 8.4327\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4647 - val_loss: 8.9239\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4991 - val_loss: 8.5598\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4919 - val_loss: 8.5839\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5935 - val_loss: 8.7740\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5163 - val_loss: 8.4749\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4953 - val_loss: 8.3889\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4400 - val_loss: 8.8082\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5056 - val_loss: 8.6583\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4738 - val_loss: 8.9512\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5704 - val_loss: 8.6950\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4758 - val_loss: 8.5872\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6077 - val_loss: 8.7860\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5339 - val_loss: 8.5011\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6771 - val_loss: 8.8633\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6546 - val_loss: 8.7723\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6236 - val_loss: 8.4348\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4347 - val_loss: 8.6987\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5777 - val_loss: 8.5888\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4618 - val_loss: 8.8322\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5330 - val_loss: 8.6679\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5331 - val_loss: 8.8709\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5010 - val_loss: 8.4115\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7735 - val_loss: 8.4495\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5094 - val_loss: 8.5992\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4833 - val_loss: 8.9733\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4344 - val_loss: 9.0303\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.7132 - val_loss: 8.7491\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6897 - val_loss: 8.9770\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6893 - val_loss: 8.4251\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6896 - val_loss: 8.7162\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7942 - val_loss: 8.7858\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5142 - val_loss: 8.8538\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4522 - val_loss: 8.5707\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4925 - val_loss: 8.6400\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4485 - val_loss: 8.7467\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4824 - val_loss: 9.3795\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5489 - val_loss: 8.7512\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7663 - val_loss: 8.9631\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8835 - val_loss: 8.4043\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6606 - val_loss: 9.1921\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4152 - val_loss: 8.4418\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5336 - val_loss: 9.4763\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8810 - val_loss: 8.5373\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5473 - val_loss: 9.1295\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4841 - val_loss: 8.8207\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6377 - val_loss: 9.0542\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8499 - val_loss: 9.3697\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.6373 - val_loss: 8.9785\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5753 - val_loss: 8.7193\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5076 - val_loss: 8.8056\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4447 - val_loss: 8.9653\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4971 - val_loss: 8.8294\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5090 - val_loss: 8.8825\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5518 - val_loss: 8.6599\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4458 - val_loss: 8.7853\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4085 - val_loss: 8.8756\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4075 - val_loss: 9.4072\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5785 - val_loss: 9.1197\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5666 - val_loss: 9.0485\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5459 - val_loss: 8.9918\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4980 - val_loss: 8.7153\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4352 - val_loss: 9.0695\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4805 - val_loss: 8.6747\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4264 - val_loss: 9.0237\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4227 - val_loss: 9.1332\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4394 - val_loss: 9.0530\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4277 - val_loss: 8.7133\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4398 - val_loss: 8.6078\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5062 - val_loss: 8.9769\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5730 - val_loss: 8.9019\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4950 - val_loss: 9.1746\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5159 - val_loss: 9.0411\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5284 - val_loss: 9.0391\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6478 - val_loss: 9.1633\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4242 - val_loss: 9.3670\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4259 - val_loss: 8.8050\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5559 - val_loss: 8.8181\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4377 - val_loss: 9.1049\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4505 - val_loss: 9.3564\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4411 - val_loss: 8.9693\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4616 - val_loss: 9.0039\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5493 - val_loss: 8.8759\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3835 - val_loss: 9.5071\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5287 - val_loss: 8.9220\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4696 - val_loss: 9.1546\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6637 - val_loss: 8.8850\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5241 - val_loss: 9.6722\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9328 - val_loss: 9.4124\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6100 - val_loss: 9.4252\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6178 - val_loss: 9.0995\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5463 - val_loss: 9.1163\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5242 - val_loss: 8.9733\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4470 - val_loss: 9.3551\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4497 - val_loss: 9.0150\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4664 - val_loss: 8.8722\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5266 - val_loss: 9.2346\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 110us/step - loss: 5.4427 - val_loss: 9.3157\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5181 - val_loss: 9.2372\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4691 - val_loss: 8.9712\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4276 - val_loss: 9.4746\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5625 - val_loss: 9.1086\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5788 - val_loss: 9.0090\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6348 - val_loss: 9.1172\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6289 - val_loss: 9.1323\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9040 - val_loss: 9.3978\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5931 - val_loss: 9.0929\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4086 - val_loss: 9.0515\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5010 - val_loss: 9.1255\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4807 - val_loss: 9.2243\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7191 - val_loss: 9.2110\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6343 - val_loss: 8.9006\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3921 - val_loss: 9.8522\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4676 - val_loss: 9.0512\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4993 - val_loss: 9.4052\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4311 - val_loss: 9.5395\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5977 - val_loss: 9.3063\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8180 - val_loss: 9.0416\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4333 - val_loss: 8.9985\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5624 - val_loss: 9.4139\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5167 - val_loss: 9.2946\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5466 - val_loss: 9.1740\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5395 - val_loss: 9.2419\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4462 - val_loss: 9.3782\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5796 - val_loss: 9.2595\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4179 - val_loss: 9.0646\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4790 - val_loss: 10.2029\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5414 - val_loss: 9.2061\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8491 - val_loss: 9.5904\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7509 - val_loss: 9.4046\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5083 - val_loss: 9.4310\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4633 - val_loss: 9.5212\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4883 - val_loss: 9.2419\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4670 - val_loss: 9.6687\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5581 - val_loss: 9.3178\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2957 - val_loss: 9.9113\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4631 - val_loss: 9.0225\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5887 - val_loss: 9.3350\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5796 - val_loss: 9.0574\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5273 - val_loss: 9.7818\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4285 - val_loss: 9.2403\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4324 - val_loss: 9.5983\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4725 - val_loss: 9.2706\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4358 - val_loss: 9.6956\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4342 - val_loss: 9.2869\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4160 - val_loss: 9.5064\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3743 - val_loss: 9.2124\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4712 - val_loss: 9.6277\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4091 - val_loss: 9.4200\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3823 - val_loss: 9.4381\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7356 - val_loss: 9.4300\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5033 - val_loss: 9.3047\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4070 - val_loss: 9.4482\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4177 - val_loss: 9.4111\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3821 - val_loss: 9.4945\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4775 - val_loss: 9.5414\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4766 - val_loss: 9.1024\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6362 - val_loss: 9.5925\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5493 - val_loss: 9.4039\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5219 - val_loss: 9.3733\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4616 - val_loss: 9.3015\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4296 - val_loss: 9.1014\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5138 - val_loss: 9.7297\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4606 - val_loss: 9.5893\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4042 - val_loss: 9.3141\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3527 - val_loss: 9.5512\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3525 - val_loss: 9.2691\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5418 - val_loss: 9.5485\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4516 - val_loss: 9.2231\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5066 - val_loss: 9.1437\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5130 - val_loss: 9.3983\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8457 - val_loss: 9.4549\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6514 - val_loss: 9.6232\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7748 - val_loss: 9.0164\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.6744 - val_loss: 9.3663\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6677 - val_loss: 8.9164\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5147 - val_loss: 9.6393\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4155 - val_loss: 9.0372\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5541 - val_loss: 9.3781\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3417 - val_loss: 9.0145\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3731 - val_loss: 9.5971\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4128 - val_loss: 9.4931\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3846 - val_loss: 9.2147\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4081 - val_loss: 9.2153\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4634 - val_loss: 9.2105\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5680 - val_loss: 9.1877\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3892 - val_loss: 9.1833\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3496 - val_loss: 9.3184\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4013 - val_loss: 9.2109\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4492 - val_loss: 9.1499\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3855 - val_loss: 9.2565\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3734 - val_loss: 9.4135\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4028 - val_loss: 9.5126\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4495 - val_loss: 9.2411\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5898 - val_loss: 8.9944\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8426 - val_loss: 9.4541\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6713 - val_loss: 9.0292\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8534 - val_loss: 9.3069\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5505 - val_loss: 9.6351\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3805 - val_loss: 8.6784\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3910 - val_loss: 9.1997\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4142 - val_loss: 8.9512\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3900 - val_loss: 9.3995\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3669 - val_loss: 9.3112\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3504 - val_loss: 9.4152\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4125 - val_loss: 8.9141\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4625 - val_loss: 9.1870\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4502 - val_loss: 9.3650\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3295 - val_loss: 9.3467\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3159 - val_loss: 9.3606\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3126 - val_loss: 9.2180\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3402 - val_loss: 9.0946\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3264 - val_loss: 9.2284\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3235 - val_loss: 9.5541\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3798 - val_loss: 9.3892\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3449 - val_loss: 9.0958\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4069 - val_loss: 9.5400\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3588 - val_loss: 9.3340\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3997 - val_loss: 9.4607\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4410 - val_loss: 9.3678\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3516 - val_loss: 9.3662\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4039 - val_loss: 9.0951\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3532 - val_loss: 8.9989\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4061 - val_loss: 9.1644\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5182 - val_loss: 9.4193\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7713 - val_loss: 9.1136\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6127 - val_loss: 8.7532\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7310 - val_loss: 9.8132\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4011 - val_loss: 8.9882\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3340 - val_loss: 9.4685\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3428 - val_loss: 8.7077\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3836 - val_loss: 8.9469\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7416 - val_loss: 9.5365\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4450 - val_loss: 8.8684\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5366 - val_loss: 9.6515\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3319 - val_loss: 8.9044\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3511 - val_loss: 9.1127\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4189 - val_loss: 8.9843\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3421 - val_loss: 8.9925\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4320 - val_loss: 9.1103\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2830 - val_loss: 8.9013\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5382 - val_loss: 9.9843\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6745 - val_loss: 9.0179\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4861 - val_loss: 9.1730\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3794 - val_loss: 9.3213\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3498 - val_loss: 9.4128\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3160 - val_loss: 9.2772\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3629 - val_loss: 9.2486\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3051 - val_loss: 9.2131\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3373 - val_loss: 9.2674\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3188 - val_loss: 9.0756\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.4606 - val_loss: 9.1683\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3594 - val_loss: 9.2193\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3608 - val_loss: 8.8384\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2898 - val_loss: 9.0984\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3852 - val_loss: 9.3553\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3939 - val_loss: 9.2045\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3597 - val_loss: 8.8539\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4025 - val_loss: 9.0976\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3341 - val_loss: 9.0256\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3973 - val_loss: 9.2050\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3507 - val_loss: 9.2510\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3553 - val_loss: 9.0387\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4455 - val_loss: 9.1719\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3431 - val_loss: 9.0749\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3429 - val_loss: 9.0345\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3014 - val_loss: 8.9946\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4609 - val_loss: 9.0397\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4199 - val_loss: 9.2872\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3498 - val_loss: 8.8893\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3307 - val_loss: 9.0167\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4877 - val_loss: 9.1494\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4531 - val_loss: 9.0347\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5257 - val_loss: 9.2870\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4096 - val_loss: 8.8730\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3537 - val_loss: 9.3821\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4078 - val_loss: 9.1226\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4625 - val_loss: 9.4100\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4003 - val_loss: 9.0839\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4275 - val_loss: 8.7758\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3393 - val_loss: 9.1538\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3459 - val_loss: 9.0219\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3885 - val_loss: 9.2790\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2952 - val_loss: 9.1391\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5454 - val_loss: 9.4092\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3904 - val_loss: 9.2846\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3860 - val_loss: 8.9593\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3395 - val_loss: 9.3897\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3190 - val_loss: 8.8757\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2773 - val_loss: 9.8205\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5079 - val_loss: 9.0494\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3483 - val_loss: 9.1496\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5326 - val_loss: 9.0822\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8791 - val_loss: 9.0096\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6751 - val_loss: 8.9515\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6198 - val_loss: 9.5587\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3372 - val_loss: 8.8694\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3222 - val_loss: 9.1868\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3922 - val_loss: 9.1079\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3358 - val_loss: 9.2577\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3451 - val_loss: 8.8315\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2975 - val_loss: 9.1985\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3378 - val_loss: 9.0596\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4092 - val_loss: 9.0828\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.3924 - val_loss: 9.4002\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3440 - val_loss: 9.2614\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3886 - val_loss: 9.0744\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3992 - val_loss: 8.8123\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3500 - val_loss: 9.2749\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3816 - val_loss: 9.1129\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3091 - val_loss: 9.2619\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2929 - val_loss: 9.1148\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2714 - val_loss: 9.0134\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3499 - val_loss: 9.2898\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3891 - val_loss: 9.0409\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6443 - val_loss: 9.0096\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5982 - val_loss: 9.4721\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2774 - val_loss: 8.7828\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4392 - val_loss: 9.3046\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3132 - val_loss: 8.9415\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3041 - val_loss: 9.0576\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6350 - val_loss: 8.8280\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7999 - val_loss: 9.3166\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4409 - val_loss: 9.1800\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2550 - val_loss: 9.0699\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3399 - val_loss: 9.1091\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3925 - val_loss: 9.0429\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5160 - val_loss: 9.0602\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.4428 - val_loss: 8.9371\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3339 - val_loss: 8.6289\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3062 - val_loss: 9.4634\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3053 - val_loss: 8.9643\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5352 - val_loss: 9.0716\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0618 - val_loss: 8.6093\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3864 - val_loss: 9.0364\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3434 - val_loss: 8.9509\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3045 - val_loss: 8.9926\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2989 - val_loss: 9.0414\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3710 - val_loss: 8.8227\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3750 - val_loss: 8.9555\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5571 - val_loss: 9.0578\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8420 - val_loss: 9.1439\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4122 - val_loss: 9.5083\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3648 - val_loss: 8.8812\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3013 - val_loss: 9.3116\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2836 - val_loss: 8.7823\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3922 - val_loss: 9.2142\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3820 - val_loss: 8.8232\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3193 - val_loss: 9.2311\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3584 - val_loss: 9.4418\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2398 - val_loss: 8.8112\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4287 - val_loss: 9.2294\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4082 - val_loss: 9.0464\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2817 - val_loss: 8.7830\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3757 - val_loss: 9.3349\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3620 - val_loss: 9.0034\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3569 - val_loss: 9.1298\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5845 - val_loss: 8.9574\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5766 - val_loss: 9.2348\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3597 - val_loss: 8.8518\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2899 - val_loss: 9.1915\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2501 - val_loss: 8.9169\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2582 - val_loss: 9.0045\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3459 - val_loss: 9.5450\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3093 - val_loss: 9.4215\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3283 - val_loss: 9.0555\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2568 - val_loss: 9.4002\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3042 - val_loss: 9.0376\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2919 - val_loss: 9.1063\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3703 - val_loss: 9.0663\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3592 - val_loss: 9.0063\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3397 - val_loss: 8.8124\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.747 - 0s 103us/step - loss: 5.4207 - val_loss: 9.4480\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3198 - val_loss: 9.0693\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3556 - val_loss: 9.2942\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2452 - val_loss: 8.7140\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2308 - val_loss: 9.3517\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3638 - val_loss: 8.7173\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3322 - val_loss: 9.0836\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2869 - val_loss: 9.1512\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2823 - val_loss: 8.8816\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4108 - val_loss: 9.4153\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.3182 - val_loss: 9.5143\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3816 - val_loss: 8.7638\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 5.3494 - val_loss: 9.1542\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.3627 - val_loss: 9.2329\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 160us/step - loss: 5.4030 - val_loss: 9.0397\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.3838 - val_loss: 8.9348\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4172 - val_loss: 9.0812\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.7359 - val_loss: 9.1942\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2899 - val_loss: 8.7394\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 211us/step - loss: 5.2296 - val_loss: 9.1984\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 211us/step - loss: 5.4918 - val_loss: 8.9042\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.4386 - val_loss: 9.4111\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4984 - val_loss: 8.9527\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.3235 - val_loss: 9.1507\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.2381 - val_loss: 9.2428\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2836 - val_loss: 9.0704\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.2494 - val_loss: 9.5558\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4429 - val_loss: 9.0655\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.3264 - val_loss: 9.1665\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.3620 - val_loss: 9.2407\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.3247 - val_loss: 9.1383\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3612 - val_loss: 9.0065\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.3144 - val_loss: 9.0247\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 138us/step - loss: 5.3161 - val_loss: 9.2228\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 160us/step - loss: 5.5051 - val_loss: 9.5675\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 167us/step - loss: 5.3821 - val_loss: 8.8739\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.3184 - val_loss: 9.0506\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 5.3213 - val_loss: 9.2518\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 175us/step - loss: 5.3145 - val_loss: 9.2490\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 167us/step - loss: 5.4892 - val_loss: 9.1926\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 189us/step - loss: 5.3992 - val_loss: 9.0727\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 182us/step - loss: 5.3838 - val_loss: 9.1169\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 197us/step - loss: 5.2491 - val_loss: 9.4715\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 171us/step - loss: 5.2541 - val_loss: 9.0521\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3881 - val_loss: 9.3672\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3411 - val_loss: 9.3364\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4611 - val_loss: 8.8290\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3998 - val_loss: 9.2357\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3129 - val_loss: 8.9846\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2663 - val_loss: 9.2239\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3093 - val_loss: 9.1122\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2626 - val_loss: 8.8178\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2641 - val_loss: 9.1484\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3880 - val_loss: 9.1166\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4360 - val_loss: 8.9733\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2780 - val_loss: 9.5425\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3321 - val_loss: 8.7617\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3114 - val_loss: 8.9290\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3947 - val_loss: 9.1847\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3047 - val_loss: 9.3072\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3433 - val_loss: 9.1713\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4183 - val_loss: 9.1530\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3474 - val_loss: 8.9673\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2976 - val_loss: 8.9203\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2646 - val_loss: 9.2732\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2618 - val_loss: 8.9969\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.2498 - val_loss: 9.0169\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2888 - val_loss: 9.5660\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2758 - val_loss: 9.0151\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4489 - val_loss: 9.3143\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4026 - val_loss: 9.0794\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2941 - val_loss: 8.7153\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4068 - val_loss: 9.2991\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2763 - val_loss: 8.9162\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5720 - val_loss: 9.3753\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3735 - val_loss: 9.1964\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3798 - val_loss: 8.9251\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3539 - val_loss: 9.5753\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2618 - val_loss: 8.7152\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3516 - val_loss: 9.1864\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3052 - val_loss: 9.1080\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3526 - val_loss: 9.1747\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2319 - val_loss: 9.6309\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4320 - val_loss: 8.8306\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4275 - val_loss: 9.1203\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2773 - val_loss: 9.0907\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3326 - val_loss: 8.9404\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2676 - val_loss: 9.0252\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3182 - val_loss: 9.1861\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3903 - val_loss: 9.2025\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3383 - val_loss: 9.1697\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4112 - val_loss: 9.1607\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2932 - val_loss: 8.9677\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3367 - val_loss: 9.1320\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3242 - val_loss: 9.1423\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3602 - val_loss: 9.1403\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2823 - val_loss: 9.1309\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3716 - val_loss: 9.1603\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2493 - val_loss: 8.6349\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3560 - val_loss: 9.1056\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2698 - val_loss: 9.3039\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2729 - val_loss: 9.2622\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4607 - val_loss: 8.7833\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6796 - val_loss: 9.2014\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5587 - val_loss: 9.2216\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5246 - val_loss: 9.0668\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3708 - val_loss: 9.5359\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4353 - val_loss: 9.2841\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2523 - val_loss: 9.7152\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4342 - val_loss: 8.6975\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 5.3177 - val_loss: 9.4260\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3107 - val_loss: 8.8335\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3593 - val_loss: 8.9539\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2546 - val_loss: 9.2255\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3059 - val_loss: 9.2692\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2713 - val_loss: 9.0341\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3712 - val_loss: 9.1282\n",
      "6.5557588237827105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.99356765,  0.16494359,  0.15535271,  0.18563902,  0.6761655 ],\n",
       "        [-1.4501251 ,  2.4916284 , -0.12775901, -1.355335  ,  1.581255  ],\n",
       "        [ 0.8945238 ,  2.2689772 , -1.2922693 ,  1.1545163 , -0.77257264],\n",
       "        [-0.2587891 , -1.7165097 ,  1.7504747 ,  0.3099132 , -1.410206  ],\n",
       "        [-0.58115524,  0.9048627 , -0.24619685, -0.4446224 ,  0.1418841 ],\n",
       "        [ 1.1654044 ,  0.6679163 , -1.9152089 ,  0.4524394 ,  0.03609947],\n",
       "        [ 0.61408573, -0.3363335 ,  0.11003856,  0.04564286, -0.30016184]],\n",
       "       dtype=float32),\n",
       " array([2.1210492 , 1.069088  , 1.5970203 , 0.87655294, 2.3812053 ],\n",
       "       dtype=float32),\n",
       " array([[-0.9688265 , -1.1545979 , -0.7451217 ,  0.9702589 , -0.4648472 ],\n",
       "        [ 1.1182098 ,  0.15094972,  1.095042  , -0.87730986, -0.13771516],\n",
       "        [ 1.1280768 ,  0.45289543,  0.9372022 , -1.0536025 ,  0.10317706],\n",
       "        [ 0.69545   ,  0.92196745,  0.99080575, -1.1879811 ,  0.5716506 ],\n",
       "        [-0.32867548, -1.8834138 , -1.5012529 , -0.10615854,  0.48240164]],\n",
       "       dtype=float32),\n",
       " array([-2.1386456 , -2.108763  , -2.1176693 ,  1.9757633 , -0.40164322],\n",
       "       dtype=float32),\n",
       " array([[-1.1721951 ],\n",
       "        [-2.467398  ],\n",
       "        [-2.3967216 ],\n",
       "        [ 1.0346067 ],\n",
       "        [-0.00704356]], dtype=float32),\n",
       " array([1.9238566], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_1(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure1_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 808us/step - loss: 521.3571 - val_loss: 335.0004\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 199.2497 - val_loss: 55.6906\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2387 - val_loss: 35.6067\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 26.8975 - val_loss: 25.9684\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 19.6974 - val_loss: 24.7561\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 18.4023 - val_loss: 21.9282\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 14.7860 - val_loss: 20.4548\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.1872 - val_loss: 19.7339\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.5276 - val_loss: 18.4218\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.8199 - val_loss: 16.9746\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.9440 - val_loss: 16.2687\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.4303 - val_loss: 15.0567\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.0757 - val_loss: 14.0848\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.7211 - val_loss: 13.3426\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.3340 - val_loss: 12.7827\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.1063 - val_loss: 12.3813\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.7528 - val_loss: 11.8776\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.7104 - val_loss: 11.7930\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.5371 - val_loss: 11.2486\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.3227 - val_loss: 11.5043\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.2929 - val_loss: 11.0803\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.1778 - val_loss: 10.7682\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.9349 - val_loss: 10.7847\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9286 - val_loss: 10.7111\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8324 - val_loss: 10.3074\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7217 - val_loss: 10.2194\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6106 - val_loss: 10.2958\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5678 - val_loss: 9.9291\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4948 - val_loss: 9.8708\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5365 - val_loss: 9.5215\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.4673 - val_loss: 9.6488\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2598 - val_loss: 9.7637\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2757 - val_loss: 9.5963\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2307 - val_loss: 9.4123\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1729 - val_loss: 9.5007\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2351 - val_loss: 9.0680\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0469 - val_loss: 9.3346\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2526 - val_loss: 9.2250\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1145 - val_loss: 9.0207\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1142 - val_loss: 9.1418\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8560 - val_loss: 9.0904\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9024 - val_loss: 9.0215\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8409 - val_loss: 8.9039\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8362 - val_loss: 8.9144\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.1056 - val_loss: 9.1140\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8076 - val_loss: 8.9481\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0491 - val_loss: 8.6766\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7326 - val_loss: 9.0072\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8564 - val_loss: 8.8235\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5768 - val_loss: 9.0356\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8166 - val_loss: 8.8519\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7337 - val_loss: 8.9561\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7126 - val_loss: 8.9030\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8891 - val_loss: 8.8762\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.8935 - val_loss: 9.0435\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.1725 - val_loss: 9.3133\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9222 - val_loss: 9.2659\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6086 - val_loss: 8.9606\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5693 - val_loss: 8.9843\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.5449 - val_loss: 9.0693\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5824 - val_loss: 9.1046\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.5602 - val_loss: 8.8912\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3706 - val_loss: 8.8865\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.5557 - val_loss: 9.0131\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9912 - val_loss: 8.9267\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4777 - val_loss: 8.9128\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4422 - val_loss: 8.8891\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 7.4574 - val_loss: 8.7780\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6668 - val_loss: 9.0483\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5580 - val_loss: 8.8385\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3970 - val_loss: 8.8802\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2857 - val_loss: 8.9404\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2484 - val_loss: 9.0185\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3022 - val_loss: 8.9732\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2217 - val_loss: 9.0698\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2176 - val_loss: 9.0400\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1768 - val_loss: 8.9053\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2840 - val_loss: 9.0278\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.1557 - val_loss: 9.1407\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1716 - val_loss: 8.8973\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2067 - val_loss: 9.0833\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1276 - val_loss: 9.2649\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4262 - val_loss: 9.0011\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1618 - val_loss: 9.3421\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0727 - val_loss: 9.1221\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1425 - val_loss: 8.9228\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2236 - val_loss: 9.0398\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1269 - val_loss: 9.1751\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2148 - val_loss: 9.0021\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1290 - val_loss: 9.0425\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.1707 - val_loss: 9.0680\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2189 - val_loss: 9.4858\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1609 - val_loss: 9.2918\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0240 - val_loss: 9.0603\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2202 - val_loss: 9.2425\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0637 - val_loss: 9.1071\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4747 - val_loss: 9.4544\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2229 - val_loss: 9.1686\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0469 - val_loss: 9.1138\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1595 - val_loss: 9.3742\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1835 - val_loss: 9.1543\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1542 - val_loss: 9.2292\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3894 - val_loss: 9.1744\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2988 - val_loss: 9.5837\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2634 - val_loss: 9.1468\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3456 - val_loss: 9.2626\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1134 - val_loss: 9.2184\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0306 - val_loss: 9.0393\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.1151 - val_loss: 9.0404\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0395 - val_loss: 8.9733\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2564 - val_loss: 8.9647\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0344 - val_loss: 8.9582\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0046 - val_loss: 8.9381\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9396 - val_loss: 9.1861\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9844 - val_loss: 8.9152\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9917 - val_loss: 9.0301\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9759 - val_loss: 8.8762\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9747 - val_loss: 8.8096\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9919 - val_loss: 8.8227\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8636 - val_loss: 9.0691\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9988 - val_loss: 9.1804\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0870 - val_loss: 9.2205\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1817 - val_loss: 9.0531\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9178 - val_loss: 9.0237\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9066 - val_loss: 8.7266\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9285 - val_loss: 8.7366\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9397 - val_loss: 8.8209\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9090 - val_loss: 9.1842\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9306 - val_loss: 8.9536\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0019 - val_loss: 8.7405\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9125 - val_loss: 8.7483\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8713 - val_loss: 8.7539\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8824 - val_loss: 8.7098\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8365 - val_loss: 8.7244\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0298 - val_loss: 8.7148\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8653 - val_loss: 8.8717\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8158 - val_loss: 8.8157\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 7.0174 - val_loss: 8.6681\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6829 - val_loss: 8.6298\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7315 - val_loss: 8.5412\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8431 - val_loss: 8.7351\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9510 - val_loss: 8.8459\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5001 - val_loss: 8.8774\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3701 - val_loss: 8.9383\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6076 - val_loss: 8.7086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8184 - val_loss: 8.7023\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8755 - val_loss: 8.4839\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6771 - val_loss: 8.5054\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7147 - val_loss: 8.4862\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6435 - val_loss: 8.5697\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8146 - val_loss: 8.5735\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7933 - val_loss: 8.4516\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5695 - val_loss: 8.5854\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0095 - val_loss: 8.7341\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7369 - val_loss: 8.4292\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7147 - val_loss: 8.4163\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5773 - val_loss: 8.7776\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6768 - val_loss: 8.7871\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5389 - val_loss: 8.4780\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5657 - val_loss: 8.5453\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4853 - val_loss: 8.4419\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5492 - val_loss: 8.1806\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 6.5455 - val_loss: 8.3003\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.4639 - val_loss: 8.4491\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5369 - val_loss: 8.4315\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.8595 - val_loss: 8.5857\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2000 - val_loss: 8.7147\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7308 - val_loss: 8.5432\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5055 - val_loss: 8.5076\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4824 - val_loss: 8.4919\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4379 - val_loss: 8.4322\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4030 - val_loss: 8.4863\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5159 - val_loss: 8.3681\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5302 - val_loss: 8.4783\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3724 - val_loss: 8.4724\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4565 - val_loss: 8.3039\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5373 - val_loss: 8.6654\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3516 - val_loss: 8.4500\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5818 - val_loss: 8.5071\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7288 - val_loss: 8.5190\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4699 - val_loss: 8.6788\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3950 - val_loss: 8.7503\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4325 - val_loss: 8.6088\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4545 - val_loss: 8.6340\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4283 - val_loss: 8.6767\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2875 - val_loss: 8.5968\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3938 - val_loss: 8.5450\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4157 - val_loss: 8.6520\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3829 - val_loss: 8.6264\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3995 - val_loss: 8.5333\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2572 - val_loss: 8.5141\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3680 - val_loss: 8.6931\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2653 - val_loss: 8.7225\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3101 - val_loss: 8.6140\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3207 - val_loss: 8.3951\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4347 - val_loss: 8.6552\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4650 - val_loss: 8.7072\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6672 - val_loss: 8.6048\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3754 - val_loss: 8.7267\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3061 - val_loss: 8.4380\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4495 - val_loss: 8.6294\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4112 - val_loss: 8.6618\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2365 - val_loss: 8.4942\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3176 - val_loss: 8.4375\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6254 - val_loss: 8.6504\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6003 - val_loss: 8.5765\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5183 - val_loss: 8.9311\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2998 - val_loss: 8.5782\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3554 - val_loss: 8.6494\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3939 - val_loss: 8.7530\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1318 - val_loss: 8.9102\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1689 - val_loss: 8.8682\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2220 - val_loss: 8.4559\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2499 - val_loss: 8.6428\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3522 - val_loss: 8.8880\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2737 - val_loss: 8.7714\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5695 - val_loss: 8.8667\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3517 - val_loss: 8.6976\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1720 - val_loss: 8.4384\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3571 - val_loss: 8.5063\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2528 - val_loss: 8.8101\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1720 - val_loss: 9.0730\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.1604 - val_loss: 8.8322\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3321 - val_loss: 8.8223\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2287 - val_loss: 8.6929\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2317 - val_loss: 8.8848\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2603 - val_loss: 8.7368\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1145 - val_loss: 8.8224\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2126 - val_loss: 8.7373\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6225 - val_loss: 8.7365\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0124 - val_loss: 8.7921\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9573 - val_loss: 8.8896\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2030 - val_loss: 8.8568\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2260 - val_loss: 8.6207\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4292 - val_loss: 8.6349\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3069 - val_loss: 8.6975\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1104 - val_loss: 8.9311\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2128 - val_loss: 8.8885\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2132 - val_loss: 8.7838\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0566 - val_loss: 8.6726\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0857 - val_loss: 8.7365\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0430 - val_loss: 8.7909\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1253 - val_loss: 8.7741\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2712 - val_loss: 8.9049\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6232 - val_loss: 9.0255\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5102 - val_loss: 8.8619\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5922 - val_loss: 8.7581\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0031 - val_loss: 9.1939\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1893 - val_loss: 9.0105\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1124 - val_loss: 8.8198\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0299 - val_loss: 8.8138\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0498 - val_loss: 8.7335\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0924 - val_loss: 8.7985\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0985 - val_loss: 8.8654\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9571 - val_loss: 8.8680\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9694 - val_loss: 8.8155\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2667 - val_loss: 8.9981\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0979 - val_loss: 8.9470\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0951 - val_loss: 9.2123\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0029 - val_loss: 9.1563\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9952 - val_loss: 8.8771\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9667 - val_loss: 8.6717\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9768 - val_loss: 8.6229\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9287 - val_loss: 8.7466\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0808 - val_loss: 8.8357\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1208 - val_loss: 8.8839\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2845 - val_loss: 9.0337\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9922 - val_loss: 9.0872\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9191 - val_loss: 8.8032\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1920 - val_loss: 8.7836\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0903 - val_loss: 9.0087\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9602 - val_loss: 9.0774\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0013 - val_loss: 9.1901\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0992 - val_loss: 8.7129\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0288 - val_loss: 8.8805\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9601 - val_loss: 8.8248\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0169 - val_loss: 8.8143\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0325 - val_loss: 8.9690\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9383 - val_loss: 8.8276\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9842 - val_loss: 8.9237\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9646 - val_loss: 9.0753\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9021 - val_loss: 8.8779\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8988 - val_loss: 8.7965\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8859 - val_loss: 8.8643\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9944 - val_loss: 9.0625\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0599 - val_loss: 8.8934\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8815 - val_loss: 8.9187\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9129 - val_loss: 8.6956\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0782 - val_loss: 8.8474\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1956 - val_loss: 8.9380\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1784 - val_loss: 8.8185\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1468 - val_loss: 8.8029\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9310 - val_loss: 8.8347\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8477 - val_loss: 8.8427\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9261 - val_loss: 9.0898\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8823 - val_loss: 9.0588\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8848 - val_loss: 9.0744\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9178 - val_loss: 8.6373\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9044 - val_loss: 8.7357\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8703 - val_loss: 8.8910\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9306 - val_loss: 8.8945\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9988 - val_loss: 8.7040\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9562 - val_loss: 8.7329\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9171 - val_loss: 9.0125\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8362 - val_loss: 8.8297\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8492 - val_loss: 8.9064\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9064 - val_loss: 9.0509\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8655 - val_loss: 8.8953\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7863 - val_loss: 8.7573\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9064 - val_loss: 8.5629\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9957 - val_loss: 9.1168\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0718 - val_loss: 9.1909\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9090 - val_loss: 8.9744\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9173 - val_loss: 8.7640\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9861 - val_loss: 8.6609\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8948 - val_loss: 9.0146\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0551 - val_loss: 9.0260\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8236 - val_loss: 8.8335\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8631 - val_loss: 8.8273\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1726 - val_loss: 8.9119\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1250 - val_loss: 8.8935\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8705 - val_loss: 8.8382\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8106 - val_loss: 9.0135\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7840 - val_loss: 8.8219\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7843 - val_loss: 8.8072\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8334 - val_loss: 9.1653\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9479 - val_loss: 9.0070\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7496 - val_loss: 8.7551\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8497 - val_loss: 8.7368\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7142 - val_loss: 8.8666\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7589 - val_loss: 8.8274\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7628 - val_loss: 8.8956\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7563 - val_loss: 8.8759\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9275 - val_loss: 8.7988\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8549 - val_loss: 8.7896\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7647 - val_loss: 8.9035\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8142 - val_loss: 8.6385\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7720 - val_loss: 8.8675\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7417 - val_loss: 8.9442\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8019 - val_loss: 8.6523\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7861 - val_loss: 8.8292\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7497 - val_loss: 8.9261\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8587 - val_loss: 8.9664\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9007 - val_loss: 9.0111\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8048 - val_loss: 8.7232\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7667 - val_loss: 8.7458\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7710 - val_loss: 8.6943\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7275 - val_loss: 8.7633\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7062 - val_loss: 8.6795\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8499 - val_loss: 8.7948\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6937 - val_loss: 8.8401\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7763 - val_loss: 8.7735\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9235 - val_loss: 8.7755\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8715 - val_loss: 8.8536\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8901 - val_loss: 8.8087\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8364 - val_loss: 8.7815\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0674 - val_loss: 8.7794\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7540 - val_loss: 9.0946\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6787 - val_loss: 8.8638\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6693 - val_loss: 8.7042\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8094 - val_loss: 8.5915\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6565 - val_loss: 8.7639\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7091 - val_loss: 8.8453\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7449 - val_loss: 8.8814\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9115 - val_loss: 9.0834\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9583 - val_loss: 8.9277\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5879 - val_loss: 8.9685\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7480 - val_loss: 8.7568\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6525 - val_loss: 8.8829\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7244 - val_loss: 8.5895\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6649 - val_loss: 8.7364\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6426 - val_loss: 8.7420\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7521 - val_loss: 8.6960\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7244 - val_loss: 8.7556\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7385 - val_loss: 8.7650\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7468 - val_loss: 8.9786\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.7428 - val_loss: 8.8095\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7776 - val_loss: 8.5137\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7087 - val_loss: 8.7843\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6196 - val_loss: 8.8473\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7443 - val_loss: 8.9039\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6575 - val_loss: 8.8795\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6285 - val_loss: 8.8320\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6913 - val_loss: 8.7830\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7593 - val_loss: 9.0121\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6534 - val_loss: 8.8728\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6663 - val_loss: 8.8305\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6462 - val_loss: 8.9235\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7590 - val_loss: 9.1141\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7597 - val_loss: 8.8116\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9465 - val_loss: 8.8295\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8802 - val_loss: 8.8011\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7384 - val_loss: 8.7990\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7955 - val_loss: 8.7438\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8432 - val_loss: 8.8380\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7099 - val_loss: 9.0088\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6928 - val_loss: 9.0330\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6667 - val_loss: 8.6938\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7787 - val_loss: 8.7631\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8235 - val_loss: 8.6887\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7052 - val_loss: 8.6496\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6257 - val_loss: 9.0468\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.6984 - val_loss: 8.5992\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8230 - val_loss: 8.5951\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6839 - val_loss: 8.6367\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.6539 - val_loss: 9.0916\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9256 - val_loss: 8.8195\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7495 - val_loss: 8.8490\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6962 - val_loss: 8.7982\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7565 - val_loss: 8.8194\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6309 - val_loss: 8.6657\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7389 - val_loss: 9.0471\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5748 - val_loss: 9.1714\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8904 - val_loss: 8.9414\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7933 - val_loss: 8.9016\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6570 - val_loss: 8.9391\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6207 - val_loss: 9.1159\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6525 - val_loss: 8.7219\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5871 - val_loss: 8.7671\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5806 - val_loss: 8.8483\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6363 - val_loss: 8.8690\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6457 - val_loss: 8.8105\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6240 - val_loss: 8.9850\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6624 - val_loss: 8.8010\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6500 - val_loss: 8.8418\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6211 - val_loss: 8.9340\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5628 - val_loss: 8.4998\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6812 - val_loss: 8.7028\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7443 - val_loss: 8.7372\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6155 - val_loss: 9.0976\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8240 - val_loss: 8.9466\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6139 - val_loss: 8.7169\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7279 - val_loss: 8.6926\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7970 - val_loss: 8.9190\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6842 - val_loss: 9.0167\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6130 - val_loss: 8.7310\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6190 - val_loss: 8.7010\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6014 - val_loss: 8.5724\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5252 - val_loss: 8.9280\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5694 - val_loss: 8.9593\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5537 - val_loss: 8.8819\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8526 - val_loss: 9.0747\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7356 - val_loss: 8.7722\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8411 - val_loss: 8.9235\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7442 - val_loss: 8.8309\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5932 - val_loss: 8.7769\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5753 - val_loss: 9.0340\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6785 - val_loss: 8.9466\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7545 - val_loss: 8.8154\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2249 - val_loss: 9.0136\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1745 - val_loss: 8.8494\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8680 - val_loss: 9.0197\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6561 - val_loss: 8.8660\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5325 - val_loss: 8.8263\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6070 - val_loss: 8.7355\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6609 - val_loss: 8.8850\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7691 - val_loss: 8.8490\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7702 - val_loss: 8.8342\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5964 - val_loss: 8.8014\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5402 - val_loss: 8.9608\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6013 - val_loss: 9.0638\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6147 - val_loss: 9.0567\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9087 - val_loss: 9.0391\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7100 - val_loss: 8.6864\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5194 - val_loss: 8.6654\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5524 - val_loss: 8.7119\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6591 - val_loss: 8.7027\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5569 - val_loss: 8.7757\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6670 - val_loss: 8.7123\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1844 - val_loss: 8.8069\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7103 - val_loss: 8.6962\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5511 - val_loss: 8.6860\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5658 - val_loss: 8.7991\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5222 - val_loss: 8.8621\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5771 - val_loss: 8.8100\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6849 - val_loss: 8.9741\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6037 - val_loss: 8.9209\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6080 - val_loss: 8.8650\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5165 - val_loss: 8.9370\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5218 - val_loss: 8.7818\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5295 - val_loss: 8.8855\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6221 - val_loss: 9.0333\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5606 - val_loss: 8.9329\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5070 - val_loss: 8.7678\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6263 - val_loss: 8.6356\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6444 - val_loss: 8.8508\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.5320 - val_loss: 8.8240\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5497 - val_loss: 8.8152\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5414 - val_loss: 8.9258\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6532 - val_loss: 8.9901\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4823 - val_loss: 8.8531\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6086 - val_loss: 8.7408\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6013 - val_loss: 9.1382\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6859 - val_loss: 8.9012\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5974 - val_loss: 8.6943\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5625 - val_loss: 8.7544\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5111 - val_loss: 8.7875\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5870 - val_loss: 8.7176\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6410 - val_loss: 9.0939\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7847 - val_loss: 8.9449\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7490 - val_loss: 8.9131\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5990 - val_loss: 8.8304\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5635 - val_loss: 8.8930\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5270 - val_loss: 9.1741\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8006 - val_loss: 8.9115\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5331 - val_loss: 8.9171\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4977 - val_loss: 8.8710\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5227 - val_loss: 8.9271\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6261 - val_loss: 9.0322\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5272 - val_loss: 8.9171\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4815 - val_loss: 8.9432\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6307 - val_loss: 9.0999\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7535 - val_loss: 8.8234\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6419 - val_loss: 8.7350\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4785 - val_loss: 9.0103\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5224 - val_loss: 9.0322\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4939 - val_loss: 8.8708\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5627 - val_loss: 8.9263\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5222 - val_loss: 9.0223\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4619 - val_loss: 8.7729\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5207 - val_loss: 8.6946\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6673 - val_loss: 8.9538\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5538 - val_loss: 8.8360\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5151 - val_loss: 9.2015\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6458 - val_loss: 8.8904\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4420 - val_loss: 9.1303\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4936 - val_loss: 9.0849\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7582 - val_loss: 8.9990\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8739 - val_loss: 8.7794\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9215 - val_loss: 9.1667\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.7553 - val_loss: 8.8233\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4969 - val_loss: 8.9775\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5462 - val_loss: 8.9543\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4611 - val_loss: 9.0146\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5950 - val_loss: 9.2269\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5889 - val_loss: 9.2112\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7779 - val_loss: 9.0465\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6459 - val_loss: 8.9187\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6120 - val_loss: 8.8634\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5050 - val_loss: 8.7848\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6876 - val_loss: 8.9042\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5021 - val_loss: 8.9729\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4768 - val_loss: 8.9888\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4391 - val_loss: 9.0316\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5130 - val_loss: 9.0150\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5439 - val_loss: 8.9633\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5759 - val_loss: 8.9083\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5157 - val_loss: 8.9248\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4712 - val_loss: 9.0311\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4587 - val_loss: 9.0610\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4909 - val_loss: 9.0252\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6413 - val_loss: 8.7252\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7360 - val_loss: 8.9212\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6665 - val_loss: 8.9768\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4802 - val_loss: 8.9724\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5673 - val_loss: 9.1024\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5243 - val_loss: 8.8706\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4906 - val_loss: 8.9780\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4856 - val_loss: 8.9405\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5765 - val_loss: 9.0728\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4954 - val_loss: 8.9312\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6519 - val_loss: 9.0424\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6045 - val_loss: 8.8382\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5396 - val_loss: 8.9303\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5567 - val_loss: 8.9381\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5800 - val_loss: 8.9532\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5282 - val_loss: 8.9909\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4226 - val_loss: 9.0348\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7073 - val_loss: 8.9265\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5628 - val_loss: 8.9979\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4537 - val_loss: 9.0859\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6092 - val_loss: 8.8913\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5316 - val_loss: 9.0328\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6578 - val_loss: 9.1664\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4377 - val_loss: 9.3530\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5724 - val_loss: 9.0207\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0035 - val_loss: 9.5988\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8349 - val_loss: 9.1076\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5475 - val_loss: 9.1573\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6582 - val_loss: 8.9426\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5785 - val_loss: 8.9886\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5551 - val_loss: 8.9573\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6349 - val_loss: 9.2959\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6334 - val_loss: 8.9805\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7686 - val_loss: 9.2984\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4896 - val_loss: 9.2571\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5200 - val_loss: 8.9931\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5457 - val_loss: 8.7727\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4597 - val_loss: 8.9221\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5465 - val_loss: 9.0831\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4459 - val_loss: 9.1150\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4318 - val_loss: 8.9814\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5133 - val_loss: 8.8695\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5169 - val_loss: 8.9137\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4994 - val_loss: 9.0896\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5085 - val_loss: 9.0633\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4316 - val_loss: 9.1385\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5179 - val_loss: 9.0506\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5238 - val_loss: 8.9272\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4340 - val_loss: 8.9373\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4817 - val_loss: 9.1662\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5345 - val_loss: 9.0187\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4903 - val_loss: 9.1034\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4761 - val_loss: 8.9843\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4456 - val_loss: 9.1042\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4436 - val_loss: 9.1275\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4445 - val_loss: 9.1912\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.6366 - val_loss: 9.3121\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4290 - val_loss: 9.1988\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4947 - val_loss: 8.9746\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7906 - val_loss: 9.0655\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0339 - val_loss: 8.9010\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8294 - val_loss: 8.8421\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5043 - val_loss: 9.0679\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4575 - val_loss: 9.0008\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4585 - val_loss: 9.2239\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4382 - val_loss: 9.1371\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5149 - val_loss: 9.2874\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5041 - val_loss: 8.9050\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5348 - val_loss: 9.2142\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7567 - val_loss: 9.0917\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6747 - val_loss: 9.0487\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5576 - val_loss: 9.0402\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4686 - val_loss: 9.0419\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5143 - val_loss: 9.1230\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4236 - val_loss: 8.9239\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4212 - val_loss: 8.9605\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5428 - val_loss: 8.9038\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6147 - val_loss: 9.1937\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4904 - val_loss: 9.2286\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5504 - val_loss: 9.1298\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4846 - val_loss: 8.9870\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5379 - val_loss: 9.0517\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5650 - val_loss: 9.1407\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8920 - val_loss: 8.8352\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5517 - val_loss: 8.8329\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4164 - val_loss: 9.0121\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4062 - val_loss: 9.0371\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4374 - val_loss: 9.0440\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4711 - val_loss: 9.0897\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7323 - val_loss: 9.0460\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4757 - val_loss: 9.1548\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4627 - val_loss: 9.1268\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4517 - val_loss: 9.1331\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5564 - val_loss: 9.1189\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5391 - val_loss: 9.1486\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5026 - val_loss: 8.9526\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4801 - val_loss: 9.0083\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.4539 - val_loss: 8.8410\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4604 - val_loss: 9.1307\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5949 - val_loss: 9.2978\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5091 - val_loss: 9.2585\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5876 - val_loss: 9.1072\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5579 - val_loss: 8.9482\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5797 - val_loss: 9.3330\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6570 - val_loss: 8.9936\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5338 - val_loss: 9.0427\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5155 - val_loss: 9.2543\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5918 - val_loss: 9.2348\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6523 - val_loss: 9.1317\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5551 - val_loss: 9.1708\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5019 - val_loss: 9.1155\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3781 - val_loss: 9.1273\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5406 - val_loss: 9.1772\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5544 - val_loss: 8.9449\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5787 - val_loss: 8.9799\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5195 - val_loss: 8.8992\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4971 - val_loss: 9.3192\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3789 - val_loss: 9.7162\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6589 - val_loss: 9.1886\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5193 - val_loss: 9.2013\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4778 - val_loss: 9.2770\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4517 - val_loss: 9.3901\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4460 - val_loss: 9.4273\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5112 - val_loss: 9.2829\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5039 - val_loss: 8.9689\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6516 - val_loss: 9.0698\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5307 - val_loss: 9.2514\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8284 - val_loss: 9.3766\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7412 - val_loss: 9.2490\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5021 - val_loss: 9.1928\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4425 - val_loss: 9.0872\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4283 - val_loss: 9.3926\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4950 - val_loss: 9.2270\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.4580 - val_loss: 9.1717\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5008 - val_loss: 9.1506\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6019 - val_loss: 9.2340\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5078 - val_loss: 9.1953\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4310 - val_loss: 9.0840\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4682 - val_loss: 9.0929\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4573 - val_loss: 9.1437\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4311 - val_loss: 9.3606\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4053 - val_loss: 9.1678\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5954 - val_loss: 9.0054\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4676 - val_loss: 9.0352\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3955 - val_loss: 9.3051\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3944 - val_loss: 9.3084\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4571 - val_loss: 9.1154\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5385 - val_loss: 9.1520\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4406 - val_loss: 9.0069\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5361 - val_loss: 9.1378\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4517 - val_loss: 9.3291\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4508 - val_loss: 9.4208\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5920 - val_loss: 9.3853\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5477 - val_loss: 9.2350\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5402 - val_loss: 9.3039\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7440 - val_loss: 9.2531\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3858 - val_loss: 9.3212\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4942 - val_loss: 9.3167\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4395 - val_loss: 9.3421\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4612 - val_loss: 9.5328\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4809 - val_loss: 9.3354\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7824 - val_loss: 9.2165\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4411 - val_loss: 9.4942\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7979 - val_loss: 9.1662\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3764 - val_loss: 9.2531\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3970 - val_loss: 9.2972\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4655 - val_loss: 9.2055\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3807 - val_loss: 9.0776\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3942 - val_loss: 9.2176\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4496 - val_loss: 9.0918\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4080 - val_loss: 9.0297\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4174 - val_loss: 9.0620\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4921 - val_loss: 9.2474\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4621 - val_loss: 9.1450\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5012 - val_loss: 9.2165\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5192 - val_loss: 9.2003\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4418 - val_loss: 9.1422\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5041 - val_loss: 9.3829\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3803 - val_loss: 9.2101\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4313 - val_loss: 9.0781\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4531 - val_loss: 9.2197\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4511 - val_loss: 8.9539\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8434 - val_loss: 8.9642\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7095 - val_loss: 9.3171\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4692 - val_loss: 9.5747\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6543 - val_loss: 9.4699\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5166 - val_loss: 9.2774\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4413 - val_loss: 9.1953\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3881 - val_loss: 9.1579\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7077 - val_loss: 9.4404\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6010 - val_loss: 9.4176\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4519 - val_loss: 9.1978\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4839 - val_loss: 9.1945\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4995 - val_loss: 9.1950\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6406 - val_loss: 9.2828\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8902 - val_loss: 9.4341\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8463 - val_loss: 9.4063\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9216 - val_loss: 9.1814\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4417 - val_loss: 9.2865\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5896 - val_loss: 9.3816\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6388 - val_loss: 9.5267\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5130 - val_loss: 9.2457\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4238 - val_loss: 9.4835\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4114 - val_loss: 9.3296\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.5074 - val_loss: 9.1262\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5680 - val_loss: 9.2421\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5318 - val_loss: 9.3823\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5624 - val_loss: 9.3685\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5733 - val_loss: 9.3443\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4953 - val_loss: 9.2961\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.4872 - val_loss: 9.2205\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4755 - val_loss: 9.0641\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4843 - val_loss: 9.0578\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4604 - val_loss: 9.1502\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4437 - val_loss: 9.1433\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4489 - val_loss: 9.1882\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4715 - val_loss: 9.1027\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4683 - val_loss: 9.5024\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4201 - val_loss: 9.3643\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4150 - val_loss: 9.1600\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4382 - val_loss: 9.3236\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5215 - val_loss: 9.3984\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6113 - val_loss: 9.3564\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4292 - val_loss: 9.1896\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5274 - val_loss: 9.3925\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5298 - val_loss: 9.5213\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5195 - val_loss: 9.5214\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6945 - val_loss: 9.2524\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5470 - val_loss: 9.3219\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3700 - val_loss: 9.6332\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6060 - val_loss: 9.4245\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3913 - val_loss: 9.2808\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5277 - val_loss: 9.2475\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7786 - val_loss: 9.3605\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6485 - val_loss: 9.4841\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4519 - val_loss: 9.3372\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6160 - val_loss: 9.0985\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5656 - val_loss: 9.3429\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4841 - val_loss: 9.6756\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4053 - val_loss: 9.5974\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4520 - val_loss: 9.4343\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.5705 - val_loss: 9.4594\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4503 - val_loss: 9.2528\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5380 - val_loss: 9.3752\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8127 - val_loss: 9.2414\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7188 - val_loss: 9.3920\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6980 - val_loss: 9.4047\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5655 - val_loss: 9.5114\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3460 - val_loss: 9.6033\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4600 - val_loss: 9.2069\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3955 - val_loss: 9.5392\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5620 - val_loss: 9.3412\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3943 - val_loss: 9.2784\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3682 - val_loss: 9.3231\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5374 - val_loss: 9.3716\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3994 - val_loss: 9.3280\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5189 - val_loss: 9.3435\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4981 - val_loss: 9.3610\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4295 - val_loss: 9.4634\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4417 - val_loss: 9.4475\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4021 - val_loss: 9.1289\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3739 - val_loss: 9.1106\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4222 - val_loss: 9.2175\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4091 - val_loss: 9.6425\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4698 - val_loss: 9.2810\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4846 - val_loss: 9.3381\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4354 - val_loss: 9.3241\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5354 - val_loss: 9.1615\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4530 - val_loss: 9.3173\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4242 - val_loss: 9.4685\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4862 - val_loss: 9.3150\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6018 - val_loss: 9.4994\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3855 - val_loss: 9.4811\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5196 - val_loss: 9.4825\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4237 - val_loss: 9.1070\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7190 - val_loss: 9.4159\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6542 - val_loss: 9.3019\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3935 - val_loss: 9.2405\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3831 - val_loss: 9.1251\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4936 - val_loss: 9.2604\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7316 - val_loss: 9.3117\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3799 - val_loss: 9.2581\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5508 - val_loss: 9.2725\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.896 - 0s 106us/step - loss: 5.3830 - val_loss: 9.2579\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4199 - val_loss: 9.2959\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4929 - val_loss: 9.1642\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4813 - val_loss: 9.3857\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.4948 - val_loss: 9.3060\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3754 - val_loss: 9.3381\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4095 - val_loss: 9.1666\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5784 - val_loss: 9.1558\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4648 - val_loss: 9.3291\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3971 - val_loss: 9.4610\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4234 - val_loss: 9.4679\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3721 - val_loss: 9.4503\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4405 - val_loss: 9.5957\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3868 - val_loss: 9.4328\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3978 - val_loss: 9.2626\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4782 - val_loss: 9.4849\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5646 - val_loss: 9.3896\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4153 - val_loss: 9.6158\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4233 - val_loss: 9.4031\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3843 - val_loss: 9.3312\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5009 - val_loss: 9.3261\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4101 - val_loss: 9.6118\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3558 - val_loss: 9.4323\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4810 - val_loss: 9.5067\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5028 - val_loss: 9.4850\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6015 - val_loss: 9.3244\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4737 - val_loss: 8.9914\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4350 - val_loss: 9.2425\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4463 - val_loss: 9.3061\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5548 - val_loss: 9.1103\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5131 - val_loss: 9.3736\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.4401 - val_loss: 9.5979\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3973 - val_loss: 9.6054\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4943 - val_loss: 9.4229\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5537 - val_loss: 9.4299\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4844 - val_loss: 9.4896\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6272 - val_loss: 9.2481\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6811 - val_loss: 9.1550\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4035 - val_loss: 9.6517\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3712 - val_loss: 9.7874\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5761 - val_loss: 9.3658\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3209 - val_loss: 9.4037\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4468 - val_loss: 9.3173\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3401 - val_loss: 9.3757\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4399 - val_loss: 9.6945\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3609 - val_loss: 9.5913\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4680 - val_loss: 9.5854\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4345 - val_loss: 9.3980\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4394 - val_loss: 9.4211\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4086 - val_loss: 9.3726\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3191 - val_loss: 9.3755\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4152 - val_loss: 9.4123\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4947 - val_loss: 9.3913\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5089 - val_loss: 9.4409\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3989 - val_loss: 9.1935\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5255 - val_loss: 9.2923\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5793 - val_loss: 9.4240\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5981 - val_loss: 9.3805\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8079 - val_loss: 9.4020\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5643 - val_loss: 9.3751\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9553 - val_loss: 9.5228\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7713 - val_loss: 9.6033\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4858 - val_loss: 9.3671\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7349 - val_loss: 9.3113\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4489 - val_loss: 9.3285\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4157 - val_loss: 9.3964\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6041 - val_loss: 9.4220\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.826 - 0s 109us/step - loss: 5.5265 - val_loss: 9.5089\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5562 - val_loss: 9.4219\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3775 - val_loss: 9.3159\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4146 - val_loss: 9.3778\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6445 - val_loss: 9.2763\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5826 - val_loss: 9.3175\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5637 - val_loss: 9.5997\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6374 - val_loss: 9.6034\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8363 - val_loss: 9.4255\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5615 - val_loss: 9.6730\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8133 - val_loss: 9.5891\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7638 - val_loss: 9.2605\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6353 - val_loss: 9.6047\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4800 - val_loss: 9.5486\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 116us/step - loss: 5.4592 - val_loss: 9.8373\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4951 - val_loss: 9.7126\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9120 - val_loss: 9.3989\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9431 - val_loss: 9.4595\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3404 - val_loss: 9.6095\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7855 - val_loss: 9.4991\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4124 - val_loss: 9.5290\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3509 - val_loss: 9.6673\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4475 - val_loss: 9.4999\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3565 - val_loss: 9.3951\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4735 - val_loss: 9.3135\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8255 - val_loss: 9.5959\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8121 - val_loss: 9.6048\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4284 - val_loss: 9.3831\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5438 - val_loss: 9.3443\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3849 - val_loss: 9.3987\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4231 - val_loss: 9.2780\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4367 - val_loss: 9.5728\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4201 - val_loss: 9.4736\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4268 - val_loss: 9.5546\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5301 - val_loss: 9.3304\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4204 - val_loss: 9.2972\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4273 - val_loss: 9.4004\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3531 - val_loss: 9.6360\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4063 - val_loss: 9.5811\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5112 - val_loss: 9.4087\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4097 - val_loss: 9.6007\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5034 - val_loss: 9.5383\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3429 - val_loss: 9.3337\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4892 - val_loss: 9.4865\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4412 - val_loss: 9.2427\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5022 - val_loss: 9.4034\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4582 - val_loss: 9.3579\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4996 - val_loss: 9.5075\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5590 - val_loss: 9.6072\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6166 - val_loss: 9.9023\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7632 - val_loss: 9.8297\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6936 - val_loss: 9.7753\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5508 - val_loss: 9.5510\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4351 - val_loss: 9.4224\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3929 - val_loss: 9.3254\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4305 - val_loss: 9.4129\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6077 - val_loss: 9.4616\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4658 - val_loss: 9.3592\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4327 - val_loss: 9.4806\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3634 - val_loss: 9.5026\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3628 - val_loss: 9.4373\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4606 - val_loss: 9.5084\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5243 - val_loss: 9.4855\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4229 - val_loss: 9.3917\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4332 - val_loss: 9.3637\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4856 - val_loss: 9.8451\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3798 - val_loss: 9.7247\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3899 - val_loss: 9.7178\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3691 - val_loss: 9.6524\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3593 - val_loss: 9.4323\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3712 - val_loss: 9.5761\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4435 - val_loss: 9.3302\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4236 - val_loss: 9.2649\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4438 - val_loss: 9.3982\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4356 - val_loss: 9.4762\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4963 - val_loss: 9.3692\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4410 - val_loss: 9.5962\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4695 - val_loss: 9.4120\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4760 - val_loss: 9.4531\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3362 - val_loss: 9.8403\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7818 - val_loss: 9.6795\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6640 - val_loss: 9.6403\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4863 - val_loss: 9.5967\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5763 - val_loss: 9.4204\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3916 - val_loss: 9.6651\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4179 - val_loss: 9.6219\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5387 - val_loss: 9.3792\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7653 - val_loss: 9.4202\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4140 - val_loss: 9.3128\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4243 - val_loss: 9.2487\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3503 - val_loss: 9.5396\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8566 - val_loss: 9.8788\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4995 - val_loss: 9.5433\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3729 - val_loss: 9.4641\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3871 - val_loss: 9.6308\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3773 - val_loss: 9.5392\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4859 - val_loss: 9.3649\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3817 - val_loss: 9.3953\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4783 - val_loss: 9.4770\n",
      "9.071677515062236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.51874214,  3.8535974 ,  2.2751915 , -3.021215  , -0.7872916 ],\n",
       "        [-0.03733763, -2.429842  ,  1.5366368 , -0.89319515, -0.36674565],\n",
       "        [ 0.72795284, -0.3823999 , -0.28429425,  0.56650466,  0.16354705],\n",
       "        [ 0.35076463,  3.2556636 , -1.7930532 ,  0.9477738 ,  0.91726685],\n",
       "        [-0.7418415 , -0.17462517,  0.4575346 ,  0.18158932,  0.6567774 ],\n",
       "        [ 0.5216368 , -1.0902793 , -3.924542  , -1.4403158 ,  0.12760918],\n",
       "        [ 0.30621868, -0.32432774, -2.727077  ,  0.05527413, -1.8019938 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.45845428,  0.7437406 , -3.5960498 , -1.6679076 , -1.8046108 ],\n",
       "       dtype=float32),\n",
       " array([[-0.9705552 ,  0.02390792,  0.39458612, -0.19922191, -0.627256  ,\n",
       "          0.7761993 , -0.59901744,  0.26018935,  0.94620734,  0.16193284],\n",
       "        [-0.3873798 ,  1.4240611 , -0.36167154,  0.83230406, -1.1943715 ,\n",
       "          0.30226052, -0.6800488 ,  0.39711514,  0.8206726 ,  0.86138636],\n",
       "        [-0.86163485,  0.6835003 ,  0.42114133, -0.25590068, -0.21108955,\n",
       "          0.61894137, -0.265618  ,  0.17798421, -0.05680148, -0.0494564 ],\n",
       "        [-0.70189464,  1.0919403 , -0.42407718, -0.10095761, -0.12706782,\n",
       "          0.16615888, -0.15081859,  0.03609988,  1.324377  ,  0.90856516],\n",
       "        [-0.46096092,  0.8392747 , -0.12190958, -0.0445641 , -0.80212677,\n",
       "          0.33972222, -0.35970187,  0.1649581 ,  1.0862421 , -0.13890006]],\n",
       "       dtype=float32),\n",
       " array([ 1.6478864, -1.609617 ,  1.3986162, -1.2606282,  1.6449159,\n",
       "        -1.6069498,  1.6628163, -1.488437 , -1.6570271, -1.6653141],\n",
       "       dtype=float32),\n",
       " array([[ 1.3063625 ],\n",
       "        [-1.3172245 ],\n",
       "        [ 0.45279264],\n",
       "        [-0.43421265],\n",
       "        [ 1.0213089 ],\n",
       "        [-1.0468245 ],\n",
       "        [ 0.9906476 ],\n",
       "        [-0.5793056 ],\n",
       "        [-1.6082203 ],\n",
       "        [-1.1916894 ]], dtype=float32),\n",
       " array([1.6350075], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_2(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure2_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 866us/step - loss: 522.7149 - val_loss: 299.6850\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 150.9385 - val_loss: 64.7717\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 46.5155 - val_loss: 33.0592\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 27.5772 - val_loss: 22.0445\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.0707 - val_loss: 17.6128\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.0700 - val_loss: 14.3036\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 13.0134 - val_loss: 13.6868\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 11.6639 - val_loss: 13.3112\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.9011 - val_loss: 13.4037\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.6841 - val_loss: 13.2922\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.9507 - val_loss: 12.9486\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.6258 - val_loss: 13.0606\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.2831 - val_loss: 13.3552\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.4373 - val_loss: 12.9113\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9858 - val_loss: 13.1022\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.0911 - val_loss: 13.4404\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9641 - val_loss: 12.7183\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6552 - val_loss: 12.6145\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.6802 - val_loss: 13.0306\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7497 - val_loss: 12.7461\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4214 - val_loss: 12.5478\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3698 - val_loss: 12.5927\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2488 - val_loss: 12.6124\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1167 - val_loss: 12.7334\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1095 - val_loss: 12.5416\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1112 - val_loss: 12.4794\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9563 - val_loss: 12.4770\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9872 - val_loss: 12.1810\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0267 - val_loss: 12.4545\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9940 - val_loss: 12.2089\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1911 - val_loss: 12.2051\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7042 - val_loss: 11.8274\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6899 - val_loss: 11.9253\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2150 - val_loss: 11.8634\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8645 - val_loss: 11.5830\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9593 - val_loss: 11.4469\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5280 - val_loss: 11.4804\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5309 - val_loss: 11.3336\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6484 - val_loss: 11.4410\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9285 - val_loss: 11.5090\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7561 - val_loss: 11.2251\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5207 - val_loss: 11.2003\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6223 - val_loss: 11.1396\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7035 - val_loss: 11.4146\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5660 - val_loss: 10.6802\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5787 - val_loss: 10.9851\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3049 - val_loss: 10.8588\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2867 - val_loss: 11.1862\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5303 - val_loss: 10.8211\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2701 - val_loss: 10.7770\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5479 - val_loss: 10.8154\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2999 - val_loss: 10.7950\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2684 - val_loss: 10.6709\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2254 - val_loss: 10.7485\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.1830 - val_loss: 10.8096\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2529 - val_loss: 11.0317\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1531 - val_loss: 10.6801\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2908 - val_loss: 10.4599\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4583 - val_loss: 10.5820\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2754 - val_loss: 11.1062\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6238 - val_loss: 10.9725\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2936 - val_loss: 10.7050\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3346 - val_loss: 10.7026\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5497 - val_loss: 10.7031\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2526 - val_loss: 10.9102\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2857 - val_loss: 10.7302\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2619 - val_loss: 10.5562\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 7.1550 - val_loss: 10.5397\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2434 - val_loss: 10.6209\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0862 - val_loss: 10.4551\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1638 - val_loss: 10.6076\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0960 - val_loss: 10.8479\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0929 - val_loss: 10.5361\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1474 - val_loss: 10.5274\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2400 - val_loss: 10.4862\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.3418 - val_loss: 10.6198\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2714 - val_loss: 10.4419\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1374 - val_loss: 10.6474\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0407 - val_loss: 10.4143\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0545 - val_loss: 10.5740\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9849 - val_loss: 10.5082\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1243 - val_loss: 10.5250\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0289 - val_loss: 10.4462\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1059 - val_loss: 10.3218\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4779 - val_loss: 10.7722\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2760 - val_loss: 10.7429\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0344 - val_loss: 10.6472\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0005 - val_loss: 10.3748\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0602 - val_loss: 10.3287\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9904 - val_loss: 10.4236\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0201 - val_loss: 10.4248\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2260 - val_loss: 10.4962\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0999 - val_loss: 10.3825\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.9900 - val_loss: 10.5280\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0755 - val_loss: 10.4094\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2591 - val_loss: 10.4702\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1159 - val_loss: 10.1953\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9303 - val_loss: 10.5348\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9416 - val_loss: 10.4442\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0292 - val_loss: 10.2831\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2330 - val_loss: 10.2422\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9642 - val_loss: 10.1947\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2132 - val_loss: 10.1822\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0597 - val_loss: 10.9731\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1831 - val_loss: 10.5389\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0584 - val_loss: 10.5701\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9743 - val_loss: 10.2183\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1641 - val_loss: 10.3170\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4663 - val_loss: 10.4961\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2251 - val_loss: 10.3342\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1958 - val_loss: 10.4746\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9505 - val_loss: 10.1634\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9925 - val_loss: 10.4380\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3046 - val_loss: 10.4517\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9496 - val_loss: 10.6066\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1311 - val_loss: 10.5069\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9789 - val_loss: 10.1686\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3309 - val_loss: 10.6581\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2331 - val_loss: 10.2964\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0287 - val_loss: 9.9814\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0833 - val_loss: 10.1724\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5135 - val_loss: 10.3491\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5580 - val_loss: 10.5966\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1414 - val_loss: 10.4283\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9599 - val_loss: 10.6805\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8510 - val_loss: 10.6977\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7977 - val_loss: 10.5890\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0230 - val_loss: 10.4202\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9029 - val_loss: 10.0667\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8415 - val_loss: 10.3023\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8377 - val_loss: 9.9218\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.8148 - val_loss: 10.2786\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7456 - val_loss: 10.3489\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0152 - val_loss: 10.2796\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1362 - val_loss: 10.3268\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2856 - val_loss: 10.2033\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1541 - val_loss: 10.3705\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8858 - val_loss: 10.4010\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0111 - val_loss: 10.3968\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8933 - val_loss: 10.2658\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8916 - val_loss: 10.2672\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7361 - val_loss: 10.5223\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0214 - val_loss: 10.6054\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9493 - val_loss: 10.3920\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.9951 - val_loss: 10.5718\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6885 - val_loss: 10.2163\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9848 - val_loss: 9.9192\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8554 - val_loss: 10.1662\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8976 - val_loss: 10.3437\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8114 - val_loss: 10.1009\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9980 - val_loss: 10.2027\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0703 - val_loss: 10.4081\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9334 - val_loss: 10.3981\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7600 - val_loss: 10.5633\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0123 - val_loss: 10.2633\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7808 - val_loss: 10.3199\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8411 - val_loss: 10.5052\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7523 - val_loss: 10.1622\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7181 - val_loss: 10.2918\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6560 - val_loss: 10.1095\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6285 - val_loss: 10.0097\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7525 - val_loss: 10.1529\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8529 - val_loss: 10.2337\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6472 - val_loss: 10.1609\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8025 - val_loss: 10.6138\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9116 - val_loss: 10.1104\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9994 - val_loss: 10.4068\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9225 - val_loss: 10.1463\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1743 - val_loss: 10.0885\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0876 - val_loss: 10.4300\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7117 - val_loss: 10.2760\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7203 - val_loss: 10.6952\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8757 - val_loss: 10.3041\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7801 - val_loss: 10.1035\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.6525 - val_loss: 9.9214\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7374 - val_loss: 10.1927\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7343 - val_loss: 10.2501\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7537 - val_loss: 10.5042\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7388 - val_loss: 10.2340\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8089 - val_loss: 10.1556\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.5904 - val_loss: 10.1964\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5693 - val_loss: 10.3010\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.5543 - val_loss: 10.4133\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6413 - val_loss: 10.2121\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6152 - val_loss: 9.8963\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5855 - val_loss: 10.2159\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5615 - val_loss: 10.2302\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.5985 - val_loss: 10.2468\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5960 - val_loss: 10.2967\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5094 - val_loss: 10.5162\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7331 - val_loss: 10.4270\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6643 - val_loss: 10.2074\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5465 - val_loss: 10.2321\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5201 - val_loss: 10.4203\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5505 - val_loss: 10.1408\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5355 - val_loss: 10.1165\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5713 - val_loss: 10.4447\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6827 - val_loss: 10.3240\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8817 - val_loss: 10.6034\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9053 - val_loss: 10.3297\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5331 - val_loss: 10.2580\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5406 - val_loss: 10.0435\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5541 - val_loss: 10.7210\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9075 - val_loss: 10.5130\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8050 - val_loss: 10.4190\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5714 - val_loss: 10.4064\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4846 - val_loss: 10.4275\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6289 - val_loss: 10.3441\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5801 - val_loss: 10.2637\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5431 - val_loss: 9.9205\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5040 - val_loss: 9.8689\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5112 - val_loss: 10.4385\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4815 - val_loss: 10.4324\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5039 - val_loss: 10.5420\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5643 - val_loss: 10.1929\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7470 - val_loss: 10.5335\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3370 - val_loss: 10.7007\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5533 - val_loss: 10.5171\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5455 - val_loss: 10.2491\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4805 - val_loss: 10.2142\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8041 - val_loss: 10.3746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5857 - val_loss: 10.5778\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6163 - val_loss: 10.5271\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4110 - val_loss: 10.3229\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6768 - val_loss: 10.2312\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6259 - val_loss: 10.4473\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4179 - val_loss: 10.3329\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4982 - val_loss: 10.5446\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3923 - val_loss: 10.2992\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3428 - val_loss: 10.4352\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3750 - val_loss: 10.2199\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6632 - val_loss: 10.2721\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7996 - val_loss: 10.6509\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6893 - val_loss: 10.3751\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5021 - val_loss: 10.6883\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5062 - val_loss: 10.8604\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4209 - val_loss: 10.3529\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3531 - val_loss: 10.3279\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4431 - val_loss: 10.4652\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4169 - val_loss: 10.4999\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5379 - val_loss: 10.5644\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4917 - val_loss: 10.6462\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4044 - val_loss: 10.5723\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3572 - val_loss: 10.6126\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3799 - val_loss: 10.3373\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3613 - val_loss: 10.6073\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3003 - val_loss: 10.3774\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3048 - val_loss: 10.5993\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2645 - val_loss: 10.7070\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2713 - val_loss: 10.5379\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.3314 - val_loss: 10.5654\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2908 - val_loss: 10.5883\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3175 - val_loss: 10.5960\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3082 - val_loss: 10.3052\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1939 - val_loss: 10.5683\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3196 - val_loss: 10.6563\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1849 - val_loss: 10.7862\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2331 - val_loss: 10.7139\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4698 - val_loss: 10.5284\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1894 - val_loss: 10.4788\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2920 - val_loss: 10.4863\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4671 - val_loss: 11.3312\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4134 - val_loss: 10.7536\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3145 - val_loss: 10.6030\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1245 - val_loss: 10.7432\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2246 - val_loss: 10.9301\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2104 - val_loss: 10.7555\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4202 - val_loss: 10.7833\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3416 - val_loss: 11.0706\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1562 - val_loss: 10.7984\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1625 - val_loss: 10.7146\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1669 - val_loss: 10.6533\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0907 - val_loss: 10.6530\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2017 - val_loss: 10.8483\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3443 - val_loss: 10.5632\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0171 - val_loss: 10.5201\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2504 - val_loss: 10.5253\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2151 - val_loss: 10.5536\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9646 - val_loss: 10.6005\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0285 - val_loss: 10.1879\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0161 - val_loss: 10.5843\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9932 - val_loss: 10.7363\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9807 - val_loss: 10.6205\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9904 - val_loss: 10.7021\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1666 - val_loss: 10.3502\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1045 - val_loss: 10.7401\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0736 - val_loss: 10.7390\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9658 - val_loss: 10.4344\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9712 - val_loss: 10.3652\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9885 - val_loss: 10.5896\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9320 - val_loss: 10.7000\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0855 - val_loss: 10.6890\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0295 - val_loss: 10.2336\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9412 - val_loss: 10.3317\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2599 - val_loss: 10.7319\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0996 - val_loss: 10.4130\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8792 - val_loss: 10.7162\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0332 - val_loss: 10.5822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0989 - val_loss: 10.6600\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0224 - val_loss: 10.6070\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0425 - val_loss: 10.7331\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0014 - val_loss: 10.4868\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8269 - val_loss: 10.4385\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8879 - val_loss: 9.9182\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2364 - val_loss: 10.8245\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2154 - val_loss: 10.6327\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9610 - val_loss: 10.4052\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1568 - val_loss: 10.1623\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7957 - val_loss: 10.5560\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8574 - val_loss: 10.3549\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0875 - val_loss: 10.2981\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8483 - val_loss: 10.4142\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8383 - val_loss: 10.4237\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9183 - val_loss: 10.0228\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9097 - val_loss: 10.0785\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0068 - val_loss: 10.2768\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9098 - val_loss: 10.1324\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8151 - val_loss: 10.3271\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.9609 - val_loss: 10.0024\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8125 - val_loss: 10.1428\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8423 - val_loss: 10.3035\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0997 - val_loss: 10.0915\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9544 - val_loss: 9.8992\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8287 - val_loss: 10.2043\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2735 - val_loss: 10.1501\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8812 - val_loss: 10.0401\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7719 - val_loss: 10.2104\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9799 - val_loss: 9.9024\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9675 - val_loss: 10.5431\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0640 - val_loss: 10.3054\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8570 - val_loss: 9.9917\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7447 - val_loss: 10.0287\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8800 - val_loss: 10.1509\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8251 - val_loss: 10.0929\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9350 - val_loss: 10.1297\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0113 - val_loss: 9.8077\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8018 - val_loss: 9.9077\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.8087 - val_loss: 9.7460\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7474 - val_loss: 9.4470\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6716 - val_loss: 9.5941\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7487 - val_loss: 9.7881\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6982 - val_loss: 9.9448\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8406 - val_loss: 9.9643\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8366 - val_loss: 9.7326\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7447 - val_loss: 9.7997\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8209 - val_loss: 9.7041\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8192 - val_loss: 9.9333\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7192 - val_loss: 9.8832\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7322 - val_loss: 9.7666\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7649 - val_loss: 9.8267\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8023 - val_loss: 9.6463\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7714 - val_loss: 9.9342\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6993 - val_loss: 9.8741\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6778 - val_loss: 9.9503\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7282 - val_loss: 9.9322\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8588 - val_loss: 9.6667\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8250 - val_loss: 9.9299\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7229 - val_loss: 9.7580\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8145 - val_loss: 9.8180\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7537 - val_loss: 9.6864\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8269 - val_loss: 9.7907\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8021 - val_loss: 9.5795\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7493 - val_loss: 9.7057\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0990 - val_loss: 9.9811\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1358 - val_loss: 9.8360\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0313 - val_loss: 9.6277\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.9374 - val_loss: 10.1625\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6926 - val_loss: 9.4494\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8539 - val_loss: 9.8321\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7667 - val_loss: 9.5991\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6484 - val_loss: 9.7819\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7104 - val_loss: 9.8105\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 5.6941 - val_loss: 9.8571\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7254 - val_loss: 9.4044\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7110 - val_loss: 9.5917\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.7352 - val_loss: 9.6547\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6193 - val_loss: 9.5717\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7193 - val_loss: 9.5182\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7813 - val_loss: 9.5207\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8280 - val_loss: 9.7530\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8469 - val_loss: 9.6193\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9422 - val_loss: 9.6973\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6841 - val_loss: 9.4517\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7010 - val_loss: 9.5054\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7005 - val_loss: 9.5929\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9760 - val_loss: 9.6071\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6832 - val_loss: 9.6278\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6464 - val_loss: 9.4909\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8444 - val_loss: 9.5111\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7926 - val_loss: 9.4606\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6786 - val_loss: 9.3850\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6371 - val_loss: 9.4884\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1751 - val_loss: 9.7964\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9212 - val_loss: 9.8379\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7382 - val_loss: 9.7676\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8362 - val_loss: 9.8542\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7197 - val_loss: 9.3031\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6146 - val_loss: 9.3746\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8140 - val_loss: 9.8094\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8455 - val_loss: 9.7563\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6138 - val_loss: 9.7069\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6941 - val_loss: 9.7586\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6561 - val_loss: 9.5462\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6673 - val_loss: 9.5773\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8244 - val_loss: 9.8963\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2444 - val_loss: 10.1249\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0324 - val_loss: 9.7977\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4785 - val_loss: 9.8942\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8589 - val_loss: 9.8603\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6901 - val_loss: 9.8348\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6323 - val_loss: 9.3713\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8088 - val_loss: 9.2788\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6410 - val_loss: 9.4191\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6383 - val_loss: 9.5978\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7060 - val_loss: 9.7799\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6257 - val_loss: 9.7011\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6010 - val_loss: 9.6509\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8567 - val_loss: 9.7857\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0546 - val_loss: 9.8606\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8762 - val_loss: 9.9323\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8280 - val_loss: 9.5149\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6693 - val_loss: 9.5221\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7106 - val_loss: 9.5023\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6933 - val_loss: 9.6652\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6736 - val_loss: 9.5708\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6293 - val_loss: 9.3748\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6059 - val_loss: 9.3757\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5689 - val_loss: 9.6243\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6817 - val_loss: 9.7489\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7368 - val_loss: 9.7625\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6338 - val_loss: 9.7253\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6629 - val_loss: 9.6284\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6359 - val_loss: 9.3579\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5677 - val_loss: 9.5133\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5799 - val_loss: 9.5136\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5957 - val_loss: 9.6268\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6815 - val_loss: 9.2924\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9664 - val_loss: 9.8206\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2401 - val_loss: 9.7522\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6820 - val_loss: 9.8739\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7840 - val_loss: 9.7092\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6245 - val_loss: 9.6030\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5780 - val_loss: 9.2896\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5499 - val_loss: 9.4153\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5722 - val_loss: 9.7062\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6086 - val_loss: 9.6873\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9568 - val_loss: 9.6060\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0370 - val_loss: 10.1031\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8661 - val_loss: 9.4535\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5562 - val_loss: 9.4956\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5852 - val_loss: 9.5147\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5168 - val_loss: 9.6287\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.8242 - val_loss: 9.5507\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6328 - val_loss: 9.4659\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7239 - val_loss: 9.8562\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6558 - val_loss: 9.5508\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6959 - val_loss: 9.3975\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8168 - val_loss: 9.4381\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6072 - val_loss: 9.6243\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5938 - val_loss: 9.8504\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5112 - val_loss: 9.7561\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5556 - val_loss: 9.6374\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6281 - val_loss: 9.7365\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6639 - val_loss: 9.7410\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6472 - val_loss: 9.4382\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5905 - val_loss: 9.5832\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6138 - val_loss: 9.6664\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6326 - val_loss: 9.4554\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5683 - val_loss: 9.4717\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6576 - val_loss: 9.8058\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5291 - val_loss: 9.4243\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6243 - val_loss: 9.4835\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9704 - val_loss: 9.3508\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6404 - val_loss: 9.7982\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5866 - val_loss: 9.5404\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6179 - val_loss: 9.3209\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5763 - val_loss: 9.3474\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5511 - val_loss: 9.5898\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5156 - val_loss: 9.7776\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5874 - val_loss: 9.9093\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5320 - val_loss: 9.4149\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4953 - val_loss: 9.4331\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5656 - val_loss: 9.5253\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6135 - val_loss: 9.5394\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5820 - val_loss: 9.3818\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5510 - val_loss: 9.5407\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6430 - val_loss: 9.6177\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 5.6293 - val_loss: 9.5653\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9703 - val_loss: 9.8524\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8614 - val_loss: 9.7465\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5537 - val_loss: 9.6710\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7727 - val_loss: 9.8564\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6807 - val_loss: 9.3651\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5200 - val_loss: 9.6276\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4994 - val_loss: 9.7085\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5672 - val_loss: 9.8747\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7022 - val_loss: 9.4500\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7676 - val_loss: 9.5324\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6434 - val_loss: 9.7338\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5797 - val_loss: 9.6002\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5464 - val_loss: 9.7987\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6336 - val_loss: 9.4412\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6281 - val_loss: 9.4673\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4907 - val_loss: 9.7045\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5308 - val_loss: 9.7984\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6559 - val_loss: 9.9476\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6449 - val_loss: 9.5759\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7560 - val_loss: 9.6588\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5572 - val_loss: 9.4626\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8861 - val_loss: 10.0787\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7958 - val_loss: 9.7389\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5773 - val_loss: 9.9877\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4638 - val_loss: 9.9058\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4939 - val_loss: 9.7510\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9535 - val_loss: 9.7285\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0715 - val_loss: 9.7790\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6065 - val_loss: 9.4762\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5705 - val_loss: 9.7082\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4665 - val_loss: 9.5157\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4674 - val_loss: 9.5644\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5675 - val_loss: 9.4287\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4923 - val_loss: 9.7400\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4789 - val_loss: 9.7206\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4743 - val_loss: 9.4914\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5146 - val_loss: 9.5913\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5500 - val_loss: 9.7404\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5913 - val_loss: 9.8479\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5920 - val_loss: 9.8155\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5711 - val_loss: 9.6876\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 5.5760 - val_loss: 9.6344\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6385 - val_loss: 9.4302\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5383 - val_loss: 9.3053\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4722 - val_loss: 9.7071\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5642 - val_loss: 9.8669\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8368 - val_loss: 9.7892\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4851 - val_loss: 9.7139\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5910 - val_loss: 9.9320\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4596 - val_loss: 9.9746\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8851 - val_loss: 10.1929\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0452 - val_loss: 10.0592\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7814 - val_loss: 9.8244\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4461 - val_loss: 9.9241\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5798 - val_loss: 9.7705\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5191 - val_loss: 9.6174\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4686 - val_loss: 9.8168\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4222 - val_loss: 9.6851\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3837 - val_loss: 9.7986\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7127 - val_loss: 9.5236\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5733 - val_loss: 9.6631\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7373 - val_loss: 9.8052\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4964 - val_loss: 9.8537\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6809 - val_loss: 9.7645\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4488 - val_loss: 9.6936\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4607 - val_loss: 9.7499\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4257 - val_loss: 9.7914\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6415 - val_loss: 10.0956\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6298 - val_loss: 9.8115\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5788 - val_loss: 9.5439\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5300 - val_loss: 9.6595\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6205 - val_loss: 9.6765\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7218 - val_loss: 9.9238\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4880 - val_loss: 9.8445\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6741 - val_loss: 10.3332\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6810 - val_loss: 10.0464\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5855 - val_loss: 9.8122\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6328 - val_loss: 9.4426\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4389 - val_loss: 9.5603\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4250 - val_loss: 9.7484\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4366 - val_loss: 9.9598\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4776 - val_loss: 9.5391\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5525 - val_loss: 9.5866\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7342 - val_loss: 9.6167\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4754 - val_loss: 10.2166\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0745 - val_loss: 10.4402\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7776 - val_loss: 10.2225\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5863 - val_loss: 9.8967\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7063 - val_loss: 9.8397\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4463 - val_loss: 9.7842\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4386 - val_loss: 9.8084\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5164 - val_loss: 9.7248\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5286 - val_loss: 9.5139\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3998 - val_loss: 9.6610\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5336 - val_loss: 9.9505\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6468 - val_loss: 9.9811\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6505 - val_loss: 9.7127\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5170 - val_loss: 10.2926\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7341 - val_loss: 10.0434\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6023 - val_loss: 10.1518\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5109 - val_loss: 9.7923\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4904 - val_loss: 9.9661\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4181 - val_loss: 9.6713\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7085 - val_loss: 9.9348\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5929 - val_loss: 10.1157\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5956 - val_loss: 9.9712\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7156 - val_loss: 10.1534\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6490 - val_loss: 9.5599\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5211 - val_loss: 9.8577\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5558 - val_loss: 9.6316\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5506 - val_loss: 9.9383\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4702 - val_loss: 10.0746\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5251 - val_loss: 10.1199\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5941 - val_loss: 10.0896\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8675 - val_loss: 10.2086\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5402 - val_loss: 10.2173\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6687 - val_loss: 9.8986\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4121 - val_loss: 9.8005\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.4037 - val_loss: 10.0890\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3908 - val_loss: 9.9060\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4209 - val_loss: 9.9735\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5711 - val_loss: 9.6685\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4240 - val_loss: 9.8164\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5633 - val_loss: 10.0790\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4042 - val_loss: 10.0052\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5286 - val_loss: 10.0391\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4288 - val_loss: 10.0276\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4665 - val_loss: 9.9295\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4053 - val_loss: 9.9005\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5416 - val_loss: 10.0934\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7954 - val_loss: 10.0417\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6608 - val_loss: 9.7796\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5090 - val_loss: 9.9957\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5362 - val_loss: 9.7174\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4374 - val_loss: 10.3017\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4794 - val_loss: 9.8865\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5624 - val_loss: 9.8019\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4810 - val_loss: 9.9569\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4987 - val_loss: 9.7628\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5104 - val_loss: 10.0711\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3787 - val_loss: 9.8117\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4116 - val_loss: 10.0202\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5910 - val_loss: 9.7375\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4462 - val_loss: 9.8292\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4251 - val_loss: 9.9901\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4322 - val_loss: 10.2847\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5059 - val_loss: 10.3974\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.5147 - val_loss: 10.1686\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4364 - val_loss: 10.1323\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7378 - val_loss: 10.2680\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4623 - val_loss: 10.3937\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7202 - val_loss: 10.3761\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8359 - val_loss: 10.1873\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5324 - val_loss: 10.3548\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6110 - val_loss: 10.0289\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4367 - val_loss: 9.8381\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4180 - val_loss: 9.7438\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3738 - val_loss: 9.8456\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4272 - val_loss: 9.9432\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5465 - val_loss: 10.2506\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4213 - val_loss: 10.1129\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4818 - val_loss: 10.0009\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5922 - val_loss: 10.1595\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8097 - val_loss: 10.4146\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8729 - val_loss: 10.8512\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5761 - val_loss: 10.1032\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3871 - val_loss: 10.1179\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4275 - val_loss: 9.9574\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4236 - val_loss: 10.0690\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4495 - val_loss: 10.0851\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3489 - val_loss: 9.9811\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4084 - val_loss: 10.1463\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4324 - val_loss: 10.0986\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3193 - val_loss: 10.0769\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4609 - val_loss: 10.1158\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3556 - val_loss: 9.7641\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3503 - val_loss: 9.8468\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5096 - val_loss: 10.1013\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9242 - val_loss: 10.4726\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5755 - val_loss: 9.8228\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3531 - val_loss: 9.9915\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3517 - val_loss: 10.0347\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4499 - val_loss: 10.0854\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6221 - val_loss: 10.4300\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6211 - val_loss: 10.6943\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6015 - val_loss: 10.2596\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3944 - val_loss: 10.0271\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6046 - val_loss: 10.4801\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9178 - val_loss: 10.5690\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6344 - val_loss: 10.8690\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7837 - val_loss: 10.7778\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5069 - val_loss: 10.2706\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3714 - val_loss: 10.2446\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4122 - val_loss: 10.5659\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6851 - val_loss: 10.2707\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.4766 - val_loss: 9.9953\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3818 - val_loss: 10.1620\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4235 - val_loss: 10.3415\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4855 - val_loss: 9.8644\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5003 - val_loss: 10.5381\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4194 - val_loss: 9.8752\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3981 - val_loss: 10.0911\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4414 - val_loss: 9.9470\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3884 - val_loss: 10.2599\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7527 - val_loss: 10.2570\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3659 - val_loss: 10.3431\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4444 - val_loss: 10.3112\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3515 - val_loss: 10.5121\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5491 - val_loss: 10.3713\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3477 - val_loss: 10.2085\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5751 - val_loss: 10.3001\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4875 - val_loss: 10.0645\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4899 - val_loss: 10.3938\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3521 - val_loss: 10.3389\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3190 - val_loss: 10.0440\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4167 - val_loss: 10.1190\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3245 - val_loss: 10.3722\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2995 - val_loss: 10.5776\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7631 - val_loss: 10.6906\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4781 - val_loss: 10.8696\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0263 - val_loss: 10.8478\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4176 - val_loss: 10.5808\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4092 - val_loss: 10.6338\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5059 - val_loss: 10.4066\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0844 - val_loss: 10.5972\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5089 - val_loss: 10.2812\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6049 - val_loss: 10.3613\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3318 - val_loss: 10.3468\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4523 - val_loss: 10.2706\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4836 - val_loss: 10.1414\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4902 - val_loss: 9.9500\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4427 - val_loss: 10.1776\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3305 - val_loss: 10.2563\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3735 - val_loss: 10.3324\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5482 - val_loss: 10.4796\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5413 - val_loss: 10.9180\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6167 - val_loss: 10.6331\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4416 - val_loss: 10.1401\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2906 - val_loss: 10.1630\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3878 - val_loss: 10.1779\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3821 - val_loss: 10.2333\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5984 - val_loss: 10.4281\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4343 - val_loss: 10.3155\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4912 - val_loss: 10.1594\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5293 - val_loss: 10.2520\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3987 - val_loss: 10.3758\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4113 - val_loss: 10.4182\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3962 - val_loss: 10.4074\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5944 - val_loss: 10.2430\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9610 - val_loss: 10.8841\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5779 - val_loss: 10.4279\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7187 - val_loss: 10.8263\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7749 - val_loss: 10.4194\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6158 - val_loss: 10.1219\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2917 - val_loss: 10.0245\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2706 - val_loss: 10.1488\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6497 - val_loss: 10.5407\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3819 - val_loss: 10.3804\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6618 - val_loss: 10.1505\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4010 - val_loss: 10.5884\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5191 - val_loss: 10.5345\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5403 - val_loss: 10.7448\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3351 - val_loss: 10.5538\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3224 - val_loss: 10.1963\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3411 - val_loss: 10.1439\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3587 - val_loss: 10.4437\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5077 - val_loss: 10.6517\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6950 - val_loss: 10.6084\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9749 - val_loss: 10.4365\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6438 - val_loss: 10.7327\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6686 - val_loss: 10.4484\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4707 - val_loss: 10.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3149 - val_loss: 10.3283\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5837 - val_loss: 10.4213\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4685 - val_loss: 10.5751\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4592 - val_loss: 10.2879\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6201 - val_loss: 10.2664\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3736 - val_loss: 10.5161\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2951 - val_loss: 10.4458\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2519 - val_loss: 10.4169\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3442 - val_loss: 10.7246\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4507 - val_loss: 10.7447\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6387 - val_loss: 10.6067\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3254 - val_loss: 10.8128\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2924 - val_loss: 10.8655\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5102 - val_loss: 10.3436\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6390 - val_loss: 10.3295\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3934 - val_loss: 10.2730\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4951 - val_loss: 10.6580\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4126 - val_loss: 10.7092\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3333 - val_loss: 10.7641\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5772 - val_loss: 10.5765\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6730 - val_loss: 10.6171\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5357 - val_loss: 11.2948\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4717 - val_loss: 10.2238\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2956 - val_loss: 10.5131\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2913 - val_loss: 10.8957\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3468 - val_loss: 10.3981\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2805 - val_loss: 10.5601\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2875 - val_loss: 10.5110\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2511 - val_loss: 10.7823\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2752 - val_loss: 10.6391\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2859 - val_loss: 10.5229\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3871 - val_loss: 10.8375\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2158 - val_loss: 10.8400\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4250 - val_loss: 10.7331\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2791 - val_loss: 10.5829\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5573 - val_loss: 10.6355\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4736 - val_loss: 10.7504\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5154 - val_loss: 10.6909\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3929 - val_loss: 10.8369\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7023 - val_loss: 11.2107\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5639 - val_loss: 10.8553\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5068 - val_loss: 10.5508\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3879 - val_loss: 10.7446\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3895 - val_loss: 10.5733\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3710 - val_loss: 10.8060\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2986 - val_loss: 10.5308\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2484 - val_loss: 10.3012\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3207 - val_loss: 11.0328\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5733 - val_loss: 11.3889\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4570 - val_loss: 10.8788\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4798 - val_loss: 10.8412\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5105 - val_loss: 10.6288\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5414 - val_loss: 10.8672\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2302 - val_loss: 10.8846\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3357 - val_loss: 10.7407\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5346 - val_loss: 11.0769\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4280 - val_loss: 10.6480\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4379 - val_loss: 10.7919\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3586 - val_loss: 11.2991\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3944 - val_loss: 10.7297\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6384 - val_loss: 11.0370\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6440 - val_loss: 10.9812\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3872 - val_loss: 10.5774\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2513 - val_loss: 10.5359\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2529 - val_loss: 10.8833\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2604 - val_loss: 10.8808\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3103 - val_loss: 10.7227\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4014 - val_loss: 10.6206\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4064 - val_loss: 10.8500\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4773 - val_loss: 10.7705\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5806 - val_loss: 10.7364\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6239 - val_loss: 10.6181\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3816 - val_loss: 10.9670\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3824 - val_loss: 10.8918\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3004 - val_loss: 10.5673\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8080 - val_loss: 11.1742\n",
      "Epoch 837/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.8030 - val_loss: 10.9490\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4402 - val_loss: 11.2336\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5232 - val_loss: 11.1528\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6445 - val_loss: 10.5036\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3333 - val_loss: 10.9452\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4199 - val_loss: 11.0184\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3532 - val_loss: 11.1492\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2736 - val_loss: 10.5540\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3990 - val_loss: 10.5856\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3476 - val_loss: 10.8208\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4126 - val_loss: 10.7433\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2824 - val_loss: 10.9708\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6137 - val_loss: 11.0108\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2431 - val_loss: 10.7473\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3188 - val_loss: 11.0623\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3172 - val_loss: 10.8304\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3654 - val_loss: 10.6525\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4046 - val_loss: 10.6218\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3085 - val_loss: 10.4909\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3451 - val_loss: 11.0422\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2905 - val_loss: 10.8099\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4692 - val_loss: 10.7745\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2416 - val_loss: 11.3343\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2577 - val_loss: 10.9217\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4182 - val_loss: 10.8034\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3236 - val_loss: 10.9399\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4217 - val_loss: 10.9386\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3742 - val_loss: 10.9080\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2800 - val_loss: 11.1538\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3956 - val_loss: 10.9532\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4148 - val_loss: 10.9484\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3265 - val_loss: 10.9550\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4501 - val_loss: 10.8912\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4426 - val_loss: 11.2466\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4418 - val_loss: 10.8663\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3624 - val_loss: 10.7540\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2254 - val_loss: 10.7363\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2365 - val_loss: 10.6437\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2261 - val_loss: 10.8831\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3470 - val_loss: 10.7838\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3895 - val_loss: 11.0788\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4011 - val_loss: 10.9537\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2580 - val_loss: 10.8671\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2409 - val_loss: 11.0760\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2576 - val_loss: 10.7403\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2752 - val_loss: 11.0318\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3063 - val_loss: 10.9430\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3342 - val_loss: 11.4495\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2518 - val_loss: 11.0240\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2564 - val_loss: 11.0835\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2528 - val_loss: 10.7781\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1897 - val_loss: 10.8252\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2154 - val_loss: 11.0370\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3237 - val_loss: 10.9240\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1712 - val_loss: 10.9540\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3472 - val_loss: 10.7135\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2398 - val_loss: 10.9233\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4065 - val_loss: 10.6803\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2630 - val_loss: 11.0834\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3442 - val_loss: 11.0190\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2717 - val_loss: 11.3146\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3765 - val_loss: 11.1510\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4551 - val_loss: 10.8645\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3418 - val_loss: 11.0768\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2022 - val_loss: 11.1096\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2161 - val_loss: 11.2159\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4245 - val_loss: 11.4105\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2995 - val_loss: 10.7294\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2514 - val_loss: 10.9713\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5861 - val_loss: 11.2883\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6086 - val_loss: 11.4652\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7746 - val_loss: 11.1435\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4386 - val_loss: 10.7272\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.2033 - val_loss: 10.9274\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2290 - val_loss: 11.0074\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3071 - val_loss: 11.2792\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3430 - val_loss: 11.2163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2505 - val_loss: 10.7106\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4890 - val_loss: 11.1053\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3112 - val_loss: 11.1822\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2662 - val_loss: 11.4369\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2507 - val_loss: 11.3143\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3338 - val_loss: 10.9135\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4414 - val_loss: 11.2803\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2097 - val_loss: 11.0558\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2130 - val_loss: 11.2568\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3194 - val_loss: 11.4484\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3064 - val_loss: 11.1987\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3145 - val_loss: 11.2758\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3287 - val_loss: 11.7291\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3319 - val_loss: 11.1992\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3716 - val_loss: 11.2610\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5511 - val_loss: 11.2200\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5695 - val_loss: 11.4047\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3931 - val_loss: 10.7931\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2011 - val_loss: 11.5789\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2870 - val_loss: 11.5793\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2075 - val_loss: 11.3888\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4070 - val_loss: 11.0703\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4715 - val_loss: 11.1778\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.2792 - val_loss: 11.5198\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.2308 - val_loss: 11.3259\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5451 - val_loss: 12.1084\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5986 - val_loss: 11.8574\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9311 - val_loss: 11.9162\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8032 - val_loss: 11.4903\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4692 - val_loss: 11.3022\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5400 - val_loss: 11.3339\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5053 - val_loss: 11.3789\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4959 - val_loss: 11.1759\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2235 - val_loss: 11.5277\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2866 - val_loss: 11.2991\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1969 - val_loss: 11.3909\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2884 - val_loss: 11.3566\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3107 - val_loss: 11.2457\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2778 - val_loss: 11.5412\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2197 - val_loss: 11.1711\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2400 - val_loss: 11.3463\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2344 - val_loss: 11.0728\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2338 - val_loss: 11.3181\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2823 - val_loss: 11.4425\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6497 - val_loss: 12.2750\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7186 - val_loss: 11.5941\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1765 - val_loss: 11.2701\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2039 - val_loss: 11.0359\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2142 - val_loss: 10.9273\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2638 - val_loss: 11.1760\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2274 - val_loss: 11.3117\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1682 - val_loss: 11.0878\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2339 - val_loss: 11.2388\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1965 - val_loss: 10.7099\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2228 - val_loss: 11.0867\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2136 - val_loss: 11.2108\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4326 - val_loss: 11.5389\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3297 - val_loss: 11.4878\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4942 - val_loss: 11.8507\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3065 - val_loss: 11.3569\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5187 - val_loss: 11.2421\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2652 - val_loss: 11.3903\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3406 - val_loss: 11.3371\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3845 - val_loss: 11.2388\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5611 - val_loss: 11.4570\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2007 - val_loss: 11.2719\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3574 - val_loss: 11.7260\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4341 - val_loss: 11.2956\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2600 - val_loss: 11.6740\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2840 - val_loss: 11.2947\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2779 - val_loss: 11.7698\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5484 - val_loss: 12.0047\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9624 - val_loss: 12.8406\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0447 - val_loss: 12.1729\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0708 - val_loss: 12.0640\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3075 - val_loss: 12.6266\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5971 - val_loss: 11.9392\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6393 - val_loss: 11.5101\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7065 - val_loss: 11.5139\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7981 - val_loss: 11.2188\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2631 - val_loss: 11.3841\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2806 - val_loss: 11.4312\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2910 - val_loss: 11.3550\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1255 - val_loss: 11.2765\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4288 - val_loss: 11.2869\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2711 - val_loss: 11.6896\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1883 - val_loss: 11.8093\n",
      "7.813881558887029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 5.9947214 ,  2.1603937 ,  2.092438  , -1.7962257 ,  0.72769296],\n",
       "        [-4.15684   , -0.27200875, -2.4469073 ,  0.93143123, -0.10899017],\n",
       "        [ 1.9528196 , -0.5212081 ,  0.61850023, -1.4901567 , -0.40282857],\n",
       "        [ 2.7759283 , -0.08122619,  2.2482688 ,  1.2712804 , -0.27706063],\n",
       "        [ 0.47253838, -0.1181616 , -1.5084828 , -1.076795  , -0.86041474],\n",
       "        [-0.93567103,  0.43867385, -0.7143239 ,  0.450369  ,  0.21587536],\n",
       "        [-1.4327155 ,  0.1297445 , -0.38170317,  0.79186046,  2.6668472 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.7499155 ,  0.83572453, -2.5078278 , -0.88122225,  2.0698762 ],\n",
       "       dtype=float32),\n",
       " array([[-1.3948843 ,  0.4887941 ,  1.4077668 , -1.358068  ,  0.7383147 ,\n",
       "          0.60628116,  0.5940842 , -1.0893748 ,  1.2588139 , -0.15023941,\n",
       "          0.99476963, -1.3742934 , -0.8014059 , -0.30399513,  0.16127667],\n",
       "        [ 1.1718462 , -1.056107  , -1.1746718 ,  1.0774827 , -0.59184355,\n",
       "         -0.85332197, -0.35659194,  0.7208892 , -1.479712  , -0.004555  ,\n",
       "         -1.1531931 ,  0.892975  ,  1.0191249 ,  0.86207914,  0.01924719],\n",
       "        [-0.02573004,  0.54282415,  0.76486385, -0.76174   ,  0.02325133,\n",
       "          0.7289429 ,  0.44948336, -0.8466608 ,  0.69879735,  0.34717512,\n",
       "         -0.15558973,  0.13408375, -0.5600617 , -0.37062553, -0.4155427 ],\n",
       "        [-0.37993306,  0.36994642,  0.7310375 , -0.46284598, -0.07150028,\n",
       "         -0.11455588, -0.02412336, -0.7800407 ,  0.6805925 ,  0.14135285,\n",
       "          0.12829366, -0.5466564 ,  0.24972723,  0.18132122,  0.0348773 ],\n",
       "        [ 0.44152007, -0.09048633, -0.7283545 ,  0.5375455 , -0.16840066,\n",
       "         -0.3675105 ,  0.23041123,  0.22341105, -0.14860003, -0.41815385,\n",
       "         -0.15531111,  0.41424382,  0.30759636, -0.04559767,  0.11553551]],\n",
       "       dtype=float32),\n",
       " array([ 1.2018247 , -1.1259264 , -1.1939762 ,  1.2732935 , -0.66208774,\n",
       "        -1.1394581 , -1.0309596 ,  1.2212849 , -1.2804958 ,  0.48706296,\n",
       "        -1.2285887 ,  1.20849   ,  1.1374815 ,  0.9465166 , -0.446649  ],\n",
       "       dtype=float32),\n",
       " array([[ 9.5056647e-01],\n",
       "        [-7.1372139e-01],\n",
       "        [-9.4381183e-01],\n",
       "        [ 1.3043767e+00],\n",
       "        [-2.5525233e-01],\n",
       "        [-7.6758242e-01],\n",
       "        [-3.8572773e-01],\n",
       "        [ 9.6815497e-01],\n",
       "        [-1.4315336e+00],\n",
       "        [ 6.5936719e-04],\n",
       "        [-9.6423435e-01],\n",
       "        [ 9.4344985e-01],\n",
       "        [ 6.6583097e-01],\n",
       "        [ 3.7422758e-01],\n",
       "        [-8.3446112e-03]], dtype=float32),\n",
       " array([1.378225], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_3(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure3_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 987us/step - loss: 499.1862 - val_loss: 291.8726\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 180.4238 - val_loss: 73.8575\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 49.2872 - val_loss: 33.1305\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 25.1616 - val_loss: 23.6372\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 20.4418 - val_loss: 21.9915\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 18.8289 - val_loss: 21.1679\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 16.7952 - val_loss: 20.3107\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 15.2894 - val_loss: 19.5609\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 13.7276 - val_loss: 18.6788\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.7082 - val_loss: 17.9763\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.1315 - val_loss: 17.4517\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.0099 - val_loss: 17.5072\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.3019 - val_loss: 17.3911\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.2135 - val_loss: 16.8898\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.9829 - val_loss: 15.7390\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.3301 - val_loss: 15.3743\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.6375 - val_loss: 14.0591\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.3188 - val_loss: 13.5885\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7788 - val_loss: 12.9535\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.4196 - val_loss: 12.1722\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.3868 - val_loss: 11.5879\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1312 - val_loss: 11.1325\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3625 - val_loss: 11.0934\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3880 - val_loss: 11.0462\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8543 - val_loss: 11.2607\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7329 - val_loss: 10.8666\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3004 - val_loss: 10.2680\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3071 - val_loss: 9.9802\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2987 - val_loss: 9.7069\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3004 - val_loss: 10.0390\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2272 - val_loss: 9.9542\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1474 - val_loss: 9.8388\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9675 - val_loss: 9.8800\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0350 - val_loss: 9.6234\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1094 - val_loss: 9.7407\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2860 - val_loss: 9.8939\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9710 - val_loss: 9.4136\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1678 - val_loss: 9.4277\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7113 - val_loss: 9.6291\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7706 - val_loss: 9.2846\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7882 - val_loss: 9.4607\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5686 - val_loss: 9.4058\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8751 - val_loss: 9.4139\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7797 - val_loss: 9.6258\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6752 - val_loss: 9.5392\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5572 - val_loss: 9.3853\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5657 - val_loss: 8.9812\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5439 - val_loss: 9.2227\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6442 - val_loss: 9.3408\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6680 - val_loss: 9.0986\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5380 - val_loss: 8.9100\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6390 - val_loss: 8.8672\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7186 - val_loss: 9.1026\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9717 - val_loss: 9.4156\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7229 - val_loss: 9.3546\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4864 - val_loss: 9.1636\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3842 - val_loss: 9.0642\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8147 - val_loss: 8.8287\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8514 - val_loss: 9.0476\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5162 - val_loss: 8.9936\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4616 - val_loss: 9.0075\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1509 - val_loss: 9.0411\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3927 - val_loss: 8.9220\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2999 - val_loss: 8.8705\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3375 - val_loss: 8.7413\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3650 - val_loss: 8.4858\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2263 - val_loss: 8.8856\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.3382 - val_loss: 8.6799\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2357 - val_loss: 8.5183\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1543 - val_loss: 8.4019\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2414 - val_loss: 8.6572\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5672 - val_loss: 8.8749\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2446 - val_loss: 8.8955\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1644 - val_loss: 8.7319\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2062 - val_loss: 8.1324\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3106 - val_loss: 8.2925\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5828 - val_loss: 8.7402\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4834 - val_loss: 8.7352\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2058 - val_loss: 8.7774\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5569 - val_loss: 8.9305\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1284 - val_loss: 8.5812\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2632 - val_loss: 8.6399\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9634 - val_loss: 8.6344\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9973 - val_loss: 8.3849\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9334 - val_loss: 8.8034\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0401 - val_loss: 8.5347\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9816 - val_loss: 8.6120\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1089 - val_loss: 8.3394\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0013 - val_loss: 8.4704\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0590 - val_loss: 8.6441\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9606 - val_loss: 8.6326\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0656 - val_loss: 8.5257\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5773 - val_loss: 8.7917\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0326 - val_loss: 8.4365\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9774 - val_loss: 8.3741\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2082 - val_loss: 8.9002\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2874 - val_loss: 8.3935\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0586 - val_loss: 8.6496\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1280 - val_loss: 8.4652\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9413 - val_loss: 8.7378\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9688 - val_loss: 8.4950\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7821 - val_loss: 8.5319\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9879 - val_loss: 8.3929\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7642 - val_loss: 8.6913\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9008 - val_loss: 8.6986\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8101 - val_loss: 8.6114\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8237 - val_loss: 8.3856\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8341 - val_loss: 8.5903\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7011 - val_loss: 8.5890\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7863 - val_loss: 8.7054\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6602 - val_loss: 8.4933\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9285 - val_loss: 8.6906\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7479 - val_loss: 8.3319\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7661 - val_loss: 8.3728\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6701 - val_loss: 8.7507\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6435 - val_loss: 8.6629\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9168 - val_loss: 8.7594\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2336 - val_loss: 9.0669\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8284 - val_loss: 8.5891\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.7488 - val_loss: 8.4875\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5814 - val_loss: 8.5326\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6529 - val_loss: 8.5884\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5788 - val_loss: 8.5671\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6441 - val_loss: 8.6524\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6333 - val_loss: 8.5331\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7003 - val_loss: 8.4425\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6262 - val_loss: 8.6995\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7009 - val_loss: 8.9260\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5844 - val_loss: 8.9085\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5225 - val_loss: 8.7505\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6110 - val_loss: 8.5753\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5447 - val_loss: 8.9797\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8231 - val_loss: 8.7519\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8399 - val_loss: 8.9909\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8491 - val_loss: 8.7229\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4935 - val_loss: 8.8083\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0454 - val_loss: 8.2922\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5894 - val_loss: 8.8688\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7386 - val_loss: 8.9237\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5766 - val_loss: 8.4599\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7249 - val_loss: 8.7138\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6070 - val_loss: 8.9488\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4926 - val_loss: 9.0866\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4956 - val_loss: 8.6133\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4509 - val_loss: 8.4832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4266 - val_loss: 8.5885\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4353 - val_loss: 8.3063\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6293 - val_loss: 8.9246\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5730 - val_loss: 9.3827\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6520 - val_loss: 8.6697\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3492 - val_loss: 8.9056\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4222 - val_loss: 8.6946\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5235 - val_loss: 9.0524\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3422 - val_loss: 9.0114\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5560 - val_loss: 9.0218\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4178 - val_loss: 8.6192\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4695 - val_loss: 8.6809\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4423 - val_loss: 8.8374\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6418 - val_loss: 8.8112\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4213 - val_loss: 9.9511\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1272 - val_loss: 9.2721\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2953 - val_loss: 9.1002\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6968 - val_loss: 8.9932\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4714 - val_loss: 9.6793\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6232 - val_loss: 8.8926\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5419 - val_loss: 8.7232\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3412 - val_loss: 9.0058\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2901 - val_loss: 8.8891\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3095 - val_loss: 9.3439\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2618 - val_loss: 9.1037\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5294 - val_loss: 9.1016\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7939 - val_loss: 8.5323\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4053 - val_loss: 9.1747\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2340 - val_loss: 8.8273\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2731 - val_loss: 8.8875\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2008 - val_loss: 8.8866\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3422 - val_loss: 8.9488\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4532 - val_loss: 8.9107\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2990 - val_loss: 8.8355\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.6378 - val_loss: 8.7430\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2273 - val_loss: 8.8639\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5744 - val_loss: 8.8288\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9612 - val_loss: 9.5972\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5743 - val_loss: 8.7862\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4023 - val_loss: 8.9499\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2431 - val_loss: 8.5729\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2012 - val_loss: 8.9572\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3379 - val_loss: 8.9329\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7419 - val_loss: 9.2794\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6217 - val_loss: 8.9389\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3662 - val_loss: 8.7944\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1452 - val_loss: 8.8515\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1064 - val_loss: 8.8465\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1366 - val_loss: 9.0221\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1316 - val_loss: 9.0802\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1144 - val_loss: 8.7476\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2212 - val_loss: 8.7336\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1888 - val_loss: 8.9426\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1267 - val_loss: 8.9317\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1097 - val_loss: 8.8856\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1068 - val_loss: 8.8240\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1042 - val_loss: 8.8031\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1660 - val_loss: 8.9380\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2276 - val_loss: 9.2430\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1224 - val_loss: 8.9417\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1376 - val_loss: 8.6986\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2181 - val_loss: 8.9526\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1598 - val_loss: 8.9118\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1526 - val_loss: 9.3252\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1479 - val_loss: 8.9512\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1263 - val_loss: 8.9625\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1991 - val_loss: 9.0648\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1775 - val_loss: 9.1700\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3416 - val_loss: 8.8620\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0303 - val_loss: 9.0542\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9932 - val_loss: 8.7679\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1191 - val_loss: 8.8549\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0644 - val_loss: 8.7759\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0319 - val_loss: 8.7803\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0584 - val_loss: 8.8406\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1215 - val_loss: 9.0421\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0070 - val_loss: 8.8517\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.9829 - val_loss: 8.7864\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0228 - val_loss: 9.1049\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1322 - val_loss: 8.9393\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0788 - val_loss: 9.2063\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0616 - val_loss: 8.8921\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0110 - val_loss: 8.8232\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0983 - val_loss: 8.7058\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1783 - val_loss: 9.0473\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2809 - val_loss: 8.9344\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0422 - val_loss: 8.9618\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0367 - val_loss: 8.9283\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0705 - val_loss: 9.0111\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0216 - val_loss: 8.8715\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8984 - val_loss: 9.1382\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9651 - val_loss: 8.6647\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0068 - val_loss: 9.2508\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1814 - val_loss: 8.6914\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1069 - val_loss: 9.1687\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0775 - val_loss: 8.8819\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9973 - val_loss: 9.2146\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0476 - val_loss: 8.7685\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0110 - val_loss: 8.8875\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9759 - val_loss: 9.1571\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9632 - val_loss: 8.9218\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0439 - val_loss: 9.1064\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9764 - val_loss: 9.2131\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0029 - val_loss: 8.8660\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9640 - val_loss: 8.9096\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1951 - val_loss: 9.6127\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4456 - val_loss: 9.1584\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9802 - val_loss: 9.2657\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0171 - val_loss: 9.0694\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1112 - val_loss: 9.0211\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2013 - val_loss: 9.8844\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1551 - val_loss: 8.8129\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9410 - val_loss: 9.2120\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1887 - val_loss: 9.2865\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9521 - val_loss: 9.0787\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8806 - val_loss: 8.8855\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9192 - val_loss: 9.0394\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9380 - val_loss: 8.8812\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8711 - val_loss: 9.1446\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8940 - val_loss: 9.1829\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1477 - val_loss: 8.8407\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1307 - val_loss: 9.0484\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0665 - val_loss: 9.0975\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0268 - val_loss: 8.9941\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0693 - val_loss: 8.8930\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3523 - val_loss: 9.4679\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1753 - val_loss: 9.0582\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9390 - val_loss: 9.1384\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8217 - val_loss: 8.9985\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8983 - val_loss: 9.0382\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8804 - val_loss: 9.2922\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0549 - val_loss: 9.1810\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8912 - val_loss: 9.0838\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9207 - val_loss: 9.0094\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8679 - val_loss: 8.8343\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1560 - val_loss: 9.5107\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4665 - val_loss: 8.8572\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0735 - val_loss: 9.1475\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8673 - val_loss: 9.0845\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9890 - val_loss: 9.4550\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8611 - val_loss: 9.2005\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9065 - val_loss: 8.9424\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9641 - val_loss: 9.0196\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8365 - val_loss: 9.0503\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8172 - val_loss: 9.1300\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0020 - val_loss: 9.0090\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8404 - val_loss: 8.9302\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8375 - val_loss: 9.1239\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9329 - val_loss: 9.0250\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9729 - val_loss: 9.2008\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7929 - val_loss: 9.0754\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8630 - val_loss: 8.8740\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9872 - val_loss: 9.0279\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0626 - val_loss: 9.0876\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 4.9565 - val_loss: 9.4080\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9179 - val_loss: 9.0772\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7902 - val_loss: 9.2181\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7427 - val_loss: 9.0220\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8160 - val_loss: 9.0257\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7418 - val_loss: 9.0126\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7636 - val_loss: 8.9607\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7473 - val_loss: 9.1022\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8710 - val_loss: 9.0014\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0316 - val_loss: 9.2157\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8973 - val_loss: 9.4978\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8770 - val_loss: 9.1324\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7695 - val_loss: 9.2022\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7288 - val_loss: 9.2333\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9602 - val_loss: 9.8801\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7779 - val_loss: 8.9943\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9613 - val_loss: 9.1577\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7604 - val_loss: 9.0624\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8806 - val_loss: 9.4115\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7985 - val_loss: 9.2612\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8661 - val_loss: 9.3423\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7333 - val_loss: 9.1348\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7233 - val_loss: 8.7556\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8835 - val_loss: 8.9588\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8087 - val_loss: 9.1965\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7801 - val_loss: 9.0882\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1585 - val_loss: 9.9985\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8508 - val_loss: 8.9612\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0030 - val_loss: 9.4931\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7398 - val_loss: 8.9708\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8483 - val_loss: 9.1103\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7487 - val_loss: 9.0542\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6851 - val_loss: 8.9459\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6838 - val_loss: 9.3054\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8485 - val_loss: 9.1887\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6548 - val_loss: 9.2622\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7578 - val_loss: 9.3596\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7388 - val_loss: 8.9900\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6743 - val_loss: 9.0339\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7039 - val_loss: 8.8947\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7916 - val_loss: 9.2337\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8839 - val_loss: 9.0445\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9712 - val_loss: 8.9168\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8794 - val_loss: 9.3184\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2113 - val_loss: 8.9604\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9715 - val_loss: 9.6201\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7427 - val_loss: 9.4598\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8732 - val_loss: 9.2501\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5928 - val_loss: 8.8535\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8693 - val_loss: 10.1027\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1173 - val_loss: 9.4027\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8174 - val_loss: 9.6374\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1056 - val_loss: 9.1580\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0193 - val_loss: 9.7039\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8622 - val_loss: 9.1967\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9325 - val_loss: 9.1178\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7478 - val_loss: 9.3383\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7269 - val_loss: 8.9110\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6455 - val_loss: 9.0219\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6449 - val_loss: 9.2599\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.6469 - val_loss: 9.1489\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6812 - val_loss: 8.8765\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6027 - val_loss: 9.0560\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7977 - val_loss: 9.3136\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6076 - val_loss: 9.0828\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5995 - val_loss: 9.1048\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.5902 - val_loss: 9.0669\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6610 - val_loss: 8.9987\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7132 - val_loss: 9.3137\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8129 - val_loss: 8.7940\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7744 - val_loss: 8.8999\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8661 - val_loss: 9.5251\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8306 - val_loss: 8.9966\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6795 - val_loss: 9.3567\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0305 - val_loss: 9.2494\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8549 - val_loss: 8.8539\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6706 - val_loss: 9.2115\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.6357 - val_loss: 8.9246\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5993 - val_loss: 8.9904\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5768 - val_loss: 9.0459\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6835 - val_loss: 8.8723\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6285 - val_loss: 9.1994\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7015 - val_loss: 9.0542\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7587 - val_loss: 9.3538\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6918 - val_loss: 9.1146\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5482 - val_loss: 8.7836\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5176 - val_loss: 8.8875\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5694 - val_loss: 8.9290\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5848 - val_loss: 9.3355\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5666 - val_loss: 8.9269\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5312 - val_loss: 8.9835\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5178 - val_loss: 9.0438\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4743 - val_loss: 8.9167\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6493 - val_loss: 9.1048\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8050 - val_loss: 8.9528\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6468 - val_loss: 9.0968\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8620 - val_loss: 9.4753\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8821 - val_loss: 8.9379\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6043 - val_loss: 9.1596\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5564 - val_loss: 8.7839\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6498 - val_loss: 9.2257\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6322 - val_loss: 9.2108\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5087 - val_loss: 8.8445\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4728 - val_loss: 8.8669\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5619 - val_loss: 8.9061\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5206 - val_loss: 9.2352\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4803 - val_loss: 9.0683\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5645 - val_loss: 9.0710\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0053 - val_loss: 10.0446\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6561 - val_loss: 9.4870\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3161 - val_loss: 9.6631\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8335 - val_loss: 9.4450\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5984 - val_loss: 9.0822\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4876 - val_loss: 8.9659\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5820 - val_loss: 9.3414\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6618 - val_loss: 8.9521\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6133 - val_loss: 9.1572\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4072 - val_loss: 9.0371\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7745 - val_loss: 9.5191\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7846 - val_loss: 8.7825\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8303 - val_loss: 8.8444\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8321 - val_loss: 9.2895\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7083 - val_loss: 8.9104\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4731 - val_loss: 8.7938\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8113 - val_loss: 9.7694\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3089 - val_loss: 8.9113\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6171 - val_loss: 9.1641\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6993 - val_loss: 8.9686\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6365 - val_loss: 9.7620\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5947 - val_loss: 8.8549\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4798 - val_loss: 9.2464\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5315 - val_loss: 8.9492\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4341 - val_loss: 9.0026\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4856 - val_loss: 8.8894\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4184 - val_loss: 8.9058\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4248 - val_loss: 8.8763\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4051 - val_loss: 8.8701\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4944 - val_loss: 9.0099\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.5199 - val_loss: 8.9064\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4514 - val_loss: 9.0250\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4330 - val_loss: 8.8410\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4100 - val_loss: 8.8706\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3967 - val_loss: 9.1281\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4429 - val_loss: 8.9572\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.4359 - val_loss: 8.8599\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5437 - val_loss: 9.0959\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3996 - val_loss: 8.8818\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4073 - val_loss: 8.5855\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5646 - val_loss: 9.5957\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7847 - val_loss: 8.7909\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5993 - val_loss: 8.8115\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3947 - val_loss: 8.7658\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6122 - val_loss: 8.6961\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4100 - val_loss: 8.7204\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.3475 - val_loss: 9.2600\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5433 - val_loss: 8.7060\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4311 - val_loss: 9.0353\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3169 - val_loss: 8.6574\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4024 - val_loss: 8.9265\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3324 - val_loss: 8.6349\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3709 - val_loss: 8.8722\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2979 - val_loss: 8.8706\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3064 - val_loss: 8.6966\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5663 - val_loss: 8.6087\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4067 - val_loss: 8.9224\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5072 - val_loss: 8.5111\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2999 - val_loss: 8.8374\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3885 - val_loss: 8.5605\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2584 - val_loss: 8.6562\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3782 - val_loss: 9.7067\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7077 - val_loss: 8.9859\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4326 - val_loss: 9.1463\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3691 - val_loss: 8.6361\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.407 - 0s 109us/step - loss: 4.2909 - val_loss: 8.8576\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3495 - val_loss: 8.5957\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3263 - val_loss: 8.6222\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3458 - val_loss: 8.7541\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2523 - val_loss: 8.9219\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2894 - val_loss: 8.4403\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5675 - val_loss: 8.6511\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2465 - val_loss: 8.4086\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2917 - val_loss: 8.5306\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2573 - val_loss: 8.4771\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1905 - val_loss: 8.7413\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2586 - val_loss: 8.3125\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6210 - val_loss: 9.4342\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9878 - val_loss: 8.1943\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4304 - val_loss: 8.3855\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2550 - val_loss: 8.6761\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3584 - val_loss: 8.3714\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7723 - val_loss: 9.2471\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4369 - val_loss: 8.4910\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3649 - val_loss: 8.4067\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2589 - val_loss: 8.5737\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1810 - val_loss: 8.4688\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4508 - val_loss: 8.5936\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5250 - val_loss: 8.4546\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3925 - val_loss: 8.4022\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2661 - val_loss: 8.5228\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1952 - val_loss: 8.3350\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2468 - val_loss: 8.1963\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4817 - val_loss: 9.1804\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9235 - val_loss: 8.6419\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7133 - val_loss: 9.7179\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7404 - val_loss: 8.2950\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3433 - val_loss: 8.7253\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4188 - val_loss: 8.5687\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6601 - val_loss: 8.3560\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5309 - val_loss: 8.8937\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4082 - val_loss: 8.1610\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3374 - val_loss: 8.2971\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1344 - val_loss: 8.3083\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1184 - val_loss: 8.9086\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4558 - val_loss: 8.6851\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4733 - val_loss: 8.0047\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3235 - val_loss: 8.4070\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2959 - val_loss: 8.2702\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2129 - val_loss: 8.5008\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4867 - val_loss: 8.1692\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2828 - val_loss: 8.8455\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2568 - val_loss: 8.0477\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1187 - val_loss: 8.7934\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1286 - val_loss: 8.0141\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4773 - val_loss: 9.1274\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3719 - val_loss: 8.1094\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2744 - val_loss: 8.5913\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5173 - val_loss: 8.6485\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2235 - val_loss: 8.5038\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2323 - val_loss: 8.4631\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1188 - val_loss: 8.1602\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4669 - val_loss: 8.0283\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.2169 - val_loss: 8.1374\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0991 - val_loss: 8.2682\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1656 - val_loss: 8.2510\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0839 - val_loss: 8.3875\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0661 - val_loss: 7.8916\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3649 - val_loss: 8.3196\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0194 - val_loss: 7.8242\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0397 - val_loss: 8.3366\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2489 - val_loss: 8.0989\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5973 - val_loss: 9.2696\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4005 - val_loss: 8.1167\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0630 - val_loss: 8.2508\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0436 - val_loss: 7.8918\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2231 - val_loss: 8.4204\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1040 - val_loss: 8.2571\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1294 - val_loss: 8.1220\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2633 - val_loss: 8.1291\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3061 - val_loss: 8.5642\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2420 - val_loss: 8.3648\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0249 - val_loss: 8.1554\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0251 - val_loss: 8.1506\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0259 - val_loss: 8.1639\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0301 - val_loss: 7.9118\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0614 - val_loss: 8.3735\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0761 - val_loss: 7.9045\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3395 - val_loss: 8.9425\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1380 - val_loss: 7.9252\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0542 - val_loss: 8.1500\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0581 - val_loss: 7.9681\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2012 - val_loss: 8.5577\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0926 - val_loss: 7.7821\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0401 - val_loss: 8.3389\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0702 - val_loss: 7.8852\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0009 - val_loss: 7.9669\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0873 - val_loss: 8.4214\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1344 - val_loss: 8.1811\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0157 - val_loss: 8.3019\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0874 - val_loss: 8.0199\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0536 - val_loss: 8.1328\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9609 - val_loss: 7.9807\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1111 - val_loss: 8.1441\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0330 - val_loss: 8.1512\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9334 - val_loss: 7.8956\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9462 - val_loss: 7.9131\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9614 - val_loss: 7.8258\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2564 - val_loss: 8.5195\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3671 - val_loss: 8.2302\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3087 - val_loss: 7.9024\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4922 - val_loss: 8.3975\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1094 - val_loss: 8.1507\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3017 - val_loss: 8.3462\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.384 - 0s 109us/step - loss: 4.0962 - val_loss: 8.0968\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1804 - val_loss: 7.7352\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3597 - val_loss: 8.3979\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2400 - val_loss: 8.1206\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4281 - val_loss: 8.7761\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9591 - val_loss: 8.0343\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9838 - val_loss: 8.3448\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0597 - val_loss: 8.0991\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9938 - val_loss: 8.4203\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9224 - val_loss: 7.9373\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9884 - val_loss: 8.4770\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1971 - val_loss: 7.9316\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0494 - val_loss: 8.0800\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1325 - val_loss: 7.9984\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0351 - val_loss: 8.1044\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8968 - val_loss: 7.8654\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1856 - val_loss: 8.3109\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9735 - val_loss: 7.8952\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0288 - val_loss: 8.5462\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1594 - val_loss: 7.8488\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9521 - val_loss: 8.0114\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9866 - val_loss: 7.8403\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9779 - val_loss: 7.8902\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9264 - val_loss: 7.8421\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9519 - val_loss: 8.4601\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9859 - val_loss: 7.8954\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.9703 - val_loss: 7.9224\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8759 - val_loss: 8.0659\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9075 - val_loss: 8.0583\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9128 - val_loss: 7.9851\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9671 - val_loss: 8.2320\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9854 - val_loss: 7.8547\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8866 - val_loss: 8.2417\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0908 - val_loss: 7.7698\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9762 - val_loss: 8.7497\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2690 - val_loss: 7.9892\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2863 - val_loss: 8.3186\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2658 - val_loss: 8.3414\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1883 - val_loss: 7.9844\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2391 - val_loss: 9.2627\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0857 - val_loss: 8.0235\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9833 - val_loss: 8.5738\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9874 - val_loss: 8.1578\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0668 - val_loss: 9.1289\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3756 - val_loss: 7.9755\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9403 - val_loss: 7.9820\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9318 - val_loss: 8.4067\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2252 - val_loss: 7.5042\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9237 - val_loss: 9.0381\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2247 - val_loss: 7.8376\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9697 - val_loss: 8.0431\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4199 - val_loss: 8.9326\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.1258 - val_loss: 8.2145\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1924 - val_loss: 8.9832\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2476 - val_loss: 7.5499\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9351 - val_loss: 9.2685\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2059 - val_loss: 7.9728\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1368 - val_loss: 8.2208\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9985 - val_loss: 7.8666\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8366 - val_loss: 8.3698\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9543 - val_loss: 7.6477\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8607 - val_loss: 8.2671\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9290 - val_loss: 7.8727\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9326 - val_loss: 7.9481\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8479 - val_loss: 8.0072\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8652 - val_loss: 7.7122\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8364 - val_loss: 8.1188\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8300 - val_loss: 8.0924\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7904 - val_loss: 8.1415\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8796 - val_loss: 7.9575\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7539 - val_loss: 7.8842\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8415 - val_loss: 8.4210\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3632 - val_loss: 7.6815\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7824 - val_loss: 8.2116\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7744 - val_loss: 7.8775\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8646 - val_loss: 8.1500\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8609 - val_loss: 8.0988\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7938 - val_loss: 7.9185\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8277 - val_loss: 7.8457\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8782 - val_loss: 8.4002\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9302 - val_loss: 7.6659\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4920 - val_loss: 7.9094\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9690 - val_loss: 8.5426\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0300 - val_loss: 8.3101\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8352 - val_loss: 7.9366\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8801 - val_loss: 8.0601\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8077 - val_loss: 8.0946\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9431 - val_loss: 8.2601\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0418 - val_loss: 7.8774\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8827 - val_loss: 7.7872\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9700 - val_loss: 7.8656\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8073 - val_loss: 7.9918\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7102 - val_loss: 8.0175\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9359 - val_loss: 7.7280\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1082 - val_loss: 8.2774\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9079 - val_loss: 8.2811\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8831 - val_loss: 7.6784\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7310 - val_loss: 8.0815\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7269 - val_loss: 7.9515\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8111 - val_loss: 8.1444\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9368 - val_loss: 7.9453\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8878 - val_loss: 8.5837\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9845 - val_loss: 7.5886\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 3.8738 - val_loss: 8.0617\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8037 - val_loss: 7.9100\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8328 - val_loss: 7.9625\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9915 - val_loss: 8.3996\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9123 - val_loss: 7.9251\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8997 - val_loss: 8.7455\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8831 - val_loss: 7.9118\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7673 - val_loss: 7.8907\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9973 - val_loss: 8.3512\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9574 - val_loss: 7.5555\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0262 - val_loss: 8.1114\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7425 - val_loss: 7.9637\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7481 - val_loss: 8.0018\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7654 - val_loss: 7.8624\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7342 - val_loss: 7.8287\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8163 - val_loss: 7.9345\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1663 - val_loss: 7.7566\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2092 - val_loss: 9.9542\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7149 - val_loss: 7.9643\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7569 - val_loss: 8.9079\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9611 - val_loss: 7.8804\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7453 - val_loss: 8.0557\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7142 - val_loss: 7.7180\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7938 - val_loss: 7.8086\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7598 - val_loss: 7.8832\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7645 - val_loss: 7.8229\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7195 - val_loss: 7.8165\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8726 - val_loss: 7.6812\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9627 - val_loss: 8.7336\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9778 - val_loss: 7.7938\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2052 - val_loss: 9.2665\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8021 - val_loss: 7.9671\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3283 - val_loss: 8.4800\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8711 - val_loss: 7.9050\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7472 - val_loss: 7.8076\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7321 - val_loss: 7.9212\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9310 - val_loss: 7.6768\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7413 - val_loss: 7.5532\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8154 - val_loss: 7.6743\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7853 - val_loss: 8.0733\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8833 - val_loss: 7.7122\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7397 - val_loss: 7.6572\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6992 - val_loss: 7.6110\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7513 - val_loss: 8.2975\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7542 - val_loss: 7.7867\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7351 - val_loss: 8.0376\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6510 - val_loss: 7.4827\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8435 - val_loss: 8.3006\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6897 - val_loss: 7.5653\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7227 - val_loss: 8.2555\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7652 - val_loss: 7.5359\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8453 - val_loss: 7.4891\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7086 - val_loss: 7.8799\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7435 - val_loss: 7.9470\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6863 - val_loss: 7.8644\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6896 - val_loss: 7.5528\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6229 - val_loss: 7.8655\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8618 - val_loss: 8.6628\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2166 - val_loss: 7.6653\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6891 - val_loss: 8.5339\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8206 - val_loss: 7.7826\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0105 - val_loss: 7.8707\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8309 - val_loss: 7.8544\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6498 - val_loss: 7.7677\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7023 - val_loss: 8.0492\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6868 - val_loss: 7.8759\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0055 - val_loss: 9.3038\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1352 - val_loss: 7.9948\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0039 - val_loss: 8.1586\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6440 - val_loss: 7.7625\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8210 - val_loss: 8.0698\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7244 - val_loss: 7.8070\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6611 - val_loss: 7.7336\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6875 - val_loss: 8.0067\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7340 - val_loss: 7.7751\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8877 - val_loss: 8.5669\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7651 - val_loss: 7.7201\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 3.6351 - val_loss: 8.4861\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8334 - val_loss: 7.8587\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6654 - val_loss: 8.0386\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7636 - val_loss: 7.6043\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7641 - val_loss: 7.8867\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6940 - val_loss: 8.1977\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7373 - val_loss: 7.8881\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7248 - val_loss: 8.2769\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0499 - val_loss: 7.7166\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1684 - val_loss: 9.0266\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8153 - val_loss: 7.6803\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9980 - val_loss: 7.7858\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6676 - val_loss: 7.7569\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.6882 - val_loss: 7.9490\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6766 - val_loss: 7.8078\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6077 - val_loss: 7.8991\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7860 - val_loss: 7.7828\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6523 - val_loss: 7.5776\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6381 - val_loss: 7.8600\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7719 - val_loss: 8.3015\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6766 - val_loss: 7.5678\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8117 - val_loss: 7.7762\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.6244 - val_loss: 8.2179\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.8894 - val_loss: 7.8378\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6421 - val_loss: 7.8735\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6617 - val_loss: 7.7058\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7254 - val_loss: 7.7932\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7764 - val_loss: 7.7798\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8108 - val_loss: 8.6266\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7546 - val_loss: 7.8238\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5637 - val_loss: 8.0355\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8277 - val_loss: 7.5446\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7730 - val_loss: 7.7522\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6236 - val_loss: 8.2512\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8401 - val_loss: 7.7452\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8339 - val_loss: 7.6591\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7785 - val_loss: 8.1102\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6904 - val_loss: 7.8677\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6974 - val_loss: 7.6702\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0861 - val_loss: 8.4251\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7322 - val_loss: 7.6721\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6771 - val_loss: 8.1553\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7677 - val_loss: 7.8581\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8160 - val_loss: 7.6343\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6586 - val_loss: 8.1408\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7408 - val_loss: 7.8138\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1827 - val_loss: 7.8886\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0606 - val_loss: 9.1313\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7320 - val_loss: 7.7721\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7711 - val_loss: 8.6691\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9482 - val_loss: 8.0715\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6766 - val_loss: 7.7491\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6142 - val_loss: 7.7903\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8616 - val_loss: 8.4260\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4958 - val_loss: 7.7208\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7428 - val_loss: 7.7839\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6546 - val_loss: 7.9518\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6110 - val_loss: 7.9326\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5847 - val_loss: 7.9516\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7966 - val_loss: 8.2053\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7889 - val_loss: 7.7529\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6596 - val_loss: 8.5369\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5640 - val_loss: 7.6993\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7140 - val_loss: 8.6250\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8418 - val_loss: 7.8769\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5593 - val_loss: 7.6482\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5380 - val_loss: 7.5162\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6314 - val_loss: 8.1807\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5837 - val_loss: 7.7602\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5776 - val_loss: 8.0835\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6512 - val_loss: 7.8601\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5998 - val_loss: 7.8621\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7192 - val_loss: 7.8516\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6407 - val_loss: 7.8131\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5930 - val_loss: 7.7113\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6048 - val_loss: 7.8171\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5959 - val_loss: 7.6026\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.7077 - val_loss: 8.2757\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7199 - val_loss: 7.8420\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.3486 - val_loss: 10.2480\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0932 - val_loss: 8.1153\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7766 - val_loss: 8.4650\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.5358 - val_loss: 7.6364\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9384 - val_loss: 7.8675\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5641 - val_loss: 7.8853\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5417 - val_loss: 7.6711\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5627 - val_loss: 7.6213\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5113 - val_loss: 8.1439\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7557 - val_loss: 7.6465\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5501 - val_loss: 7.8079\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6146 - val_loss: 7.6794\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5349 - val_loss: 7.6735\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6692 - val_loss: 8.1548\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0751 - val_loss: 7.8830\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8621 - val_loss: 7.5886\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6762 - val_loss: 8.1788\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5043 - val_loss: 7.7544\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5849 - val_loss: 8.2493\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5394 - val_loss: 7.5663\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5783 - val_loss: 8.1937\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.5458 - val_loss: 7.7300\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6363 - val_loss: 8.0849\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9055 - val_loss: 8.7863\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8567 - val_loss: 7.6537\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7354 - val_loss: 8.3888\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6851 - val_loss: 7.7609\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6210 - val_loss: 8.0919\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6822 - val_loss: 8.0441\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6793 - val_loss: 7.5835\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7062 - val_loss: 8.1935\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.5659 - val_loss: 7.7669\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.5532 - val_loss: 8.3022\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7460 - val_loss: 7.6604\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7371 - val_loss: 8.1996\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4782 - val_loss: 7.6570\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7947 - val_loss: 8.9106\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6773 - val_loss: 7.7149\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5407 - val_loss: 8.1999\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6662 - val_loss: 7.6564\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7160 - val_loss: 8.3489\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7070 - val_loss: 7.8380\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.6340 - val_loss: 7.8513\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5734 - val_loss: 7.9891\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6255 - val_loss: 7.8539\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6859 - val_loss: 7.7514\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5243 - val_loss: 7.8361\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4996 - val_loss: 7.8256\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5275 - val_loss: 7.9488\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5118 - val_loss: 7.8967\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5588 - val_loss: 7.5737\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7264 - val_loss: 9.1610\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9925 - val_loss: 7.6749\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9945 - val_loss: 7.8423\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9119 - val_loss: 8.9219\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1299 - val_loss: 7.8027\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5016 - val_loss: 8.2414\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5229 - val_loss: 7.7467\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8866 - val_loss: 7.7213\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8080 - val_loss: 8.1235\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8610 - val_loss: 7.8169\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9156 - val_loss: 7.9625\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5256 - val_loss: 7.7210\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6481 - val_loss: 7.8260\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6274 - val_loss: 8.2790\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7169 - val_loss: 7.6324\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6524 - val_loss: 7.8165\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4814 - val_loss: 7.9131\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5560 - val_loss: 7.9451\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4200 - val_loss: 7.6730\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5268 - val_loss: 8.0338\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4919 - val_loss: 7.7504\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5017 - val_loss: 7.9341\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.5300 - val_loss: 7.7345\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8022 - val_loss: 7.7771\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 120us/step - loss: 4.1595 - val_loss: 8.9834\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7806 - val_loss: 7.8353\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6358 - val_loss: 8.3170\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.4606 - val_loss: 7.7311\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5185 - val_loss: 7.7413\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4835 - val_loss: 7.9551\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5365 - val_loss: 7.7658\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6893 - val_loss: 8.4265\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6208 - val_loss: 7.8458\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5473 - val_loss: 7.8592\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5024 - val_loss: 7.7343\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.4380 - val_loss: 8.0860\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.4652 - val_loss: 7.7239\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.4411 - val_loss: 8.2327\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5821 - val_loss: 7.8542\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5842 - val_loss: 8.2697\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5652 - val_loss: 7.7855\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.4213 - val_loss: 8.1698\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7226 - val_loss: 7.9865\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5087 - val_loss: 8.0651\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5101 - val_loss: 7.9404\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5025 - val_loss: 7.7279\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5805 - val_loss: 7.9017\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.6543 - val_loss: 9.0587\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6854 - val_loss: 7.6387\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5250 - val_loss: 8.3054\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8768 - val_loss: 7.8593\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4844 - val_loss: 7.8031\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4696 - val_loss: 7.8824\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6115 - val_loss: 7.6041\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.4732 - val_loss: 8.2336\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6810 - val_loss: 7.8200\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5784 - val_loss: 8.6562\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7249 - val_loss: 7.9616\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.5597 - val_loss: 7.9467\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4728 - val_loss: 7.8161\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6566 - val_loss: 8.4169\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.5632 - val_loss: 7.8865\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5518 - val_loss: 7.7386\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4421 - val_loss: 7.9127\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.5657 - val_loss: 7.8037\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6514 - val_loss: 8.9838\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2517 - val_loss: 7.9189\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 3.5345 - val_loss: 8.7579\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7177 - val_loss: 7.9243\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7192 - val_loss: 8.1610\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.5913 - val_loss: 8.3565\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7890 - val_loss: 7.7452\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.2802 - val_loss: 8.7928\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.5629 - val_loss: 7.7684\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7598 - val_loss: 9.1940\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7834 - val_loss: 7.9440\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5222 - val_loss: 8.3596\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5135 - val_loss: 7.8082\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5489 - val_loss: 7.6849\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6511 - val_loss: 8.7872\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9540 - val_loss: 7.9885\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4878 - val_loss: 7.8068\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.4601 - val_loss: 8.1317\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6489 - val_loss: 7.8810\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6489 - val_loss: 8.0597\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4464 - val_loss: 7.9822\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4646 - val_loss: 8.1873\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.5430 - val_loss: 7.7077\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5357 - val_loss: 8.4927\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5618 - val_loss: 8.0264\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4072 - val_loss: 8.3128\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5679 - val_loss: 7.7970\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4495 - val_loss: 7.9873\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4913 - val_loss: 7.9940\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5275 - val_loss: 7.8493\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6015 - val_loss: 7.7715\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6417 - val_loss: 7.8202\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6092 - val_loss: 8.3555\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4813 - val_loss: 7.8165\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5097 - val_loss: 7.8428\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5544 - val_loss: 8.5465\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.5395 - val_loss: 7.8374\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8849 - val_loss: 9.2859\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7206 - val_loss: 7.8367\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5748 - val_loss: 8.7890\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7292 - val_loss: 8.2017\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.4603 - val_loss: 8.1120\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6156 - val_loss: 7.5798\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6022 - val_loss: 7.9730\n",
      "8.809314226700089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-8.7864208e+00,  7.6267326e-01, -2.4002421e+00, -1.7280487e+00,\n",
       "         -4.1630650e+00, -2.3844576e+00, -5.3514713e-01,  1.4467013e+00,\n",
       "         -1.4786328e+00, -2.9776237e+00],\n",
       "        [ 4.3011904e+00,  5.6811059e-01,  7.5648427e-01, -1.9832537e+00,\n",
       "          4.0114980e+00, -2.0964696e+00, -5.6311917e-01,  7.3642260e-01,\n",
       "         -2.1150808e-01, -1.5615532e+00],\n",
       "        [-1.0612311e+00, -1.2349058e+00, -3.0803852e-02, -2.9918370e+00,\n",
       "         -3.7360594e-01, -6.5256411e-01,  4.5209745e-01, -1.3624247e+00,\n",
       "          1.3914407e+00,  7.4851239e-01],\n",
       "        [-2.6732850e+00,  4.6401474e-01,  3.0440798e-01, -8.2014389e-02,\n",
       "         -3.4087372e+00,  2.6543715e+00,  1.0478257e+00,  1.5046620e-01,\n",
       "         -3.5844037e-01,  5.1586467e-01],\n",
       "        [ 1.7730545e-01,  4.6385849e-01, -7.8923684e-03, -1.8282443e+00,\n",
       "          2.0283082e+00, -9.8568851e-01,  5.3708541e-01,  1.0762062e+00,\n",
       "         -1.1287360e+00,  9.3779892e-02],\n",
       "        [ 1.1659927e+00, -9.3233806e-01,  7.7578716e-02, -1.1158392e+00,\n",
       "          1.6124526e+00,  4.4897976e+00, -5.1023698e-01, -3.2787895e-01,\n",
       "          1.0787659e+00, -1.8649881e+00],\n",
       "        [-4.1500214e-01,  1.4293764e+00,  3.0082806e-03,  2.0460117e+00,\n",
       "         -7.0170712e-01,  2.5472968e+00,  1.9544776e-01, -2.1413505e+00,\n",
       "         -8.2587492e-01,  1.1296059e-01]], dtype=float32),\n",
       " array([-2.1905463, -2.0807517, -0.5045524, -1.8586583,  2.9163182,\n",
       "         4.0070415, -1.7612306, -2.8931727,  1.1129165, -2.1989977],\n",
       "       dtype=float32),\n",
       " array([[ 1.9233214 ,  2.2889209 ,  1.6468474 ,  1.247487  ,  2.2209716 ],\n",
       "        [-0.7348492 , -0.6926158 , -0.53806204,  0.01680204, -0.49605078],\n",
       "        [-1.9847347 , -1.757317  , -1.968747  , -2.1564088 , -1.614639  ],\n",
       "        [ 0.5817452 , -0.09144862,  0.09966645,  0.81984824,  0.6567945 ],\n",
       "        [-0.2844914 ,  0.07473016,  1.1964356 ,  0.7560874 ,  0.39025888],\n",
       "        [-0.16443017,  0.2779959 ,  0.5075953 ,  0.7627465 , -0.00232845],\n",
       "        [-0.10066012, -1.089489  , -0.7518994 , -0.4228321 , -0.2829114 ],\n",
       "        [-0.77982736, -0.05249429, -1.0023644 , -0.15789007, -0.5160467 ],\n",
       "        [-0.5770995 , -0.68701816, -0.561723  , -0.6501085 , -0.44268602],\n",
       "        [-0.25722557, -0.53190106, -1.1687684 , -0.88541764, -0.33218783]],\n",
       "       dtype=float32),\n",
       " array([1.3070613, 1.3262103, 1.3575847, 1.353524 , 1.3284597],\n",
       "       dtype=float32),\n",
       " array([[0.9677345],\n",
       "        [1.4757018],\n",
       "        [1.9449619],\n",
       "        [1.2368212],\n",
       "        [1.3645712]], dtype=float32),\n",
       " array([1.3775886], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_4(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure4_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 992us/step - loss: 464.0207 - val_loss: 192.5328\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 105.6123 - val_loss: 53.6869\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 35.6883 - val_loss: 30.1301\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 20.4439 - val_loss: 18.5233\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.2128 - val_loss: 14.3552\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.8389 - val_loss: 13.4484\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.6088 - val_loss: 12.0985\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.9504 - val_loss: 12.1746\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.5142 - val_loss: 11.2782\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 9.1108 - val_loss: 11.2539\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.5659 - val_loss: 10.7476\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3119 - val_loss: 10.6013\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.0931 - val_loss: 10.7834\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3190 - val_loss: 10.4978\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.4322 - val_loss: 11.6004\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9132 - val_loss: 10.2859\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7602 - val_loss: 10.9683\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5374 - val_loss: 10.1542\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 506us/step - loss: 7.4304 - val_loss: 10.3566\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.3608 - val_loss: 9.9746\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.8049 - val_loss: 11.7648\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.7763 - val_loss: 9.5127\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.6807 - val_loss: 9.9578\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5491 - val_loss: 10.5576\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 7.7377 - val_loss: 10.4083\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.3432 - val_loss: 11.2904\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9397 - val_loss: 10.2569\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.2694 - val_loss: 9.8222\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.1302 - val_loss: 10.2879\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.9507 - val_loss: 9.9744\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1291 - val_loss: 10.7985\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9398 - val_loss: 10.0490\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1137 - val_loss: 10.5071\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1484 - val_loss: 10.7233\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.2979 - val_loss: 10.0162\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.6936 - val_loss: 11.1630\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9500 - val_loss: 10.5122\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9897 - val_loss: 10.3849\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7934 - val_loss: 10.5498\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0510 - val_loss: 10.2974\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.7016 - val_loss: 11.7593\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0734 - val_loss: 10.5186\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8358 - val_loss: 10.6933\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8582 - val_loss: 10.6254\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 160us/step - loss: 6.7997 - val_loss: 10.4872\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6817 - val_loss: 10.4667\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7854 - val_loss: 10.4574\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7041 - val_loss: 10.6062\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8121 - val_loss: 10.6485\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7937 - val_loss: 10.5612\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8214 - val_loss: 10.4980\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7448 - val_loss: 10.3102\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6088 - val_loss: 10.1806\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7588 - val_loss: 10.2989\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7523 - val_loss: 10.7688\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8502 - val_loss: 10.2394\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1008 - val_loss: 10.7058\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5865 - val_loss: 10.2331\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5036 - val_loss: 10.5948\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6746 - val_loss: 10.2062\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6991 - val_loss: 10.7030\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6329 - val_loss: 10.5450\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1865 - val_loss: 12.7032\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8577 - val_loss: 10.3371\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4042 - val_loss: 11.8870\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9820 - val_loss: 10.3107\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9216 - val_loss: 10.4973\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.6191 - val_loss: 10.2011\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6932 - val_loss: 11.0334\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9525 - val_loss: 10.2748\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5840 - val_loss: 10.9012\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4958 - val_loss: 10.2440\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5515 - val_loss: 10.2471\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6199 - val_loss: 11.0670\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4899 - val_loss: 10.2531\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4075 - val_loss: 10.6322\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.5012 - val_loss: 10.4398\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4632 - val_loss: 10.4789\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4184 - val_loss: 10.5522\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4337 - val_loss: 10.3336\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4824 - val_loss: 10.8279\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.4766 - val_loss: 10.1867\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4435 - val_loss: 10.4077\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4614 - val_loss: 10.2455\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3867 - val_loss: 10.3987\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4889 - val_loss: 10.8417\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4957 - val_loss: 10.3344\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5124 - val_loss: 10.4308\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5526 - val_loss: 10.6461\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6684 - val_loss: 10.9289\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2708 - val_loss: 10.2775\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7944 - val_loss: 10.4211\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4527 - val_loss: 10.7373\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2182 - val_loss: 10.3079\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3185 - val_loss: 11.2618\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4021 - val_loss: 10.3549\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3403 - val_loss: 10.9739\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6157 - val_loss: 10.3322\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4616 - val_loss: 11.0251\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2215 - val_loss: 10.1584\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2838 - val_loss: 10.3491\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2347 - val_loss: 10.6217\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2541 - val_loss: 9.7506\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.2929 - val_loss: 11.1415\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4363 - val_loss: 10.7113\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2400 - val_loss: 10.2728\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2310 - val_loss: 10.4866\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1912 - val_loss: 10.1315\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4797 - val_loss: 10.4944\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2667 - val_loss: 10.2607\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1695 - val_loss: 11.0441\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0705 - val_loss: 10.4038\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0253 - val_loss: 10.2348\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1679 - val_loss: 10.9254\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5719 - val_loss: 11.7633\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3483 - val_loss: 14.6432\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0398 - val_loss: 10.4753\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8868 - val_loss: 11.2232\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0650 - val_loss: 10.4181\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9314 - val_loss: 10.6673\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0080 - val_loss: 10.1969\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9548 - val_loss: 10.2348\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1296 - val_loss: 10.8117\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0218 - val_loss: 10.4537\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9453 - val_loss: 10.3834\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0263 - val_loss: 10.1563\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8957 - val_loss: 10.2283\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9269 - val_loss: 10.4197\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5155 - val_loss: 12.4296\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2360 - val_loss: 10.8144\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6370 - val_loss: 12.3767\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0129 - val_loss: 10.6480\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2502 - val_loss: 11.5226\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9977 - val_loss: 10.1617\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1525 - val_loss: 11.2203\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1595 - val_loss: 9.8842\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8577 - val_loss: 10.9625\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9143 - val_loss: 10.3322\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4971 - val_loss: 10.3072\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7622 - val_loss: 12.8790\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4421 - val_loss: 10.3871\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0976 - val_loss: 11.4563\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9304 - val_loss: 10.0724\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7400 - val_loss: 10.4845\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.7444 - val_loss: 9.9291\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7589 - val_loss: 10.7733\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1687 - val_loss: 10.3883\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1397 - val_loss: 11.1819\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9701 - val_loss: 10.2631\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8237 - val_loss: 10.9290\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7189 - val_loss: 9.7691\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7803 - val_loss: 10.6120\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7355 - val_loss: 9.5711\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6655 - val_loss: 9.8395\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6319 - val_loss: 9.7972\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7032 - val_loss: 9.9177\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7543 - val_loss: 10.0831\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5968 - val_loss: 10.1064\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5647 - val_loss: 9.8445\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6037 - val_loss: 9.5164\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6903 - val_loss: 9.6651\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6184 - val_loss: 10.1504\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7934 - val_loss: 10.1669\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0876 - val_loss: 10.1592\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9046 - val_loss: 9.9820\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8966 - val_loss: 9.8515\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8884 - val_loss: 10.8297\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8877 - val_loss: 9.9784\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9084 - val_loss: 9.7674\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5755 - val_loss: 9.2697\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5514 - val_loss: 9.6918\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6503 - val_loss: 10.0940\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8351 - val_loss: 9.4875\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7702 - val_loss: 10.7766\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5814 - val_loss: 9.4191\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4537 - val_loss: 10.0289\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6840 - val_loss: 9.4935\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4138 - val_loss: 9.8698\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5261 - val_loss: 9.4528\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0003 - val_loss: 9.9635\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3987 - val_loss: 9.3662\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3794 - val_loss: 9.4795\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4198 - val_loss: 9.3782\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4209 - val_loss: 9.2275\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3270 - val_loss: 9.5863\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4203 - val_loss: 9.1427\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3516 - val_loss: 9.9278\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5933 - val_loss: 9.4614\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4244 - val_loss: 9.4962\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3226 - val_loss: 9.5856\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4120 - val_loss: 9.4951\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3204 - val_loss: 9.3203\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3241 - val_loss: 9.0874\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3805 - val_loss: 9.0990\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4964 - val_loss: 9.1273\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7122 - val_loss: 9.9331\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1972 - val_loss: 9.1491\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3990 - val_loss: 9.2658\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1570 - val_loss: 9.3154\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3035 - val_loss: 9.1309\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1620 - val_loss: 9.2451\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4620 - val_loss: 9.4673\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3013 - val_loss: 9.6243\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1511 - val_loss: 8.8970\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2131 - val_loss: 9.4352\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4664 - val_loss: 9.2820\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1923 - val_loss: 9.2802\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4585 - val_loss: 9.6143\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1445 - val_loss: 9.0882\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1897 - val_loss: 9.0992\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2580 - val_loss: 9.0695\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2922 - val_loss: 9.7012\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1899 - val_loss: 9.4391\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1989 - val_loss: 9.8390\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7180 - val_loss: 9.0839\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4200 - val_loss: 10.2403\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6051 - val_loss: 9.4424\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7018 - val_loss: 9.0971\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5202 - val_loss: 8.8076\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2337 - val_loss: 9.5050\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2236 - val_loss: 9.1657\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.3109 - val_loss: 9.0126\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7425 - val_loss: 9.7125\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2729 - val_loss: 8.9892\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1560 - val_loss: 10.0639\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1403 - val_loss: 9.0515\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1815 - val_loss: 8.8849\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0537 - val_loss: 9.0099\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0834 - val_loss: 9.4112\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1936 - val_loss: 8.9900\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1621 - val_loss: 9.5645\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1649 - val_loss: 9.0380\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3557 - val_loss: 9.1155\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0864 - val_loss: 9.5511\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9929 - val_loss: 8.8868\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9814 - val_loss: 9.4597\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3345 - val_loss: 8.9025\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3756 - val_loss: 8.9928\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0410 - val_loss: 9.4763\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1993 - val_loss: 9.3253\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3623 - val_loss: 8.9091\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2184 - val_loss: 10.2006\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6795 - val_loss: 8.9933\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0082 - val_loss: 9.2100\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1612 - val_loss: 9.0478\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4548 - val_loss: 8.9030\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0332 - val_loss: 9.2373\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9723 - val_loss: 9.1014\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0252 - val_loss: 9.0160\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1463 - val_loss: 9.0163\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9485 - val_loss: 9.0001\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9950 - val_loss: 9.2515\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0559 - val_loss: 8.5672\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1619 - val_loss: 10.1723\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2386 - val_loss: 8.5444\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9110 - val_loss: 9.5611\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0885 - val_loss: 8.7766\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9733 - val_loss: 9.5263\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0944 - val_loss: 8.9869\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9033 - val_loss: 8.8610\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1253 - val_loss: 8.8703\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9050 - val_loss: 8.7468\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1788 - val_loss: 9.5523\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8740 - val_loss: 9.1414\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0049 - val_loss: 9.1600\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0775 - val_loss: 8.8245\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0205 - val_loss: 8.9787\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0180 - val_loss: 9.8360\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9061 - val_loss: 8.6499\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9308 - val_loss: 9.2995\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4860 - val_loss: 9.2850\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4771 - val_loss: 10.2734\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2499 - val_loss: 9.4915\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0279 - val_loss: 9.1441\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1755 - val_loss: 9.4676\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9611 - val_loss: 8.8069\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0826 - val_loss: 10.3940\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2451 - val_loss: 8.6340\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0133 - val_loss: 8.8017\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1057 - val_loss: 8.6450\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8955 - val_loss: 8.9088\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8694 - val_loss: 9.0743\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0252 - val_loss: 8.7912\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8832 - val_loss: 8.9128\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9280 - val_loss: 8.8904\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0514 - val_loss: 8.8064\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8774 - val_loss: 8.8795\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0105 - val_loss: 8.9539\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8678 - val_loss: 8.8721\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9946 - val_loss: 9.6112\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9630 - val_loss: 8.9642\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9592 - val_loss: 10.0840\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9739 - val_loss: 9.0016\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3314 - val_loss: 9.7208\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3081 - val_loss: 9.4524\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1426 - val_loss: 8.7291\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9856 - val_loss: 9.5609\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.8872 - val_loss: 8.9378\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.2834 - val_loss: 8.7682\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.9482 - val_loss: 9.7013\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4152 - val_loss: 8.5380\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9793 - val_loss: 8.9231\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7682 - val_loss: 8.5826\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8430 - val_loss: 9.1954\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8073 - val_loss: 9.2046\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9077 - val_loss: 8.8938\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8737 - val_loss: 8.7904\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9904 - val_loss: 9.9823\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9441 - val_loss: 8.8807\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0410 - val_loss: 8.9760\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8761 - val_loss: 9.0538\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8623 - val_loss: 8.7795\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8175 - val_loss: 9.1883\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7096 - val_loss: 8.8430\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8403 - val_loss: 9.9177\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0178 - val_loss: 9.0249\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0670 - val_loss: 8.8094\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0612 - val_loss: 9.3126\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8166 - val_loss: 9.0954\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7255 - val_loss: 9.4226\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2999 - val_loss: 8.6616\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9947 - val_loss: 9.1415\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7763 - val_loss: 8.6080\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2794 - val_loss: 9.6919\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8669 - val_loss: 8.9032\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7195 - val_loss: 8.9324\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0059 - val_loss: 9.1959\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9020 - val_loss: 8.5477\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0494 - val_loss: 8.9744\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4525 - val_loss: 10.2020\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3285 - val_loss: 8.7881\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8162 - val_loss: 8.8412\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7622 - val_loss: 9.1292\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7205 - val_loss: 8.7014\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7030 - val_loss: 8.8365\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7177 - val_loss: 8.8666\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7101 - val_loss: 9.2581\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9000 - val_loss: 8.7779\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7091 - val_loss: 8.6317\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9554 - val_loss: 9.6822\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2048 - val_loss: 8.6518\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8007 - val_loss: 8.8654\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7356 - val_loss: 8.8535\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1702 - val_loss: 10.2248\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1894 - val_loss: 8.7908\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4747 - val_loss: 8.8384\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7292 - val_loss: 8.9808\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6657 - val_loss: 9.3241\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6879 - val_loss: 9.0267\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6486 - val_loss: 8.8239\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6640 - val_loss: 8.8746\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7648 - val_loss: 8.7881\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6976 - val_loss: 9.7297\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8555 - val_loss: 8.9476\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6630 - val_loss: 8.6291\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8305 - val_loss: 9.5107\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9049 - val_loss: 8.6036\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7768 - val_loss: 9.0041\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5894 - val_loss: 8.7858\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2244 - val_loss: 9.9625\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0401 - val_loss: 8.6814\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7290 - val_loss: 8.6550\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6549 - val_loss: 9.3763\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8397 - val_loss: 8.7724\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0451 - val_loss: 9.6893\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0443 - val_loss: 8.9599\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5600 - val_loss: 9.7613\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8550 - val_loss: 8.3240\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6044 - val_loss: 8.7928\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7955 - val_loss: 9.1118\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6952 - val_loss: 8.7607\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7014 - val_loss: 8.7648\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6634 - val_loss: 9.8772\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8207 - val_loss: 8.5234\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5955 - val_loss: 8.7832\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.7274 - val_loss: 8.4659\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5744 - val_loss: 8.9952\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7973 - val_loss: 8.6090\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6158 - val_loss: 9.2984\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6511 - val_loss: 8.8417\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5906 - val_loss: 8.6605\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7098 - val_loss: 8.8411\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2233 - val_loss: 8.8519\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1483 - val_loss: 8.8112\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7818 - val_loss: 8.8731\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9032 - val_loss: 9.0000\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8846 - val_loss: 9.7941\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4022 - val_loss: 8.4051\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2235 - val_loss: 10.0504\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8480 - val_loss: 9.1091\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8581 - val_loss: 8.5575\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8392 - val_loss: 8.8054\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5481 - val_loss: 8.5350\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6551 - val_loss: 8.5043\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5683 - val_loss: 9.0779\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6374 - val_loss: 8.3171\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6514 - val_loss: 8.4781\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7972 - val_loss: 9.9571\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8370 - val_loss: 8.7190\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2642 - val_loss: 9.3599\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3950 - val_loss: 9.6250\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8914 - val_loss: 8.7631\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5898 - val_loss: 8.9295\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6127 - val_loss: 8.4423\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5434 - val_loss: 9.1054\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6657 - val_loss: 8.6044\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9669 - val_loss: 9.1807\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7737 - val_loss: 8.3713\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8559 - val_loss: 8.6985\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7832 - val_loss: 8.6986\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6400 - val_loss: 8.7848\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6984 - val_loss: 8.4608\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7172 - val_loss: 9.2940\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4306 - val_loss: 8.5233\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6404 - val_loss: 8.9342\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5548 - val_loss: 8.3883\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5432 - val_loss: 9.4691\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1189 - val_loss: 9.2046\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8526 - val_loss: 9.3547\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.5898 - val_loss: 8.0829\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6954 - val_loss: 8.9444\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5259 - val_loss: 8.7159\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5725 - val_loss: 9.8386\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2420 - val_loss: 9.1070\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2266 - val_loss: 9.4475\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5444 - val_loss: 8.7816\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9137 - val_loss: 8.5370\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7974 - val_loss: 8.7221\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7561 - val_loss: 8.6898\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5531 - val_loss: 8.6767\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7119 - val_loss: 8.4930\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5412 - val_loss: 8.3586\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5353 - val_loss: 8.3879\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4957 - val_loss: 9.3737\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5377 - val_loss: 8.3053\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6803 - val_loss: 8.5505\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4878 - val_loss: 8.4669\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4848 - val_loss: 8.2717\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4961 - val_loss: 8.5963\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4798 - val_loss: 8.6186\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5207 - val_loss: 8.1973\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5656 - val_loss: 9.1110\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7794 - val_loss: 8.7192\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8941 - val_loss: 8.4875\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5290 - val_loss: 8.6571\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5909 - val_loss: 8.3148\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4873 - val_loss: 8.7209\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4384 - val_loss: 8.1159\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.6433 - val_loss: 9.3084\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7432 - val_loss: 8.9467\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5007 - val_loss: 10.3602\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6316 - val_loss: 8.4112\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.5933 - val_loss: 9.1561\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6557 - val_loss: 8.4260\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6056 - val_loss: 8.2828\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4346 - val_loss: 9.4229\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6033 - val_loss: 8.5587\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4962 - val_loss: 8.3630\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3975 - val_loss: 8.4912\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4204 - val_loss: 8.6935\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5085 - val_loss: 8.3851\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4619 - val_loss: 8.1808\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4980 - val_loss: 9.2430\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7086 - val_loss: 10.1260\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4974 - val_loss: 10.3628\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5813 - val_loss: 8.0453\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6531 - val_loss: 8.2689\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3840 - val_loss: 8.2964\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4115 - val_loss: 8.4567\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4028 - val_loss: 8.4749\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4193 - val_loss: 8.3084\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5093 - val_loss: 7.9889\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3396 - val_loss: 8.8712\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4178 - val_loss: 8.0778\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4485 - val_loss: 8.2800\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3579 - val_loss: 8.9825\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8349 - val_loss: 8.1321\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7258 - val_loss: 8.2315\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5467 - val_loss: 8.8646\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5524 - val_loss: 8.4851\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4180 - val_loss: 8.7629\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5608 - val_loss: 8.4322\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4202 - val_loss: 8.7880\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3549 - val_loss: 8.6382\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4714 - val_loss: 8.4791\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6273 - val_loss: 8.2223\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9295 - val_loss: 8.8892\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4898 - val_loss: 8.1692\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4992 - val_loss: 9.3766\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5545 - val_loss: 8.4937\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3061 - val_loss: 8.4295\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3288 - val_loss: 8.5559\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4230 - val_loss: 8.8630\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4024 - val_loss: 8.0669\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3510 - val_loss: 8.6983\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3589 - val_loss: 8.4369\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2922 - val_loss: 8.3839\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5147 - val_loss: 9.1718\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5793 - val_loss: 8.2419\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5171 - val_loss: 8.6155\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4138 - val_loss: 8.1260\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4339 - val_loss: 8.5865\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2860 - val_loss: 8.3364\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2993 - val_loss: 8.0880\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2955 - val_loss: 8.4213\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4035 - val_loss: 8.6591\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4414 - val_loss: 9.0088\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5497 - val_loss: 8.5277\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3665 - val_loss: 8.2226\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2885 - val_loss: 8.4542\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2717 - val_loss: 8.1515\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5593 - val_loss: 8.3708\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2277 - val_loss: 8.2437\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3624 - val_loss: 8.1729\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2585 - val_loss: 8.4806\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2358 - val_loss: 8.2501\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3691 - val_loss: 8.3616\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3287 - val_loss: 8.3209\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3420 - val_loss: 8.5860\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2582 - val_loss: 8.2868\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2865 - val_loss: 8.3660\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2527 - val_loss: 8.1025\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2529 - val_loss: 8.6673\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3173 - val_loss: 8.6108\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2493 - val_loss: 8.3782\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3151 - val_loss: 8.4790\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4468 - val_loss: 8.1911\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3543 - val_loss: 8.8674\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2860 - val_loss: 8.1680\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.3481 - val_loss: 10.0041\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7502 - val_loss: 8.9868\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5654 - val_loss: 8.8713\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6551 - val_loss: 8.1639\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3546 - val_loss: 8.3514\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2915 - val_loss: 8.1987\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2043 - val_loss: 8.9200\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6800 - val_loss: 8.3650\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.3654 - val_loss: 8.6765\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5039 - val_loss: 9.0248\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5775 - val_loss: 8.1596\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7397 - val_loss: 8.3746\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8007 - val_loss: 8.7057\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5745 - val_loss: 8.7523\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3572 - val_loss: 8.9009\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4766 - val_loss: 9.1547\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4118 - val_loss: 8.3206\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2474 - val_loss: 8.8431\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3283 - val_loss: 8.5431\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1743 - val_loss: 8.5457\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5625 - val_loss: 8.2754\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2462 - val_loss: 8.5060\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4653 - val_loss: 8.8933\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5732 - val_loss: 7.9803\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4374 - val_loss: 8.0275\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7236 - val_loss: 9.1006\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5229 - val_loss: 8.0247\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2449 - val_loss: 8.6672\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2384 - val_loss: 10.9958\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2731 - val_loss: 8.7005\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5408 - val_loss: 8.2073\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4103 - val_loss: 9.2221\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4614 - val_loss: 8.1639\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.2019 - val_loss: 8.2198\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2239 - val_loss: 8.3856\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2349 - val_loss: 8.1195\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1692 - val_loss: 8.8413\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3549 - val_loss: 8.3181\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2757 - val_loss: 8.3744\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2929 - val_loss: 8.1965\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4896 - val_loss: 8.4403\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2597 - val_loss: 8.5552\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3305 - val_loss: 8.4760\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3368 - val_loss: 8.3987\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3748 - val_loss: 8.9579\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2978 - val_loss: 8.1884\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3911 - val_loss: 8.1791\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4198 - val_loss: 8.4928\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.3327 - val_loss: 8.5354\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2884 - val_loss: 8.7934\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2893 - val_loss: 8.2333\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3157 - val_loss: 8.6204\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.3376 - val_loss: 8.9454\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4522 - val_loss: 8.5836\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3297 - val_loss: 9.0876\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.4393 - val_loss: 8.7517\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3847 - val_loss: 7.7304\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3308 - val_loss: 8.6539\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2115 - val_loss: 8.3610\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.4434 - val_loss: 8.7448\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3550 - val_loss: 8.3048\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3378 - val_loss: 8.8549\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4221 - val_loss: 8.3602\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1474 - val_loss: 8.7076\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3133 - val_loss: 8.0976\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2703 - val_loss: 8.3101\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3311 - val_loss: 8.6293\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1693 - val_loss: 8.5368\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4661 - val_loss: 10.5318\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4388 - val_loss: 9.8180\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8492 - val_loss: 9.4835\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4380 - val_loss: 8.4001\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3122 - val_loss: 8.5413\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5420 - val_loss: 8.4138\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2219 - val_loss: 8.1894\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3545 - val_loss: 8.0456\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3430 - val_loss: 8.6465\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.6654 - val_loss: 8.7320\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7807 - val_loss: 9.5574\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5725 - val_loss: 8.6918\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1829 - val_loss: 7.8657\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3911 - val_loss: 8.1872\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4087 - val_loss: 8.7293\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2940 - val_loss: 8.1739\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2801 - val_loss: 8.9026\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4261 - val_loss: 8.1514\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3811 - val_loss: 8.0821\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5585 - val_loss: 8.8927\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2034 - val_loss: 8.1814\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2513 - val_loss: 8.2310\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2697 - val_loss: 8.8209\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5310 - val_loss: 8.8307\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4494 - val_loss: 8.1381\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2881 - val_loss: 8.3542\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2574 - val_loss: 8.2757\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2925 - val_loss: 8.2065\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1966 - val_loss: 8.2232\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2691 - val_loss: 8.4547\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4395 - val_loss: 8.4413\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0959 - val_loss: 8.2980\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1326 - val_loss: 8.4341\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2288 - val_loss: 7.9316\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1640 - val_loss: 8.6516\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1933 - val_loss: 8.4974\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1438 - val_loss: 8.9899\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3003 - val_loss: 8.4536\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2982 - val_loss: 8.0617\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3274 - val_loss: 8.6726\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4296 - val_loss: 8.7090\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2152 - val_loss: 8.2517\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2572 - val_loss: 8.7944\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3483 - val_loss: 8.7249\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7262 - val_loss: 8.8375\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2205 - val_loss: 8.4079\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3073 - val_loss: 8.4019\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2277 - val_loss: 8.3003\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3956 - val_loss: 8.6982\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2381 - val_loss: 8.7648\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1960 - val_loss: 8.0273\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 4.3713 - val_loss: 8.6542\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4188 - val_loss: 8.5777\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1383 - val_loss: 8.6434\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1606 - val_loss: 8.4079\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0771 - val_loss: 8.3616\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3339 - val_loss: 8.2147\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0627 - val_loss: 9.0664\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1174 - val_loss: 8.5639\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4936 - val_loss: 8.3954\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6643 - val_loss: 8.8985\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2422 - val_loss: 8.5124\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2954 - val_loss: 9.2367\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4231 - val_loss: 8.5202\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4717 - val_loss: 8.6649\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4188 - val_loss: 8.5945\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4240 - val_loss: 8.4546\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2679 - val_loss: 8.3880\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2868 - val_loss: 9.5170\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6167 - val_loss: 8.7058\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4778 - val_loss: 8.8274\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2539 - val_loss: 8.8460\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2374 - val_loss: 8.7537\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2782 - val_loss: 8.4203\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1998 - val_loss: 8.3543\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1621 - val_loss: 8.2849\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1383 - val_loss: 8.9299\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2247 - val_loss: 9.0899\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2473 - val_loss: 8.4253\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1612 - val_loss: 8.2257\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2097 - val_loss: 8.7688\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7579 - val_loss: 9.7132\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5814 - val_loss: 9.3188\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6579 - val_loss: 8.7217\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0634 - val_loss: 8.5113\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5369 - val_loss: 7.9985\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.2503 - val_loss: 8.8917\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2959 - val_loss: 8.2954\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1285 - val_loss: 8.4559\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1865 - val_loss: 8.3840\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2932 - val_loss: 8.2810\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3016 - val_loss: 8.9887\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.1739 - val_loss: 8.2466\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4395 - val_loss: 8.1568\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4971 - val_loss: 9.1105\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3361 - val_loss: 9.0846\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3701 - val_loss: 8.4446\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1558 - val_loss: 8.5162\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4000 - val_loss: 8.4586\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1873 - val_loss: 8.4049\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2754 - val_loss: 8.8022\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1868 - val_loss: 8.7809\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2104 - val_loss: 8.3107\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0701 - val_loss: 8.4602\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1294 - val_loss: 8.5278\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0675 - val_loss: 8.3236\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1344 - val_loss: 8.5907\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3393 - val_loss: 8.4752\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2889 - val_loss: 8.5273\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1891 - val_loss: 8.4999\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4896 - val_loss: 8.6248\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1810 - val_loss: 8.6000\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1043 - val_loss: 8.5373\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1605 - val_loss: 8.4065\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4723 - val_loss: 8.1178\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0530 - val_loss: 8.6684\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1627 - val_loss: 8.8803\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0779 - val_loss: 8.4573\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0373 - val_loss: 8.2461\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0989 - val_loss: 8.4653\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0449 - val_loss: 8.4718\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1765 - val_loss: 8.4258\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1190 - val_loss: 8.2624\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4321 - val_loss: 9.2466\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2883 - val_loss: 8.1441\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0970 - val_loss: 8.1182\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1536 - val_loss: 8.5512\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.0688 - val_loss: 8.3553\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.1446 - val_loss: 8.4934\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0863 - val_loss: 8.6152\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2081 - val_loss: 9.3571\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3936 - val_loss: 9.2588\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5449 - val_loss: 8.5713\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3795 - val_loss: 8.1125\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2153 - val_loss: 8.7493\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1860 - val_loss: 8.9743\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3235 - val_loss: 9.1284\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7815 - val_loss: 9.8981\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3726 - val_loss: 9.6862\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2839 - val_loss: 8.9100\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1815 - val_loss: 8.4011\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.0638 - val_loss: 8.8234\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5554 - val_loss: 8.6110\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0593 - val_loss: 8.3640\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1780 - val_loss: 8.4831\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2902 - val_loss: 8.8910\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2417 - val_loss: 8.9177\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1573 - val_loss: 9.4172\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5224 - val_loss: 8.6991\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2556 - val_loss: 8.4626\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1297 - val_loss: 8.4701\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0398 - val_loss: 8.2007\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1575 - val_loss: 8.1662\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1234 - val_loss: 8.4453\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4614 - val_loss: 9.1873\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1599 - val_loss: 8.7065\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1877 - val_loss: 8.4629\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1512 - val_loss: 8.4027\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1159 - val_loss: 8.8010\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1645 - val_loss: 8.7528\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1569 - val_loss: 9.4605\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4282 - val_loss: 9.1607\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3446 - val_loss: 8.5647\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.0769 - val_loss: 8.5512\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3630 - val_loss: 8.7006\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2831 - val_loss: 8.4053\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1707 - val_loss: 8.6522\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0785 - val_loss: 8.6223\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2404 - val_loss: 8.6193\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0584 - val_loss: 8.7891\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0586 - val_loss: 8.2860\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0110 - val_loss: 8.2491\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1765 - val_loss: 8.5207\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6443 - val_loss: 8.7280\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2488 - val_loss: 9.6283\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2329 - val_loss: 9.4377\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4941 - val_loss: 8.8521\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9658 - val_loss: 8.2657\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3548 - val_loss: 8.5014\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8694 - val_loss: 9.7250\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5238 - val_loss: 8.3438\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0894 - val_loss: 8.4383\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1446 - val_loss: 8.8159\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1696 - val_loss: 8.5445\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0444 - val_loss: 8.3472\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2692 - val_loss: 9.0250\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2298 - val_loss: 8.5228\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5365 - val_loss: 8.7554\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3609 - val_loss: 8.2507\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2190 - val_loss: 8.9896\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5039 - val_loss: 8.6614\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2407 - val_loss: 8.6344\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1313 - val_loss: 8.5866\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2677 - val_loss: 9.1304\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2979 - val_loss: 9.4151\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2327 - val_loss: 9.1409\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2405 - val_loss: 8.7222\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3282 - val_loss: 8.8501\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2752 - val_loss: 8.4345\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5233 - val_loss: 8.9288\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2969 - val_loss: 8.4170\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1245 - val_loss: 8.5459\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2263 - val_loss: 8.8586\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7065 - val_loss: 9.5313\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4324 - val_loss: 8.8951\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1038 - val_loss: 8.5649\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4360 - val_loss: 8.4831\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3464 - val_loss: 9.0708\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1918 - val_loss: 9.1003\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3548 - val_loss: 8.8949\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3586 - val_loss: 9.2203\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7396 - val_loss: 10.5690\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2103 - val_loss: 9.0069\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5284 - val_loss: 8.5427\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3749 - val_loss: 8.3146\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6223 - val_loss: 9.1971\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2396 - val_loss: 9.4813\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1652 - val_loss: 8.8203\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2293 - val_loss: 8.6426\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0341 - val_loss: 8.5372\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1065 - val_loss: 8.3011\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1052 - val_loss: 8.7718\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2074 - val_loss: 8.5408\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0263 - val_loss: 8.8281\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0867 - val_loss: 8.6196\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2825 - val_loss: 9.0967\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2008 - val_loss: 8.7480\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0347 - val_loss: 8.4313\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0904 - val_loss: 8.4805\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0853 - val_loss: 9.7066\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3311 - val_loss: 8.8119\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0688 - val_loss: 8.6040\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1647 - val_loss: 8.3984\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0894 - val_loss: 8.3388\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1089 - val_loss: 8.8457\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0650 - val_loss: 8.5962\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3189 - val_loss: 8.8819\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1706 - val_loss: 8.4155\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9648 - val_loss: 8.8123\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0232 - val_loss: 8.6448\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.0004 - val_loss: 8.4085\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1361 - val_loss: 8.7605\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0413 - val_loss: 8.2641\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1292 - val_loss: 8.7545\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9798 - val_loss: 8.5007\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0401 - val_loss: 8.6662\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0684 - val_loss: 8.3399\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0564 - val_loss: 8.5915\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1383 - val_loss: 8.7192\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0396 - val_loss: 8.5734\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1094 - val_loss: 9.1059\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1734 - val_loss: 8.8837\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2069 - val_loss: 9.0719\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1447 - val_loss: 9.4457\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5234 - val_loss: 9.1514\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2603 - val_loss: 8.6186\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2637 - val_loss: 8.5375\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5669 - val_loss: 8.8319\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1916 - val_loss: 8.6902\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0729 - val_loss: 8.9417\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1904 - val_loss: 8.8575\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1817 - val_loss: 8.8687\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1215 - val_loss: 8.8789\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9662 - val_loss: 8.7830\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0611 - val_loss: 8.8477\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0747 - val_loss: 8.6224\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0325 - val_loss: 8.5529\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0315 - val_loss: 8.6999\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0978 - val_loss: 9.0700\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0967 - val_loss: 8.6943\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0398 - val_loss: 9.1128\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1425 - val_loss: 8.6715\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2155 - val_loss: 8.8570\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0021 - val_loss: 8.9732\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2569 - val_loss: 8.8051\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0248 - val_loss: 8.5119\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0370 - val_loss: 8.6565\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0504 - val_loss: 8.6146\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0871 - val_loss: 9.0103\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7545 - val_loss: 10.0501\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4522 - val_loss: 9.6679\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3932 - val_loss: 9.6423\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5821 - val_loss: 8.4876\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3461 - val_loss: 9.3358\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.7812 - val_loss: 9.6311\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4611 - val_loss: 8.2176\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3890 - val_loss: 8.8263\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1616 - val_loss: 9.2300\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3746 - val_loss: 8.7881\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1685 - val_loss: 9.0496\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1810 - val_loss: 9.0052\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0797 - val_loss: 8.3184\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1218 - val_loss: 8.6218\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1702 - val_loss: 8.5871\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1408 - val_loss: 8.5877\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0333 - val_loss: 8.6013\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0933 - val_loss: 8.7304\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1044 - val_loss: 8.5015\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0097 - val_loss: 8.7675\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9109 - val_loss: 8.5970\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9965 - val_loss: 8.4044\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0476 - val_loss: 8.3291\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0083 - val_loss: 8.5351\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1596 - val_loss: 8.6165\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0629 - val_loss: 9.0518\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0045 - val_loss: 8.7573\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2692 - val_loss: 9.1139\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2084 - val_loss: 8.8289\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1043 - val_loss: 9.0394\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2705 - val_loss: 8.4022\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1326 - val_loss: 8.8362\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0465 - val_loss: 9.2875\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9721 - val_loss: 9.0180\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1684 - val_loss: 8.4719\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9522 - val_loss: 8.6035\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3576 - val_loss: 9.5841\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2328 - val_loss: 9.0861\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.0168 - val_loss: 8.6883\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0279 - val_loss: 8.4772\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9949 - val_loss: 9.0520\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1008 - val_loss: 8.8853\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1514 - val_loss: 8.4090\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0454 - val_loss: 8.7317\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0409 - val_loss: 8.8228\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4459 - val_loss: 9.0959\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2503 - val_loss: 10.1916\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9972 - val_loss: 9.2665\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0250 - val_loss: 9.4485\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3086 - val_loss: 8.6173\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2808 - val_loss: 8.2988\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6837 - val_loss: 9.1092\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3636 - val_loss: 8.9402\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2475 - val_loss: 8.5226\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0054 - val_loss: 8.6413\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1632 - val_loss: 8.9999\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9916 - val_loss: 9.1450\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1991 - val_loss: 8.7038\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0520 - val_loss: 8.7552\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9999 - val_loss: 8.7408\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1213 - val_loss: 8.8659\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0045 - val_loss: 8.8120\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2156 - val_loss: 9.1817\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0816 - val_loss: 8.7957\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0760 - val_loss: 8.7076\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1075 - val_loss: 8.5590\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1555 - val_loss: 8.7289\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0888 - val_loss: 8.8409\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0422 - val_loss: 8.7291\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0585 - val_loss: 8.8072\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0782 - val_loss: 8.6744\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1174 - val_loss: 8.5152\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1699 - val_loss: 8.4710\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0701 - val_loss: 8.8507\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9224 - val_loss: 8.5880\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0002 - val_loss: 8.7247\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0039 - val_loss: 8.7692\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9459 - val_loss: 8.5718\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9541 - val_loss: 8.8255\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0354 - val_loss: 9.5690\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1627 - val_loss: 8.9025\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0116 - val_loss: 8.5514\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0144 - val_loss: 8.3514\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0222 - val_loss: 8.9840\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9577 - val_loss: 8.6413\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1653 - val_loss: 9.0708\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9901 - val_loss: 9.4650\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4864 - val_loss: 9.5356\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8658 - val_loss: 9.3125\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0993 - val_loss: 9.1951\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2639 - val_loss: 8.6219\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4173 - val_loss: 8.9858\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9401 - val_loss: 8.6386\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0662 - val_loss: 8.9370\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1838 - val_loss: 9.1820\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2149 - val_loss: 8.4326\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9848 - val_loss: 8.6083\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0142 - val_loss: 9.0028\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0838 - val_loss: 8.5798\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0597 - val_loss: 8.6763\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0885 - val_loss: 9.0858\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2020 - val_loss: 9.1304\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9912 - val_loss: 8.9052\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9876 - val_loss: 8.8850\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1477 - val_loss: 8.8309\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9873 - val_loss: 9.2655\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0027 - val_loss: 9.8545\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1331 - val_loss: 8.6372\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9875 - val_loss: 8.7166\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9606 - val_loss: 9.0878\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1047 - val_loss: 8.7457\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3022 - val_loss: 8.5923\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0112 - val_loss: 9.1960\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9764 - val_loss: 8.8886\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9432 - val_loss: 8.7569\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.0270 - val_loss: 9.1207\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0752 - val_loss: 9.2064\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0849 - val_loss: 8.9553\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9762 - val_loss: 8.9602\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9351 - val_loss: 8.6470\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2680 - val_loss: 8.7133\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9426 - val_loss: 9.3683\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0791 - val_loss: 9.0661\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1000 - val_loss: 8.6873\n",
      "12.727670637227721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1313021 , -3.085816  ,  1.927065  , -2.7717645 , -0.7528484 ,\n",
       "          3.0921245 , -0.56679404, -2.6540577 , -1.4992825 , -0.10916438],\n",
       "        [ 0.17657736,  2.7950933 , -2.3319662 , -1.6171544 ,  1.7938892 ,\n",
       "         -0.83670485, -1.9791273 , -0.38262868, -0.60952485,  0.6687368 ],\n",
       "        [-1.556922  , -0.61373425,  0.02359732, -0.6884323 , -0.25900364,\n",
       "         -1.6079075 ,  0.09938377,  0.85870457, -0.9627764 ,  0.811659  ],\n",
       "        [ 0.33005598, -2.5487976 ,  1.437822  ,  1.2607117 , -1.1283998 ,\n",
       "          0.81424636,  0.8093724 ,  0.53105897,  2.1964357 , -1.4426455 ],\n",
       "        [-0.49514183, -0.17535456, -0.8312414 , -0.30191547, -0.08503196,\n",
       "          1.3110816 ,  0.11915448, -0.6774414 , -0.47471035,  0.5783829 ],\n",
       "        [-0.32195765, -0.3910366 ,  0.57404995, -0.8167367 , -1.783452  ,\n",
       "         -1.8777193 ,  1.7414455 ,  0.61654943, -0.5295694 ,  1.7261318 ],\n",
       "        [ 0.12503324,  1.2568306 ,  0.77544165, -0.19657214,  1.3289266 ,\n",
       "         -3.5433874 ,  0.89472836,  0.93873096,  0.33377635,  0.1953598 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.8321944 ,  1.1488799 ,  2.5149467 , -1.4351978 ,  3.2340922 ,\n",
       "        -0.84436154,  2.0995948 , -0.6680672 , -1.7091467 , -1.9240196 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.50196105, -0.36114505, -0.31315067, -0.32713866, -1.0159788 ,\n",
       "          0.6762426 ,  0.10797255,  0.10671346, -0.90956086, -0.25706577],\n",
       "        [-0.22617452, -0.63754976, -0.01985725,  0.21648721, -0.61125124,\n",
       "          0.51918507,  0.19482799, -0.59629583, -0.43589643, -0.09452236],\n",
       "        [ 0.66811776, -0.9910391 ,  0.34618735,  0.08823418, -1.0415564 ,\n",
       "          0.6549195 ,  1.1628461 , -0.36251688, -0.8808948 , -0.9483359 ],\n",
       "        [ 0.6594146 , -0.40240884,  0.39191484, -0.35818097, -1.0953981 ,\n",
       "          0.9056559 ,  1.1470416 , -1.0745687 , -1.0024006 , -0.8724276 ],\n",
       "        [ 0.16342513, -0.48758557,  0.39901382,  0.42828992, -0.6020302 ,\n",
       "          0.72593194,  0.9018749 ,  0.0068491 , -0.5486654 , -0.19001652],\n",
       "        [-0.766582  ,  0.8416016 , -0.7433315 ,  0.22106273,  0.08992709,\n",
       "         -1.0370224 , -0.6765221 ,  0.13288052,  0.1309856 ,  0.13027358],\n",
       "        [ 0.28989166, -0.76532656, -0.33255124,  0.20437497, -0.38527146,\n",
       "          0.6973319 ,  0.5493504 ,  0.07239452, -0.34070688,  0.16610624],\n",
       "        [-0.77813745,  1.3938309 , -1.1315678 ,  0.22739597,  0.64025277,\n",
       "         -1.1015806 , -1.3082267 ,  1.1925104 ,  1.2974437 ,  1.0070174 ],\n",
       "        [-0.05340379,  0.00837984,  0.03384813, -0.31328017,  1.1592388 ,\n",
       "         -0.98930615, -0.7155773 ,  0.6364491 ,  0.857842  , -0.0269952 ],\n",
       "        [ 1.0292324 , -1.0438006 ,  1.1320484 , -0.23788777, -0.45579097,\n",
       "          0.96198946,  0.9735835 , -0.41560447, -1.306169  , -1.2131984 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.0855582 , -1.2274323 ,  0.96673447, -0.77631   , -1.2667382 ,\n",
       "         1.292454  ,  1.2918551 , -1.1437861 , -1.2506572 , -1.0588533 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5463855 ],\n",
       "        [-0.9202396 ],\n",
       "        [ 0.22403719],\n",
       "        [ 0.00174104],\n",
       "        [-1.2052808 ],\n",
       "        [ 1.3064965 ],\n",
       "        [ 1.3697035 ],\n",
       "        [-0.57117057],\n",
       "        [-0.9762542 ],\n",
       "        [-0.5062898 ]], dtype=float32),\n",
       " array([1.3912345], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_5(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure5_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 481.3947 - val_loss: 211.0675\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 104.0624 - val_loss: 59.7411\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 30.8967 - val_loss: 34.2426\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.5394 - val_loss: 17.9646\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 15.2548 - val_loss: 16.1715\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.7779 - val_loss: 15.4594\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.2565 - val_loss: 14.0884\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 9.6373 - val_loss: 12.4044\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.8807 - val_loss: 12.3278\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6333 - val_loss: 12.2121\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.2894 - val_loss: 11.9163\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.7823 - val_loss: 11.2867\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.0255 - val_loss: 11.1136\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.4960 - val_loss: 10.9380\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.4861 - val_loss: 11.5564\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 8.4621 - val_loss: 11.2406\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2766 - val_loss: 11.0500\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.3605 - val_loss: 11.2360\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8285 - val_loss: 11.7695\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.4407 - val_loss: 11.9412\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.8172 - val_loss: 11.8168\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7874 - val_loss: 11.4787\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6917 - val_loss: 11.1504\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7530 - val_loss: 11.4735\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8734 - val_loss: 10.9977\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6663 - val_loss: 11.0711\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5550 - val_loss: 10.9481\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.6031 - val_loss: 11.0764\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.5069 - val_loss: 11.0115\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6525 - val_loss: 10.8961\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4118 - val_loss: 10.6375\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4829 - val_loss: 10.7481\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3477 - val_loss: 10.4868\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5336 - val_loss: 10.8479\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5721 - val_loss: 10.7057\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5024 - val_loss: 10.8928\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7630 - val_loss: 10.6455\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5446 - val_loss: 10.7168\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3659 - val_loss: 10.3255\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4518 - val_loss: 11.3003\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1919 - val_loss: 11.8193\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5279 - val_loss: 10.7263\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2301 - val_loss: 10.2950\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2581 - val_loss: 9.9828\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2658 - val_loss: 9.9741\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0582 - val_loss: 10.4794\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5178 - val_loss: 11.3822\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5365 - val_loss: 10.2461\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1972 - val_loss: 10.1610\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0612 - val_loss: 10.1312\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0566 - val_loss: 10.0377\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0301 - val_loss: 10.6235\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8446 - val_loss: 10.0612\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3234 - val_loss: 10.0598\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0030 - val_loss: 9.7337\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0710 - val_loss: 10.0847\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2322 - val_loss: 9.9180\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8895 - val_loss: 9.8915\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9700 - val_loss: 9.7512\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8909 - val_loss: 10.5974\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0883 - val_loss: 10.3245\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0601 - val_loss: 9.8548\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1825 - val_loss: 9.8990\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1431 - val_loss: 10.6922\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5258 - val_loss: 9.7514\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2295 - val_loss: 10.0974\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7717 - val_loss: 10.0390\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 124us/step - loss: 6.9386 - val_loss: 9.3848\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.871 - 0s 109us/step - loss: 7.6235 - val_loss: 10.1675\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0960 - val_loss: 9.7996\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6779 - val_loss: 9.5047\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7044 - val_loss: 9.3571\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6742 - val_loss: 9.4451\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6776 - val_loss: 9.5682\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6381 - val_loss: 9.4929\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6909 - val_loss: 9.5134\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5682 - val_loss: 9.6160\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6271 - val_loss: 9.6456\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.6627 - val_loss: 9.7178\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6739 - val_loss: 9.7037\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7320 - val_loss: 10.1762\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6526 - val_loss: 9.4991\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8850 - val_loss: 9.4168\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8580 - val_loss: 9.5578\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9313 - val_loss: 9.9833\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8555 - val_loss: 9.6733\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8602 - val_loss: 9.7180\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5263 - val_loss: 9.6819\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 6.5579 - val_loss: 9.5105\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5593 - val_loss: 9.2702\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6946 - val_loss: 9.4462\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5340 - val_loss: 9.9310\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6789 - val_loss: 10.1018\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4894 - val_loss: 10.7970\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5416 - val_loss: 11.0165\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9537 - val_loss: 10.4802\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6256 - val_loss: 9.6912\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6907 - val_loss: 9.3605\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4685 - val_loss: 9.5962\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6467 - val_loss: 9.5854\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4594 - val_loss: 9.7888\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8032 - val_loss: 9.4405\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6128 - val_loss: 10.1526\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9121 - val_loss: 9.8149\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1360 - val_loss: 8.8206\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4158 - val_loss: 9.3143\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3958 - val_loss: 9.4076\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3499 - val_loss: 9.1286\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3087 - val_loss: 8.9191\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5658 - val_loss: 10.0595\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4555 - val_loss: 9.4525\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4597 - val_loss: 9.0965\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3544 - val_loss: 9.8185\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4933 - val_loss: 9.4110\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5323 - val_loss: 9.1428\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2794 - val_loss: 11.2976\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7419 - val_loss: 10.0881\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0312 - val_loss: 9.2496\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8017 - val_loss: 10.0264\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2909 - val_loss: 8.6363\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1472 - val_loss: 8.9871\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4145 - val_loss: 9.8965\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5378 - val_loss: 9.7699\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9524 - val_loss: 9.5285\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5084 - val_loss: 9.5063\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2548 - val_loss: 8.9606\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6954 - val_loss: 10.3190\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5540 - val_loss: 9.7720\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5163 - val_loss: 9.0034\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2127 - val_loss: 9.0218\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1106 - val_loss: 8.7988\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1927 - val_loss: 9.2996\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4069 - val_loss: 9.0433\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5240 - val_loss: 10.6251\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7823 - val_loss: 9.2831\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2412 - val_loss: 8.9666\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0208 - val_loss: 8.9460\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1940 - val_loss: 8.9388\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0353 - val_loss: 8.9109\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0510 - val_loss: 9.5906\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9794 - val_loss: 9.1225\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9112 - val_loss: 8.7125\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9977 - val_loss: 8.8867\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0218 - val_loss: 8.9985\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9036 - val_loss: 9.3776\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1309 - val_loss: 9.0986\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1890 - val_loss: 9.1293\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7989 - val_loss: 9.3588\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9046 - val_loss: 10.0181\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9498 - val_loss: 9.2121\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2748 - val_loss: 9.8890\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1569 - val_loss: 8.9019\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9537 - val_loss: 9.2107\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7361 - val_loss: 8.9292\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8862 - val_loss: 8.8278\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8362 - val_loss: 9.1153\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9555 - val_loss: 9.1307\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1267 - val_loss: 9.2131\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8465 - val_loss: 9.3817\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9934 - val_loss: 9.8231\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7788 - val_loss: 9.9670\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8707 - val_loss: 9.0477\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9909 - val_loss: 10.5110\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9626 - val_loss: 10.1739\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0829 - val_loss: 10.7266\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9571 - val_loss: 11.2928\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2883 - val_loss: 9.4996\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9541 - val_loss: 8.9896\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2813 - val_loss: 8.7748\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7549 - val_loss: 9.6296\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6884 - val_loss: 9.7511\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7572 - val_loss: 9.2450\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7829 - val_loss: 8.9442\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7316 - val_loss: 9.4939\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4787 - val_loss: 8.9008\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5742 - val_loss: 9.7037\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7308 - val_loss: 9.8484\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2476 - val_loss: 8.8435\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6701 - val_loss: 9.2557\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5806 - val_loss: 9.6202\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4596 - val_loss: 9.7177\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3449 - val_loss: 10.6981\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7534 - val_loss: 9.0356\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6685 - val_loss: 9.2916\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6058 - val_loss: 9.8303\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6646 - val_loss: 9.2990\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3600 - val_loss: 9.4355\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5172 - val_loss: 9.3101\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5859 - val_loss: 9.1288\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4937 - val_loss: 9.1662\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3973 - val_loss: 9.2654\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4166 - val_loss: 9.2191\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5167 - val_loss: 9.1546\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2748 - val_loss: 9.6112\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3290 - val_loss: 9.5514\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.5946 - val_loss: 9.5192\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6355 - val_loss: 10.4948\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8919 - val_loss: 9.5526\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5759 - val_loss: 10.1611\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0567 - val_loss: 9.8641\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6887 - val_loss: 10.6488\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3742 - val_loss: 9.7009\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4303 - val_loss: 8.9774\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5122 - val_loss: 9.6875\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2031 - val_loss: 9.9523\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6533 - val_loss: 9.3371\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5048 - val_loss: 9.7372\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7070 - val_loss: 9.6724\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3076 - val_loss: 9.8141\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2351 - val_loss: 10.0130\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2876 - val_loss: 9.6008\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1231 - val_loss: 9.6301\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1387 - val_loss: 9.3272\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2766 - val_loss: 9.9652\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1604 - val_loss: 10.0292\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1891 - val_loss: 9.3364\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2207 - val_loss: 9.9868\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1998 - val_loss: 10.3259\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1012 - val_loss: 10.0205\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1964 - val_loss: 9.6620\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1489 - val_loss: 9.9758\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 5.0828 - val_loss: 9.6009\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1521 - val_loss: 10.0698\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3431 - val_loss: 10.1354\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9425 - val_loss: 9.9751\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1052 - val_loss: 10.1111\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1533 - val_loss: 10.2298\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4684 - val_loss: 11.7675\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6756 - val_loss: 9.9090\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3525 - val_loss: 10.5427\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0846 - val_loss: 10.1868\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3398 - val_loss: 11.2074\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2683 - val_loss: 9.7688\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0076 - val_loss: 10.3862\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9450 - val_loss: 10.7865\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2842 - val_loss: 12.4078\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1657 - val_loss: 12.0542\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0156 - val_loss: 10.4604\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0144 - val_loss: 9.9187\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9116 - val_loss: 10.7628\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0527 - val_loss: 10.1817\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9703 - val_loss: 10.7784\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9843 - val_loss: 10.6632\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0885 - val_loss: 10.1882\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4890 - val_loss: 10.4043\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8858 - val_loss: 10.2675\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1075 - val_loss: 10.7455\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2875 - val_loss: 10.8132\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1103 - val_loss: 10.8416\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9481 - val_loss: 9.5168\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9680 - val_loss: 10.4132\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3516 - val_loss: 10.8064\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9846 - val_loss: 10.0620\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0237 - val_loss: 9.8166\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9198 - val_loss: 10.7734\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8185 - val_loss: 10.1600\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8547 - val_loss: 10.5828\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9015 - val_loss: 10.1715\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3283 - val_loss: 10.1587\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8480 - val_loss: 10.5830\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7539 - val_loss: 10.3688\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8570 - val_loss: 11.0547\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7970 - val_loss: 10.2908\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8960 - val_loss: 10.5415\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8448 - val_loss: 10.3668\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7011 - val_loss: 10.2283\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9685 - val_loss: 11.0742\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2795 - val_loss: 10.4139\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4791 - val_loss: 11.6399\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7783 - val_loss: 10.8307\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2662 - val_loss: 10.9497\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1052 - val_loss: 10.8085\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0468 - val_loss: 10.2816\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0127 - val_loss: 10.7204\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7501 - val_loss: 10.4784\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8439 - val_loss: 10.6010\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9255 - val_loss: 10.8080\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0353 - val_loss: 10.5182\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0356 - val_loss: 10.6978\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7390 - val_loss: 10.6161\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7158 - val_loss: 10.5141\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1022 - val_loss: 11.2793\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8726 - val_loss: 11.0824\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8024 - val_loss: 11.6665\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6728 - val_loss: 10.3633\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9533 - val_loss: 10.6675\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9413 - val_loss: 10.7450\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8177 - val_loss: 10.9644\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9416 - val_loss: 10.8263\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7041 - val_loss: 11.8939\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2065 - val_loss: 12.7976\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2439 - val_loss: 11.7230\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9247 - val_loss: 11.0446\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1347 - val_loss: 10.8252\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9349 - val_loss: 10.2528\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1066 - val_loss: 11.2839\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2801 - val_loss: 10.7358\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8077 - val_loss: 11.0424\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.3795 - val_loss: 10.8064\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8591 - val_loss: 9.9946\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7417 - val_loss: 10.8429\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8638 - val_loss: 11.2246\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7963 - val_loss: 10.9854\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7833 - val_loss: 11.1279\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7369 - val_loss: 11.0101\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5638 - val_loss: 10.4582\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7009 - val_loss: 11.3042\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7146 - val_loss: 10.8203\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5655 - val_loss: 10.4322\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6632 - val_loss: 11.2596\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5990 - val_loss: 11.0139\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6118 - val_loss: 10.4391\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9728 - val_loss: 11.0325\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7128 - val_loss: 10.6107\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8490 - val_loss: 11.8119\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0335 - val_loss: 10.7424\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2137 - val_loss: 10.6779\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9724 - val_loss: 11.6032\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2802 - val_loss: 10.2267\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9098 - val_loss: 11.2360\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0270 - val_loss: 12.6653\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1587 - val_loss: 10.9697\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7387 - val_loss: 11.4217\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6796 - val_loss: 11.1816\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5192 - val_loss: 11.5429\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4559 - val_loss: 11.6448\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7947 - val_loss: 10.8006\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1094 - val_loss: 10.5098\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7943 - val_loss: 11.2802\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0161 - val_loss: 11.4238\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5922 - val_loss: 11.1353\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7667 - val_loss: 11.0569\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7028 - val_loss: 11.2653\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8816 - val_loss: 12.0787\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1821 - val_loss: 11.5868\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7349 - val_loss: 11.4663\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6756 - val_loss: 10.8384\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6840 - val_loss: 10.9547\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4487 - val_loss: 11.0065\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6314 - val_loss: 10.8298\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7147 - val_loss: 11.6128\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8964 - val_loss: 11.5430\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4607 - val_loss: 11.2013\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5009 - val_loss: 10.8222\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4744 - val_loss: 11.2868\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8095 - val_loss: 12.0952\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1454 - val_loss: 11.4566\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4956 - val_loss: 12.3161\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1753 - val_loss: 12.4241\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9119 - val_loss: 9.9986\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5033 - val_loss: 10.4821\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6293 - val_loss: 11.3043\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7896 - val_loss: 10.6359\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5960 - val_loss: 10.5534\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5367 - val_loss: 11.0012\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4290 - val_loss: 10.4589\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6437 - val_loss: 10.8548\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3468 - val_loss: 10.4683\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4906 - val_loss: 10.4362\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6177 - val_loss: 11.5085\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9234 - val_loss: 11.1416\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7202 - val_loss: 11.9146\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7258 - val_loss: 10.6711\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5288 - val_loss: 11.1106\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4536 - val_loss: 10.8592\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4333 - val_loss: 11.3554\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.8928 - val_loss: 10.7209\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5868 - val_loss: 11.3174\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5239 - val_loss: 11.1840\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7834 - val_loss: 11.7350\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5927 - val_loss: 12.0162\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4881 - val_loss: 11.0424\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4946 - val_loss: 10.1571\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6551 - val_loss: 10.7024\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4362 - val_loss: 10.8347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4163 - val_loss: 10.7740\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4303 - val_loss: 10.5965\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0478 - val_loss: 10.7679\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6401 - val_loss: 11.1927\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4165 - val_loss: 10.6666\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3919 - val_loss: 11.4596\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6282 - val_loss: 10.6963\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3564 - val_loss: 11.1606\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4327 - val_loss: 10.4685\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4491 - val_loss: 10.7679\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4096 - val_loss: 10.9748\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4967 - val_loss: 10.3384\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3631 - val_loss: 10.1611\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3843 - val_loss: 10.5968\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3458 - val_loss: 10.9742\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8524 - val_loss: 11.8216\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0375 - val_loss: 11.0161\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6393 - val_loss: 10.1612\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5422 - val_loss: 11.2619\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5724 - val_loss: 11.1855\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6741 - val_loss: 10.4523\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4257 - val_loss: 10.7052\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4225 - val_loss: 11.1906\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3599 - val_loss: 10.6605\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4717 - val_loss: 10.2649\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4341 - val_loss: 10.7538\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3984 - val_loss: 10.8137\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4974 - val_loss: 10.3413\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5017 - val_loss: 10.9630\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3854 - val_loss: 10.4235\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3138 - val_loss: 10.6674\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4142 - val_loss: 10.8946\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3234 - val_loss: 10.5526\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5015 - val_loss: 10.5735\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5147 - val_loss: 10.4528\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3273 - val_loss: 10.5552\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4966 - val_loss: 11.1045\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5698 - val_loss: 10.5146\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3495 - val_loss: 12.4198\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2255 - val_loss: 10.4605\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7036 - val_loss: 10.7109\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5494 - val_loss: 10.5224\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3392 - val_loss: 10.3730\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3451 - val_loss: 10.5493\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3157 - val_loss: 10.9589\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4850 - val_loss: 10.1694\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3032 - val_loss: 10.3919\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2967 - val_loss: 11.0980\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4071 - val_loss: 11.5132\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8279 - val_loss: 10.8663\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8930 - val_loss: 11.3009\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5599 - val_loss: 10.6522\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2273 - val_loss: 10.8806\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6703 - val_loss: 10.4658\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2912 - val_loss: 10.3226\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2933 - val_loss: 10.9079\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2691 - val_loss: 10.9838\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5784 - val_loss: 10.7490\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8916 - val_loss: 11.2668\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6035 - val_loss: 11.8607\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8195 - val_loss: 11.3001\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4389 - val_loss: 10.8743\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3397 - val_loss: 10.9848\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5497 - val_loss: 11.5014\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5355 - val_loss: 10.2087\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7061 - val_loss: 11.0048\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4805 - val_loss: 10.7170\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4357 - val_loss: 10.9946\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6069 - val_loss: 10.9194\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9148 - val_loss: 11.2379\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5805 - val_loss: 10.8278\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.3849 - val_loss: 11.4783\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5711 - val_loss: 11.1221\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5596 - val_loss: 10.4698\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8238 - val_loss: 11.5772\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2478 - val_loss: 12.3001\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.0182 - val_loss: 10.5964\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9966 - val_loss: 11.0830\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9243 - val_loss: 11.6454\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0293 - val_loss: 11.2845\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9619 - val_loss: 11.8783\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9921 - val_loss: 11.5961\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4607 - val_loss: 10.7882\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3193 - val_loss: 11.4371\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4942 - val_loss: 11.5284\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3061 - val_loss: 11.5706\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6395 - val_loss: 11.9962\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2676 - val_loss: 12.1418\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4503 - val_loss: 11.3360\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4539 - val_loss: 11.0404\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4684 - val_loss: 11.4817\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7830 - val_loss: 10.5837\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5234 - val_loss: 10.9094\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3561 - val_loss: 11.7474\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3596 - val_loss: 10.8881\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2813 - val_loss: 11.1560\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2026 - val_loss: 11.4564\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5856 - val_loss: 10.8369\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1998 - val_loss: 11.1067\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3419 - val_loss: 10.8014\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5013 - val_loss: 12.2220\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5501 - val_loss: 11.7624\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6567 - val_loss: 11.3229\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2568 - val_loss: 10.8273\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2295 - val_loss: 10.7212\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3707 - val_loss: 11.5556\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3694 - val_loss: 11.1292\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3934 - val_loss: 10.8186\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1970 - val_loss: 10.9501\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3657 - val_loss: 11.0925\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2336 - val_loss: 10.8751\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2487 - val_loss: 10.8930\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2363 - val_loss: 11.1178\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3080 - val_loss: 11.6480\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4038 - val_loss: 11.6541\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5297 - val_loss: 10.9980\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2251 - val_loss: 10.8447\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3604 - val_loss: 11.4937\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6519 - val_loss: 11.4292\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3335 - val_loss: 11.1698\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2397 - val_loss: 11.1869\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5931 - val_loss: 12.0058\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8577 - val_loss: 12.1609\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8976 - val_loss: 12.5373\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9100 - val_loss: 11.2428\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8450 - val_loss: 12.1862\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4796 - val_loss: 11.2991\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5225 - val_loss: 11.1116\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2240 - val_loss: 11.7133\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1863 - val_loss: 11.3742\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1721 - val_loss: 10.5638\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2965 - val_loss: 11.3823\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1055 - val_loss: 12.2887\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3078 - val_loss: 11.3528\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3409 - val_loss: 11.1814\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1939 - val_loss: 11.8473\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3648 - val_loss: 11.2475\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2973 - val_loss: 11.4275\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3373 - val_loss: 11.3004\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1740 - val_loss: 11.1958\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2790 - val_loss: 12.3045\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3242 - val_loss: 11.3074\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2098 - val_loss: 11.1006\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1170 - val_loss: 11.5137\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.5863 - val_loss: 12.3127\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7053 - val_loss: 11.6599\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4840 - val_loss: 11.0255\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1607 - val_loss: 11.9007\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5622 - val_loss: 11.6987\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0817 - val_loss: 11.3138\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3003 - val_loss: 11.2172\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1109 - val_loss: 11.7350\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1544 - val_loss: 12.1815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5673 - val_loss: 12.4565\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6823 - val_loss: 12.1342\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4641 - val_loss: 11.0043\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3143 - val_loss: 12.0572\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4452 - val_loss: 14.0013\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6894 - val_loss: 12.5542\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9369 - val_loss: 11.1683\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4472 - val_loss: 11.8880\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0852 - val_loss: 11.9531\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4764 - val_loss: 11.4089\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4564 - val_loss: 12.4500\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5293 - val_loss: 11.5055\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1899 - val_loss: 11.1365\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1527 - val_loss: 11.5414\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0773 - val_loss: 11.4478\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1512 - val_loss: 11.6391\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5514 - val_loss: 11.9269\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1555 - val_loss: 11.8764\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1382 - val_loss: 13.0201\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7034 - val_loss: 11.7942\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2673 - val_loss: 11.6522\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1956 - val_loss: 11.4623\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0620 - val_loss: 12.2230\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1319 - val_loss: 11.9754\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2457 - val_loss: 11.9959\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1320 - val_loss: 11.7522\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1616 - val_loss: 11.7624\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0867 - val_loss: 12.0617\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1328 - val_loss: 11.8095\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1703 - val_loss: 11.4645\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1658 - val_loss: 11.3443\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1033 - val_loss: 12.1713\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0364 - val_loss: 11.3768\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0947 - val_loss: 12.0819\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0020 - val_loss: 11.5043\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1518 - val_loss: 11.4945\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2502 - val_loss: 12.3037\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3743 - val_loss: 12.4183\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2942 - val_loss: 11.3970\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2222 - val_loss: 11.5886\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2376 - val_loss: 12.2794\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1626 - val_loss: 11.7428\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2703 - val_loss: 11.5086\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0504 - val_loss: 12.0826\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1681 - val_loss: 11.5428\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0635 - val_loss: 11.2588\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1585 - val_loss: 12.3740\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2125 - val_loss: 11.5077\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.1161 - val_loss: 11.4255\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1091 - val_loss: 11.6100\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1248 - val_loss: 11.4716\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0042 - val_loss: 12.1769\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0052 - val_loss: 12.3473\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1049 - val_loss: 11.7648\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8120 - val_loss: 12.3234\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3143 - val_loss: 11.7843\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0995 - val_loss: 12.1673\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.1350 - val_loss: 11.8676\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7101 - val_loss: 12.2897\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8720 - val_loss: 12.4633\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4637 - val_loss: 12.3780\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1548 - val_loss: 12.1082\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4064 - val_loss: 12.1085\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9308 - val_loss: 12.1960\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0750 - val_loss: 11.9810\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2354 - val_loss: 11.8691\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1846 - val_loss: 12.1922\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1278 - val_loss: 12.1195\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9785 - val_loss: 12.0044\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2729 - val_loss: 11.9541\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1794 - val_loss: 11.8036\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9416 - val_loss: 11.6915\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0090 - val_loss: 12.3753\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1900 - val_loss: 11.9507\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9947 - val_loss: 11.8846\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5127 - val_loss: 11.5437\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1422 - val_loss: 12.3703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0924 - val_loss: 11.6916\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1271 - val_loss: 11.2573\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9445 - val_loss: 11.8410\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0212 - val_loss: 12.4358\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1353 - val_loss: 11.6447\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7647 - val_loss: 14.2057\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5215 - val_loss: 12.8711\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7722 - val_loss: 12.3182\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0884 - val_loss: 12.4399\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1208 - val_loss: 12.0759\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9451 - val_loss: 11.9372\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9946 - val_loss: 12.0986\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1126 - val_loss: 12.6150\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0509 - val_loss: 12.4371\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6449 - val_loss: 12.3282\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2906 - val_loss: 12.4009\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0630 - val_loss: 12.2221\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1231 - val_loss: 11.7828\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9392 - val_loss: 12.4847\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1692 - val_loss: 12.1441\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2239 - val_loss: 12.4661\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9464 - val_loss: 11.8605\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1415 - val_loss: 12.0983\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1073 - val_loss: 11.9176\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1020 - val_loss: 12.1729\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9758 - val_loss: 12.5177\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0235 - val_loss: 11.9094\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8504 - val_loss: 12.6200\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3841 - val_loss: 12.1557\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9932 - val_loss: 11.5839\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0493 - val_loss: 12.3787\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0276 - val_loss: 12.2215\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2288 - val_loss: 13.2594\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.5926 - val_loss: 11.9072\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4605 - val_loss: 12.6368\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3363 - val_loss: 12.3989\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2213 - val_loss: 12.1765\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1469 - val_loss: 12.3329\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 3.9021 - val_loss: 12.1426\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0241 - val_loss: 12.0969\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3098 - val_loss: 13.2074\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0722 - val_loss: 12.3028\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0213 - val_loss: 12.1378\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9329 - val_loss: 11.9089\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2450 - val_loss: 12.4689\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1336 - val_loss: 11.8083\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1503 - val_loss: 12.2930\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3942 - val_loss: 13.7867\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2993 - val_loss: 12.0635\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5722 - val_loss: 13.3210\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1885 - val_loss: 12.1558\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1919 - val_loss: 12.7850\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9313 - val_loss: 11.6624\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0602 - val_loss: 11.7883\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1505 - val_loss: 12.7415\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9369 - val_loss: 12.4834\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0143 - val_loss: 12.5812\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3051 - val_loss: 12.0201\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8306 - val_loss: 12.2783\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1060 - val_loss: 11.8699\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9570 - val_loss: 12.7895\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0137 - val_loss: 12.6322\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3446 - val_loss: 12.0399\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0742 - val_loss: 12.4118\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0657 - val_loss: 12.9743\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0431 - val_loss: 12.3172\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9956 - val_loss: 12.5080\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8578 - val_loss: 11.9370\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0308 - val_loss: 12.0596\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9190 - val_loss: 12.7245\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1205 - val_loss: 12.3448\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8148 - val_loss: 12.4921\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0832 - val_loss: 12.2105\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0270 - val_loss: 12.4702\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9623 - val_loss: 12.5433\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9551 - val_loss: 12.6308\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1423 - val_loss: 11.4143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.1300 - val_loss: 12.7176\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3822 - val_loss: 12.8309\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2682 - val_loss: 12.1900\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.8605 - val_loss: 12.1359\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9337 - val_loss: 12.1389\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1037 - val_loss: 12.5676\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0230 - val_loss: 12.8351\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3908 - val_loss: 12.3422\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.048 - 0s 105us/step - loss: 3.8737 - val_loss: 12.4264\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0320 - val_loss: 12.3010\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9300 - val_loss: 11.8628\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8952 - val_loss: 11.9224\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9191 - val_loss: 12.1832\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9661 - val_loss: 12.6855\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3478 - val_loss: 13.3122\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1019 - val_loss: 12.2857\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9487 - val_loss: 11.9842\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8618 - val_loss: 11.6667\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8030 - val_loss: 12.2627\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9046 - val_loss: 13.1257\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1522 - val_loss: 12.6614\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0707 - val_loss: 12.2308\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3255 - val_loss: 12.8444\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4524 - val_loss: 13.5626\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0377 - val_loss: 12.2772\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3222 - val_loss: 12.7284\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4825 - val_loss: 13.5404\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7107 - val_loss: 12.8995\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9108 - val_loss: 13.4445\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9565 - val_loss: 12.0811\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8766 - val_loss: 11.9269\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8675 - val_loss: 12.4359\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8183 - val_loss: 12.8034\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8197 - val_loss: 12.3506\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.9382 - val_loss: 12.5126\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0696 - val_loss: 12.9070\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0906 - val_loss: 12.5692\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0542 - val_loss: 12.5161\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9315 - val_loss: 12.1566\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9502 - val_loss: 12.1638\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3491 - val_loss: 12.7812\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0228 - val_loss: 12.6415\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9237 - val_loss: 12.1149\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8023 - val_loss: 11.8519\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9836 - val_loss: 12.4710\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8599 - val_loss: 12.8028\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8986 - val_loss: 12.4719\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7897 - val_loss: 12.3692\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8322 - val_loss: 12.6818\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1273 - val_loss: 12.7921\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2438 - val_loss: 12.5671\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0446 - val_loss: 12.9132\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8858 - val_loss: 12.5452\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9269 - val_loss: 12.8082\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4533 - val_loss: 13.2475\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2678 - val_loss: 12.8270\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2980 - val_loss: 13.4250\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2009 - val_loss: 14.4114\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8349 - val_loss: 12.6927\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2882 - val_loss: 12.1970\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9124 - val_loss: 12.7996\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0222 - val_loss: 12.8020\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8397 - val_loss: 12.2551\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7801 - val_loss: 12.4426\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0345 - val_loss: 12.5596\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7988 - val_loss: 12.4495\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9646 - val_loss: 12.6663\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0201 - val_loss: 12.8150\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8752 - val_loss: 12.5062\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9011 - val_loss: 13.1444\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8793 - val_loss: 12.5508\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0227 - val_loss: 12.9670\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0286 - val_loss: 12.8003\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1198 - val_loss: 13.3638\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1544 - val_loss: 11.4047\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9378 - val_loss: 12.9467\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.0205 - val_loss: 12.2734\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1312 - val_loss: 12.6683\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9862 - val_loss: 12.8910\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3068 - val_loss: 13.3273\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0396 - val_loss: 13.1687\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8481 - val_loss: 12.3985\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8513 - val_loss: 12.3536\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8746 - val_loss: 12.8815\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1060 - val_loss: 12.6469\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8197 - val_loss: 12.3664\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8908 - val_loss: 12.3159\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8865 - val_loss: 13.1334\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9473 - val_loss: 12.2400\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8152 - val_loss: 12.9879\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1894 - val_loss: 12.6656\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0327 - val_loss: 12.4599\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1317 - val_loss: 12.9104\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9172 - val_loss: 12.2674\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8035 - val_loss: 12.9109\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0777 - val_loss: 12.8735\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2929 - val_loss: 12.3462\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0265 - val_loss: 12.5100\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0765 - val_loss: 12.2926\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8514 - val_loss: 12.6792\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7571 - val_loss: 12.7209\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9014 - val_loss: 13.2503\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1032 - val_loss: 12.5351\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8537 - val_loss: 13.0035\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3491 - val_loss: 12.4051\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2737 - val_loss: 12.5410\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9088 - val_loss: 13.2935\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9211 - val_loss: 12.4957\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9258 - val_loss: 12.7779\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1062 - val_loss: 12.8418\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0996 - val_loss: 11.9121\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8455 - val_loss: 12.9525\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8609 - val_loss: 12.3825\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8584 - val_loss: 12.5719\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8277 - val_loss: 13.3404\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0906 - val_loss: 12.9948\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2476 - val_loss: 12.5158\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9963 - val_loss: 12.5636\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9703 - val_loss: 12.0001\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1804 - val_loss: 13.1609\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9990 - val_loss: 12.8767\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9073 - val_loss: 12.3742\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7735 - val_loss: 11.9818\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1140 - val_loss: 13.2717\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9841 - val_loss: 12.2585\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3444 - val_loss: 12.1272\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9359 - val_loss: 13.4240\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9052 - val_loss: 13.7092\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3299 - val_loss: 12.9535\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9268 - val_loss: 12.0941\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8083 - val_loss: 12.2681\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8092 - val_loss: 12.3779\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9212 - val_loss: 12.8462\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9102 - val_loss: 12.8256\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8709 - val_loss: 12.1861\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8367 - val_loss: 12.4487\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9973 - val_loss: 13.4655\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0648 - val_loss: 12.8006\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9132 - val_loss: 12.5585\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1179 - val_loss: 13.0361\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1297 - val_loss: 12.8575\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8160 - val_loss: 12.6291\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7787 - val_loss: 12.4903\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0155 - val_loss: 13.2548\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0265 - val_loss: 12.4610\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2552 - val_loss: 13.2003\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5984 - val_loss: 13.0311\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7786 - val_loss: 12.5386\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8194 - val_loss: 12.1177\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8724 - val_loss: 12.9139\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9404 - val_loss: 12.5520\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8897 - val_loss: 13.2828\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0728 - val_loss: 12.4497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8167 - val_loss: 12.7485\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9686 - val_loss: 12.3360\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3841 - val_loss: 13.0537\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0359 - val_loss: 13.3552\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9516 - val_loss: 12.8598\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8334 - val_loss: 12.9180\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9156 - val_loss: 12.9501\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8779 - val_loss: 13.1575\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8441 - val_loss: 12.2963\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0610 - val_loss: 13.0632\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0635 - val_loss: 13.1965\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0898 - val_loss: 13.5842\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2618 - val_loss: 12.8240\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7716 - val_loss: 13.0316\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0602 - val_loss: 12.7575\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0780 - val_loss: 13.0930\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9082 - val_loss: 12.4579\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9461 - val_loss: 12.6000\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9503 - val_loss: 12.3684\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9507 - val_loss: 12.6894\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7261 - val_loss: 13.0787\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8864 - val_loss: 12.5876\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2142 - val_loss: 12.1124\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8420 - val_loss: 12.7698\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1414 - val_loss: 13.2698\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8984 - val_loss: 12.2297\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7841 - val_loss: 12.7374\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9444 - val_loss: 12.4211\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0083 - val_loss: 12.6022\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0572 - val_loss: 13.3015\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8415 - val_loss: 13.3000\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0938 - val_loss: 12.7905\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9406 - val_loss: 13.3529\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8402 - val_loss: 12.6138\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9845 - val_loss: 12.8442\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9615 - val_loss: 13.1189\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2380 - val_loss: 13.2067\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9030 - val_loss: 12.2775\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0295 - val_loss: 13.4975\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3443 - val_loss: 12.8554\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0623 - val_loss: 12.3615\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8770 - val_loss: 12.8712\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7382 - val_loss: 12.8518\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7354 - val_loss: 13.1488\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8917 - val_loss: 12.7489\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7979 - val_loss: 12.4636\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7644 - val_loss: 12.5332\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8421 - val_loss: 13.4012\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7732 - val_loss: 12.8883\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7905 - val_loss: 12.6400\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8218 - val_loss: 12.4975\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7925 - val_loss: 12.4454\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7348 - val_loss: 12.7087\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7161 - val_loss: 12.7121\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6889 - val_loss: 12.8310\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6825 - val_loss: 12.4900\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6974 - val_loss: 12.5229\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4955 - val_loss: 13.5156\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7541 - val_loss: 12.8734\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7670 - val_loss: 13.4995\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9982 - val_loss: 12.8616\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7004 - val_loss: 12.9630\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6802 - val_loss: 12.9828\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9868 - val_loss: 12.6868\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7039 - val_loss: 12.9976\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7682 - val_loss: 12.4395\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6758 - val_loss: 12.9145\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6914 - val_loss: 13.0992\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7623 - val_loss: 13.1326\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2496 - val_loss: 13.3735\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8794 - val_loss: 12.7623\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8825 - val_loss: 13.1641\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4498 - val_loss: 14.1177\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4765 - val_loss: 13.5537\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3468 - val_loss: 13.1241\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8374 - val_loss: 13.2062\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8010 - val_loss: 12.2379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8656 - val_loss: 13.2620\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9451 - val_loss: 14.4127\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6447 - val_loss: 12.5520\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9814 - val_loss: 12.7219\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0734 - val_loss: 13.4563\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2206 - val_loss: 13.5664\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4420 - val_loss: 13.4480\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3028 - val_loss: 13.1369\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1987 - val_loss: 12.7831\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9509 - val_loss: 12.4948\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9560 - val_loss: 12.2969\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7716 - val_loss: 12.9997\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9331 - val_loss: 12.9368\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7529 - val_loss: 12.8206\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7626 - val_loss: 13.5890\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6405 - val_loss: 13.4915\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8414 - val_loss: 13.0072\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7254 - val_loss: 13.1470\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8501 - val_loss: 12.3044\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8402 - val_loss: 13.1920\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9005 - val_loss: 12.6689\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7603 - val_loss: 12.5511\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7151 - val_loss: 12.6019\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7429 - val_loss: 12.3584\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6548 - val_loss: 12.9452\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7375 - val_loss: 12.9439\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6787 - val_loss: 13.1623\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7713 - val_loss: 12.3544\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1066 - val_loss: 12.7383\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7979 - val_loss: 12.9111\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8738 - val_loss: 13.3765\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9252 - val_loss: 14.2319\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3399 - val_loss: 12.3209\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0834 - val_loss: 13.1895\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9332 - val_loss: 13.6351\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8328 - val_loss: 13.0311\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9734 - val_loss: 13.1812\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7330 - val_loss: 12.2507\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7506 - val_loss: 12.6814\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6814 - val_loss: 12.9106\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7545 - val_loss: 13.1371\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0191 - val_loss: 12.7791\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9979 - val_loss: 12.6877\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9000 - val_loss: 12.8505\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6808 - val_loss: 12.7367\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6963 - val_loss: 12.6058\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8562 - val_loss: 13.3083\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7679 - val_loss: 13.3089\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7118 - val_loss: 12.6821\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8189 - val_loss: 12.9769\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7677 - val_loss: 12.7563\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7288 - val_loss: 12.6947\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7094 - val_loss: 13.0087\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7295 - val_loss: 13.3463\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7880 - val_loss: 12.2222\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6924 - val_loss: 13.6918\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1771 - val_loss: 12.5458\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1717 - val_loss: 12.9465\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0594 - val_loss: 12.9257\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8230 - val_loss: 13.6430\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9395 - val_loss: 12.6329\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7747 - val_loss: 12.9682\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8643 - val_loss: 13.1345\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0361 - val_loss: 12.6753\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7752 - val_loss: 12.6072\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8582 - val_loss: 12.8625\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0533 - val_loss: 13.0661\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7632 - val_loss: 12.8156\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6999 - val_loss: 13.0705\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8540 - val_loss: 12.8907\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0621 - val_loss: 12.9360\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6176 - val_loss: 13.5034\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7549 - val_loss: 13.2061\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2007 - val_loss: 13.5402\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8825 - val_loss: 13.1366\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8094 - val_loss: 13.7729\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7198 - val_loss: 12.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7630 - val_loss: 12.9430\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6669 - val_loss: 13.0172\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6877 - val_loss: 12.8849\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8401 - val_loss: 12.9996\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9854 - val_loss: 13.4278\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6766 - val_loss: 12.7849\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6294 - val_loss: 12.5243\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6603 - val_loss: 13.2259\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8571 - val_loss: 12.5389\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.8038 - val_loss: 12.8915\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7849 - val_loss: 13.5627\n",
      "7.877942618677172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.74368   ,  1.7133001 ,  0.25153714,  2.4530897 , -0.60649467,\n",
       "         -2.7800236 ,  0.17223884, -2.328713  , -4.0844045 , -1.2376384 ],\n",
       "        [ 1.0465827 , -1.7843602 ,  1.4337764 ,  4.73622   , -0.36702675,\n",
       "         -1.1285523 ,  0.33607495, -0.06482416,  2.180313  , -0.21038881],\n",
       "        [ 0.03352092,  0.30336407, -0.34950233,  6.152499  ,  0.50855255,\n",
       "          0.92281836, -0.5262648 , -0.00723746, -0.36696988, -0.12285184],\n",
       "        [-0.18452948,  1.9864478 , -1.5635035 , -1.8603466 ,  1.039308  ,\n",
       "          0.15082143, -0.9892345 ,  0.79273665, -1.713075  ,  0.9506096 ],\n",
       "        [ 0.09883347, -1.344607  ,  0.18596324,  0.49432337,  1.0163242 ,\n",
       "          0.04321545,  0.0231383 , -0.40512738,  0.25061497, -0.2389735 ],\n",
       "        [ 0.15451103,  0.04828291,  1.5626211 , -0.742409  ,  0.5056832 ,\n",
       "         -1.8813436 ,  0.41858533, -0.05174155,  0.7161473 ,  2.3426726 ],\n",
       "        [ 0.06106795, -0.3065995 ,  1.3134176 ,  0.16400507, -2.64701   ,\n",
       "         -0.01288791, -0.07531811,  0.01175054,  0.4806601 ,  2.2091794 ]],\n",
       "       dtype=float32),\n",
       " array([-0.9780647 , -2.445286  ,  1.658681  ,  1.1485801 , -2.2540355 ,\n",
       "        -1.8308169 ,  0.3009299 , -0.02194796, -1.3360567 ,  2.5024679 ],\n",
       "       dtype=float32),\n",
       " array([[-0.75722563,  0.85762167,  0.6351876 ,  0.55968106, -0.209027  ,\n",
       "         -0.29882506, -0.20562026,  0.23038854, -0.25883228, -0.9820235 ,\n",
       "         -0.98934567, -0.9749388 ,  0.35396573, -0.94398236,  0.7800043 ],\n",
       "        [-0.85447395,  0.8768389 ,  0.9085825 ,  0.6889692 ,  0.11325039,\n",
       "         -0.45167276, -0.7446144 ,  0.5101594 , -0.00238773, -0.30401075,\n",
       "         -0.21900812, -0.06326477,  0.19180222, -0.20134269,  0.47382504],\n",
       "        [-0.28332466,  0.30462706,  0.99007094,  0.754858  , -0.54956156,\n",
       "         -0.8856667 , -1.045949  ,  1.0174694 , -0.667394  , -0.18157563,\n",
       "         -0.62253606, -0.278741  ,  0.37038788, -0.07823692,  0.78047454],\n",
       "        [ 0.21832639, -0.4507233 , -0.47517502,  0.02019753,  0.6310976 ,\n",
       "          0.2546845 ,  0.34294298,  0.0145213 ,  0.33405373,  0.36851087,\n",
       "         -0.09570028, -0.10883788, -0.09156302, -0.05237805, -0.72894436],\n",
       "        [-0.35855016,  0.51370156,  0.6291388 ,  0.03192215, -0.4517301 ,\n",
       "         -0.1918026 ,  0.14040504,  0.09508602,  0.10674301, -0.5695027 ,\n",
       "         -0.1451604 , -0.63610095,  0.03194423, -0.38779616,  0.12633678],\n",
       "        [-0.43299705,  0.6978381 ,  0.7829565 ,  0.5421178 , -0.51398176,\n",
       "         -0.10694637, -0.3983516 ,  0.32645863, -0.29683617, -0.03053862,\n",
       "         -0.73596483, -0.50704354,  0.02833096, -0.58425653,  0.11188422],\n",
       "        [ 0.34249744, -0.5649968 ,  0.00289567, -0.53854537,  0.61257285,\n",
       "          0.11653038,  0.6814842 , -0.0371815 , -0.05509986,  0.02048012,\n",
       "         -0.09604481,  0.39887065, -0.07221367,  0.75169176, -0.10197394],\n",
       "        [-0.9998165 ,  1.1758001 ,  0.49783096,  1.3901801 , -0.86608297,\n",
       "         -1.0568392 , -1.2864482 ,  0.68783987, -0.94379985, -0.9040329 ,\n",
       "         -0.741856  , -0.5213255 ,  0.52389246, -0.99948525,  1.1966783 ],\n",
       "        [ 1.4287118 , -1.4457719 , -1.3458416 , -1.8948507 ,  0.9984659 ,\n",
       "          1.7865052 ,  1.3680114 , -1.317179  ,  1.2536696 ,  1.4595478 ,\n",
       "          1.5064286 ,  1.8137718 , -0.5197139 ,  1.6126584 , -1.6629117 ],\n",
       "        [ 0.6675701 , -0.44279385, -0.782631  , -0.79635525,  0.08594849,\n",
       "          0.8328674 ,  0.04701278, -0.47342902,  0.24342692,  0.718609  ,\n",
       "          0.00811484,  0.80540764, -0.33467564,  0.43255565, -0.59426886]],\n",
       "       dtype=float32),\n",
       " array([ 1.2550924, -1.2766192, -1.223342 , -1.2018367,  1.0732132,\n",
       "         1.1220605,  1.1861911, -1.1163018,  0.8796131,  1.2116805,\n",
       "         1.1588337,  1.301344 ,  0.2736695,  1.2824273, -1.1073697],\n",
       "       dtype=float32),\n",
       " array([[ 0.8857206 ],\n",
       "        [-1.0986356 ],\n",
       "        [-0.8295848 ],\n",
       "        [-0.80008376],\n",
       "        [ 0.27139568],\n",
       "        [ 0.7276015 ],\n",
       "        [ 0.65960103],\n",
       "        [-0.43646547],\n",
       "        [ 0.1969263 ],\n",
       "        [ 0.72589284],\n",
       "        [ 0.57122684],\n",
       "        [ 1.1908396 ],\n",
       "        [ 0.00219836],\n",
       "        [ 1.0430313 ],\n",
       "        [-0.60784495]], dtype=float32),\n",
       " array([1.410224], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_6(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure6_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1529 - val_loss: 0.0248\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0323 - val_loss: 0.0295\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0424 - val_loss: 0.0117\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0226 - val_loss: 0.0167\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0132\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0188 - val_loss: 0.0099\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0037\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.7571e-04 - val_loss: 0.0041\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.6607e-04 - val_loss: 0.0044\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.7208e-04 - val_loss: 0.0043\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 9.5905e-04 - val_loss: 0.0043\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.4790e-04 - val_loss: 0.0043\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.2825e-04 - val_loss: 0.0047\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.9071e-04 - val_loss: 0.0042\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9536e-04 - val_loss: 0.0042\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8948e-04 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.8517e-04 - val_loss: 0.0046\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.3869e-04 - val_loss: 0.0047\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9902e-04 - val_loss: 0.0046\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9522e-04 - val_loss: 0.0045\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7971e-04 - val_loss: 0.0045\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9292e-04 - val_loss: 0.0046\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.3422e-04 - val_loss: 0.0046\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.0770e-04 - val_loss: 0.0048\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4006e-04 - val_loss: 0.0046\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6123e-04 - val_loss: 0.0047\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.5157e-04 - val_loss: 0.0049\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.5590e-04 - val_loss: 0.0049\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.0760e-04 - val_loss: 0.0056\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "0.005807793699204922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 7.90543318e-01,  2.32354224e-01,  1.73854142e-01,\n",
       "         -2.78059579e-02, -9.76069033e-01],\n",
       "        [ 2.95857191e-01,  1.90213144e-01, -5.27419269e-01,\n",
       "         -5.06315827e-01,  1.34484458e+00],\n",
       "        [-6.74630523e-01, -1.68378785e-01, -3.54216546e-01,\n",
       "         -8.35229158e-02,  6.96405351e-01],\n",
       "        [ 1.62511981e+00,  3.28252614e-01,  8.35627094e-02,\n",
       "          1.88651234e-01,  1.71503916e-01],\n",
       "        [ 2.46903226e-01,  2.08581388e-01,  6.49674356e-01,\n",
       "         -6.07086420e-01, -1.95436239e-01],\n",
       "        [ 8.01487923e-01,  5.34134448e-01, -1.93868652e-01,\n",
       "         -4.12134290e-01, -1.71646520e-01],\n",
       "        [-6.40931487e-01,  5.79086132e-03, -1.09814811e+00,\n",
       "         -1.51550606e-01,  5.69350958e-01],\n",
       "        [-1.13744754e-04, -1.06804550e-01, -5.24082661e-01,\n",
       "          9.20144916e-01,  7.10977390e-02],\n",
       "        [-5.00250041e-01,  3.56020182e-01,  2.50352803e-03,\n",
       "         -2.81417519e-01, -1.06464517e+00],\n",
       "        [-3.13393176e-01, -1.09153891e+00, -8.71781588e-01,\n",
       "          1.15934849e+00,  1.04047704e+00],\n",
       "        [ 8.60715270e-01, -2.38955721e-01, -3.01602364e-01,\n",
       "         -2.06009582e-01, -7.41921723e-01],\n",
       "        [-1.72780097e-01, -1.27096486e+00,  8.45801294e-01,\n",
       "          6.66541100e-01,  5.20744145e-01],\n",
       "        [ 6.96471930e-01, -6.42444551e-01,  8.19146752e-01,\n",
       "          2.28611365e-01,  1.00101578e+00],\n",
       "        [ 3.29142004e-01, -1.72292888e-01,  4.69702780e-01,\n",
       "         -1.22456086e+00, -1.54949272e+00],\n",
       "        [ 5.02969623e-01, -1.20888852e-01,  1.77625552e-01,\n",
       "         -2.95551598e-01,  6.42492235e-01],\n",
       "        [ 3.14597666e-01,  5.20312667e-01, -4.15916787e-03,\n",
       "         -3.62143159e-01, -8.03212762e-01],\n",
       "        [-8.08039755e-02,  2.31870189e-01,  1.77946091e-01,\n",
       "          4.14932892e-02,  1.93858176e-01],\n",
       "        [ 3.77980888e-01,  2.01022848e-01,  1.53538585e-01,\n",
       "         -4.47068959e-01, -5.95574796e-01],\n",
       "        [ 3.83830905e-01,  9.13055420e-01,  6.92558408e-01,\n",
       "         -1.03108060e+00, -5.03042758e-01],\n",
       "        [-2.23822546e+00, -6.58491075e-01,  3.07283551e-02,\n",
       "          2.60602772e-01, -1.46232927e+00],\n",
       "        [-1.44817340e+00,  4.58062291e-01, -2.41077855e-01,\n",
       "         -6.30778313e-01,  1.84734154e+00],\n",
       "        [-5.39723992e-01, -9.74529982e-01,  2.28446275e-01,\n",
       "          6.61648214e-02,  4.24075961e-01]], dtype=float32),\n",
       " array([-0.6007881 ,  0.04194535,  0.06342658,  0.4104888 ,  0.40487066],\n",
       "       dtype=float32),\n",
       " array([[-0.13216808, -0.2220075 , -0.31643376, -0.5284392 ,  0.6249205 ],\n",
       "        [ 0.828386  ,  0.26769915,  0.28889984, -0.09954207, -1.2017856 ],\n",
       "        [-0.02755373, -0.19066864,  0.66056806, -0.40135032,  0.09106375],\n",
       "        [-0.14375272, -0.23077041,  0.43701673, -0.4586494 , -0.2505082 ],\n",
       "        [ 0.85474813, -0.02722282, -0.03122802, -0.50720257, -0.701651  ]],\n",
       "       dtype=float32),\n",
       " array([-0.20166461,  0.01504008, -0.02369169,  0.02408698,  0.07093401],\n",
       "       dtype=float32),\n",
       " array([[-0.10749068],\n",
       "        [-0.00167176],\n",
       "        [-0.3409443 ],\n",
       "        [ 0.16010568],\n",
       "        [ 0.2826632 ]], dtype=float32),\n",
       " array([0.1220872], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_1(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure1_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1683 - val_loss: 0.0360\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0462 - val_loss: 0.0160\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0314 - val_loss: 0.0124\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0179 - val_loss: 0.0055\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0144 - val_loss: 0.0072\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0144 - val_loss: 0.0058\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0050\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0097 - val_loss: 0.0044\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0101 - val_loss: 0.0047\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0102 - val_loss: 0.0044\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 133us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0077\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0081\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 111us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0072\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0077\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0060\n",
      "0.005600437521934509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-8.86414051e-01,  1.32266268e-01, -1.06589937e+00,\n",
       "          4.00397003e-01,  5.15955202e-02],\n",
       "        [-1.96940199e-01, -8.16048443e-01,  2.59725302e-01,\n",
       "         -1.29662350e-01, -1.44067153e-01],\n",
       "        [ 1.47310555e-01, -9.64490592e-01,  4.53336149e-01,\n",
       "          2.50594735e-01,  5.14563560e-01],\n",
       "        [-9.31146368e-02, -7.14909554e-01, -2.95087576e-01,\n",
       "         -4.96858805e-02,  5.22911549e-01],\n",
       "        [ 2.57437527e-01, -3.09611052e-01, -3.59715484e-02,\n",
       "         -7.91981071e-02,  9.79757249e-01],\n",
       "        [ 2.96865609e-02,  1.47427118e+00, -8.40211153e-01,\n",
       "         -4.46789265e-01, -7.21016619e-03],\n",
       "        [ 9.64553207e-02, -2.65305758e-01,  3.88571233e-01,\n",
       "          1.22244157e-01, -8.33731294e-01],\n",
       "        [-1.11125760e-01,  2.14378268e-01, -3.01701814e-01,\n",
       "          1.06715865e-01,  4.27079767e-01],\n",
       "        [ 4.55073593e-03, -8.37093443e-02, -1.65488869e-02,\n",
       "         -1.18894996e-02,  1.09087563e+00],\n",
       "        [-7.22066283e-01,  2.58447956e-02, -5.81416070e-01,\n",
       "         -5.46959281e-01, -8.78940761e-01],\n",
       "        [ 8.71861428e-02, -4.32480127e-02,  1.60410261e+00,\n",
       "         -2.89253801e-01, -3.92344534e-01],\n",
       "        [ 1.21510386e-01,  5.32164514e-01,  6.60734624e-02,\n",
       "         -4.43586022e-01, -8.68390977e-01],\n",
       "        [ 2.38265485e-01,  1.91530490e+00,  2.52034396e-01,\n",
       "          6.14019670e-02, -1.81255829e+00],\n",
       "        [-6.07728541e-01,  2.30701184e+00,  9.62001264e-01,\n",
       "          6.00091398e-01,  7.51714706e-01],\n",
       "        [-3.47173363e-01, -2.61640906e-01,  5.99175811e-01,\n",
       "          4.27508831e-01, -1.88160375e-01],\n",
       "        [-1.07096517e+00,  3.63221973e-01, -4.69054937e-01,\n",
       "          6.44655228e-02, -5.52063346e-01],\n",
       "        [ 7.38705158e-01, -1.16811013e+00,  4.65922713e-01,\n",
       "          3.18430036e-01,  8.09445441e-01],\n",
       "        [ 9.92113650e-01,  6.30502284e-01, -1.60211131e-01,\n",
       "         -1.41677022e+00, -3.14478934e-01],\n",
       "        [ 1.27267861e+00,  4.22228277e-01,  1.54450130e+00,\n",
       "          8.59608889e-01,  1.30728984e+00],\n",
       "        [-7.47964859e-01, -1.42829239e+00,  6.50639594e-01,\n",
       "          5.37076652e-01,  5.05389988e-01],\n",
       "        [ 2.31107211e+00, -2.51128888e+00, -4.95410636e-02,\n",
       "          1.54270837e-03,  1.27403104e+00],\n",
       "        [ 1.01796305e+00, -7.33307600e-01, -7.25392066e-03,\n",
       "         -9.26086247e-01,  2.30159998e+00]], dtype=float32),\n",
       " array([ 0.47776246, -0.8495688 , -0.10561778,  0.09554575,  0.28109428],\n",
       "       dtype=float32),\n",
       " array([[-0.21534342, -0.08555876, -0.01775082,  0.09395412, -0.05115049,\n",
       "          0.0277629 , -0.41394696, -0.40234637,  0.2569812 , -0.6654133 ],\n",
       "        [ 0.6019148 ,  0.4828133 , -0.18376343,  0.00646004,  0.6065882 ,\n",
       "          0.19030721,  0.4550413 ,  0.48212057, -0.02347017,  0.40130576],\n",
       "        [-0.28432125,  0.04600853, -0.33946773, -0.22867988,  0.05187596,\n",
       "          0.60075533,  0.20160414,  0.34544754,  0.4719669 ,  0.2564943 ],\n",
       "        [ 0.07102382, -0.07673097,  0.10056007,  0.2481948 ,  0.0436555 ,\n",
       "         -0.28598684, -0.5511101 , -0.21006079, -0.17124118, -0.41639033],\n",
       "        [ 0.8702968 ,  0.51823604, -0.39577433, -0.11298657,  0.6501252 ,\n",
       "         -0.19187777,  0.6698174 ,  0.1430183 , -0.43446204,  0.6120359 ]],\n",
       "       dtype=float32),\n",
       " array([-0.05614972, -0.06015318,  0.04659317,  0.14831898, -0.10443347,\n",
       "         0.03410399, -0.09901205,  0.26187503,  0.02379658,  0.05019978],\n",
       "       dtype=float32),\n",
       " array([[ 0.10127126],\n",
       "        [ 0.0455775 ],\n",
       "        [-0.22444376],\n",
       "        [-0.00596442],\n",
       "        [ 0.06514117],\n",
       "        [ 0.01878049],\n",
       "        [ 0.07723973],\n",
       "        [ 0.05923926],\n",
       "        [ 0.00422908],\n",
       "        [ 0.28249276]], dtype=float32),\n",
       " array([0.10231949], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_2(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure2_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2007 - val_loss: 0.0213\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0526 - val_loss: 0.0670\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0526 - val_loss: 0.0317\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0297 - val_loss: 0.0147\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0222 - val_loss: 0.0093\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0173 - val_loss: 0.0061\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0160 - val_loss: 0.0053\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0144 - val_loss: 0.0051\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0131 - val_loss: 0.0050\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0125 - val_loss: 0.0051\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0117 - val_loss: 0.0053\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0055\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.008 - 0s 119us/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0051\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "0.010777363553643227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.7279971e-02,  2.9943231e-01,  9.0393430e-01, -5.9731603e-01,\n",
       "         -8.9487797e-01],\n",
       "        [ 7.4676394e-01,  9.5974666e-01,  4.1767249e-01, -6.1545318e-01,\n",
       "          4.0519825e-01],\n",
       "        [ 1.5307154e-01, -3.4375250e-02, -5.5678999e-01,  1.4221966e-01,\n",
       "          1.1012456e+00],\n",
       "        [ 1.4741780e-01, -5.9487408e-01,  3.9456129e-01, -5.5574030e-01,\n",
       "          4.5671150e-01],\n",
       "        [ 1.9418897e-01,  3.7098399e-01,  3.1744611e-02,  3.4804888e-02,\n",
       "          3.0280882e-01],\n",
       "        [ 8.0029619e-01, -4.4479106e-02,  1.0647094e+00,  2.0831505e-02,\n",
       "         -9.9530458e-01],\n",
       "        [-1.6531734e-01,  3.3767572e-01,  4.5795050e-01, -5.6175864e-01,\n",
       "          2.7772254e-01],\n",
       "        [-5.0927210e-01, -2.9762965e-01,  3.1207989e-03, -4.9909785e-02,\n",
       "         -1.0117702e-01],\n",
       "        [ 1.1878413e+00, -2.9919842e-01,  5.6227803e-01,  1.7936060e-01,\n",
       "          1.4655854e-01],\n",
       "        [-1.2192087e+00, -1.0600297e-01, -3.9776513e-01, -1.2437670e+00,\n",
       "         -5.8558998e-03],\n",
       "        [ 1.6043921e-01, -1.4175625e-03, -8.2887006e-01, -1.8686600e-01,\n",
       "          5.3442824e-01],\n",
       "        [-6.9469976e-01,  2.2893095e-01, -5.4996324e-01,  1.9779958e-01,\n",
       "         -3.5499558e-01],\n",
       "        [-1.0972999e+00,  6.5582645e-01, -6.6566050e-01,  6.1805457e-02,\n",
       "         -7.7715605e-02],\n",
       "        [ 7.4489719e-01,  3.7638408e-01, -1.3572576e+00,  5.3229028e-01,\n",
       "         -2.3023663e+00],\n",
       "        [ 3.1781381e-01,  3.2468188e-01, -3.2519966e-02,  2.6710099e-01,\n",
       "         -5.6573756e-02],\n",
       "        [-5.7915646e-01,  3.3687776e-01, -4.7439456e-01, -4.5107502e-02,\n",
       "         -1.9014592e-01],\n",
       "        [ 3.1876773e-01,  3.7939870e-01,  7.2728056e-01, -7.3343605e-02,\n",
       "          1.1202354e-01],\n",
       "        [-1.3546364e-01, -2.3796998e-01, -7.5992244e-01,  3.4116596e-01,\n",
       "         -3.1052008e-01],\n",
       "        [ 1.1350139e+00,  1.8868284e-01, -1.5783920e+00,  1.3759550e+00,\n",
       "          7.2843647e-01],\n",
       "        [-3.4885805e-02, -7.0356920e-02, -5.5380899e-01,  3.8403082e-01,\n",
       "         -6.5989047e-01],\n",
       "        [ 2.3664115e-01,  1.9268160e-01,  2.4276690e-01, -6.9488108e-02,\n",
       "          2.4213250e+00],\n",
       "        [ 7.4473321e-01,  2.9683068e-01, -2.4475642e-01, -2.5811476e-01,\n",
       "          4.4175845e-01]], dtype=float32),\n",
       " array([-0.19786337,  0.1827922 ,  0.16861667, -0.03963304,  0.770659  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.11573602, -0.10775026,  0.6615631 , -0.07909615, -0.30253035,\n",
       "         -0.17462616, -0.12392967,  0.02309626,  0.18876544,  0.2985633 ,\n",
       "          0.04148746,  0.2387417 ,  0.03620301,  0.18616572,  0.02775781],\n",
       "        [ 0.3313625 ,  0.2845937 , -0.4804527 , -0.01168137,  0.03525345,\n",
       "          0.02027821,  0.08967269,  0.09798816,  0.60494953, -0.1521761 ,\n",
       "         -0.21747492, -0.36032295,  0.0680557 , -0.2384691 , -0.20463356],\n",
       "        [ 0.12993859,  0.09047153, -0.631632  , -0.0142677 ,  0.04053967,\n",
       "          0.19410908,  0.03742978,  0.00481692,  0.06837734,  0.21178514,\n",
       "          0.15439901, -0.1730913 , -0.21252602,  0.23110929, -0.03128812],\n",
       "        [-0.2829278 , -0.06327979, -0.5821462 , -0.01387686, -0.10302874,\n",
       "          0.17517492,  0.12986538, -0.06040189,  0.15350261,  0.4548786 ,\n",
       "          0.09100946, -0.38990575, -0.15657789,  0.38178527,  0.03253926],\n",
       "        [-0.439926  , -0.0724906 , -0.90476924,  0.24671987, -0.15115257,\n",
       "         -0.11945795, -0.06206245, -0.01556699, -0.3761147 ,  0.696393  ,\n",
       "          0.16657837, -0.34296107,  0.04043178,  0.27075443,  0.07280933]],\n",
       "       dtype=float32),\n",
       " array([-0.13910744, -0.17290248,  0.29214674, -0.14831161,  0.15449849,\n",
       "         0.27331632,  0.08741938, -0.11445253, -0.25496578, -0.18529022,\n",
       "         0.14275463,  0.23880817, -0.23910575,  0.19925477,  0.1287416 ],\n",
       "       dtype=float32),\n",
       " array([[ 4.7366817e-02],\n",
       "        [ 5.2217478e-03],\n",
       "        [ 3.9033529e-01],\n",
       "        [-1.7986573e-02],\n",
       "        [ 9.0819616e-03],\n",
       "        [ 1.8541142e-04],\n",
       "        [-6.3580443e-04],\n",
       "        [ 2.1297021e-03],\n",
       "        [ 1.2149673e-02],\n",
       "        [-1.2236924e-01],\n",
       "        [-6.7254570e-03],\n",
       "        [ 3.5409842e-02],\n",
       "        [ 2.7795462e-03],\n",
       "        [-1.7004283e-02],\n",
       "        [-2.4921738e-03]], dtype=float32),\n",
       " array([0.25618544], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_3(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure3_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.2790\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.1931 - val_loss: 0.2062\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.1142 - val_loss: 0.0549\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0507 - val_loss: 0.0476\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0330 - val_loss: 0.0224\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0300 - val_loss: 0.0084\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0187 - val_loss: 0.0150\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0195 - val_loss: 0.0082\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0178 - val_loss: 0.0089\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0168 - val_loss: 0.0080\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0154 - val_loss: 0.0071\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0143 - val_loss: 0.0068\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0141 - val_loss: 0.0066\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0132 - val_loss: 0.0064\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0128 - val_loss: 0.0061\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0120 - val_loss: 0.0059\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0116 - val_loss: 0.0057\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0116 - val_loss: 0.0055\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0109 - val_loss: 0.0054\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0107 - val_loss: 0.0051\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0100 - val_loss: 0.0049\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0102 - val_loss: 0.0048\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0077 - val_loss: 0.0040\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0066\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0088\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0088\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0079\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0100\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0077\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0076\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0081\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0077\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0073\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0092\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 111us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9167e-04 - val_loss: 0.0041\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0064\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9036e-04 - val_loss: 0.0045\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0053\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 9.9881e-04 - val_loss: 0.0043\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.5886e-04 - val_loss: 0.0048\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 139us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.7841e-04 - val_loss: 0.0043\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.5932e-04 - val_loss: 0.0041\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9642e-04 - val_loss: 0.0043\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7017e-04 - val_loss: 0.0044\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7149e-04 - val_loss: 0.0047\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9036e-04 - val_loss: 0.0041\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.9058e-04 - val_loss: 0.0049\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8964e-04 - val_loss: 0.0042\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.4419e-04 - val_loss: 0.0046\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7330e-04 - val_loss: 0.0045\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 9.1978e-04 - val_loss: 0.0041\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9551e-04 - val_loss: 0.0045\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.4720e-04 - val_loss: 0.0046\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.3928e-04 - val_loss: 0.0043\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.8392e-04 - val_loss: 0.0048\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7666e-04 - val_loss: 0.0044\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.2747e-04 - val_loss: 0.0051\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 9.6409e-04 - val_loss: 0.0042\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 9.1579e-04 - val_loss: 0.0047\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "0.007034643553197384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.91722715,  0.5758587 , -0.48319298,  0.09125376,  0.18881534,\n",
       "         -0.5500606 ,  0.6568376 , -0.34302747,  1.1065031 ,  0.31543764],\n",
       "        [-0.22976469,  0.18436275,  0.88150686, -0.15410334,  0.40616852,\n",
       "         -0.38216847,  0.4086883 ,  0.05774491, -0.24632572, -0.35412735],\n",
       "        [ 0.04137542, -0.02945466, -0.24242914,  0.1576141 ,  0.31490415,\n",
       "          0.31700954, -0.08720154, -0.26713595, -0.62284094, -0.85291266],\n",
       "        [ 0.17443593,  0.69980097,  0.40314028, -0.20724869,  0.24679257,\n",
       "         -0.27532348,  0.46421412, -0.5459795 ,  0.02271914, -0.5305957 ],\n",
       "        [-0.7128735 ,  0.4603771 ,  0.7173084 , -0.44174784, -0.02010692,\n",
       "         -0.07123181, -0.12152233, -0.07929222, -0.11691898, -0.01606906],\n",
       "        [ 0.23514627,  0.24979448,  0.8008222 , -0.45207635,  0.2740736 ,\n",
       "         -0.60224795,  0.13710837, -0.1515329 , -0.1866573 ,  1.0521652 ],\n",
       "        [ 0.29991263,  0.05605277, -0.53563833,  0.13459536,  0.57570606,\n",
       "          0.15409581,  0.6616179 , -0.14943887, -0.5408451 , -0.4805466 ],\n",
       "        [-0.18854962,  0.45663694, -0.1787188 ,  0.06614483,  0.20173097,\n",
       "         -0.18214574,  0.36675453, -0.0818899 ,  0.20588131, -0.14956966],\n",
       "        [ 0.3684081 ,  0.52314585,  0.8905    , -0.521046  , -0.05645593,\n",
       "         -0.1322946 ,  0.34640023,  0.3840879 , -0.1593144 ,  0.07088675],\n",
       "        [-0.6125395 ,  0.08313064, -0.88575786, -0.41865724, -0.08601509,\n",
       "          0.63971347,  1.2188821 , -0.3821357 ,  0.01053454, -0.07737347],\n",
       "        [ 0.08454733,  0.7079177 , -0.21766031, -0.0800367 ,  0.16333881,\n",
       "          0.6236038 , -0.5848712 ,  0.4202566 , -0.17674536,  0.56688887],\n",
       "        [ 0.2889305 ,  0.48985472, -0.6307387 , -0.5905004 , -0.12525971,\n",
       "          1.4093302 , -0.5919959 ,  0.1968673 , -0.49016917, -0.04910697],\n",
       "        [-0.60444075,  0.57503945, -0.8423169 ,  0.26745796, -0.21090937,\n",
       "          0.63025016, -0.1318432 ,  0.05293012, -0.23667945,  1.0176611 ],\n",
       "        [ 0.27228773,  0.4606548 ,  1.2709712 , -0.07745194,  0.13487744,\n",
       "          0.3271579 , -0.2670593 , -0.05939558,  0.37607557,  2.147893  ],\n",
       "        [ 0.09356181,  0.05341493,  0.37083554,  0.0557406 ,  0.1693127 ,\n",
       "         -0.3049234 , -0.3343846 ,  0.37733552,  0.38726032, -0.0970616 ],\n",
       "        [-0.54358834,  0.34006605,  0.41739258, -0.08928745, -0.5375172 ,\n",
       "         -0.28310034,  0.04707542,  0.11787196,  1.0348862 , -0.13574605],\n",
       "        [ 0.4465937 , -0.02478526, -0.15758705, -0.30581814,  0.47681096,\n",
       "         -0.3625183 , -0.32495278,  0.46206102, -0.32084677, -0.08162921],\n",
       "        [ 0.07056614,  0.31336468, -0.22758818, -0.29908544, -0.17592944,\n",
       "          0.23256762,  0.2695043 ,  0.4429008 , -0.81260276,  0.04738025],\n",
       "        [-1.1282679 ,  0.04855511,  1.3740451 , -0.00247876,  0.02093891,\n",
       "         -0.02833556, -0.8159899 ,  0.02532656, -0.21677352,  0.05498214],\n",
       "        [ 0.06648006,  0.13262479, -0.04941767,  0.17520982,  0.50089943,\n",
       "          0.42872134, -0.21539377, -0.03434232,  1.1174808 , -1.4481494 ],\n",
       "        [ 0.4284922 ,  0.38217804, -0.8087499 ,  0.2758466 , -0.16802435,\n",
       "         -0.02273034,  0.65163153, -0.09372477, -1.5938878 , -1.7957686 ],\n",
       "        [ 0.81305367,  0.21635354,  0.48365015, -0.31322193, -0.29373324,\n",
       "          0.37846988,  0.86959463,  0.12579994, -1.023883  , -0.2980567 ]],\n",
       "       dtype=float32),\n",
       " array([-0.3727261 ,  0.3837793 , -0.49284446, -0.14970157,  0.07113484,\n",
       "         0.0147678 , -0.1194014 ,  0.01173038, -0.479223  , -0.70585155],\n",
       "       dtype=float32),\n",
       " array([[ 2.28329971e-01,  4.39239219e-02,  2.42911533e-01,\n",
       "          7.36409128e-02, -3.27225141e-02],\n",
       "        [ 3.52573842e-01, -3.54908735e-01, -4.85911369e-02,\n",
       "          1.52461365e-01, -3.01004827e-01],\n",
       "        [-1.08473115e-01, -5.08713007e-01,  5.90213120e-01,\n",
       "          6.59766436e-01, -1.31537110e-01],\n",
       "        [-2.38199025e-01,  3.04369271e-01,  1.86181054e-01,\n",
       "          3.82819861e-01, -1.50963143e-02],\n",
       "        [-5.04015982e-01,  4.98512417e-01,  4.76828754e-01,\n",
       "         -2.90715158e-01,  5.34819722e-01],\n",
       "        [ 3.08639288e-01, -2.64634609e-01,  2.85265297e-01,\n",
       "          5.36674121e-03,  6.75027907e-01],\n",
       "        [ 3.70442450e-01, -1.10801667e-01,  3.41353476e-01,\n",
       "          6.86833501e-01, -1.74538735e-02],\n",
       "        [ 3.79993379e-01,  1.00031933e-02,  2.34016076e-01,\n",
       "         -4.86325771e-01,  5.02627227e-04],\n",
       "        [ 4.65064883e-01, -9.29861426e-01,  7.87418485e-01,\n",
       "          2.15892538e-01, -2.56480929e-02],\n",
       "        [ 4.44699407e-01,  8.09451044e-02, -1.08131200e-01,\n",
       "          1.41336903e-01,  7.45731354e-01]], dtype=float32),\n",
       " array([ 0.18343918, -0.14203675,  0.10221941,  0.22041577,  0.1310026 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.21841289],\n",
       "        [-0.0469468 ],\n",
       "        [ 0.24038416],\n",
       "        [ 0.1721291 ],\n",
       "        [ 0.3158475 ]], dtype=float32),\n",
       " array([0.20693812], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_4(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure4_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 351\n",
      "Trainable params: 351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.0167\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.1035 - val_loss: 0.0911\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0681 - val_loss: 0.0596\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0327 - val_loss: 0.0293\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0294 - val_loss: 0.0245\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0235 - val_loss: 0.0136\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0091\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0105 - val_loss: 0.0079\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0076\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0083\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0072\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0070\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0066\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0082\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 195us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0068\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0076\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0078\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 216us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 9.9157e-04 - val_loss: 0.0036\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 9.7974e-04 - val_loss: 0.0038\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0035\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0035\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.8936e-04 - val_loss: 0.0039\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 9.8182e-04 - val_loss: 0.0036\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8069e-04 - val_loss: 0.0037\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.8035e-04 - val_loss: 0.0040\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.8828e-04 - val_loss: 0.0036\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.3615e-04 - val_loss: 0.0036\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6795e-04 - val_loss: 0.0035\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6103e-04 - val_loss: 0.0036\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 9.6179e-04 - val_loss: 0.0038\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 9.9681e-04 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 9.3158e-04 - val_loss: 0.0037\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8537e-04 - val_loss: 0.0038\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "0.010381639935076237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.29963291e-01,  6.97986409e-02,  3.18107814e-01,\n",
       "         -1.08309366e-01, -1.01609623e+00,  2.52303839e-01,\n",
       "          9.79532301e-01, -6.45831823e-01,  4.06560242e-01,\n",
       "          4.37312245e-01],\n",
       "        [ 3.57357234e-01,  2.85633445e-01,  4.09653515e-01,\n",
       "         -1.03565884e+00,  5.35709321e-01,  8.43365669e-01,\n",
       "          1.93874687e-02, -2.84766018e-01,  9.46947560e-02,\n",
       "         -2.38238826e-01],\n",
       "        [ 2.53757000e-01, -1.04769789e-01, -5.15147485e-02,\n",
       "          4.35683936e-01,  6.39678121e-01,  2.06354886e-01,\n",
       "         -3.54564250e-01, -7.32497498e-02,  3.95391017e-01,\n",
       "          1.14027068e-01],\n",
       "        [ 4.07543153e-01, -1.18131131e-01,  1.56310606e+00,\n",
       "          4.61439699e-01,  1.17608897e-01,  6.46215677e-01,\n",
       "          3.94269168e-01, -3.24352942e-02, -1.07234858e-01,\n",
       "          8.60613137e-02],\n",
       "        [ 5.17353833e-01,  3.28013927e-01, -2.27990106e-01,\n",
       "         -7.66262293e-01,  1.09685101e-01,  1.07119095e+00,\n",
       "          3.97755176e-01, -4.59859163e-01,  1.14488497e-01,\n",
       "         -2.19459251e-01],\n",
       "        [ 4.63110864e-01,  1.18566521e-01,  2.14044020e-01,\n",
       "          9.40814242e-02, -8.93131346e-02,  7.62044013e-01,\n",
       "          5.58490157e-01, -7.56973103e-02,  2.53839940e-01,\n",
       "         -3.03160697e-02],\n",
       "        [ 1.09224916e-02,  2.46408895e-01,  4.31387186e-01,\n",
       "          3.88964266e-01,  2.69580692e-01,  4.08226997e-01,\n",
       "         -7.22585768e-02, -1.22561669e+00, -3.26425552e-01,\n",
       "         -1.74524829e-01],\n",
       "        [-3.72542083e-01, -2.46667877e-01, -3.86627734e-01,\n",
       "         -1.18465900e-01, -5.14688343e-02,  4.57056880e-01,\n",
       "         -2.55196482e-01, -1.23335585e-01,  6.22910187e-02,\n",
       "          1.81253463e-01],\n",
       "        [ 8.27450395e-01, -3.96328777e-01, -4.98602502e-02,\n",
       "          1.56103981e+00, -1.43062651e-01,  3.90283972e-01,\n",
       "          3.62232000e-01, -3.64682108e-01,  1.93385229e-01,\n",
       "          2.59966195e-01],\n",
       "        [-8.10459256e-01, -1.60812587e-01,  9.10220325e-01,\n",
       "          2.80745149e-01,  1.22264586e-01, -8.01889077e-02,\n",
       "         -7.21445620e-01, -1.37115324e+00, -5.83210528e-01,\n",
       "          1.47428960e-01],\n",
       "        [ 1.96502268e-01, -1.00364096e-01, -6.18292749e-01,\n",
       "          1.61082521e-01, -3.47411394e-01, -6.09436989e-01,\n",
       "         -9.05074298e-01, -3.96604091e-02,  2.55371463e-02,\n",
       "         -3.98399651e-01],\n",
       "        [-1.05488694e+00, -4.07664418e-01,  1.13984346e-01,\n",
       "         -3.07043850e-01,  4.22936212e-03, -1.76143622e+00,\n",
       "         -6.17522061e-01,  1.00285292e+00,  4.93530959e-01,\n",
       "         -5.00268638e-02],\n",
       "        [-1.07412152e-01,  2.20933884e-01,  2.19276503e-01,\n",
       "          5.52725606e-03,  2.81085879e-01, -5.28871775e-01,\n",
       "         -7.01595664e-01,  1.84282422e-01,  4.42089915e-01,\n",
       "         -2.81902879e-01],\n",
       "        [ 9.92959619e-01,  1.95595756e-01,  2.56747842e-01,\n",
       "          7.01018095e-01, -1.04599738e+00, -1.27601385e+00,\n",
       "         -9.16554868e-01,  7.99237072e-01, -2.20542505e-01,\n",
       "          6.02699101e-01],\n",
       "        [ 3.37601900e-01,  1.35918051e-01, -6.65492952e-01,\n",
       "          3.06446478e-03,  5.74861467e-02, -5.13132572e-01,\n",
       "         -4.91952933e-02,  3.31232965e-01, -3.91509116e-01,\n",
       "          2.72362292e-01],\n",
       "        [-2.82494485e-01,  4.37063962e-01,  4.90632594e-01,\n",
       "          2.01658174e-01, -3.69781822e-01,  1.49827078e-01,\n",
       "         -3.07355016e-01,  3.25740397e-01,  3.08992952e-01,\n",
       "         -3.75798464e-01],\n",
       "        [-7.38182440e-02,  1.32270098e-01, -4.42533530e-02,\n",
       "          6.57350793e-02,  2.22615838e-01, -3.37834537e-01,\n",
       "          5.03334999e-01,  4.19294447e-01, -3.84235412e-01,\n",
       "         -1.53096423e-01],\n",
       "        [-3.04199368e-01, -1.44587204e-01, -2.70718038e-01,\n",
       "         -1.30678225e+00, -1.86832890e-01, -3.61252964e-01,\n",
       "         -1.48416981e-01, -1.63377270e-01, -5.25149368e-02,\n",
       "         -3.35394740e-01],\n",
       "        [ 9.13255632e-01,  9.63806957e-02, -8.99059832e-01,\n",
       "          4.89448637e-01, -6.38349205e-02, -3.26721549e-01,\n",
       "         -2.34043285e-01,  1.50056994e+00,  1.60552159e-01,\n",
       "         -2.74070770e-01],\n",
       "        [-1.75164714e-01, -3.55458915e-01, -2.34161392e-01,\n",
       "         -7.66552091e-01, -2.07761094e-01, -1.51711896e-01,\n",
       "         -2.56364018e-01, -1.76576883e-01,  1.47607946e-03,\n",
       "          1.87757254e-01],\n",
       "        [ 2.75581144e-02, -3.81775796e-01,  8.29978138e-02,\n",
       "         -5.84626980e-02,  1.96364272e+00, -8.12852159e-02,\n",
       "          6.48455024e-01, -2.19902620e-01,  7.83582628e-02,\n",
       "         -3.72406375e-03],\n",
       "        [ 5.56757450e-01,  2.53344774e-01,  2.75978535e-01,\n",
       "         -3.10831964e-01,  5.74947059e-01, -2.99893320e-01,\n",
       "          7.39796236e-02,  3.80789727e-01,  4.34148699e-01,\n",
       "         -2.75432825e-01]], dtype=float32),\n",
       " array([-0.08745858, -0.0278525 ,  0.11636065, -0.16638465,  0.3850041 ,\n",
       "         0.06652552,  0.04887158, -0.18254595,  0.00279036, -0.04051613],\n",
       "       dtype=float32),\n",
       " array([[-0.8147243 , -0.20359205,  0.7678319 , -0.30263248,  0.01677634,\n",
       "          0.0135313 , -0.2576217 ,  0.00645752, -0.10112832, -0.11405347],\n",
       "        [-0.02438492, -0.2427319 , -0.37319115, -0.2909806 , -0.03629331,\n",
       "          0.16805808,  0.2279783 , -0.4426155 , -0.27426487,  0.04629314],\n",
       "        [-0.3878285 , -0.43886626, -0.07765433, -0.19679156,  0.10838653,\n",
       "         -0.10847296, -0.41549304, -0.43144268,  0.30872658,  0.54257506],\n",
       "        [ 0.08886836, -0.23855932, -0.10143247,  0.23163325, -0.2539309 ,\n",
       "          0.3562821 ,  0.5289828 ,  0.26900923,  0.24771133,  0.06515215],\n",
       "        [ 0.2717881 ,  0.01566291, -0.7007882 ,  0.5257866 , -0.12092736,\n",
       "          0.11813779,  0.40397877,  0.22098854, -0.23405679, -0.49493235],\n",
       "        [-0.00498134,  0.09197392, -0.05164604,  0.522785  , -0.19433172,\n",
       "          0.38157797,  0.2560299 ,  0.11451203, -0.00933926, -0.2867273 ],\n",
       "        [ 0.22587618,  0.0519385 , -0.12338525,  0.45592806, -0.04345161,\n",
       "         -0.02843695,  0.35659447,  0.13730077,  0.38879755,  0.3847226 ],\n",
       "        [ 0.31498915, -0.09428927, -0.49236652,  0.308227  , -0.01445851,\n",
       "          0.1194538 , -0.16737315,  0.10825174, -0.14807102,  0.18794626],\n",
       "        [ 0.15263729,  0.32715294,  0.07376692, -0.13034368, -0.1326316 ,\n",
       "          0.11082345, -0.25853363,  0.25911227,  0.26008052,  0.58319217],\n",
       "        [-0.43481097, -0.13244532, -0.3109859 ,  0.15890957,  0.16233599,\n",
       "          0.22311814,  0.03977824,  0.03691985,  0.4538232 ,  0.52825016]],\n",
       "       dtype=float32),\n",
       " array([ 0.04596692,  0.06712209,  0.0242743 , -0.00846729,  0.1493244 ,\n",
       "        -0.09625248,  0.0384399 ,  0.001705  , -0.08077575,  0.01716286],\n",
       "       dtype=float32),\n",
       " array([[-0.1659706 ],\n",
       "        [ 0.00967173],\n",
       "        [ 0.18600874],\n",
       "        [-0.39131668],\n",
       "        [-0.00092828],\n",
       "        [-0.00194082],\n",
       "        [-0.07756734],\n",
       "        [-0.00296969],\n",
       "        [ 0.01870381],\n",
       "        [ 0.08905807]], dtype=float32),\n",
       " array([0.07256951], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_5(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure5_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1427\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.1138 - val_loss: 0.0872\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0679 - val_loss: 0.0571\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0341 - val_loss: 0.0172\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0210 - val_loss: 0.0118\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0205 - val_loss: 0.0110\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0164 - val_loss: 0.0069\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0142 - val_loss: 0.0058\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0122 - val_loss: 0.0070\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0117 - val_loss: 0.0039\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0117 - val_loss: 0.0046\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0133 - val_loss: 0.0058\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0113 - val_loss: 0.0043\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0111 - val_loss: 0.0052\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0091 - val_loss: 0.0036\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0039\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0056\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0070\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0077\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0071\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0075\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0090\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0081\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0064\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0076\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0073\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0071\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0067\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0076\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0080\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9803e-04 - val_loss: 0.0047\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.5500e-04 - val_loss: 0.0046\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 9.8635e-04 - val_loss: 0.0055\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.3728e-04 - val_loss: 0.0043\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4989e-04 - val_loss: 0.0046\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0050\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6514e-04 - val_loss: 0.0043\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6439e-04 - val_loss: 0.0044\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.4418e-04 - val_loss: 0.0043\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.5685e-04 - val_loss: 0.0044\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.3870e-04 - val_loss: 0.0044\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.5400e-04 - val_loss: 0.0051\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.6378e-04 - val_loss: 0.0052\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 9.6485e-04 - val_loss: 0.0043\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.6087e-04 - val_loss: 0.0046\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7110e-04 - val_loss: 0.0049\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4396e-04 - val_loss: 0.0044\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.2548e-04 - val_loss: 0.0046\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.7706e-04 - val_loss: 0.0047\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 8.8538e-04 - val_loss: 0.0043\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0058\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.9977e-04 - val_loss: 0.0042\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0058\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0050\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.9780e-04 - val_loss: 0.0044\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.0038e-04 - val_loss: 0.0043\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7710e-04 - val_loss: 0.0042\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.8534e-04 - val_loss: 0.0043\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.2368e-04 - val_loss: 0.0046\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 9.1942e-04 - val_loss: 0.0048\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.4649e-04 - val_loss: 0.0049\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.8735e-04 - val_loss: 0.0051\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7314e-04 - val_loss: 0.0040\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.9323e-04 - val_loss: 0.0048\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 8.8897e-04 - val_loss: 0.0056\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.9127e-04 - val_loss: 0.0052\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.8520e-04 - val_loss: 0.0048\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.9710e-04 - val_loss: 0.0047\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.7313e-04 - val_loss: 0.0044\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.3923e-04 - val_loss: 0.0046\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.2331e-04 - val_loss: 0.0050\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.3223e-04 - val_loss: 0.0046\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7475e-04 - val_loss: 0.0048\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.9708e-04 - val_loss: 0.0046\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7594e-04 - val_loss: 0.0045\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7514e-04 - val_loss: 0.0046\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 9.0918e-04 - val_loss: 0.0055\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.1132e-04 - val_loss: 0.0047\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.3726e-04 - val_loss: 0.0043\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7876e-04 - val_loss: 0.0055\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6725e-04 - val_loss: 0.0048\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.2307e-04 - val_loss: 0.0058\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7252e-04 - val_loss: 0.0047\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.1352e-04 - val_loss: 0.0046\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 8.8809e-04 - val_loss: 0.0045\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.4954e-04 - val_loss: 0.0047\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 8.5914e-04 - val_loss: 0.0049\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.5474e-04 - val_loss: 0.0041\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0064\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.1156e-04 - val_loss: 0.0040\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.2919e-04 - val_loss: 0.0041\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0076\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.8852e-04 - val_loss: 0.0040\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.8609e-04 - val_loss: 0.0044\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.3592e-04 - val_loss: 0.0043\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.4409e-04 - val_loss: 0.0043\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.1198e-04 - val_loss: 0.0043\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 8.6924e-04 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 7.9767e-04 - val_loss: 0.0042\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 9.1749e-04 - val_loss: 0.0048\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 8.9808e-04 - val_loss: 0.0049\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 9.1341e-04 - val_loss: 0.0046\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 9.0932e-04 - val_loss: 0.0048\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.9082e-04 - val_loss: 0.0050\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.5628e-04 - val_loss: 0.0050\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.9034e-04 - val_loss: 0.0041\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.7565e-04 - val_loss: 0.0043\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.2246e-04 - val_loss: 0.0046\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 8.6168e-04 - val_loss: 0.0043\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9808e-04 - val_loss: 0.0044\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7170e-04 - val_loss: 0.0048\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 8.4737e-04 - val_loss: 0.0044\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.5794e-04 - val_loss: 0.0050\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6949e-04 - val_loss: 0.0053\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 8.7792e-04 - val_loss: 0.0047\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.9843e-04 - val_loss: 0.0043\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.1402e-04 - val_loss: 0.0046\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.1414e-04 - val_loss: 0.0048\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.1627e-04 - val_loss: 0.0044\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 8.9584e-04 - val_loss: 0.0043\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.5437e-04 - val_loss: 0.0043\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8645e-04 - val_loss: 0.0049\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.8948e-04 - val_loss: 0.0056\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.7512e-04 - val_loss: 0.0044\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 8.6162e-04 - val_loss: 0.0048\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 8.5119e-04 - val_loss: 0.0050\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.0454e-04 - val_loss: 0.0044\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 7.9669e-04 - val_loss: 0.0051\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.0072e-04 - val_loss: 0.0053\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.7463e-04 - val_loss: 0.0045\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 8.8247e-04 - val_loss: 0.0048\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9586e-04 - val_loss: 0.0074\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.3477e-04 - val_loss: 0.0044\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 7.9630e-04 - val_loss: 0.0048\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.6305e-04 - val_loss: 0.0051\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 8.3391e-04 - val_loss: 0.0044\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 8.5785e-04 - val_loss: 0.0048\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 7.9298e-04 - val_loss: 0.0048\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 8.9795e-04 - val_loss: 0.0057\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.3953e-04 - val_loss: 0.0046\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 9.0215e-04 - val_loss: 0.0049\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 251us/step - loss: 8.5313e-04 - val_loss: 0.0052\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 8.4937e-04 - val_loss: 0.0046\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 8.5541e-04 - val_loss: 0.0041\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.6213e-04 - val_loss: 0.0041\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4428e-04 - val_loss: 0.0050\n",
      "0.008450138382613659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 3.60642076e-01, -7.80959606e-01, -2.82180756e-01,\n",
       "         -8.66913617e-01,  3.05884838e-01,  7.65535891e-01,\n",
       "          2.25269586e-01, -1.02888608e+00, -2.11435959e-01,\n",
       "         -5.31107664e-01],\n",
       "        [ 8.24444711e-01, -1.10601828e-01,  1.70715228e-01,\n",
       "          5.20451725e-01,  5.00187695e-01,  4.27367464e-02,\n",
       "          5.85199594e-01,  6.08285032e-02, -1.57977313e-01,\n",
       "          5.06036818e-01],\n",
       "        [-1.54866293e-01, -5.27568758e-01,  4.11440164e-01,\n",
       "          6.59774184e-01, -6.28085583e-02, -1.51573643e-01,\n",
       "         -6.27428368e-02,  7.08883226e-01, -3.03330421e-01,\n",
       "          9.48388278e-02],\n",
       "        [-8.49251866e-01, -5.45350134e-01, -9.03452218e-01,\n",
       "         -4.91938561e-01, -1.85577542e-01,  3.81667674e-01,\n",
       "          2.90073723e-01,  1.23370981e+00, -4.68990773e-01,\n",
       "         -6.91534430e-02],\n",
       "        [-6.48926497e-02,  5.36015213e-01,  7.14949369e-01,\n",
       "         -4.50780280e-02,  1.44578844e-01,  2.92833447e-02,\n",
       "         -2.90979296e-01,  1.61800355e-01, -2.34432936e-01,\n",
       "          5.94068944e-01],\n",
       "        [-3.28894645e-01, -8.37909579e-01,  8.70243609e-01,\n",
       "          3.34977247e-02,  5.71182787e-01,  7.17609644e-01,\n",
       "          1.58057380e-02, -4.97661471e-01,  1.59772202e-01,\n",
       "          6.46157742e-01],\n",
       "        [ 2.69803584e-01, -1.15034020e+00, -5.22556067e-01,\n",
       "          4.18367684e-01,  4.62472856e-01,  1.85748652e-01,\n",
       "         -6.08991906e-02,  2.72652030e-01,  8.53008553e-02,\n",
       "         -3.07343602e-02],\n",
       "        [-3.69710326e-01, -2.59585202e-01, -3.96686375e-01,\n",
       "          1.69819400e-01, -2.37762164e-02,  1.30705878e-01,\n",
       "          3.89118612e-01,  2.74135143e-01, -7.94118177e-03,\n",
       "         -2.60223359e-01],\n",
       "        [-7.06043303e-01,  1.15524702e-01,  2.98677802e-01,\n",
       "         -3.86787266e-01,  2.83399582e-01,  5.37189543e-01,\n",
       "         -2.30406061e-01,  4.53048438e-01,  5.53017139e-01,\n",
       "          7.88208723e-01],\n",
       "        [ 2.75437474e-01,  9.71862301e-02, -5.99395670e-02,\n",
       "          1.41829695e-03,  3.91348988e-01, -1.02585447e+00,\n",
       "         -4.17000055e-01, -5.06200731e-01, -2.41748542e-01,\n",
       "         -7.87205160e-01],\n",
       "        [-2.42102280e-01, -2.46028062e-02,  3.96069735e-02,\n",
       "         -3.09947908e-01, -6.31734952e-02, -4.59713712e-02,\n",
       "          4.66121227e-01, -4.14606065e-01,  5.36150515e-01,\n",
       "          5.28705776e-01],\n",
       "        [-3.99754867e-02,  1.22017038e+00,  3.61480862e-01,\n",
       "          4.25466210e-01, -1.23536542e-01, -1.69943142e+00,\n",
       "          2.77502298e-01,  8.47094059e-02,  3.20942998e-01,\n",
       "         -9.34880912e-01],\n",
       "        [ 2.14895997e-02, -1.03644766e-01,  2.69218534e-01,\n",
       "          9.66746926e-01, -1.59383953e-01, -8.18923533e-01,\n",
       "          4.67000604e-01, -3.52141887e-01,  5.09080350e-01,\n",
       "         -3.92354906e-01],\n",
       "        [ 1.49564162e-01,  1.24910390e+00,  8.17525089e-01,\n",
       "         -6.20572686e-01,  1.69675052e-01, -8.56626809e-01,\n",
       "         -4.06902075e-01, -1.47672546e+00,  1.02820396e+00,\n",
       "          9.98070657e-01],\n",
       "        [ 7.54718259e-02,  3.99395823e-01,  5.51662296e-02,\n",
       "         -1.11210413e-01,  5.09378731e-01,  2.33530954e-01,\n",
       "         -2.02027932e-01,  1.15342010e-02, -1.62655681e-01,\n",
       "          3.70280057e-01],\n",
       "        [-3.71755540e-01, -5.72676003e-01, -3.89409184e-01,\n",
       "         -5.70201635e-01, -1.05501071e-01, -2.09227964e-01,\n",
       "         -5.21710396e-01,  1.19516969e-01, -8.01348329e-01,\n",
       "         -5.58629215e-01],\n",
       "        [ 3.78174096e-01, -2.26603553e-01,  1.58792719e-01,\n",
       "          3.97600412e-01, -2.62194097e-01, -5.76583408e-02,\n",
       "         -5.97822517e-02,  1.04510024e-01,  2.65334517e-01,\n",
       "         -4.54083264e-01],\n",
       "        [-1.15471378e-01,  5.30375123e-01, -1.30026686e+00,\n",
       "          1.75862070e-02,  3.07515621e-01, -4.48925674e-01,\n",
       "         -1.52033865e-01,  1.17232764e+00, -6.86611086e-02,\n",
       "         -5.62777743e-02],\n",
       "        [ 3.15795571e-01,  1.05407977e+00,  1.08798909e+00,\n",
       "         -5.35215363e-02, -2.34381899e-01,  1.50497958e-01,\n",
       "         -7.64798820e-01, -3.23228061e-01,  5.29868454e-02,\n",
       "          1.20173323e+00],\n",
       "        [-2.32061341e-01,  6.55556262e-01, -1.56202689e-01,\n",
       "         -1.34965718e+00,  3.16904671e-02, -4.24674183e-01,\n",
       "          2.80793697e-01,  4.05771852e-01, -2.00456309e+00,\n",
       "          2.58549303e-01],\n",
       "        [ 5.32934517e-02, -1.24061421e-01, -1.00923407e+00,\n",
       "          1.39600897e+00, -1.81981787e-01,  3.35944086e-01,\n",
       "          2.58193135e-01,  1.13182509e+00, -5.26741624e-01,\n",
       "         -2.88954854e-01],\n",
       "        [ 3.12381476e-01, -3.00624460e-01, -5.34889042e-01,\n",
       "          3.75401676e-01,  1.41522214e-01, -2.76153181e-02,\n",
       "         -4.96051945e-02,  7.31209636e-01,  1.18186101e-01,\n",
       "          7.04374433e-01]], dtype=float32),\n",
       " array([ 0.03961116, -0.1385255 ,  0.07549129,  0.35880485,  0.1164215 ,\n",
       "         0.25175777,  0.06709959,  0.51983255, -0.34477872, -0.14742127],\n",
       "       dtype=float32),\n",
       " array([[ 2.7638171e-02,  1.2614278e-01, -2.3848359e-01, -6.7691930e-02,\n",
       "         -2.2707576e-01, -2.4628738e-01,  2.3958212e-01, -2.5894585e-01,\n",
       "          2.5091055e-01,  3.0286215e-02, -1.0324663e-02, -4.8667260e-02,\n",
       "         -7.9303727e-02, -6.7356922e-02, -3.2419646e-01],\n",
       "        [-2.1887596e-01, -2.2708990e-01, -2.9260764e-01, -2.4339607e-01,\n",
       "          1.0497339e-01,  4.4279826e-01, -3.3252615e-01, -1.6004753e-01,\n",
       "         -6.3080925e-01,  1.1301915e-01,  2.4048861e-02,  4.7960395e-01,\n",
       "          1.8041256e-01,  3.7768912e-02,  6.1356334e-04],\n",
       "        [-1.3983618e-01, -3.4825340e-01,  9.5436968e-02,  2.7654284e-01,\n",
       "          8.9149833e-02,  1.3262759e-01, -2.4813451e-01, -6.3717194e-02,\n",
       "          1.2406488e-02,  3.8914487e-01,  6.7585818e-02,  3.6539757e-01,\n",
       "          2.4030644e-01, -2.1344922e-01,  3.2769686e-01],\n",
       "        [-2.8278214e-01, -2.8327796e-01, -4.0180370e-01, -1.9273962e-01,\n",
       "         -7.6616406e-02,  5.5478567e-01, -2.9822960e-01, -1.4756629e-01,\n",
       "         -3.3761326e-02, -7.0048369e-02, -1.5799925e-01,  7.1772450e-01,\n",
       "         -7.1015947e-02,  1.9451934e-01, -1.9595118e-01],\n",
       "        [ 2.0543121e-01, -5.1406723e-02, -3.9255178e-01,  3.4397028e-02,\n",
       "          1.8160151e-02,  2.1728249e-01, -4.3079671e-02,  2.2613434e-01,\n",
       "         -5.3986466e-01,  6.4254865e-02,  2.2809651e-01, -3.1787154e-01,\n",
       "          3.2502916e-02,  1.0885384e-01, -4.1020551e-01],\n",
       "        [-3.6246675e-01, -5.0476141e-02, -3.2494119e-01, -5.1903706e-03,\n",
       "          1.5053254e-01,  1.0373622e+00, -5.1804137e-01,  1.6887487e-01,\n",
       "         -2.6595837e-01,  5.3295344e-01, -1.8466561e-01,  4.9274582e-01,\n",
       "          4.5711178e-01,  1.1919070e-01, -1.6105174e-01],\n",
       "        [ 1.7758287e-01, -3.3608243e-01, -2.7838668e-01,  2.4329749e-01,\n",
       "         -3.4154233e-01, -1.4045945e-01, -2.5146885e-02,  2.1000198e-01,\n",
       "         -2.1896096e-01,  4.5650795e-02,  5.6842798e-01, -8.6702012e-02,\n",
       "          7.0718667e-03,  1.3080955e-01,  9.8740265e-02],\n",
       "        [-4.4399893e-01, -2.7234697e-01,  8.6884454e-02,  1.5533917e-01,\n",
       "          2.7967972e-01,  6.6315717e-01, -1.6464823e-01, -3.2584941e-01,\n",
       "          9.6660502e-02,  2.6007697e-01,  9.8435812e-02,  6.5673369e-01,\n",
       "          1.7287283e-01,  9.9094793e-02,  3.6281484e-01],\n",
       "        [ 3.1885320e-01, -2.8184366e-01,  1.4446223e-01,  1.8610382e-01,\n",
       "          2.2028832e-01, -1.9019958e-01,  3.6718377e-01,  2.0040929e-01,\n",
       "          5.5990750e-01, -3.3450737e-03,  3.3994794e-01, -2.6353868e-02,\n",
       "         -3.7193289e-01,  4.6797544e-01,  3.0676189e-01],\n",
       "        [ 2.2639856e-01,  2.2968252e-01,  4.1353360e-01, -2.1350050e-01,\n",
       "         -2.1419390e-01, -5.8266211e-01,  6.4673382e-01,  8.9255944e-02,\n",
       "          4.0790907e-01, -5.5923027e-01,  1.0007346e-01, -3.1571048e-01,\n",
       "         -4.1785219e-01,  3.9513263e-01, -2.0287542e-01]], dtype=float32),\n",
       " array([ 0.2983231 ,  0.14486499,  0.145574  , -0.1249085 ,  0.12657039,\n",
       "        -0.42483628,  0.20465058,  0.2078904 ,  0.2760222 ,  0.03799879,\n",
       "        -0.04411634, -0.19427645, -0.13022645,  0.14197932,  0.22677645],\n",
       "       dtype=float32),\n",
       " array([[ 0.04693182],\n",
       "        [ 0.01457458],\n",
       "        [ 0.10258375],\n",
       "        [ 0.00676741],\n",
       "        [ 0.00501441],\n",
       "        [-0.17285839],\n",
       "        [ 0.07297849],\n",
       "        [ 0.04243558],\n",
       "        [ 0.0262498 ],\n",
       "        [-0.01058956],\n",
       "        [ 0.00812448],\n",
       "        [-0.18569376],\n",
       "        [-0.06653626],\n",
       "        [ 0.01549152],\n",
       "        [ 0.00531872]], dtype=float32),\n",
       " array([0.20821084], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_6(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure6_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 36.1592 - val_loss: 35.2207\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9752 - val_loss: 34.2955\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3735 - val_loss: 32.5016\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1099 - val_loss: 29.8281\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 28.0188 - val_loss: 26.1144\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 23.9866 - val_loss: 21.1942\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 19.0182 - val_loss: 15.1999\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 13.3145 - val_loss: 8.7592\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3987 - val_loss: 3.0805\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3724 - val_loss: 0.1169\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0940 - val_loss: 1.8529\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2377 - val_loss: 5.7170\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9591 - val_loss: 6.7095\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7694 - val_loss: 4.9941\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 5.0189 - val_loss: 2.6205\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.6579 - val_loss: 0.9796\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.9833 - val_loss: 0.4147\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.3189 - val_loss: 0.6122\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.3986 - val_loss: 1.1204\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.8267 - val_loss: 1.6220\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.3046 - val_loss: 1.9544\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6619 - val_loss: 2.0632\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8280 - val_loss: 1.9599\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7969 - val_loss: 1.6923\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5998 - val_loss: 1.3250\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2889 - val_loss: 0.9277\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9264 - val_loss: 0.5653\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.5759 - val_loss: 0.2890\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2944 - val_loss: 0.1282\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1224 - val_loss: 0.0844\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0757 - val_loss: 0.1301\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1386 - val_loss: 0.2176\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.2662 - val_loss: 0.2960\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3979 - val_loss: 0.3301\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.4803 - val_loss: 0.3106\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4872 - val_loss: 0.2520\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4241 - val_loss: 0.1802\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3193 - val_loss: 0.1197\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.2077 - val_loss: 0.0852\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1177 - val_loss: 0.0796\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0644 - val_loss: 0.0967\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0486 - val_loss: 0.1253\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0618 - val_loss: 0.1541\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0907 - val_loss: 0.1743\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1221 - val_loss: 0.1811\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1460 - val_loss: 0.1737\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1566 - val_loss: 0.1543\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1523 - val_loss: 0.1274\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1354 - val_loss: 0.0979\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1104 - val_loss: 0.0706\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0829 - val_loss: 0.0488\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0584 - val_loss: 0.0343\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0407 - val_loss: 0.0270\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0316 - val_loss: 0.0253\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0271\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0360 - val_loss: 0.0298\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0439 - val_loss: 0.0317\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0513 - val_loss: 0.0315\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0557 - val_loss: 0.0292\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0559 - val_loss: 0.0253\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0522 - val_loss: 0.0209\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0457 - val_loss: 0.0168\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0140\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0311 - val_loss: 0.0128\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0258 - val_loss: 0.0131\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0147\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0171\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0195\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0244 - val_loss: 0.0215\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0272 - val_loss: 0.0229\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0272 - val_loss: 0.0223\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0262 - val_loss: 0.0208\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0244 - val_loss: 0.0189\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0221 - val_loss: 0.0168\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0131\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0104\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0101\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0101\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0152 - val_loss: 0.0101\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0072\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0105 - val_loss: 0.0064\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0102 - val_loss: 0.0060\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0097 - val_loss: 0.0060\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.9909e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.9588e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 9.9269e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 9.8953e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 9.8636e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.8324e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.8014e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 9.7704e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 9.7398e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.7091e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.6787e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 9.6487e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.6186e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.5887e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.5589e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.5294e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.5001e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 9.4711e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.4422e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.4134e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 9.3848e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.3564e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.3280e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.2999e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.2719e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.2443e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.2167e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.1895e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.1621e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.1349e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.1078e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.0810e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 9.0544e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.0278e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.0015e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 8.9754e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0017 - val_loss: 8.9494e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 8.9234e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.8975e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 8.8719e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.8462e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.8212e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 8.7960e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 8.7708e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 8.7459e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.7212e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 8.6965e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.6721e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0017 - val_loss: 8.6478e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 8.6236e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.5996e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.5757e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 8.5518e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.5282e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.5048e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.4812e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.4581e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.4349e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.4118e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.3889e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 8.3661e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.3434e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.3209e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 8.2985e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 8.2761e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.2540e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.2320e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.2102e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0016 - val_loss: 8.1885e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 8.1667e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.1450e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.1236e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.1023e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 8.0811e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.0601e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 8.0391e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.0182e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.9974e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.9768e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.9563e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.9359e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.9155e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.8951e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.8751e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.8550e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.8350e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.8153e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.7955e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 7.7760e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.7565e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.7372e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.7178e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.6988e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.6796e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.6605e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.6418e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.6229e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.6043e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.5856e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.5671e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.5485e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.5302e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.5119e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.4938e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.4755e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.4577e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.4397e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.4218e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.4043e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.3865e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.3691e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.3518e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.3344e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.3170e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.2997e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.2826e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.2657e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.2485e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.2318e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.2151e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1983e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.1816e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.1651e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.1487e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.1323e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 7.1160e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.0996e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.0834e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.0674e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.0513e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.0355e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.0197e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.0037e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9880e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9724e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.9567e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9413e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.9257e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9104e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.8952e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8799e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8648e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8497e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8348e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8198e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.8049e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.7901e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.7754e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.7606e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.7460e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7314e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.7169e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7025e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6879e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6736e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6593e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6452e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.6313e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6171e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.6032e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5891e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5754e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.5615e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5478e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5340e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5203e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.5068e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.4931e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.4797e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.4662e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.4527e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.4394e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.4261e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.4129e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3997e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3866e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3737e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3606e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3475e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3347e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3220e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3092e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.2965e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.2837e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.2712e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.2584e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.2459e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.2334e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.2209e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.2085e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 6.1961e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.1838e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.1715e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.1593e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.1471e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.1350e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.1231e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.1108e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0011 - val_loss: 6.0990e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.0869e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.0751e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.0633e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.0515e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.0396e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.0279e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.0162e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.0046e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 5.9930e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 5.9815e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.9700e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.9586e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.9471e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.9357e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.9243e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 5.9130e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.9018e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.8905e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.8794e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.8682e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 5.8570e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.8461e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.8349e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.8240e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.8130e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.8020e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.7911e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0010 - val_loss: 5.7802e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.7696e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0010 - val_loss: 5.7587e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.7480e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.7372e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.7267e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.7160e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.7054e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 5.6949e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.6844e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0010 - val_loss: 5.6738e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.6632e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.6528e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0010 - val_loss: 5.6425e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.6321e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9827e-04 - val_loss: 5.6218e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9590e-04 - val_loss: 5.6115e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9356e-04 - val_loss: 5.6012e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9122e-04 - val_loss: 5.5911e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8889e-04 - val_loss: 5.5807e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8656e-04 - val_loss: 5.5705e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8425e-04 - val_loss: 5.5606e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8193e-04 - val_loss: 5.5505e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7962e-04 - val_loss: 5.5404e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7733e-04 - val_loss: 5.5302e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 9.7504e-04 - val_loss: 5.5202e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7275e-04 - val_loss: 5.5105e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7049e-04 - val_loss: 5.5004e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6821e-04 - val_loss: 5.4906e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6596e-04 - val_loss: 5.4806e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6370e-04 - val_loss: 5.4707e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6146e-04 - val_loss: 5.4609e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5921e-04 - val_loss: 5.4512e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5698e-04 - val_loss: 5.4414e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5476e-04 - val_loss: 5.4317e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5255e-04 - val_loss: 5.4219e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5033e-04 - val_loss: 5.4124e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4813e-04 - val_loss: 5.4026e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4593e-04 - val_loss: 5.3930e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4375e-04 - val_loss: 5.3834e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4156e-04 - val_loss: 5.3738e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3938e-04 - val_loss: 5.3643e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3721e-04 - val_loss: 5.3550e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3505e-04 - val_loss: 5.3454e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3289e-04 - val_loss: 5.3360e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3075e-04 - val_loss: 5.3265e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2859e-04 - val_loss: 5.3171e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2646e-04 - val_loss: 5.3078e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2434e-04 - val_loss: 5.2985e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2221e-04 - val_loss: 5.2891e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2009e-04 - val_loss: 5.2799e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1799e-04 - val_loss: 5.2705e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1588e-04 - val_loss: 5.2613e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1378e-04 - val_loss: 5.2520e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1169e-04 - val_loss: 5.2429e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0961e-04 - val_loss: 5.2337e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0753e-04 - val_loss: 5.2246e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0546e-04 - val_loss: 5.2156e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0339e-04 - val_loss: 5.2064e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0133e-04 - val_loss: 5.1973e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9928e-04 - val_loss: 5.1882e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9724e-04 - val_loss: 5.1792e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9520e-04 - val_loss: 5.1703e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9315e-04 - val_loss: 5.1613e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.9113e-04 - val_loss: 5.1524e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8911e-04 - val_loss: 5.1434e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8709e-04 - val_loss: 5.1346e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8508e-04 - val_loss: 5.1259e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8308e-04 - val_loss: 5.1170e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8108e-04 - val_loss: 5.1082e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7909e-04 - val_loss: 5.0994e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7710e-04 - val_loss: 5.0906e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7512e-04 - val_loss: 5.0819e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7315e-04 - val_loss: 5.0732e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.7118e-04 - val_loss: 5.0645e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.6922e-04 - val_loss: 5.0558e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6727e-04 - val_loss: 5.0471e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6531e-04 - val_loss: 5.0386e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6337e-04 - val_loss: 5.0298e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6143e-04 - val_loss: 5.0211e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5950e-04 - val_loss: 5.0127e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5758e-04 - val_loss: 5.0040e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5564e-04 - val_loss: 4.9957e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5374e-04 - val_loss: 4.9872e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5182e-04 - val_loss: 4.9787e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4992e-04 - val_loss: 4.9702e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4802e-04 - val_loss: 4.9618e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4612e-04 - val_loss: 4.9534e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4423e-04 - val_loss: 4.9450e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4236e-04 - val_loss: 4.9365e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4048e-04 - val_loss: 4.9284e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3861e-04 - val_loss: 4.9200e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3674e-04 - val_loss: 4.9117e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3489e-04 - val_loss: 4.9034e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3302e-04 - val_loss: 4.8951e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3118e-04 - val_loss: 4.8868e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2933e-04 - val_loss: 4.8786e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2749e-04 - val_loss: 4.8704e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2566e-04 - val_loss: 4.8621e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2383e-04 - val_loss: 4.8539e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2201e-04 - val_loss: 4.8458e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2019e-04 - val_loss: 4.8377e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.1838e-04 - val_loss: 4.8296e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1657e-04 - val_loss: 4.8215e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.1477e-04 - val_loss: 4.8135e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1298e-04 - val_loss: 4.8054e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1118e-04 - val_loss: 4.7975e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0940e-04 - val_loss: 4.7895e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0762e-04 - val_loss: 4.7814e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0584e-04 - val_loss: 4.7736e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0407e-04 - val_loss: 4.7656e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0230e-04 - val_loss: 4.7576e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0055e-04 - val_loss: 4.7497e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9879e-04 - val_loss: 4.7419e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.9703e-04 - val_loss: 4.7339e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9529e-04 - val_loss: 4.7260e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9355e-04 - val_loss: 4.7182e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9181e-04 - val_loss: 4.7103e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9009e-04 - val_loss: 4.7025e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8836e-04 - val_loss: 4.6948e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8664e-04 - val_loss: 4.6870e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8492e-04 - val_loss: 4.6792e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8321e-04 - val_loss: 4.6713e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8151e-04 - val_loss: 4.6636e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 7.7981e-04 - val_loss: 4.6560e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 7.7810e-04 - val_loss: 4.6483e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7642e-04 - val_loss: 4.6408e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.7473e-04 - val_loss: 4.6330e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7305e-04 - val_loss: 4.6254e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7137e-04 - val_loss: 4.6178e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6970e-04 - val_loss: 4.6103e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.6803e-04 - val_loss: 4.6027e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6636e-04 - val_loss: 4.5951e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.6471e-04 - val_loss: 4.5876e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6305e-04 - val_loss: 4.5800e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6140e-04 - val_loss: 4.5725e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5976e-04 - val_loss: 4.5649e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5812e-04 - val_loss: 4.5575e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5648e-04 - val_loss: 4.5501e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.5485e-04 - val_loss: 4.5426e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5323e-04 - val_loss: 4.5352e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5160e-04 - val_loss: 4.5277e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.4998e-04 - val_loss: 4.5203e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4838e-04 - val_loss: 4.5129e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4677e-04 - val_loss: 4.5057e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4516e-04 - val_loss: 4.4982e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4356e-04 - val_loss: 4.4909e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4197e-04 - val_loss: 4.4837e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4038e-04 - val_loss: 4.4764e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3879e-04 - val_loss: 4.4690e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3721e-04 - val_loss: 4.4618e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3563e-04 - val_loss: 4.4544e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3405e-04 - val_loss: 4.4471e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3249e-04 - val_loss: 4.4398e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3092e-04 - val_loss: 4.4328e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2936e-04 - val_loss: 4.4255e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2780e-04 - val_loss: 4.4184e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2626e-04 - val_loss: 4.4113e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2470e-04 - val_loss: 4.4041e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2316e-04 - val_loss: 4.3969e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2162e-04 - val_loss: 4.3898e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2009e-04 - val_loss: 4.3827e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1855e-04 - val_loss: 4.3756e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1703e-04 - val_loss: 4.3685e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.1551e-04 - val_loss: 4.3613e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.1399e-04 - val_loss: 4.3545e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1247e-04 - val_loss: 4.3473e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1096e-04 - val_loss: 4.3403e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0946e-04 - val_loss: 4.3334e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.0796e-04 - val_loss: 4.3264e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0647e-04 - val_loss: 4.3194e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0497e-04 - val_loss: 4.3125e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0348e-04 - val_loss: 4.3055e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0198e-04 - val_loss: 4.2986e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0051e-04 - val_loss: 4.2917e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.9903e-04 - val_loss: 4.2847e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9756e-04 - val_loss: 4.2778e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9609e-04 - val_loss: 4.2710e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9462e-04 - val_loss: 4.2641e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9317e-04 - val_loss: 4.2572e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9170e-04 - val_loss: 4.2503e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9025e-04 - val_loss: 4.2435e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8880e-04 - val_loss: 4.2367e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8736e-04 - val_loss: 4.2300e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.8590e-04 - val_loss: 4.2231e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8447e-04 - val_loss: 4.2163e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8303e-04 - val_loss: 4.2096e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8161e-04 - val_loss: 4.2028e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8017e-04 - val_loss: 4.1961e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7875e-04 - val_loss: 4.1894e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7733e-04 - val_loss: 4.1827e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7592e-04 - val_loss: 4.1759e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7450e-04 - val_loss: 4.1693e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7311e-04 - val_loss: 4.1626e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7169e-04 - val_loss: 4.1559e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7029e-04 - val_loss: 4.1495e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6890e-04 - val_loss: 4.1427e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6751e-04 - val_loss: 4.1362e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6612e-04 - val_loss: 4.1296e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6473e-04 - val_loss: 4.1229e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6335e-04 - val_loss: 4.1163e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6197e-04 - val_loss: 4.1097e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6059e-04 - val_loss: 4.1032e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5922e-04 - val_loss: 4.0966e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5785e-04 - val_loss: 4.0901e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5649e-04 - val_loss: 4.0835e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5513e-04 - val_loss: 4.0770e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5377e-04 - val_loss: 4.0705e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5242e-04 - val_loss: 4.0640e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5107e-04 - val_loss: 4.0576e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4972e-04 - val_loss: 4.0512e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4838e-04 - val_loss: 4.0448e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4703e-04 - val_loss: 4.0384e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4570e-04 - val_loss: 4.0320e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4437e-04 - val_loss: 4.0256e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4304e-04 - val_loss: 4.0192e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4171e-04 - val_loss: 4.0127e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4039e-04 - val_loss: 4.0064e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3907e-04 - val_loss: 4.0000e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3776e-04 - val_loss: 3.9935e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3645e-04 - val_loss: 3.9872e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3514e-04 - val_loss: 3.9808e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3383e-04 - val_loss: 3.9746e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3253e-04 - val_loss: 3.9682e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3123e-04 - val_loss: 3.9620e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2993e-04 - val_loss: 3.9557e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2865e-04 - val_loss: 3.9495e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2736e-04 - val_loss: 3.9433e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2607e-04 - val_loss: 3.9371e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2479e-04 - val_loss: 3.9308e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2351e-04 - val_loss: 3.9245e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2224e-04 - val_loss: 3.9183e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2097e-04 - val_loss: 3.9122e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1970e-04 - val_loss: 3.9060e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1843e-04 - val_loss: 3.8999e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1717e-04 - val_loss: 3.8937e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1591e-04 - val_loss: 3.8875e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1465e-04 - val_loss: 3.8812e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1340e-04 - val_loss: 3.8751e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1215e-04 - val_loss: 3.8690e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1090e-04 - val_loss: 3.8629e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0967e-04 - val_loss: 3.8568e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0843e-04 - val_loss: 3.8507e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0719e-04 - val_loss: 3.8446e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0596e-04 - val_loss: 3.8386e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0473e-04 - val_loss: 3.8325e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0350e-04 - val_loss: 3.8264e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0227e-04 - val_loss: 3.8204e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0105e-04 - val_loss: 3.8144e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9983e-04 - val_loss: 3.8084e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9861e-04 - val_loss: 3.8024e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9741e-04 - val_loss: 3.7964e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9620e-04 - val_loss: 3.7904e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9499e-04 - val_loss: 3.7844e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9379e-04 - val_loss: 3.7784e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9259e-04 - val_loss: 3.7725e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9139e-04 - val_loss: 3.7665e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9021e-04 - val_loss: 3.7607e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8901e-04 - val_loss: 3.7548e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8783e-04 - val_loss: 3.7489e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8664e-04 - val_loss: 3.7430e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8546e-04 - val_loss: 3.7371e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8428e-04 - val_loss: 3.7311e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8311e-04 - val_loss: 3.7252e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8193e-04 - val_loss: 3.7195e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8076e-04 - val_loss: 3.7137e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7960e-04 - val_loss: 3.7079e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7843e-04 - val_loss: 3.7020e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7727e-04 - val_loss: 3.6961e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7611e-04 - val_loss: 3.6903e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7495e-04 - val_loss: 3.6845e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7381e-04 - val_loss: 3.6788e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7265e-04 - val_loss: 3.6730e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7151e-04 - val_loss: 3.6673e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 5.7036e-04 - val_loss: 3.6614e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6922e-04 - val_loss: 3.6558e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6808e-04 - val_loss: 3.6500e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6695e-04 - val_loss: 3.6441e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6581e-04 - val_loss: 3.6385e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6469e-04 - val_loss: 3.6329e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6356e-04 - val_loss: 3.6272e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6243e-04 - val_loss: 3.6214e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6131e-04 - val_loss: 3.6157e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6019e-04 - val_loss: 3.6101e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5908e-04 - val_loss: 3.6044e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5796e-04 - val_loss: 3.5988e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5686e-04 - val_loss: 3.5930e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5575e-04 - val_loss: 3.5876e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5464e-04 - val_loss: 3.5819e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5354e-04 - val_loss: 3.5763e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5244e-04 - val_loss: 3.5707e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.5135e-04 - val_loss: 3.5652e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 5.5026e-04 - val_loss: 3.5596e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.4916e-04 - val_loss: 3.5540e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.4807e-04 - val_loss: 3.5484e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4699e-04 - val_loss: 3.5429e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4590e-04 - val_loss: 3.5374e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4482e-04 - val_loss: 3.5317e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4374e-04 - val_loss: 3.5264e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4267e-04 - val_loss: 3.5207e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4160e-04 - val_loss: 3.5153e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4053e-04 - val_loss: 3.5098e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3946e-04 - val_loss: 3.5042e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3840e-04 - val_loss: 3.4988e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3733e-04 - val_loss: 3.4934e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3627e-04 - val_loss: 3.4879e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3522e-04 - val_loss: 3.4824e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3416e-04 - val_loss: 3.4771e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3311e-04 - val_loss: 3.4716e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3206e-04 - val_loss: 3.4661e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3101e-04 - val_loss: 3.4606e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2997e-04 - val_loss: 3.4553e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2893e-04 - val_loss: 3.4499e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2789e-04 - val_loss: 3.4446e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2685e-04 - val_loss: 3.4392e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.2582e-04 - val_loss: 3.4338e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2478e-04 - val_loss: 3.4284e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2376e-04 - val_loss: 3.4231e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2273e-04 - val_loss: 3.4177e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2170e-04 - val_loss: 3.4124e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 5.2068e-04 - val_loss: 3.4071e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1966e-04 - val_loss: 3.4018e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1864e-04 - val_loss: 3.3966e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1763e-04 - val_loss: 3.3912e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1662e-04 - val_loss: 3.3860e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1561e-04 - val_loss: 3.3806e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1460e-04 - val_loss: 3.3754e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1360e-04 - val_loss: 3.3701e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1259e-04 - val_loss: 3.3649e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1160e-04 - val_loss: 3.3596e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1059e-04 - val_loss: 3.3543e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0960e-04 - val_loss: 3.3490e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0860e-04 - val_loss: 3.3439e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0761e-04 - val_loss: 3.3387e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0663e-04 - val_loss: 3.3335e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0564e-04 - val_loss: 3.3284e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0466e-04 - val_loss: 3.3231e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0367e-04 - val_loss: 3.3180e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0271e-04 - val_loss: 3.3129e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0173e-04 - val_loss: 3.3077e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0075e-04 - val_loss: 3.3026e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9978e-04 - val_loss: 3.2974e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9880e-04 - val_loss: 3.2923e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.9784e-04 - val_loss: 3.2872e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9687e-04 - val_loss: 3.2820e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9591e-04 - val_loss: 3.2769e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9495e-04 - val_loss: 3.2718e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9399e-04 - val_loss: 3.2667e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9303e-04 - val_loss: 3.2617e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9209e-04 - val_loss: 3.2566e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9114e-04 - val_loss: 3.2516e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9017e-04 - val_loss: 3.2464e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8923e-04 - val_loss: 3.2414e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8830e-04 - val_loss: 3.2364e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8735e-04 - val_loss: 3.2315e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8641e-04 - val_loss: 3.2264e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8547e-04 - val_loss: 3.2214e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8454e-04 - val_loss: 3.2165e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8360e-04 - val_loss: 3.2114e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8267e-04 - val_loss: 3.2063e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8174e-04 - val_loss: 3.2013e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8082e-04 - val_loss: 3.1964e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7989e-04 - val_loss: 3.1914e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7897e-04 - val_loss: 3.1865e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7805e-04 - val_loss: 3.1816e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7713e-04 - val_loss: 3.1766e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7621e-04 - val_loss: 3.1716e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7530e-04 - val_loss: 3.1666e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7439e-04 - val_loss: 3.1616e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7348e-04 - val_loss: 3.1569e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7257e-04 - val_loss: 3.1520e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7166e-04 - val_loss: 3.1471e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7076e-04 - val_loss: 3.1423e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6986e-04 - val_loss: 3.1374e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6896e-04 - val_loss: 3.1326e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6806e-04 - val_loss: 3.1275e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6717e-04 - val_loss: 3.1228e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6628e-04 - val_loss: 3.1179e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6539e-04 - val_loss: 3.1131e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6450e-04 - val_loss: 3.1083e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6361e-04 - val_loss: 3.1035e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6273e-04 - val_loss: 3.0987e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6184e-04 - val_loss: 3.0940e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6096e-04 - val_loss: 3.0892e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.6008e-04 - val_loss: 3.0843e-04\n",
      "0.00020734181453008205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.00643784, -0.67432886, -0.69756997, -0.01782282,  0.20315535],\n",
       "        [-0.18590218,  0.6707559 ,  0.6489374 , -0.14127694,  0.3411386 ],\n",
       "        [-0.1780206 ,  0.9059355 , -0.670769  , -0.33804742,  1.4364766 ]],\n",
       "       dtype=float32),\n",
       " array([-0.65187085, -0.52265525,  0.5999584 ,  0.58907104,  0.45946464],\n",
       "       dtype=float32),\n",
       " array([[ 0.05702494,  0.8888617 , -0.49676722,  0.6230014 , -0.2927776 ],\n",
       "        [ 0.3184487 ,  0.5937209 ,  0.58160615,  0.8651863 ,  0.24036802],\n",
       "        [-0.15816599, -0.45121938,  0.14499214, -0.8854137 ,  0.6428694 ],\n",
       "        [-0.75713044,  0.29873237, -0.9027046 , -0.75456864,  0.7719495 ],\n",
       "        [ 0.24106322, -0.09745515, -0.82654244, -0.79251784,  0.39338687]],\n",
       "       dtype=float32),\n",
       " array([ 0.61430645, -0.89365065, -0.8551208 , -0.8896346 ,  0.8596787 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.14992635],\n",
       "        [-0.7578798 ],\n",
       "        [-0.6890243 ],\n",
       "        [-0.7817559 ],\n",
       "        [ 0.63425153]], dtype=float32),\n",
       " array([0.97055846], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_1(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure1_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 36.5316 - val_loss: 33.2687\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.9436 - val_loss: 29.7450\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.8187 - val_loss: 25.7246\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 26.9151 - val_loss: 20.7138\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 21.9527 - val_loss: 14.9139\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 16.2345 - val_loss: 8.9686\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 10.2606 - val_loss: 3.7214\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6376 - val_loss: 0.5468\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8870 - val_loss: 1.0771\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1098 - val_loss: 4.4707\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8283 - val_loss: 6.4195\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2011 - val_loss: 5.7360\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3707 - val_loss: 3.7576\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8947 - val_loss: 1.8393\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5922 - val_loss: 0.6585\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3711 - val_loss: 0.2640\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2163 - val_loss: 0.3921\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6585 - val_loss: 0.7505\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2537 - val_loss: 1.1292\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7514 - val_loss: 1.4003\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0457 - val_loss: 1.4988\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1074 - val_loss: 1.4107\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9506 - val_loss: 1.1656\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6214 - val_loss: 0.8274\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1910 - val_loss: 0.4810\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.7460 - val_loss: 0.2119\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3732 - val_loss: 0.0810\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1391 - val_loss: 0.1022\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0703 - val_loss: 0.2355\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1435 - val_loss: 0.4049\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2956 - val_loss: 0.5345\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4499 - val_loss: 0.5804\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5459 - val_loss: 0.5402\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.5555 - val_loss: 0.4406\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4842 - val_loss: 0.3175\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3613 - val_loss: 0.2026\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2262 - val_loss: 0.1169\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1148 - val_loss: 0.0696\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0491 - val_loss: 0.0587\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0331 - val_loss: 0.0739\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0552 - val_loss: 0.1013\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0958 - val_loss: 0.1277\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1357 - val_loss: 0.1431\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1613 - val_loss: 0.1430\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1669 - val_loss: 0.1275\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1538 - val_loss: 0.1004\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1274 - val_loss: 0.0681\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0950 - val_loss: 0.0377\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0636 - val_loss: 0.0154\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0389 - val_loss: 0.0054\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0243 - val_loss: 0.0085\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0205 - val_loss: 0.0217\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0258 - val_loss: 0.0393\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0360 - val_loss: 0.0545\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0464 - val_loss: 0.0622\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0527 - val_loss: 0.0604\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0528 - val_loss: 0.0509\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0470 - val_loss: 0.0376\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0375 - val_loss: 0.0248\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0274 - val_loss: 0.0158\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0190 - val_loss: 0.0116\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0138 - val_loss: 0.0118\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0182\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0151 - val_loss: 0.0213\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0178 - val_loss: 0.0228\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0199 - val_loss: 0.0225\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0207 - val_loss: 0.0205\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.0172\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0146 - val_loss: 0.0095\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0027\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 9.9218e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0042 - val_loss: 9.3984e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 8.9762e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 8.5640e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 8.1556e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 7.8034e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 7.5839e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 7.5638e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 7.7772e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 8.2140e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 8.8198e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 9.5025e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.8467e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 9.1081e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 8.3363e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 7.6210e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 7.0159e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.5393e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.1827e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 5.9266e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 5.7542e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 5.6567e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 5.6343e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 5.6894e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 5.8223e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 6.0266e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.2879e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 6.5855e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 6.8948e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.1910e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 7.4521e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.6615e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.8100e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.8951e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 7.9219e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 7.8987e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 7.8374e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 7.7521e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 7.6565e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 7.5646e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 7.4883e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.4376e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.4192e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.4379e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.4949e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.5896e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 7.7194e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 7.8797e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.0643e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 8.2654e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.4749e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.6837e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.8836e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 9.0688e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0019 - val_loss: 9.2348e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.3813e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.5084e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.6191e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 9.7173e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.8072e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 9.8931e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 9.9793e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9753e-04 - val_loss: 0.0017\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9492e-04 - val_loss: 0.0017\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9232e-04 - val_loss: 0.0017\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8971e-04 - val_loss: 0.0017\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8713e-04 - val_loss: 0.0017\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.8455e-04 - val_loss: 0.0017\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8197e-04 - val_loss: 0.0017\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7941e-04 - val_loss: 0.0017\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7685e-04 - val_loss: 0.0017\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7430e-04 - val_loss: 0.0017\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7176e-04 - val_loss: 0.0017\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6922e-04 - val_loss: 0.0017\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6668e-04 - val_loss: 0.0017\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6416e-04 - val_loss: 0.0017\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6166e-04 - val_loss: 0.0017\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5914e-04 - val_loss: 0.0017\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5664e-04 - val_loss: 0.0017\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.5414e-04 - val_loss: 0.0017\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5165e-04 - val_loss: 0.0017\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4917e-04 - val_loss: 0.0016\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.4669e-04 - val_loss: 0.0016\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4422e-04 - val_loss: 0.0016\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4177e-04 - val_loss: 0.0016\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3930e-04 - val_loss: 0.0016\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3685e-04 - val_loss: 0.0016\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3441e-04 - val_loss: 0.0016\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3197e-04 - val_loss: 0.0016\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2954e-04 - val_loss: 0.0016\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2712e-04 - val_loss: 0.0016\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2469e-04 - val_loss: 0.0016\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2228e-04 - val_loss: 0.0016\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1988e-04 - val_loss: 0.0016\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1747e-04 - val_loss: 0.0016\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1508e-04 - val_loss: 0.0016\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1269e-04 - val_loss: 0.0016\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1031e-04 - val_loss: 0.0016\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0793e-04 - val_loss: 0.0016\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0557e-04 - val_loss: 0.0016\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0319e-04 - val_loss: 0.0016\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0084e-04 - val_loss: 0.0016\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9848e-04 - val_loss: 0.0016\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9613e-04 - val_loss: 0.0016\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9380e-04 - val_loss: 0.0016\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9146e-04 - val_loss: 0.0016\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8913e-04 - val_loss: 0.0016\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8681e-04 - val_loss: 0.0016\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8448e-04 - val_loss: 0.0015\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8217e-04 - val_loss: 0.0015\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7987e-04 - val_loss: 0.0015\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 8.7758e-04 - val_loss: 0.0015\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7527e-04 - val_loss: 0.0015\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7298e-04 - val_loss: 0.0015\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.7070e-04 - val_loss: 0.0015\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6842e-04 - val_loss: 0.0015\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6614e-04 - val_loss: 0.0015\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6388e-04 - val_loss: 0.0015\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6161e-04 - val_loss: 0.0015\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5935e-04 - val_loss: 0.0015\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5710e-04 - val_loss: 0.0015\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5485e-04 - val_loss: 0.0015\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5262e-04 - val_loss: 0.0015\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5038e-04 - val_loss: 0.0015\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4815e-04 - val_loss: 0.0015\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4593e-04 - val_loss: 0.0015\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4370e-04 - val_loss: 0.0015\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4149e-04 - val_loss: 0.0015\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3928e-04 - val_loss: 0.0015\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3709e-04 - val_loss: 0.0015\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3489e-04 - val_loss: 0.0015\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3269e-04 - val_loss: 0.0015\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3051e-04 - val_loss: 0.0015\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2832e-04 - val_loss: 0.0014\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2614e-04 - val_loss: 0.0014\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2398e-04 - val_loss: 0.0014\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2181e-04 - val_loss: 0.0014\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1966e-04 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1749e-04 - val_loss: 0.0014\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1535e-04 - val_loss: 0.0014\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1321e-04 - val_loss: 0.0014\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1106e-04 - val_loss: 0.0014\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0892e-04 - val_loss: 0.0014\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0680e-04 - val_loss: 0.0014\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0468e-04 - val_loss: 0.0014\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0256e-04 - val_loss: 0.0014\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0043e-04 - val_loss: 0.0014\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9834e-04 - val_loss: 0.0014\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9623e-04 - val_loss: 0.0014\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9414e-04 - val_loss: 0.0014\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9204e-04 - val_loss: 0.0014\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8995e-04 - val_loss: 0.0014\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8787e-04 - val_loss: 0.0014\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8580e-04 - val_loss: 0.0014\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8372e-04 - val_loss: 0.0014\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8165e-04 - val_loss: 0.0014\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7959e-04 - val_loss: 0.0014\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7754e-04 - val_loss: 0.0014\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7549e-04 - val_loss: 0.0013\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7344e-04 - val_loss: 0.0013\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 7.7140e-04 - val_loss: 0.0013\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6935e-04 - val_loss: 0.0013\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6733e-04 - val_loss: 0.0013\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 7.6531e-04 - val_loss: 0.0013\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6328e-04 - val_loss: 0.0013\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6127e-04 - val_loss: 0.0013\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5925e-04 - val_loss: 0.0013\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5725e-04 - val_loss: 0.0013\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5524e-04 - val_loss: 0.0013\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5325e-04 - val_loss: 0.0013\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5126e-04 - val_loss: 0.0013\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4928e-04 - val_loss: 0.0013\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4728e-04 - val_loss: 0.0013\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4532e-04 - val_loss: 0.0013\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4334e-04 - val_loss: 0.0013\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4138e-04 - val_loss: 0.0013\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3941e-04 - val_loss: 0.0013\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3745e-04 - val_loss: 0.0013\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3551e-04 - val_loss: 0.0013\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3355e-04 - val_loss: 0.0013\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3162e-04 - val_loss: 0.0013\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2968e-04 - val_loss: 0.0013\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2775e-04 - val_loss: 0.0013\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2582e-04 - val_loss: 0.0013\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2390e-04 - val_loss: 0.0012\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2198e-04 - val_loss: 0.0012\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2007e-04 - val_loss: 0.0012\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1816e-04 - val_loss: 0.0012\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1626e-04 - val_loss: 0.0012\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1435e-04 - val_loss: 0.0012\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1246e-04 - val_loss: 0.0012\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1058e-04 - val_loss: 0.0012\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0870e-04 - val_loss: 0.0012\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0682e-04 - val_loss: 0.0012\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0494e-04 - val_loss: 0.0012\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0307e-04 - val_loss: 0.0012\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0121e-04 - val_loss: 0.0012\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9935e-04 - val_loss: 0.0012\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9749e-04 - val_loss: 0.0012\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9564e-04 - val_loss: 0.0012\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9380e-04 - val_loss: 0.0012\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9196e-04 - val_loss: 0.0012\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.9012e-04 - val_loss: 0.0012\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8828e-04 - val_loss: 0.0012\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8647e-04 - val_loss: 0.0012\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8464e-04 - val_loss: 0.0012\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8283e-04 - val_loss: 0.0012\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8101e-04 - val_loss: 0.0012\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 6.7921e-04 - val_loss: 0.0012\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7740e-04 - val_loss: 0.0012\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7560e-04 - val_loss: 0.0012\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7381e-04 - val_loss: 0.0012\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7202e-04 - val_loss: 0.0011\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7024e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6846e-04 - val_loss: 0.0011\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6668e-04 - val_loss: 0.0011\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6490e-04 - val_loss: 0.0011\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6314e-04 - val_loss: 0.0011\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6139e-04 - val_loss: 0.0011\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 6.5963e-04 - val_loss: 0.0011\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5788e-04 - val_loss: 0.0011\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5612e-04 - val_loss: 0.0011\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5439e-04 - val_loss: 0.0011\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.5264e-04 - val_loss: 0.0011\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5090e-04 - val_loss: 0.0011\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4918e-04 - val_loss: 0.0011\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.4746e-04 - val_loss: 0.0011\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4573e-04 - val_loss: 0.0011\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4402e-04 - val_loss: 0.0011\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4231e-04 - val_loss: 0.0011\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4060e-04 - val_loss: 0.0011\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3890e-04 - val_loss: 0.0011\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3720e-04 - val_loss: 0.0011\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3550e-04 - val_loss: 0.0011\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3381e-04 - val_loss: 0.0011\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3213e-04 - val_loss: 0.0011\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3045e-04 - val_loss: 0.0011\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2878e-04 - val_loss: 0.0011\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2711e-04 - val_loss: 0.0011\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.2544e-04 - val_loss: 0.0011\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2378e-04 - val_loss: 0.0011\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2212e-04 - val_loss: 0.0010\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2046e-04 - val_loss: 0.0010\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1882e-04 - val_loss: 0.0010\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1717e-04 - val_loss: 0.0010\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1553e-04 - val_loss: 0.0010\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1390e-04 - val_loss: 0.0010\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1226e-04 - val_loss: 0.0010\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1064e-04 - val_loss: 0.0010\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0901e-04 - val_loss: 0.0010\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0739e-04 - val_loss: 0.0010\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0579e-04 - val_loss: 0.0010\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0417e-04 - val_loss: 0.0010\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0257e-04 - val_loss: 0.0010\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0096e-04 - val_loss: 0.0010\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9936e-04 - val_loss: 0.0010\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9777e-04 - val_loss: 0.0010\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9618e-04 - val_loss: 9.9841e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9460e-04 - val_loss: 9.9534e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9302e-04 - val_loss: 9.9230e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9144e-04 - val_loss: 9.8925e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8987e-04 - val_loss: 9.8617e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8830e-04 - val_loss: 9.8314e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8674e-04 - val_loss: 9.8013e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8517e-04 - val_loss: 9.7710e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8362e-04 - val_loss: 9.7409e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8208e-04 - val_loss: 9.7111e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8053e-04 - val_loss: 9.6815e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7898e-04 - val_loss: 9.6514e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7745e-04 - val_loss: 9.6218e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7591e-04 - val_loss: 9.5921e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7438e-04 - val_loss: 9.5625e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7285e-04 - val_loss: 9.5334e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7134e-04 - val_loss: 9.5040e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6981e-04 - val_loss: 9.4748e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.6830e-04 - val_loss: 9.4455e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6679e-04 - val_loss: 9.4166e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6529e-04 - val_loss: 9.3876e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.6379e-04 - val_loss: 9.3586e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6228e-04 - val_loss: 9.3301e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6080e-04 - val_loss: 9.3015e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5930e-04 - val_loss: 9.2727e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5781e-04 - val_loss: 9.2445e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5634e-04 - val_loss: 9.2163e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5485e-04 - val_loss: 9.1880e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5338e-04 - val_loss: 9.1598e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5191e-04 - val_loss: 9.1317e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5045e-04 - val_loss: 9.1037e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4899e-04 - val_loss: 9.0761e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4754e-04 - val_loss: 9.0480e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4608e-04 - val_loss: 9.0202e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4463e-04 - val_loss: 8.9928e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4318e-04 - val_loss: 8.9652e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4174e-04 - val_loss: 8.9377e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4030e-04 - val_loss: 8.9105e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.3887e-04 - val_loss: 8.8833e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3744e-04 - val_loss: 8.8563e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3602e-04 - val_loss: 8.8292e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3460e-04 - val_loss: 8.8023e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3318e-04 - val_loss: 8.7752e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3176e-04 - val_loss: 8.7488e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3035e-04 - val_loss: 8.7219e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2894e-04 - val_loss: 8.6954e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2754e-04 - val_loss: 8.6690e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2614e-04 - val_loss: 8.6427e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2475e-04 - val_loss: 8.6163e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2335e-04 - val_loss: 8.5902e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2196e-04 - val_loss: 8.5641e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2059e-04 - val_loss: 8.5379e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.1920e-04 - val_loss: 8.5119e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1783e-04 - val_loss: 8.4862e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1646e-04 - val_loss: 8.4604e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1508e-04 - val_loss: 8.4346e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.1372e-04 - val_loss: 8.4091e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1236e-04 - val_loss: 8.3835e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1100e-04 - val_loss: 8.3580e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0965e-04 - val_loss: 8.3328e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0830e-04 - val_loss: 8.3078e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0695e-04 - val_loss: 8.2826e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0561e-04 - val_loss: 8.2575e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0427e-04 - val_loss: 8.2326e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0294e-04 - val_loss: 8.2077e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0160e-04 - val_loss: 8.1827e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0028e-04 - val_loss: 8.1581e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9895e-04 - val_loss: 8.1334e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9763e-04 - val_loss: 8.1090e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9632e-04 - val_loss: 8.0844e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9500e-04 - val_loss: 8.0601e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9368e-04 - val_loss: 8.0358e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9238e-04 - val_loss: 8.0116e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9107e-04 - val_loss: 7.9876e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8978e-04 - val_loss: 7.9634e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8849e-04 - val_loss: 7.9397e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8719e-04 - val_loss: 7.9160e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.8591e-04 - val_loss: 7.8921e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8462e-04 - val_loss: 7.8685e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8334e-04 - val_loss: 7.8448e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8206e-04 - val_loss: 7.8213e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8079e-04 - val_loss: 7.7980e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7951e-04 - val_loss: 7.7744e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7825e-04 - val_loss: 7.7512e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7699e-04 - val_loss: 7.7278e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7572e-04 - val_loss: 7.7048e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7447e-04 - val_loss: 7.6819e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7321e-04 - val_loss: 7.6591e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7196e-04 - val_loss: 7.6362e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7072e-04 - val_loss: 7.6134e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6947e-04 - val_loss: 7.5907e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6823e-04 - val_loss: 7.5683e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6700e-04 - val_loss: 7.5457e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6577e-04 - val_loss: 7.5232e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6454e-04 - val_loss: 7.5008e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6331e-04 - val_loss: 7.4787e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6209e-04 - val_loss: 7.4565e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6087e-04 - val_loss: 7.4344e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5965e-04 - val_loss: 7.4123e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5844e-04 - val_loss: 7.3903e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5723e-04 - val_loss: 7.3681e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5603e-04 - val_loss: 7.3465e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5482e-04 - val_loss: 7.3248e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5362e-04 - val_loss: 7.3034e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5242e-04 - val_loss: 7.2817e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5124e-04 - val_loss: 7.2603e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5004e-04 - val_loss: 7.2387e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4886e-04 - val_loss: 7.2174e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4767e-04 - val_loss: 7.1963e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4650e-04 - val_loss: 7.1751e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4533e-04 - val_loss: 7.1541e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4416e-04 - val_loss: 7.1329e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4298e-04 - val_loss: 7.1122e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4181e-04 - val_loss: 7.0911e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4065e-04 - val_loss: 7.0703e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3949e-04 - val_loss: 7.0496e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 4.3834e-04 - val_loss: 7.0290e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3718e-04 - val_loss: 7.0083e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3603e-04 - val_loss: 6.9881e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3488e-04 - val_loss: 6.9677e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3375e-04 - val_loss: 6.9474e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3260e-04 - val_loss: 6.9273e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3146e-04 - val_loss: 6.9069e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3033e-04 - val_loss: 6.8868e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2920e-04 - val_loss: 6.8667e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2807e-04 - val_loss: 6.8468e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2695e-04 - val_loss: 6.8268e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2582e-04 - val_loss: 6.8070e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2470e-04 - val_loss: 6.7872e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2359e-04 - val_loss: 6.7676e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2248e-04 - val_loss: 6.7479e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2137e-04 - val_loss: 6.7284e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2025e-04 - val_loss: 6.7090e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1916e-04 - val_loss: 6.6896e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1806e-04 - val_loss: 6.6703e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1696e-04 - val_loss: 6.6513e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1587e-04 - val_loss: 6.6317e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1477e-04 - val_loss: 6.6127e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1369e-04 - val_loss: 6.5937e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1260e-04 - val_loss: 6.5749e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1151e-04 - val_loss: 6.5558e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1044e-04 - val_loss: 6.5373e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0936e-04 - val_loss: 6.5185e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0830e-04 - val_loss: 6.5000e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0722e-04 - val_loss: 6.4811e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0616e-04 - val_loss: 6.4627e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0509e-04 - val_loss: 6.4440e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0403e-04 - val_loss: 6.4256e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0297e-04 - val_loss: 6.4074e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0192e-04 - val_loss: 6.3889e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0086e-04 - val_loss: 6.3709e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.9982e-04 - val_loss: 6.3526e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9877e-04 - val_loss: 6.3346e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9773e-04 - val_loss: 6.3165e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9668e-04 - val_loss: 6.2987e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9565e-04 - val_loss: 6.2808e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9461e-04 - val_loss: 6.2632e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9359e-04 - val_loss: 6.2454e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9255e-04 - val_loss: 6.2275e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9152e-04 - val_loss: 6.2101e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9051e-04 - val_loss: 6.1927e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8949e-04 - val_loss: 6.1752e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8847e-04 - val_loss: 6.1577e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8745e-04 - val_loss: 6.1403e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8644e-04 - val_loss: 6.1231e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8543e-04 - val_loss: 6.1059e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8443e-04 - val_loss: 6.0887e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8341e-04 - val_loss: 6.0716e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8242e-04 - val_loss: 6.0544e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8143e-04 - val_loss: 6.0376e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8042e-04 - val_loss: 6.0208e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7943e-04 - val_loss: 6.0041e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7844e-04 - val_loss: 5.9873e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7746e-04 - val_loss: 5.9705e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7648e-04 - val_loss: 5.9538e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7549e-04 - val_loss: 5.9372e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7452e-04 - val_loss: 5.9206e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7354e-04 - val_loss: 5.9042e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7256e-04 - val_loss: 5.8878e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.7160e-04 - val_loss: 5.8714e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7062e-04 - val_loss: 5.8552e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6966e-04 - val_loss: 5.8392e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6870e-04 - val_loss: 5.8229e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6774e-04 - val_loss: 5.8069e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6679e-04 - val_loss: 5.7907e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6583e-04 - val_loss: 5.7747e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6488e-04 - val_loss: 5.7587e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6392e-04 - val_loss: 5.7432e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6298e-04 - val_loss: 5.7272e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6204e-04 - val_loss: 5.7114e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6109e-04 - val_loss: 5.6957e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6015e-04 - val_loss: 5.6801e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5922e-04 - val_loss: 5.6645e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5829e-04 - val_loss: 5.6489e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5736e-04 - val_loss: 5.6335e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5643e-04 - val_loss: 5.6182e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5551e-04 - val_loss: 5.6028e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5458e-04 - val_loss: 5.5877e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5367e-04 - val_loss: 5.5724e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5275e-04 - val_loss: 5.5574e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5184e-04 - val_loss: 5.5421e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5092e-04 - val_loss: 5.5272e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5001e-04 - val_loss: 5.5121e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4910e-04 - val_loss: 5.4971e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4819e-04 - val_loss: 5.4824e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4729e-04 - val_loss: 5.4676e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4639e-04 - val_loss: 5.4528e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4550e-04 - val_loss: 5.4382e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4460e-04 - val_loss: 5.4234e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4371e-04 - val_loss: 5.4087e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.4282e-04 - val_loss: 5.3944e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4193e-04 - val_loss: 5.3799e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4105e-04 - val_loss: 5.3653e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4016e-04 - val_loss: 5.3509e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3928e-04 - val_loss: 5.3366e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3841e-04 - val_loss: 5.3224e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3753e-04 - val_loss: 5.3081e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3666e-04 - val_loss: 5.2940e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3579e-04 - val_loss: 5.2799e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3492e-04 - val_loss: 5.2657e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3406e-04 - val_loss: 5.2518e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3319e-04 - val_loss: 5.2379e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3234e-04 - val_loss: 5.2240e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3148e-04 - val_loss: 5.2102e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3063e-04 - val_loss: 5.1963e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2977e-04 - val_loss: 5.1825e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2892e-04 - val_loss: 5.1688e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2807e-04 - val_loss: 5.1552e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2722e-04 - val_loss: 5.1415e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2638e-04 - val_loss: 5.1282e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2554e-04 - val_loss: 5.1145e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2470e-04 - val_loss: 5.1011e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2386e-04 - val_loss: 5.0876e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2303e-04 - val_loss: 5.0744e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2220e-04 - val_loss: 5.0610e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2136e-04 - val_loss: 5.0478e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2054e-04 - val_loss: 5.0346e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1972e-04 - val_loss: 5.0215e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1889e-04 - val_loss: 5.0082e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1807e-04 - val_loss: 4.9953e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1726e-04 - val_loss: 4.9823e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1644e-04 - val_loss: 4.9692e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1562e-04 - val_loss: 4.9565e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1482e-04 - val_loss: 4.9437e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1401e-04 - val_loss: 4.9308e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1320e-04 - val_loss: 4.9180e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1240e-04 - val_loss: 4.9052e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1159e-04 - val_loss: 4.8925e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1079e-04 - val_loss: 4.8801e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1000e-04 - val_loss: 4.8674e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0920e-04 - val_loss: 4.8548e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0841e-04 - val_loss: 4.8426e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0762e-04 - val_loss: 4.8301e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0683e-04 - val_loss: 4.8176e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0604e-04 - val_loss: 4.8052e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0526e-04 - val_loss: 4.7929e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0448e-04 - val_loss: 4.7807e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0370e-04 - val_loss: 4.7686e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0292e-04 - val_loss: 4.7564e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0214e-04 - val_loss: 4.7443e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.0137e-04 - val_loss: 4.7322e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0060e-04 - val_loss: 4.7201e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9983e-04 - val_loss: 4.7082e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9906e-04 - val_loss: 4.6963e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9830e-04 - val_loss: 4.6843e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9754e-04 - val_loss: 4.6724e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.9677e-04 - val_loss: 4.6606e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.9602e-04 - val_loss: 4.6489e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9526e-04 - val_loss: 4.6371e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9451e-04 - val_loss: 4.6255e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9376e-04 - val_loss: 4.6138e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9301e-04 - val_loss: 4.6023e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9226e-04 - val_loss: 4.5908e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9151e-04 - val_loss: 4.5792e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9077e-04 - val_loss: 4.5679e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9003e-04 - val_loss: 4.5564e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8929e-04 - val_loss: 4.5450e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8856e-04 - val_loss: 4.5337e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8782e-04 - val_loss: 4.5223e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8708e-04 - val_loss: 4.5113e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8636e-04 - val_loss: 4.5001e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8563e-04 - val_loss: 4.4888e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8490e-04 - val_loss: 4.4775e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8417e-04 - val_loss: 4.4666e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8345e-04 - val_loss: 4.4555e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8273e-04 - val_loss: 4.4447e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8201e-04 - val_loss: 4.4336e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8129e-04 - val_loss: 4.4228e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8058e-04 - val_loss: 4.4120e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7987e-04 - val_loss: 4.4011e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7916e-04 - val_loss: 4.3903e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7845e-04 - val_loss: 4.3795e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7775e-04 - val_loss: 4.3687e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7704e-04 - val_loss: 4.3581e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7634e-04 - val_loss: 4.3474e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7563e-04 - val_loss: 4.3369e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7494e-04 - val_loss: 4.3262e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7424e-04 - val_loss: 4.3157e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7355e-04 - val_loss: 4.3051e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7285e-04 - val_loss: 4.2948e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7217e-04 - val_loss: 4.2845e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7148e-04 - val_loss: 4.2740e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 2.7079e-04 - val_loss: 4.2636e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7010e-04 - val_loss: 4.2532e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6942e-04 - val_loss: 4.2431e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6873e-04 - val_loss: 4.2330e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6806e-04 - val_loss: 4.2228e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6738e-04 - val_loss: 4.2127e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 2.6671e-04 - val_loss: 4.2025e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6603e-04 - val_loss: 4.1923e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6536e-04 - val_loss: 4.1824e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6468e-04 - val_loss: 4.1723e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6402e-04 - val_loss: 4.1625e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6335e-04 - val_loss: 4.1526e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6270e-04 - val_loss: 4.1427e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6203e-04 - val_loss: 4.1328e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6137e-04 - val_loss: 4.1230e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6071e-04 - val_loss: 4.1132e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6006e-04 - val_loss: 4.1036e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5940e-04 - val_loss: 4.0938e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5875e-04 - val_loss: 4.0840e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5809e-04 - val_loss: 4.0745e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5745e-04 - val_loss: 4.0650e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5680e-04 - val_loss: 4.0553e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5615e-04 - val_loss: 4.0459e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5551e-04 - val_loss: 4.0362e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5487e-04 - val_loss: 4.0268e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5423e-04 - val_loss: 4.0174e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5360e-04 - val_loss: 4.0081e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5296e-04 - val_loss: 3.9987e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5232e-04 - val_loss: 3.9893e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 2.5169e-04 - val_loss: 3.9800e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5105e-04 - val_loss: 3.9708e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5043e-04 - val_loss: 3.9615e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4980e-04 - val_loss: 3.9523e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4918e-04 - val_loss: 3.9432e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4855e-04 - val_loss: 3.9341e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4793e-04 - val_loss: 3.9249e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4731e-04 - val_loss: 3.9158e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4669e-04 - val_loss: 3.9070e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4607e-04 - val_loss: 3.8979e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4546e-04 - val_loss: 3.8890e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4484e-04 - val_loss: 3.8801e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4424e-04 - val_loss: 3.8711e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4363e-04 - val_loss: 3.8624e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4301e-04 - val_loss: 3.8535e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4241e-04 - val_loss: 3.8445e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4180e-04 - val_loss: 3.8358e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4120e-04 - val_loss: 3.8271e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4060e-04 - val_loss: 3.8184e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4000e-04 - val_loss: 3.8097e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3940e-04 - val_loss: 3.8012e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3881e-04 - val_loss: 3.7925e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3821e-04 - val_loss: 3.7840e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3762e-04 - val_loss: 3.7754e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.3703e-04 - val_loss: 3.7669e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3644e-04 - val_loss: 3.7585e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3585e-04 - val_loss: 3.7500e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3526e-04 - val_loss: 3.7414e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3468e-04 - val_loss: 3.7331e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3410e-04 - val_loss: 3.7248e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3351e-04 - val_loss: 3.7165e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3294e-04 - val_loss: 3.7081e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3236e-04 - val_loss: 3.6998e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3178e-04 - val_loss: 3.6916e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3121e-04 - val_loss: 3.6835e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3064e-04 - val_loss: 3.6752e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3006e-04 - val_loss: 3.6670e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.2950e-04 - val_loss: 3.6589e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2893e-04 - val_loss: 3.6508e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2836e-04 - val_loss: 3.6428e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2780e-04 - val_loss: 3.6346e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2723e-04 - val_loss: 3.6268e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2667e-04 - val_loss: 3.6187e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2611e-04 - val_loss: 3.6108e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2555e-04 - val_loss: 3.6026e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2499e-04 - val_loss: 3.5949e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2444e-04 - val_loss: 3.5870e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2389e-04 - val_loss: 3.5790e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2334e-04 - val_loss: 3.5713e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2278e-04 - val_loss: 3.5636e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2223e-04 - val_loss: 3.5557e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2169e-04 - val_loss: 3.5480e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2114e-04 - val_loss: 3.5403e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2060e-04 - val_loss: 3.5327e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2006e-04 - val_loss: 3.5250e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1951e-04 - val_loss: 3.5172e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1897e-04 - val_loss: 3.5097e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1844e-04 - val_loss: 3.5023e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1791e-04 - val_loss: 3.4947e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1737e-04 - val_loss: 3.4871e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1683e-04 - val_loss: 3.4797e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1630e-04 - val_loss: 3.4724e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1577e-04 - val_loss: 3.4648e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1524e-04 - val_loss: 3.4574e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1471e-04 - val_loss: 3.4500e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1419e-04 - val_loss: 3.4427e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1367e-04 - val_loss: 3.4352e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1314e-04 - val_loss: 3.4279e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1262e-04 - val_loss: 3.4207e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1210e-04 - val_loss: 3.4133e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1158e-04 - val_loss: 3.4061e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.1106e-04 - val_loss: 3.3990e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 2.1055e-04 - val_loss: 3.3918e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1003e-04 - val_loss: 3.3848e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0953e-04 - val_loss: 3.3775e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0901e-04 - val_loss: 3.3705e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0850e-04 - val_loss: 3.3634e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0799e-04 - val_loss: 3.3563e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0749e-04 - val_loss: 3.3492e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0698e-04 - val_loss: 3.3423e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0648e-04 - val_loss: 3.3352e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0598e-04 - val_loss: 3.3282e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0547e-04 - val_loss: 3.3214e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0498e-04 - val_loss: 3.3145e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0448e-04 - val_loss: 3.3075e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0398e-04 - val_loss: 3.3006e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0348e-04 - val_loss: 3.2939e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0300e-04 - val_loss: 3.2870e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0250e-04 - val_loss: 3.2801e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0201e-04 - val_loss: 3.2735e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0153e-04 - val_loss: 3.2667e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0103e-04 - val_loss: 3.2602e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0055e-04 - val_loss: 3.2535e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0006e-04 - val_loss: 3.2467e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9958e-04 - val_loss: 3.2401e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9910e-04 - val_loss: 3.2334e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9861e-04 - val_loss: 3.2268e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9813e-04 - val_loss: 3.2201e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9766e-04 - val_loss: 3.2135e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9718e-04 - val_loss: 3.2070e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9670e-04 - val_loss: 3.2006e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9623e-04 - val_loss: 3.1940e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9575e-04 - val_loss: 3.1876e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9529e-04 - val_loss: 3.1811e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9482e-04 - val_loss: 3.1746e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9435e-04 - val_loss: 3.1682e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9388e-04 - val_loss: 3.1620e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9342e-04 - val_loss: 3.1556e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9295e-04 - val_loss: 3.1492e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9249e-04 - val_loss: 3.1429e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9202e-04 - val_loss: 3.1367e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9156e-04 - val_loss: 3.1305e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9111e-04 - val_loss: 3.1242e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9065e-04 - val_loss: 3.1178e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9019e-04 - val_loss: 3.1117e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8974e-04 - val_loss: 3.1056e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8928e-04 - val_loss: 3.0992e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8883e-04 - val_loss: 3.0933e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8838e-04 - val_loss: 3.0870e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8793e-04 - val_loss: 3.0810e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8748e-04 - val_loss: 3.0748e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8703e-04 - val_loss: 3.0688e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8659e-04 - val_loss: 3.0627e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8614e-04 - val_loss: 3.0567e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8569e-04 - val_loss: 3.0507e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8525e-04 - val_loss: 3.0448e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8481e-04 - val_loss: 3.0388e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8437e-04 - val_loss: 3.0329e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8393e-04 - val_loss: 3.0269e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8349e-04 - val_loss: 3.0210e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8306e-04 - val_loss: 3.0153e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8263e-04 - val_loss: 3.0094e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.8219e-04 - val_loss: 3.0035e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8176e-04 - val_loss: 2.9977e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8132e-04 - val_loss: 2.9918e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.8090e-04 - val_loss: 2.9860e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8047e-04 - val_loss: 2.9802e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8004e-04 - val_loss: 2.9745e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7962e-04 - val_loss: 2.9688e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7919e-04 - val_loss: 2.9630e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7877e-04 - val_loss: 2.9573e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.7834e-04 - val_loss: 2.9518e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7793e-04 - val_loss: 2.9462e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7751e-04 - val_loss: 2.9404e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7709e-04 - val_loss: 2.9350e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7667e-04 - val_loss: 2.9293e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7625e-04 - val_loss: 2.9238e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7584e-04 - val_loss: 2.9183e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7543e-04 - val_loss: 2.9127e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7502e-04 - val_loss: 2.9071e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7460e-04 - val_loss: 2.9016e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7419e-04 - val_loss: 2.8960e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7378e-04 - val_loss: 2.8907e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7337e-04 - val_loss: 2.8851e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7297e-04 - val_loss: 2.8799e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7256e-04 - val_loss: 2.8744e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7216e-04 - val_loss: 2.8690e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7176e-04 - val_loss: 2.8636e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7135e-04 - val_loss: 2.8582e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7095e-04 - val_loss: 2.8528e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7055e-04 - val_loss: 2.8475e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7015e-04 - val_loss: 2.8423e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6976e-04 - val_loss: 2.8371e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6936e-04 - val_loss: 2.8319e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6897e-04 - val_loss: 2.8266e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6857e-04 - val_loss: 2.8214e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6818e-04 - val_loss: 2.8162e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6778e-04 - val_loss: 2.8108e-04\n",
      "0.00017624285828787833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.54169637,  0.34929857,  0.8768658 ,  0.52372444, -0.49833632],\n",
       "        [ 1.140828  ,  0.03867984, -0.19162105, -0.5043923 , -0.2447526 ],\n",
       "        [-0.5315727 , -0.35692093,  0.36236218, -0.8627294 , -0.9970089 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.64209014, -0.23871034, -0.6807144 ,  0.5031508 , -0.3620726 ],\n",
       "       dtype=float32),\n",
       " array([[-0.5829349 ,  0.4226227 ,  0.43882722,  0.11619586,  0.516009  ,\n",
       "          0.25665694, -0.34029523,  0.57242346,  0.03887531, -0.12503229],\n",
       "        [ 0.29511276,  0.1649536 , -0.04252048,  0.28458565,  0.46312296,\n",
       "         -0.13703355,  0.12020335, -0.48242283,  0.3994536 , -0.15723334],\n",
       "        [-0.6967453 , -0.19629787,  0.33185515, -0.16314606,  0.13715091,\n",
       "         -0.01736727,  0.25997677, -0.3552291 , -0.36874533, -0.22631767],\n",
       "        [ 0.46257073,  0.62157387, -0.17002627, -0.15960087,  0.14568098,\n",
       "         -0.1596013 , -0.35578078,  0.4262544 ,  0.30941567,  0.58108246],\n",
       "        [-0.6150803 , -0.7495975 ,  0.23389503, -0.04808602,  0.00636454,\n",
       "          0.02841628, -0.44556165,  0.10939199,  0.36223406,  0.22499895]],\n",
       "       dtype=float32),\n",
       " array([ 0.7692925 ,  0.79491216, -0.7690788 , -0.60653454,  0.7487676 ,\n",
       "        -0.5484455 , -0.6645101 ,  0.8017839 , -0.7605215 , -0.64655703],\n",
       "       dtype=float32),\n",
       " array([[ 0.72854906],\n",
       "        [ 0.8264873 ],\n",
       "        [-0.690762  ],\n",
       "        [-0.2736703 ],\n",
       "        [ 0.545514  ],\n",
       "        [-0.25664735],\n",
       "        [-0.31753403],\n",
       "        [ 0.8269367 ],\n",
       "        [-0.5893225 ],\n",
       "        [-0.31068647]], dtype=float32),\n",
       " array([0.8606236], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_2(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure2_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.4422 - val_loss: 31.2569\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0228 - val_loss: 27.3036\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.9897 - val_loss: 21.1529\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 23.8181 - val_loss: 13.9077\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 17.5865 - val_loss: 7.6692\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 11.3173 - val_loss: 4.5856\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2023 - val_loss: 5.4065\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7495 - val_loss: 7.1067\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7713 - val_loss: 6.1980\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9893 - val_loss: 4.0564\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4598 - val_loss: 2.5533\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 2.5490 - val_loss: 1.8131\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7834 - val_loss: 1.5401\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4373 - val_loss: 1.4970\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4373 - val_loss: 1.4930\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.5500 - val_loss: 1.4087\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5876 - val_loss: 1.2121\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4730 - val_loss: 0.9360\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2166 - val_loss: 0.6429\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.8775 - val_loss: 0.3990\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.5334 - val_loss: 0.2546\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2595 - val_loss: 0.2312\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1082 - val_loss: 0.3115\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0923 - val_loss: 0.4422\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1772 - val_loss: 0.5524\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2944 - val_loss: 0.5841\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3735 - val_loss: 0.5177\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3747 - val_loss: 0.3774\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3016 - val_loss: 0.2142\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1901 - val_loss: 0.0814\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0852 - val_loss: 0.0131\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0205 - val_loss: 0.0158\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0709\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.1464\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0844 - val_loss: 0.2108\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1274 - val_loss: 0.2435\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1490 - val_loss: 0.2385\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1441 - val_loss: 0.2023\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1174 - val_loss: 0.1486\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0795 - val_loss: 0.0931\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0426 - val_loss: 0.0485\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0216\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0078 - val_loss: 0.0132\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0136 - val_loss: 0.0182\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0278 - val_loss: 0.0291\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0417 - val_loss: 0.0388\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0486 - val_loss: 0.0427\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0465 - val_loss: 0.0398\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0317\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0260 - val_loss: 0.0220\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0110 - val_loss: 0.0146\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0180 - val_loss: 0.0212\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0200\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0174\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0082 - val_loss: 0.0150\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0054 - val_loss: 0.0131\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0121\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0115\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0109\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9630e-04 - val_loss: 0.0016\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6868e-04 - val_loss: 0.0017\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5483e-04 - val_loss: 0.0018\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5095e-04 - val_loss: 0.0018\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5004e-04 - val_loss: 0.0018\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4528e-04 - val_loss: 0.0018\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3303e-04 - val_loss: 0.0017\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1342e-04 - val_loss: 0.0017\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8944e-04 - val_loss: 0.0016\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6506e-04 - val_loss: 0.0015\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.4375e-04 - val_loss: 0.0014\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2748e-04 - val_loss: 0.0013\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1644e-04 - val_loss: 0.0012\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0897e-04 - val_loss: 0.0012\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0249e-04 - val_loss: 0.0012\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9464e-04 - val_loss: 0.0011\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8419e-04 - val_loss: 0.0011\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7136e-04 - val_loss: 0.0011\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5735e-04 - val_loss: 0.0011\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4360e-04 - val_loss: 0.0011\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3117e-04 - val_loss: 0.0011\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2047e-04 - val_loss: 0.0011\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1138e-04 - val_loss: 0.0012\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0326e-04 - val_loss: 0.0012\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9536e-04 - val_loss: 0.0012\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8699e-04 - val_loss: 0.0011\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7792e-04 - val_loss: 0.0011\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6835e-04 - val_loss: 0.0011\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5874e-04 - val_loss: 0.0011\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4956e-04 - val_loss: 0.0010\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4103e-04 - val_loss: 0.0010\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3317e-04 - val_loss: 9.9325e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2576e-04 - val_loss: 9.6907e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1858e-04 - val_loss: 9.4818e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1137e-04 - val_loss: 9.3097e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.0398e-04 - val_loss: 9.1744e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9644e-04 - val_loss: 9.0722e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8887e-04 - val_loss: 8.9966e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8147e-04 - val_loss: 8.9390e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7439e-04 - val_loss: 8.8894e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6768e-04 - val_loss: 8.8388e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.6128e-04 - val_loss: 8.7789e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5507e-04 - val_loss: 8.7053e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4892e-04 - val_loss: 8.6163e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4278e-04 - val_loss: 8.5131e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3660e-04 - val_loss: 8.3981e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3043e-04 - val_loss: 8.2757e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2432e-04 - val_loss: 8.1502e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1834e-04 - val_loss: 8.0256e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1255e-04 - val_loss: 7.9049e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0696e-04 - val_loss: 7.7908e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0152e-04 - val_loss: 7.6852e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9619e-04 - val_loss: 7.5893e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9094e-04 - val_loss: 7.5030e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8571e-04 - val_loss: 7.4265e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8054e-04 - val_loss: 7.3582e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7541e-04 - val_loss: 7.2962e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.7035e-04 - val_loss: 7.2378e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6540e-04 - val_loss: 7.1798e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6054e-04 - val_loss: 7.1196e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5579e-04 - val_loss: 7.0548e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5115e-04 - val_loss: 6.9838e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4656e-04 - val_loss: 6.9064e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.4205e-04 - val_loss: 6.8237e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3758e-04 - val_loss: 6.7371e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3317e-04 - val_loss: 6.6489e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2883e-04 - val_loss: 6.5609e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2455e-04 - val_loss: 6.4756e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2034e-04 - val_loss: 6.3942e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1621e-04 - val_loss: 6.3174e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1214e-04 - val_loss: 6.2459e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 4.0813e-04 - val_loss: 6.1798e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.0419e-04 - val_loss: 6.1185e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.0029e-04 - val_loss: 6.0618e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9644e-04 - val_loss: 6.0088e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.9265e-04 - val_loss: 5.9583e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8892e-04 - val_loss: 5.9097e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8523e-04 - val_loss: 5.8614e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.8161e-04 - val_loss: 5.8127e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.7804e-04 - val_loss: 5.7624e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.7451e-04 - val_loss: 5.7101e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7105e-04 - val_loss: 5.6554e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6763e-04 - val_loss: 5.5980e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6425e-04 - val_loss: 5.5391e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6092e-04 - val_loss: 5.4789e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5762e-04 - val_loss: 5.4188e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5438e-04 - val_loss: 5.3592e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5117e-04 - val_loss: 5.3015e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4803e-04 - val_loss: 5.2457e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4492e-04 - val_loss: 5.1922e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4185e-04 - val_loss: 5.1414e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3882e-04 - val_loss: 5.0927e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3583e-04 - val_loss: 5.0463e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3288e-04 - val_loss: 5.0015e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2996e-04 - val_loss: 4.9583e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2708e-04 - val_loss: 4.9162e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2425e-04 - val_loss: 4.8745e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2144e-04 - val_loss: 4.8333e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1867e-04 - val_loss: 4.7921e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1594e-04 - val_loss: 4.7509e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1325e-04 - val_loss: 4.7091e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1059e-04 - val_loss: 4.6669e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0795e-04 - val_loss: 4.6243e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0536e-04 - val_loss: 4.5817e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0279e-04 - val_loss: 4.5392e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0026e-04 - val_loss: 4.4968e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9776e-04 - val_loss: 4.4553e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9529e-04 - val_loss: 4.4145e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9285e-04 - val_loss: 4.3747e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9044e-04 - val_loss: 4.3358e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8805e-04 - val_loss: 4.2980e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8570e-04 - val_loss: 4.2611e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8337e-04 - val_loss: 4.2251e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8107e-04 - val_loss: 4.1896e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7880e-04 - val_loss: 4.1549e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7656e-04 - val_loss: 4.1203e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7434e-04 - val_loss: 4.0862e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7215e-04 - val_loss: 4.0525e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6999e-04 - val_loss: 4.0188e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6784e-04 - val_loss: 3.9853e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6573e-04 - val_loss: 3.9522e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6363e-04 - val_loss: 3.9191e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6157e-04 - val_loss: 3.8862e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5952e-04 - val_loss: 3.8536e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5750e-04 - val_loss: 3.8214e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5550e-04 - val_loss: 3.7898e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5352e-04 - val_loss: 3.7583e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5157e-04 - val_loss: 3.7276e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4963e-04 - val_loss: 3.6974e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4772e-04 - val_loss: 3.6676e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4583e-04 - val_loss: 3.6384e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4396e-04 - val_loss: 3.6095e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4211e-04 - val_loss: 3.5811e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4028e-04 - val_loss: 3.5531e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3847e-04 - val_loss: 3.5252e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3668e-04 - val_loss: 3.4977e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3491e-04 - val_loss: 3.4702e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3316e-04 - val_loss: 3.4430e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3143e-04 - val_loss: 3.4160e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2971e-04 - val_loss: 3.3894e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2802e-04 - val_loss: 3.3628e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2634e-04 - val_loss: 3.3365e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2468e-04 - val_loss: 3.3106e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2303e-04 - val_loss: 3.2850e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2141e-04 - val_loss: 3.2597e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1980e-04 - val_loss: 3.2346e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1821e-04 - val_loss: 3.2099e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1663e-04 - val_loss: 3.1856e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1507e-04 - val_loss: 3.1617e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1353e-04 - val_loss: 3.1380e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1200e-04 - val_loss: 3.1146e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1049e-04 - val_loss: 3.0915e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0899e-04 - val_loss: 3.0685e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0750e-04 - val_loss: 3.0459e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0604e-04 - val_loss: 3.0233e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0458e-04 - val_loss: 3.0010e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0315e-04 - val_loss: 2.9790e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0173e-04 - val_loss: 2.9571e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0032e-04 - val_loss: 2.9354e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9892e-04 - val_loss: 2.9139e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9754e-04 - val_loss: 2.8926e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9617e-04 - val_loss: 2.8715e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9481e-04 - val_loss: 2.8505e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9347e-04 - val_loss: 2.8300e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9214e-04 - val_loss: 2.8095e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9082e-04 - val_loss: 2.7894e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8952e-04 - val_loss: 2.7695e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8823e-04 - val_loss: 2.7497e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8696e-04 - val_loss: 2.7303e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8568e-04 - val_loss: 2.7110e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8443e-04 - val_loss: 2.6919e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 1.8319e-04 - val_loss: 2.6729e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8195e-04 - val_loss: 2.6542e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8074e-04 - val_loss: 2.6356e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7953e-04 - val_loss: 2.6172e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7833e-04 - val_loss: 2.5990e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7715e-04 - val_loss: 2.5810e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7598e-04 - val_loss: 2.5632e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7481e-04 - val_loss: 2.5452e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7365e-04 - val_loss: 2.5278e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7251e-04 - val_loss: 2.5104e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7138e-04 - val_loss: 2.4931e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7026e-04 - val_loss: 2.4761e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6915e-04 - val_loss: 2.4592e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6805e-04 - val_loss: 2.4424e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6695e-04 - val_loss: 2.4259e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6587e-04 - val_loss: 2.4095e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6480e-04 - val_loss: 2.3933e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6374e-04 - val_loss: 2.3772e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6269e-04 - val_loss: 2.3613e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6164e-04 - val_loss: 2.3455e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6061e-04 - val_loss: 2.3298e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5958e-04 - val_loss: 2.3143e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5857e-04 - val_loss: 2.2988e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5756e-04 - val_loss: 2.2838e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5656e-04 - val_loss: 2.2687e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5557e-04 - val_loss: 2.2537e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5459e-04 - val_loss: 2.2388e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5361e-04 - val_loss: 2.2242e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5265e-04 - val_loss: 2.2096e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5170e-04 - val_loss: 2.1952e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5075e-04 - val_loss: 2.1809e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4981e-04 - val_loss: 2.1668e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4888e-04 - val_loss: 2.1527e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4796e-04 - val_loss: 2.1389e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4704e-04 - val_loss: 2.1250e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4613e-04 - val_loss: 2.1114e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4523e-04 - val_loss: 2.0978e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4434e-04 - val_loss: 2.0845e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4345e-04 - val_loss: 2.0711e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4258e-04 - val_loss: 2.0580e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4170e-04 - val_loss: 2.0449e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4085e-04 - val_loss: 2.0319e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3998e-04 - val_loss: 2.0192e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3914e-04 - val_loss: 2.0064e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3830e-04 - val_loss: 1.9937e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3746e-04 - val_loss: 1.9811e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3663e-04 - val_loss: 1.9687e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.3581e-04 - val_loss: 1.9564e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3499e-04 - val_loss: 1.9442e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3419e-04 - val_loss: 1.9321e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3339e-04 - val_loss: 1.9202e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3259e-04 - val_loss: 1.9082e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3180e-04 - val_loss: 1.8965e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3102e-04 - val_loss: 1.8848e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3024e-04 - val_loss: 1.8732e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2947e-04 - val_loss: 1.8617e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2871e-04 - val_loss: 1.8503e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2795e-04 - val_loss: 1.8390e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2719e-04 - val_loss: 1.8278e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2645e-04 - val_loss: 1.8167e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2571e-04 - val_loss: 1.8056e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2498e-04 - val_loss: 1.7946e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2425e-04 - val_loss: 1.7838e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2353e-04 - val_loss: 1.7731e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2281e-04 - val_loss: 1.7623e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2210e-04 - val_loss: 1.7518e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2139e-04 - val_loss: 1.7412e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2069e-04 - val_loss: 1.7308e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1999e-04 - val_loss: 1.7205e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1931e-04 - val_loss: 1.7101e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.1862e-04 - val_loss: 1.7001e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1795e-04 - val_loss: 1.6900e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1727e-04 - val_loss: 1.6800e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1660e-04 - val_loss: 1.6700e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1594e-04 - val_loss: 1.6602e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1528e-04 - val_loss: 1.6505e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1463e-04 - val_loss: 1.6407e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1397e-04 - val_loss: 1.6311e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1333e-04 - val_loss: 1.6216e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1269e-04 - val_loss: 1.6120e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1206e-04 - val_loss: 1.6026e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.1143e-04 - val_loss: 1.5933e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1080e-04 - val_loss: 1.5840e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1018e-04 - val_loss: 1.5748e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0957e-04 - val_loss: 1.5657e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0895e-04 - val_loss: 1.5568e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0835e-04 - val_loss: 1.5478e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0775e-04 - val_loss: 1.5388e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0715e-04 - val_loss: 1.5300e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0656e-04 - val_loss: 1.5212e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0596e-04 - val_loss: 1.5126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0538e-04 - val_loss: 1.5039e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0480e-04 - val_loss: 1.4953e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0422e-04 - val_loss: 1.4868e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0365e-04 - val_loss: 1.4784e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0308e-04 - val_loss: 1.4700e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0252e-04 - val_loss: 1.4618e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0196e-04 - val_loss: 1.4535e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0140e-04 - val_loss: 1.4452e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0085e-04 - val_loss: 1.4371e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0031e-04 - val_loss: 1.4290e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9759e-05 - val_loss: 1.4210e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9223e-05 - val_loss: 1.4130e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8683e-05 - val_loss: 1.4051e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8150e-05 - val_loss: 1.3973e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7622e-05 - val_loss: 1.3896e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7095e-05 - val_loss: 1.3818e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6576e-05 - val_loss: 1.3742e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6058e-05 - val_loss: 1.3666e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5543e-05 - val_loss: 1.3590e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5034e-05 - val_loss: 1.3515e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4526e-05 - val_loss: 1.3441e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4022e-05 - val_loss: 1.3367e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.3522e-05 - val_loss: 1.3294e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3026e-05 - val_loss: 1.3220e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2534e-05 - val_loss: 1.3148e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2043e-05 - val_loss: 1.3076e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1558e-05 - val_loss: 1.3005e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1074e-05 - val_loss: 1.2934e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0593e-05 - val_loss: 1.2864e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0113e-05 - val_loss: 1.2794e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9643e-05 - val_loss: 1.2725e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9173e-05 - val_loss: 1.2656e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.8707e-05 - val_loss: 1.2587e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8242e-05 - val_loss: 1.2520e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7785e-05 - val_loss: 1.2452e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7323e-05 - val_loss: 1.2385e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6870e-05 - val_loss: 1.2319e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6417e-05 - val_loss: 1.2253e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5972e-05 - val_loss: 1.2188e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5523e-05 - val_loss: 1.2122e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5079e-05 - val_loss: 1.2057e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4644e-05 - val_loss: 1.1993e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4201e-05 - val_loss: 1.1929e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3770e-05 - val_loss: 1.1866e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3338e-05 - val_loss: 1.1803e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.2910e-05 - val_loss: 1.1740e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.2486e-05 - val_loss: 1.1679e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.2065e-05 - val_loss: 1.1616e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1643e-05 - val_loss: 1.1556e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1224e-05 - val_loss: 1.1495e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0811e-05 - val_loss: 1.1435e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0400e-05 - val_loss: 1.1375e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9989e-05 - val_loss: 1.1314e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9584e-05 - val_loss: 1.1256e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9181e-05 - val_loss: 1.1197e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8781e-05 - val_loss: 1.1138e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8379e-05 - val_loss: 1.1081e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7985e-05 - val_loss: 1.1023e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7593e-05 - val_loss: 1.0965e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7199e-05 - val_loss: 1.0909e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6813e-05 - val_loss: 1.0852e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6424e-05 - val_loss: 1.0797e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6044e-05 - val_loss: 1.0740e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5663e-05 - val_loss: 1.0685e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 7.5283e-05 - val_loss: 1.0630e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.4904e-05 - val_loss: 1.0575e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4531e-05 - val_loss: 1.0521e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.4161e-05 - val_loss: 1.0467e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3792e-05 - val_loss: 1.0414e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3424e-05 - val_loss: 1.0360e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.3058e-05 - val_loss: 1.0308e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2697e-05 - val_loss: 1.0255e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2334e-05 - val_loss: 1.0203e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.1979e-05 - val_loss: 1.0151e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1622e-05 - val_loss: 1.0099e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.1271e-05 - val_loss: 1.0048e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.0916e-05 - val_loss: 9.9973e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.0570e-05 - val_loss: 9.9465e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.0224e-05 - val_loss: 9.8964e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9878e-05 - val_loss: 9.8468e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.9534e-05 - val_loss: 9.7967e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.9194e-05 - val_loss: 9.7479e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8857e-05 - val_loss: 9.6976e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8515e-05 - val_loss: 9.6499e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.8185e-05 - val_loss: 9.6014e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 6.7851e-05 - val_loss: 9.5534e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7520e-05 - val_loss: 9.5060e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.7194e-05 - val_loss: 9.4583e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6865e-05 - val_loss: 9.4111e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.6542e-05 - val_loss: 9.3642e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.6219e-05 - val_loss: 9.3165e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5900e-05 - val_loss: 9.2711e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5578e-05 - val_loss: 9.2249e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5262e-05 - val_loss: 9.1784e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4945e-05 - val_loss: 9.1338e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4634e-05 - val_loss: 9.0883e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4323e-05 - val_loss: 9.0445e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4014e-05 - val_loss: 8.9992e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3707e-05 - val_loss: 8.9555e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3400e-05 - val_loss: 8.9114e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3097e-05 - val_loss: 8.8675e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2795e-05 - val_loss: 8.8238e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2496e-05 - val_loss: 8.7803e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2195e-05 - val_loss: 8.7370e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1898e-05 - val_loss: 8.6944e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1605e-05 - val_loss: 8.6518e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1313e-05 - val_loss: 8.6095e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1017e-05 - val_loss: 8.5673e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0729e-05 - val_loss: 8.5258e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0441e-05 - val_loss: 8.4842e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0154e-05 - val_loss: 8.4430e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9871e-05 - val_loss: 8.4021e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9589e-05 - val_loss: 8.3617e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9304e-05 - val_loss: 8.3216e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9027e-05 - val_loss: 8.2811e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8747e-05 - val_loss: 8.2409e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8468e-05 - val_loss: 8.2012e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8196e-05 - val_loss: 8.1618e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7920e-05 - val_loss: 8.1222e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7652e-05 - val_loss: 8.0834e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7378e-05 - val_loss: 8.0442e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7109e-05 - val_loss: 8.0056e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6841e-05 - val_loss: 7.9674e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6576e-05 - val_loss: 7.9284e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6310e-05 - val_loss: 7.8914e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6048e-05 - val_loss: 7.8533e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5786e-05 - val_loss: 7.8158e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5526e-05 - val_loss: 7.7785e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5268e-05 - val_loss: 7.7415e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5011e-05 - val_loss: 7.7049e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4757e-05 - val_loss: 7.6684e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4500e-05 - val_loss: 7.6321e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4250e-05 - val_loss: 7.5959e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3997e-05 - val_loss: 7.5599e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3747e-05 - val_loss: 7.5240e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3499e-05 - val_loss: 7.4874e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3250e-05 - val_loss: 7.4527e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3003e-05 - val_loss: 7.4173e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2761e-05 - val_loss: 7.3826e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2517e-05 - val_loss: 7.3479e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.2278e-05 - val_loss: 7.3125e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2036e-05 - val_loss: 7.2786e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1797e-05 - val_loss: 7.2443e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1559e-05 - val_loss: 7.2105e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1323e-05 - val_loss: 7.1766e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1089e-05 - val_loss: 7.1432e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0854e-05 - val_loss: 7.1093e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0621e-05 - val_loss: 7.0762e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0391e-05 - val_loss: 7.0440e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0160e-05 - val_loss: 7.0107e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.9932e-05 - val_loss: 6.9784e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9702e-05 - val_loss: 6.9460e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.9476e-05 - val_loss: 6.9135e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9252e-05 - val_loss: 6.8815e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9027e-05 - val_loss: 6.8494e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8805e-05 - val_loss: 6.8174e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8584e-05 - val_loss: 6.7856e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8363e-05 - val_loss: 6.7540e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8142e-05 - val_loss: 6.7223e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7927e-05 - val_loss: 6.6914e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7707e-05 - val_loss: 6.6605e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7493e-05 - val_loss: 6.6298e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7279e-05 - val_loss: 6.5993e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7067e-05 - val_loss: 6.5688e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 4.6851e-05 - val_loss: 6.5392e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6642e-05 - val_loss: 6.5083e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6430e-05 - val_loss: 6.4785e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6222e-05 - val_loss: 6.4491e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6015e-05 - val_loss: 6.4195e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.5807e-05 - val_loss: 6.3903e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5603e-05 - val_loss: 6.3610e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5398e-05 - val_loss: 6.3319e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5195e-05 - val_loss: 6.3029e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4994e-05 - val_loss: 6.2745e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4792e-05 - val_loss: 6.2455e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4592e-05 - val_loss: 6.2174e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4394e-05 - val_loss: 6.1882e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4194e-05 - val_loss: 6.1603e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3997e-05 - val_loss: 6.1321e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3800e-05 - val_loss: 6.1037e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3606e-05 - val_loss: 6.0764e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3411e-05 - val_loss: 6.0488e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3219e-05 - val_loss: 6.0215e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3028e-05 - val_loss: 5.9942e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2835e-05 - val_loss: 5.9672e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2644e-05 - val_loss: 5.9402e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2454e-05 - val_loss: 5.9135e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2269e-05 - val_loss: 5.8868e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2081e-05 - val_loss: 5.8597e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1896e-05 - val_loss: 5.8341e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1708e-05 - val_loss: 5.8072e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1523e-05 - val_loss: 5.7815e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1342e-05 - val_loss: 5.7558e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1160e-05 - val_loss: 5.7297e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0978e-05 - val_loss: 5.7037e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0795e-05 - val_loss: 5.6780e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0619e-05 - val_loss: 5.6524e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0439e-05 - val_loss: 5.6271e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0261e-05 - val_loss: 5.6015e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0083e-05 - val_loss: 5.5762e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9907e-05 - val_loss: 5.5518e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9733e-05 - val_loss: 5.5266e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9558e-05 - val_loss: 5.5024e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.9386e-05 - val_loss: 5.4775e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9212e-05 - val_loss: 5.4533e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9041e-05 - val_loss: 5.4292e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8871e-05 - val_loss: 5.4049e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8699e-05 - val_loss: 5.3814e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8533e-05 - val_loss: 5.3573e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8364e-05 - val_loss: 5.3330e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8197e-05 - val_loss: 5.3094e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8029e-05 - val_loss: 5.2858e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7862e-05 - val_loss: 5.2626e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7699e-05 - val_loss: 5.2391e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7534e-05 - val_loss: 5.2161e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7371e-05 - val_loss: 5.1927e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7210e-05 - val_loss: 5.1697e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7046e-05 - val_loss: 5.1468e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6886e-05 - val_loss: 5.1236e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6726e-05 - val_loss: 5.1018e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6566e-05 - val_loss: 5.0789e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6410e-05 - val_loss: 5.0564e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6251e-05 - val_loss: 5.0341e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6095e-05 - val_loss: 5.0123e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5938e-05 - val_loss: 4.9899e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5782e-05 - val_loss: 4.9682e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5628e-05 - val_loss: 4.9459e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5474e-05 - val_loss: 4.9243e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5319e-05 - val_loss: 4.9032e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5167e-05 - val_loss: 4.8813e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5016e-05 - val_loss: 4.8603e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.4867e-05 - val_loss: 4.8389e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4717e-05 - val_loss: 4.8176e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4566e-05 - val_loss: 4.7966e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4417e-05 - val_loss: 4.7753e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4270e-05 - val_loss: 4.7545e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4124e-05 - val_loss: 4.7334e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3975e-05 - val_loss: 4.7133e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3831e-05 - val_loss: 4.6926e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3684e-05 - val_loss: 4.6721e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3540e-05 - val_loss: 4.6515e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3396e-05 - val_loss: 4.6313e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3253e-05 - val_loss: 4.6111e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3111e-05 - val_loss: 4.5918e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2970e-05 - val_loss: 4.5710e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2828e-05 - val_loss: 4.5514e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2688e-05 - val_loss: 4.5318e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2547e-05 - val_loss: 4.5121e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2409e-05 - val_loss: 4.4924e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2270e-05 - val_loss: 4.4730e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2134e-05 - val_loss: 4.4535e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1996e-05 - val_loss: 4.4344e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1861e-05 - val_loss: 4.4149e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1723e-05 - val_loss: 4.3960e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1591e-05 - val_loss: 4.3775e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1456e-05 - val_loss: 4.3585e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1320e-05 - val_loss: 4.3394e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1188e-05 - val_loss: 4.3206e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1056e-05 - val_loss: 4.3020e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0924e-05 - val_loss: 4.2832e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0792e-05 - val_loss: 4.2646e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0662e-05 - val_loss: 4.2461e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0532e-05 - val_loss: 4.2283e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0402e-05 - val_loss: 4.2096e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0273e-05 - val_loss: 4.1921e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0147e-05 - val_loss: 4.1746e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0016e-05 - val_loss: 4.1559e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9889e-05 - val_loss: 4.1378e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9766e-05 - val_loss: 4.1205e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9638e-05 - val_loss: 4.1024e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9512e-05 - val_loss: 4.0848e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9388e-05 - val_loss: 4.0675e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9264e-05 - val_loss: 4.0498e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9140e-05 - val_loss: 4.0328e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9018e-05 - val_loss: 4.0152e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8896e-05 - val_loss: 3.9980e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8774e-05 - val_loss: 3.9810e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8653e-05 - val_loss: 3.9642e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8532e-05 - val_loss: 3.9466e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8410e-05 - val_loss: 3.9304e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8292e-05 - val_loss: 3.9135e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8173e-05 - val_loss: 3.8970e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8053e-05 - val_loss: 3.8806e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7937e-05 - val_loss: 3.8642e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7819e-05 - val_loss: 3.8472e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7702e-05 - val_loss: 3.8311e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7586e-05 - val_loss: 3.8146e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7471e-05 - val_loss: 3.7984e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7354e-05 - val_loss: 3.7822e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7241e-05 - val_loss: 3.7659e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7125e-05 - val_loss: 3.7506e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7012e-05 - val_loss: 3.7344e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6900e-05 - val_loss: 3.7184e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6786e-05 - val_loss: 3.7027e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6675e-05 - val_loss: 3.6866e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6562e-05 - val_loss: 3.6708e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6450e-05 - val_loss: 3.6555e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6341e-05 - val_loss: 3.6397e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6230e-05 - val_loss: 3.6243e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6121e-05 - val_loss: 3.6090e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6012e-05 - val_loss: 3.5940e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5904e-05 - val_loss: 3.5787e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.5795e-05 - val_loss: 3.5636e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.5687e-05 - val_loss: 3.5483e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5579e-05 - val_loss: 3.5332e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5473e-05 - val_loss: 3.5185e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5368e-05 - val_loss: 3.5038e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5262e-05 - val_loss: 3.4893e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5157e-05 - val_loss: 3.4746e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5051e-05 - val_loss: 3.4601e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4948e-05 - val_loss: 3.4452e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4844e-05 - val_loss: 3.4305e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4739e-05 - val_loss: 3.4161e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4639e-05 - val_loss: 3.4013e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4535e-05 - val_loss: 3.3874e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4433e-05 - val_loss: 3.3728e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4331e-05 - val_loss: 3.3588e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4231e-05 - val_loss: 3.3450e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4130e-05 - val_loss: 3.3307e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4026e-05 - val_loss: 3.3167e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3931e-05 - val_loss: 3.3026e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3830e-05 - val_loss: 3.2885e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3731e-05 - val_loss: 3.2750e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.3633e-05 - val_loss: 3.2614e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3534e-05 - val_loss: 3.2475e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3437e-05 - val_loss: 3.2342e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3342e-05 - val_loss: 3.2203e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3244e-05 - val_loss: 3.2068e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3148e-05 - val_loss: 3.1934e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3052e-05 - val_loss: 3.1800e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2957e-05 - val_loss: 3.1664e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2861e-05 - val_loss: 3.1532e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2767e-05 - val_loss: 3.1402e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2673e-05 - val_loss: 3.1269e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2579e-05 - val_loss: 3.1141e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2486e-05 - val_loss: 3.1010e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2394e-05 - val_loss: 3.0882e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2302e-05 - val_loss: 3.0751e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2210e-05 - val_loss: 3.0620e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2117e-05 - val_loss: 3.0494e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2026e-05 - val_loss: 3.0365e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1933e-05 - val_loss: 3.0245e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1845e-05 - val_loss: 3.0117e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1754e-05 - val_loss: 2.9991e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1665e-05 - val_loss: 2.9862e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1576e-05 - val_loss: 2.9741e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1485e-05 - val_loss: 2.9618e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1397e-05 - val_loss: 2.9488e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1309e-05 - val_loss: 2.9368e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1222e-05 - val_loss: 2.9250e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1134e-05 - val_loss: 2.9122e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1048e-05 - val_loss: 2.9002e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0960e-05 - val_loss: 2.8881e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0875e-05 - val_loss: 2.8763e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0788e-05 - val_loss: 2.8643e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0704e-05 - val_loss: 2.8524e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0618e-05 - val_loss: 2.8406e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0532e-05 - val_loss: 2.8290e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0448e-05 - val_loss: 2.8171e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0364e-05 - val_loss: 2.8054e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0281e-05 - val_loss: 2.7934e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0196e-05 - val_loss: 2.7818e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0115e-05 - val_loss: 2.7701e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0032e-05 - val_loss: 2.7588e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9950e-05 - val_loss: 2.7475e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9869e-05 - val_loss: 2.7359e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.9785e-05 - val_loss: 2.7244e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9705e-05 - val_loss: 2.7133e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9625e-05 - val_loss: 2.7022e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9545e-05 - val_loss: 2.6910e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9463e-05 - val_loss: 2.6800e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9384e-05 - val_loss: 2.6688e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9305e-05 - val_loss: 2.6577e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9225e-05 - val_loss: 2.6468e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9147e-05 - val_loss: 2.6358e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9068e-05 - val_loss: 2.6250e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8991e-05 - val_loss: 2.6139e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8912e-05 - val_loss: 2.6034e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8836e-05 - val_loss: 2.5924e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8758e-05 - val_loss: 2.5813e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8681e-05 - val_loss: 2.5707e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8604e-05 - val_loss: 2.5603e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8529e-05 - val_loss: 2.5501e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8453e-05 - val_loss: 2.5391e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8377e-05 - val_loss: 2.5287e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8303e-05 - val_loss: 2.5183e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8227e-05 - val_loss: 2.5077e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8152e-05 - val_loss: 2.4970e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8078e-05 - val_loss: 2.4872e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8004e-05 - val_loss: 2.4769e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7931e-05 - val_loss: 2.4667e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7858e-05 - val_loss: 2.4566e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7785e-05 - val_loss: 2.4464e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7712e-05 - val_loss: 2.4360e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7640e-05 - val_loss: 2.4262e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7568e-05 - val_loss: 2.4158e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7495e-05 - val_loss: 2.4062e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7424e-05 - val_loss: 2.3960e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7353e-05 - val_loss: 2.3864e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 1.7283e-05 - val_loss: 2.3767e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7212e-05 - val_loss: 2.3666e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7141e-05 - val_loss: 2.3570e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7071e-05 - val_loss: 2.3473e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7002e-05 - val_loss: 2.3378e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.6932e-05 - val_loss: 2.3279e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 1.6863e-05 - val_loss: 2.3184e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6794e-05 - val_loss: 2.3088e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6727e-05 - val_loss: 2.2993e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6657e-05 - val_loss: 2.2899e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6590e-05 - val_loss: 2.2804e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6523e-05 - val_loss: 2.2709e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6454e-05 - val_loss: 2.2618e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6388e-05 - val_loss: 2.2524e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 250us/step - loss: 1.6321e-05 - val_loss: 2.2430e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6255e-05 - val_loss: 2.2336e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6188e-05 - val_loss: 2.2248e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6122e-05 - val_loss: 2.2156e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6057e-05 - val_loss: 2.2066e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5991e-05 - val_loss: 2.1972e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.5926e-05 - val_loss: 2.1880e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5861e-05 - val_loss: 2.1792e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5796e-05 - val_loss: 2.1707e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5733e-05 - val_loss: 2.1613e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5669e-05 - val_loss: 2.1526e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5604e-05 - val_loss: 2.1437e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5541e-05 - val_loss: 2.1349e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5477e-05 - val_loss: 2.1261e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5415e-05 - val_loss: 2.1177e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5352e-05 - val_loss: 2.1090e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5289e-05 - val_loss: 2.1000e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5227e-05 - val_loss: 2.0914e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5164e-05 - val_loss: 2.0830e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5104e-05 - val_loss: 2.0741e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5041e-05 - val_loss: 2.0661e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4981e-05 - val_loss: 2.0571e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4919e-05 - val_loss: 2.0489e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4859e-05 - val_loss: 2.0403e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4798e-05 - val_loss: 2.0320e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4737e-05 - val_loss: 2.0235e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4678e-05 - val_loss: 2.0153e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4619e-05 - val_loss: 2.0071e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4559e-05 - val_loss: 1.9991e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.4499e-05 - val_loss: 1.9904e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4440e-05 - val_loss: 1.9828e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4382e-05 - val_loss: 1.9744e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4323e-05 - val_loss: 1.9664e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.4266e-05 - val_loss: 1.9583e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4206e-05 - val_loss: 1.9502e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4149e-05 - val_loss: 1.9421e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4092e-05 - val_loss: 1.9343e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4035e-05 - val_loss: 1.9264e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3979e-05 - val_loss: 1.9184e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3921e-05 - val_loss: 1.9105e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3864e-05 - val_loss: 1.9029e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3809e-05 - val_loss: 1.8950e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3752e-05 - val_loss: 1.8871e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3696e-05 - val_loss: 1.8795e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3641e-05 - val_loss: 1.8718e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3585e-05 - val_loss: 1.8639e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3528e-05 - val_loss: 1.8565e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3473e-05 - val_loss: 1.8488e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3420e-05 - val_loss: 1.8413e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3364e-05 - val_loss: 1.8336e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3310e-05 - val_loss: 1.8261e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3256e-05 - val_loss: 1.8188e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3202e-05 - val_loss: 1.8111e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3149e-05 - val_loss: 1.8037e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3094e-05 - val_loss: 1.7964e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3042e-05 - val_loss: 1.7891e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2989e-05 - val_loss: 1.7816e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2936e-05 - val_loss: 1.7744e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2883e-05 - val_loss: 1.7672e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 1.2831e-05 - val_loss: 1.7598e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2779e-05 - val_loss: 1.7527e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2728e-05 - val_loss: 1.7453e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2675e-05 - val_loss: 1.7382e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2623e-05 - val_loss: 1.7310e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2571e-05 - val_loss: 1.7241e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2521e-05 - val_loss: 1.7170e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 1.2470e-05 - val_loss: 1.7099e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2418e-05 - val_loss: 1.7032e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2369e-05 - val_loss: 1.6960e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2319e-05 - val_loss: 1.6889e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2269e-05 - val_loss: 1.6823e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2218e-05 - val_loss: 1.6752e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2168e-05 - val_loss: 1.6686e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2120e-05 - val_loss: 1.6617e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2070e-05 - val_loss: 1.6546e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2021e-05 - val_loss: 1.6478e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1972e-05 - val_loss: 1.6414e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1924e-05 - val_loss: 1.6347e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1875e-05 - val_loss: 1.6278e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1826e-05 - val_loss: 1.6209e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1778e-05 - val_loss: 1.6144e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1731e-05 - val_loss: 1.6076e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.1683e-05 - val_loss: 1.6012e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1635e-05 - val_loss: 1.5946e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1588e-05 - val_loss: 1.5882e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1541e-05 - val_loss: 1.5817e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1494e-05 - val_loss: 1.5750e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1447e-05 - val_loss: 1.5688e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1400e-05 - val_loss: 1.5622e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1353e-05 - val_loss: 1.5560e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1308e-05 - val_loss: 1.5493e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1261e-05 - val_loss: 1.5433e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1216e-05 - val_loss: 1.5369e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1170e-05 - val_loss: 1.5305e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1125e-05 - val_loss: 1.5243e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1079e-05 - val_loss: 1.5180e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1034e-05 - val_loss: 1.5117e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0988e-05 - val_loss: 1.5053e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0944e-05 - val_loss: 1.4994e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0900e-05 - val_loss: 1.4936e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0856e-05 - val_loss: 1.4873e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0811e-05 - val_loss: 1.4810e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0767e-05 - val_loss: 1.4751e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0724e-05 - val_loss: 1.4687e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0680e-05 - val_loss: 1.4631e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0637e-05 - val_loss: 1.4572e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0593e-05 - val_loss: 1.4509e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0550e-05 - val_loss: 1.4450e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0507e-05 - val_loss: 1.4390e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0463e-05 - val_loss: 1.4331e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0422e-05 - val_loss: 1.4272e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0379e-05 - val_loss: 1.4213e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0337e-05 - val_loss: 1.4153e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0294e-05 - val_loss: 1.4097e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0252e-05 - val_loss: 1.4039e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0211e-05 - val_loss: 1.3982e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0168e-05 - val_loss: 1.3927e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0127e-05 - val_loss: 1.3868e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0086e-05 - val_loss: 1.3809e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0045e-05 - val_loss: 1.3753e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0004e-05 - val_loss: 1.3697e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9627e-06 - val_loss: 1.3640e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9226e-06 - val_loss: 1.3585e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8807e-06 - val_loss: 1.3530e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8415e-06 - val_loss: 1.3473e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8009e-06 - val_loss: 1.3417e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7617e-06 - val_loss: 1.3362e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.7211e-06 - val_loss: 1.3311e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6821e-06 - val_loss: 1.3253e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6419e-06 - val_loss: 1.3198e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6028e-06 - val_loss: 1.3146e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5635e-06 - val_loss: 1.3091e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5237e-06 - val_loss: 1.3037e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4850e-06 - val_loss: 1.2983e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4469e-06 - val_loss: 1.2931e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4082e-06 - val_loss: 1.2876e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3692e-06 - val_loss: 1.2823e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3313e-06 - val_loss: 1.2770e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2931e-06 - val_loss: 1.2718e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2553e-06 - val_loss: 1.2668e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2167e-06 - val_loss: 1.2614e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 9.1793e-06 - val_loss: 1.2562e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1418e-06 - val_loss: 1.2508e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1048e-06 - val_loss: 1.2460e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0669e-06 - val_loss: 1.2407e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0295e-06 - val_loss: 1.2358e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9940e-06 - val_loss: 1.2305e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9563e-06 - val_loss: 1.2257e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9196e-06 - val_loss: 1.2206e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8831e-06 - val_loss: 1.2155e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8465e-06 - val_loss: 1.2105e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8105e-06 - val_loss: 1.2056e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7746e-06 - val_loss: 1.2004e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7383e-06 - val_loss: 1.1955e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7038e-06 - val_loss: 1.1906e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6671e-06 - val_loss: 1.1858e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6315e-06 - val_loss: 1.1808e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5966e-06 - val_loss: 1.1761e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5612e-06 - val_loss: 1.1710e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5260e-06 - val_loss: 1.1663e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4906e-06 - val_loss: 1.1613e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4557e-06 - val_loss: 1.1567e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4208e-06 - val_loss: 1.1517e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3866e-06 - val_loss: 1.1472e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3533e-06 - val_loss: 1.1424e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3180e-06 - val_loss: 1.1376e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2837e-06 - val_loss: 1.1330e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2498e-06 - val_loss: 1.1282e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2153e-06 - val_loss: 1.1238e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1827e-06 - val_loss: 1.1191e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1491e-06 - val_loss: 1.1144e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1149e-06 - val_loss: 1.1100e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0822e-06 - val_loss: 1.1056e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.0487e-06 - val_loss: 1.1009e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0165e-06 - val_loss: 1.0962e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9826e-06 - val_loss: 1.0914e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9504e-06 - val_loss: 1.0868e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9175e-06 - val_loss: 1.0824e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8847e-06 - val_loss: 1.0782e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8529e-06 - val_loss: 1.0736e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8192e-06 - val_loss: 1.0695e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7880e-06 - val_loss: 1.0647e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7553e-06 - val_loss: 1.0605e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7231e-06 - val_loss: 1.0560e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6921e-06 - val_loss: 1.0515e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6597e-06 - val_loss: 1.0472e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6292e-06 - val_loss: 1.0431e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5969e-06 - val_loss: 1.0386e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5658e-06 - val_loss: 1.0343e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5347e-06 - val_loss: 1.0300e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5045e-06 - val_loss: 1.0257e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4732e-06 - val_loss: 1.0214e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4425e-06 - val_loss: 1.0174e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4112e-06 - val_loss: 1.0131e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3809e-06 - val_loss: 1.0089e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3506e-06 - val_loss: 1.0049e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3204e-06 - val_loss: 1.0004e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2902e-06 - val_loss: 9.9639e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2597e-06 - val_loss: 9.9231e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2304e-06 - val_loss: 9.8806e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2005e-06 - val_loss: 9.8415e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1705e-06 - val_loss: 9.8002e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1407e-06 - val_loss: 9.7612e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1112e-06 - val_loss: 9.7192e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0817e-06 - val_loss: 9.6789e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0515e-06 - val_loss: 9.6377e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0231e-06 - val_loss: 9.5980e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9938e-06 - val_loss: 9.5577e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9656e-06 - val_loss: 9.5174e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9363e-06 - val_loss: 9.4767e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9074e-06 - val_loss: 9.4408e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8785e-06 - val_loss: 9.4022e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.8504e-06 - val_loss: 9.3603e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8221e-06 - val_loss: 9.3211e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7939e-06 - val_loss: 9.2845e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7664e-06 - val_loss: 9.2441e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7383e-06 - val_loss: 9.2062e-06\n",
      "5.6798839978000615e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.7003244 ,  1.3716525 , -0.10923705, -0.19709598, -0.47631347],\n",
       "        [-0.21304703, -0.26567638, -0.4049768 ,  0.6179817 ,  0.8688171 ],\n",
       "        [-0.1713454 , -0.41981235,  0.8031276 , -0.90102935, -1.0292379 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.14315966, -0.15401782, -0.4217508 ,  0.7311326 , -0.56353766],\n",
       "       dtype=float32),\n",
       " array([[-0.33576006,  0.05490396,  0.29599604,  0.17336951, -0.11966818,\n",
       "         -0.31975496,  0.1966273 , -0.18240315, -0.2947267 ,  0.2086887 ,\n",
       "         -0.04697833, -0.01192727,  0.5100307 , -0.10733802,  0.381238  ],\n",
       "        [ 0.40976143, -0.01556473,  0.28002492,  0.24071418, -0.03901509,\n",
       "         -0.14970142,  0.00382109, -0.27926257, -0.16640183,  0.42351407,\n",
       "          0.32319412,  0.26947573,  0.34322205,  0.2516954 , -0.44240528],\n",
       "        [-0.2537775 , -0.3261055 ,  0.32144028, -0.53254855,  0.19507056,\n",
       "          0.06046795,  0.39527306, -0.4809832 ,  0.23045105,  0.31690848,\n",
       "         -0.4140889 , -0.480011  , -0.15833531,  0.16021901, -0.15539275],\n",
       "        [-0.25680852, -0.34965938,  0.33296397, -0.5024011 , -0.06550201,\n",
       "          0.3719944 , -0.17603187, -0.09882801,  0.4308016 ,  0.10449815,\n",
       "         -0.24075606, -0.41071463, -0.08856701,  0.58343536,  0.35617664],\n",
       "        [ 0.17125112, -0.6390959 ,  0.24826151,  0.01447557, -0.09755874,\n",
       "          0.41846877,  0.15530814,  0.38516757,  0.20501804,  0.47347337,\n",
       "          0.31429788,  0.10019739, -0.12388819,  0.2365859 , -0.41750205]],\n",
       "       dtype=float32),\n",
       " array([ 0.74656427, -0.72174984, -0.77239305,  0.7473371 , -0.7398117 ,\n",
       "        -0.73602235,  0.6121239 , -0.74640846,  0.7775041 ,  0.7502334 ,\n",
       "         0.71398485, -0.76197684, -0.7418411 , -0.5422693 ,  0.76878506],\n",
       "       dtype=float32),\n",
       " array([[ 0.5337939 ],\n",
       "        [-0.27844813],\n",
       "        [-0.8188481 ],\n",
       "        [ 0.57042956],\n",
       "        [-0.42847922],\n",
       "        [-0.45063853],\n",
       "        [ 0.1454225 ],\n",
       "        [-0.4978631 ],\n",
       "        [ 0.7343542 ],\n",
       "        [ 0.569704  ],\n",
       "        [ 0.36277837],\n",
       "        [-0.52172863],\n",
       "        [-0.34129137],\n",
       "        [-0.12297358],\n",
       "        [ 0.6141587 ]], dtype=float32),\n",
       " array([0.7971042], dtype=float32)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_3(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure3_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.0237 - val_loss: 33.2586\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.7219 - val_loss: 27.5735\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4320 - val_loss: 21.4311\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 23.2204 - val_loss: 15.1364\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.2208 - val_loss: 9.1952\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.9609 - val_loss: 4.2684\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2326 - val_loss: 1.2933\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2778 - val_loss: 1.4674\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.7993 - val_loss: 4.4926\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9921 - val_loss: 6.4004\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1577 - val_loss: 5.6206\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2322 - val_loss: 3.5754\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9409 - val_loss: 1.7238\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0444 - val_loss: 0.7563\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3270 - val_loss: 0.6187\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6363 - val_loss: 0.8530\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3022 - val_loss: 1.0480\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7816 - val_loss: 1.0526\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9329 - val_loss: 0.8921\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8283 - val_loss: 0.6500\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5604 - val_loss: 0.4180\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2010 - val_loss: 0.2718\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8262 - val_loss: 0.2432\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5144 - val_loss: 0.3053\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3166 - val_loss: 0.3930\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2351 - val_loss: 0.4517\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2359 - val_loss: 0.4752\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2815 - val_loss: 0.4922\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3473 - val_loss: 0.5197\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4127 - val_loss: 0.5351\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4491 - val_loss: 0.4967\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4296 - val_loss: 0.3892\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3512 - val_loss: 0.2426\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2425 - val_loss: 0.1111\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1454 - val_loss: 0.0363\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0891 - val_loss: 0.0261\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0777 - val_loss: 0.0577\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0957 - val_loss: 0.0986\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1230 - val_loss: 0.1261\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1453 - val_loss: 0.1338\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1564 - val_loss: 0.1268\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1547 - val_loss: 0.1131\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1407 - val_loss: 0.0976\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1171 - val_loss: 0.0821\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0887 - val_loss: 0.0667\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0624 - val_loss: 0.0517\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0435 - val_loss: 0.0383\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0337 - val_loss: 0.0276\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0203\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0328 - val_loss: 0.0165\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0356 - val_loss: 0.0156\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0388 - val_loss: 0.0164\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0419 - val_loss: 0.0177\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0440 - val_loss: 0.0186\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0436 - val_loss: 0.0186\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0397 - val_loss: 0.0184\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0328 - val_loss: 0.0189\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0252 - val_loss: 0.0211\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0193 - val_loss: 0.0251\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0305\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0362\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0179 - val_loss: 0.0411\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0198 - val_loss: 0.0442\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0451\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0217 - val_loss: 0.0435\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0399\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0201 - val_loss: 0.0352\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0183 - val_loss: 0.0301\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0161 - val_loss: 0.0257\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0141 - val_loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0196\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0176\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0115 - val_loss: 0.0161\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0115 - val_loss: 0.0150\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0145\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 405us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 9.9438e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 9.8319e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 9.7216e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 9.6130e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 9.5059e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 9.3999e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 9.2951e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 9.1914e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 9.0889e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0021 - val_loss: 8.9877e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 8.8876e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.7887e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.6911e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.5947e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.4994e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.4057e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.3127e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.2211e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.1307e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.0412e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 7.9530e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 7.8658e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 7.7800e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 7.6947e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 7.6110e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 7.5280e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0018 - val_loss: 7.4462e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.3652e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 7.2859e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.2071e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 7.1293e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 7.0526e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 6.9765e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 6.9014e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.8270e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.7539e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 6.6813e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.6097e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.5388e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.4688e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.3998e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.3316e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.2639e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 6.1974e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 6.1315e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 6.0664e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 6.0021e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 5.9387e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 5.8761e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 5.8142e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 5.7530e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 5.6924e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 5.6325e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 5.5736e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 5.5154e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 5.4575e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.4005e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.3442e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 5.2885e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.2334e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 5.1788e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 5.1252e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.0721e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.0193e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 4.9674e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 4.9162e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 4.8654e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 4.8154e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 4.7657e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 4.7168e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 4.6684e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 4.6205e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0014 - val_loss: 4.5732e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 4.5266e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 4.4802e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.4346e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 4.3897e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.3451e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.3010e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.2573e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.2143e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 4.1716e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 4.1296e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 4.0880e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.0468e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 4.0061e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.9657e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.9261e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.8868e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.8480e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.8095e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.7716e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.7341e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.6969e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.6603e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.6240e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.5882e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.5527e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.5176e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.4830e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.4487e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.4149e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.3813e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.3482e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.3155e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.2831e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.2511e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.2194e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1882e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 3.1572e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.1266e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0963e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0663e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.0368e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0075e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.9786e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9500e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9218e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.8938e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.8662e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.8387e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.8117e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.7849e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.7585e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9827e-04 - val_loss: 2.7325e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9251e-04 - val_loss: 2.7065e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8675e-04 - val_loss: 2.6808e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8105e-04 - val_loss: 2.6557e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7538e-04 - val_loss: 2.6307e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6976e-04 - val_loss: 2.6059e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6418e-04 - val_loss: 2.5815e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5864e-04 - val_loss: 2.5573e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5313e-04 - val_loss: 2.5333e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4766e-04 - val_loss: 2.5096e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4224e-04 - val_loss: 2.4863e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3684e-04 - val_loss: 2.4630e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3149e-04 - val_loss: 2.4401e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2618e-04 - val_loss: 2.4174e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.2090e-04 - val_loss: 2.3950e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1567e-04 - val_loss: 2.3730e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1045e-04 - val_loss: 2.3510e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0529e-04 - val_loss: 2.3293e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0016e-04 - val_loss: 2.3079e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9508e-04 - val_loss: 2.2867e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9001e-04 - val_loss: 2.2657e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8499e-04 - val_loss: 2.2450e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8000e-04 - val_loss: 2.2245e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7505e-04 - val_loss: 2.2042e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7013e-04 - val_loss: 2.1841e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6523e-04 - val_loss: 2.1641e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6038e-04 - val_loss: 2.1444e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.5557e-04 - val_loss: 2.1249e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5078e-04 - val_loss: 2.1058e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4603e-04 - val_loss: 2.0868e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4129e-04 - val_loss: 2.0679e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3660e-04 - val_loss: 2.0494e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3195e-04 - val_loss: 2.0308e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2733e-04 - val_loss: 2.0127e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2274e-04 - val_loss: 1.9946e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1818e-04 - val_loss: 1.9768e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1364e-04 - val_loss: 1.9592e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0915e-04 - val_loss: 1.9418e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0467e-04 - val_loss: 1.9246e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0023e-04 - val_loss: 1.9076e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9583e-04 - val_loss: 1.8906e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9145e-04 - val_loss: 1.8739e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8708e-04 - val_loss: 1.8574e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8276e-04 - val_loss: 1.8410e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7847e-04 - val_loss: 1.8248e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7420e-04 - val_loss: 1.8088e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.6997e-04 - val_loss: 1.7929e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6576e-04 - val_loss: 1.7771e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6158e-04 - val_loss: 1.7617e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5742e-04 - val_loss: 1.7464e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5330e-04 - val_loss: 1.7311e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4922e-04 - val_loss: 1.7161e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4514e-04 - val_loss: 1.7012e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4109e-04 - val_loss: 1.6864e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3708e-04 - val_loss: 1.6719e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3309e-04 - val_loss: 1.6576e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2912e-04 - val_loss: 1.6433e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2519e-04 - val_loss: 1.6292e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2127e-04 - val_loss: 1.6152e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1739e-04 - val_loss: 1.6014e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1352e-04 - val_loss: 1.5878e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0969e-04 - val_loss: 1.5742e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0588e-04 - val_loss: 1.5608e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0209e-04 - val_loss: 1.5475e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9834e-04 - val_loss: 1.5344e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9460e-04 - val_loss: 1.5215e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9089e-04 - val_loss: 1.5086e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8720e-04 - val_loss: 1.4959e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8353e-04 - val_loss: 1.4834e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7989e-04 - val_loss: 1.4709e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7626e-04 - val_loss: 1.4586e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7268e-04 - val_loss: 1.4464e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6911e-04 - val_loss: 1.4343e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6556e-04 - val_loss: 1.4224e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6203e-04 - val_loss: 1.4106e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5853e-04 - val_loss: 1.3988e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5505e-04 - val_loss: 1.3873e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5159e-04 - val_loss: 1.3759e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4815e-04 - val_loss: 1.3645e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4475e-04 - val_loss: 1.3533e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4136e-04 - val_loss: 1.3423e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3796e-04 - val_loss: 1.3312e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3463e-04 - val_loss: 1.3203e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3129e-04 - val_loss: 1.3095e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2799e-04 - val_loss: 1.2988e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2470e-04 - val_loss: 1.2882e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2144e-04 - val_loss: 1.2778e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1820e-04 - val_loss: 1.2675e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1497e-04 - val_loss: 1.2572e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1176e-04 - val_loss: 1.2471e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0857e-04 - val_loss: 1.2370e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0540e-04 - val_loss: 1.2271e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0226e-04 - val_loss: 1.2173e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9914e-04 - val_loss: 1.2075e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9603e-04 - val_loss: 1.1979e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9294e-04 - val_loss: 1.1883e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8987e-04 - val_loss: 1.1789e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8683e-04 - val_loss: 1.1695e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8379e-04 - val_loss: 1.1603e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8078e-04 - val_loss: 1.1511e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7779e-04 - val_loss: 1.1421e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7481e-04 - val_loss: 1.1330e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7186e-04 - val_loss: 1.1241e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6893e-04 - val_loss: 1.1153e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6600e-04 - val_loss: 1.1066e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6310e-04 - val_loss: 1.0980e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6022e-04 - val_loss: 1.0894e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5735e-04 - val_loss: 1.0810e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5450e-04 - val_loss: 1.0727e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5167e-04 - val_loss: 1.0643e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4886e-04 - val_loss: 1.0561e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4607e-04 - val_loss: 1.0479e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4327e-04 - val_loss: 1.0399e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4052e-04 - val_loss: 1.0319e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.3776e-04 - val_loss: 1.0240e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3503e-04 - val_loss: 1.0162e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3232e-04 - val_loss: 1.0084e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2963e-04 - val_loss: 1.0008e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2694e-04 - val_loss: 9.9317e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2428e-04 - val_loss: 9.8566e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2162e-04 - val_loss: 9.7815e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1900e-04 - val_loss: 9.7080e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1637e-04 - val_loss: 9.6349e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1377e-04 - val_loss: 9.5624e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1118e-04 - val_loss: 9.4905e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0862e-04 - val_loss: 9.4205e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0607e-04 - val_loss: 9.3502e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0353e-04 - val_loss: 9.2805e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0100e-04 - val_loss: 9.2117e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9849e-04 - val_loss: 9.1432e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9599e-04 - val_loss: 9.0758e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9352e-04 - val_loss: 9.0084e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9105e-04 - val_loss: 8.9420e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8859e-04 - val_loss: 8.8761e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.8617e-04 - val_loss: 8.8103e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8373e-04 - val_loss: 8.7462e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8133e-04 - val_loss: 8.6824e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7894e-04 - val_loss: 8.6197e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7656e-04 - val_loss: 8.5578e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7419e-04 - val_loss: 8.4955e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7184e-04 - val_loss: 8.4333e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6951e-04 - val_loss: 8.3729e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6718e-04 - val_loss: 8.3122e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6487e-04 - val_loss: 8.2521e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6257e-04 - val_loss: 8.1931e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6029e-04 - val_loss: 8.1347e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5801e-04 - val_loss: 8.0765e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5576e-04 - val_loss: 8.0184e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5351e-04 - val_loss: 7.9618e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5128e-04 - val_loss: 7.9056e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4906e-04 - val_loss: 7.8503e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4686e-04 - val_loss: 7.7949e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4466e-04 - val_loss: 7.7401e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4248e-04 - val_loss: 7.6846e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4031e-04 - val_loss: 7.6316e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3816e-04 - val_loss: 7.5784e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3601e-04 - val_loss: 7.5246e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3388e-04 - val_loss: 7.4730e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3176e-04 - val_loss: 7.4210e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2966e-04 - val_loss: 7.3701e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2757e-04 - val_loss: 7.3190e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2548e-04 - val_loss: 7.2687e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2341e-04 - val_loss: 7.2183e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2134e-04 - val_loss: 7.1692e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1930e-04 - val_loss: 7.1201e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1727e-04 - val_loss: 7.0709e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.1524e-04 - val_loss: 7.0226e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1323e-04 - val_loss: 6.9747e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1123e-04 - val_loss: 6.9277e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0924e-04 - val_loss: 6.8808e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0726e-04 - val_loss: 6.8342e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0530e-04 - val_loss: 6.7887e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0334e-04 - val_loss: 6.7425e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0139e-04 - val_loss: 6.6978e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9946e-04 - val_loss: 6.6524e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9754e-04 - val_loss: 6.6085e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9563e-04 - val_loss: 6.5646e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9372e-04 - val_loss: 6.5210e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9183e-04 - val_loss: 6.4780e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8995e-04 - val_loss: 6.4345e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8808e-04 - val_loss: 6.3923e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8622e-04 - val_loss: 6.3505e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8437e-04 - val_loss: 6.3088e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8253e-04 - val_loss: 6.2678e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8070e-04 - val_loss: 6.2267e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7888e-04 - val_loss: 6.1855e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7707e-04 - val_loss: 6.1458e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7527e-04 - val_loss: 6.1063e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7349e-04 - val_loss: 6.0666e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7170e-04 - val_loss: 6.0279e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6994e-04 - val_loss: 5.9890e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6818e-04 - val_loss: 5.9502e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6642e-04 - val_loss: 5.9120e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6469e-04 - val_loss: 5.8746e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6295e-04 - val_loss: 5.8368e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6124e-04 - val_loss: 5.8001e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5952e-04 - val_loss: 5.7630e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.5782e-04 - val_loss: 5.7274e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5612e-04 - val_loss: 5.6906e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5444e-04 - val_loss: 5.6554e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5277e-04 - val_loss: 5.6195e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5111e-04 - val_loss: 5.5848e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4945e-04 - val_loss: 5.5496e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4780e-04 - val_loss: 5.5148e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4617e-04 - val_loss: 5.4806e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4454e-04 - val_loss: 5.4462e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4292e-04 - val_loss: 5.4133e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4129e-04 - val_loss: 5.3794e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3970e-04 - val_loss: 5.3464e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3810e-04 - val_loss: 5.3144e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3652e-04 - val_loss: 5.2815e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3494e-04 - val_loss: 5.2489e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3337e-04 - val_loss: 5.2168e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3182e-04 - val_loss: 5.1857e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3026e-04 - val_loss: 5.1548e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2872e-04 - val_loss: 5.1235e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2719e-04 - val_loss: 5.0928e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2566e-04 - val_loss: 5.0621e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2414e-04 - val_loss: 5.0314e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2262e-04 - val_loss: 5.0016e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2112e-04 - val_loss: 4.9712e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1963e-04 - val_loss: 4.9418e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1814e-04 - val_loss: 4.9122e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1666e-04 - val_loss: 4.8833e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1519e-04 - val_loss: 4.8550e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1373e-04 - val_loss: 4.8262e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1227e-04 - val_loss: 4.7984e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1083e-04 - val_loss: 4.7701e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0939e-04 - val_loss: 4.7416e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0796e-04 - val_loss: 4.7148e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0654e-04 - val_loss: 4.6871e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0512e-04 - val_loss: 4.6600e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0370e-04 - val_loss: 4.6331e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0230e-04 - val_loss: 4.6064e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0090e-04 - val_loss: 4.5801e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9952e-04 - val_loss: 4.5538e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.9814e-04 - val_loss: 4.5280e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9677e-04 - val_loss: 4.5024e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9540e-04 - val_loss: 4.4774e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9404e-04 - val_loss: 4.4515e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9269e-04 - val_loss: 4.4270e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9135e-04 - val_loss: 4.4016e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9001e-04 - val_loss: 4.3766e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8868e-04 - val_loss: 4.3518e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8736e-04 - val_loss: 4.3270e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8603e-04 - val_loss: 4.3034e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8473e-04 - val_loss: 4.2793e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8343e-04 - val_loss: 4.2559e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8213e-04 - val_loss: 4.2326e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8084e-04 - val_loss: 4.2094e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7956e-04 - val_loss: 4.1866e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7829e-04 - val_loss: 4.1633e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7701e-04 - val_loss: 4.1401e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7576e-04 - val_loss: 4.1171e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7449e-04 - val_loss: 4.0952e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7325e-04 - val_loss: 4.0729e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7201e-04 - val_loss: 4.0511e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7077e-04 - val_loss: 4.0294e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6954e-04 - val_loss: 4.0074e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6831e-04 - val_loss: 3.9862e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6710e-04 - val_loss: 3.9654e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6588e-04 - val_loss: 3.9439e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6468e-04 - val_loss: 3.9231e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6348e-04 - val_loss: 3.9026e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6229e-04 - val_loss: 3.8818e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6110e-04 - val_loss: 3.8614e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5992e-04 - val_loss: 3.8413e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5875e-04 - val_loss: 3.8210e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5758e-04 - val_loss: 3.8013e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5642e-04 - val_loss: 3.7814e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5525e-04 - val_loss: 3.7617e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5411e-04 - val_loss: 3.7426e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5296e-04 - val_loss: 3.7229e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5182e-04 - val_loss: 3.7034e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5069e-04 - val_loss: 3.6843e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4956e-04 - val_loss: 3.6649e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4843e-04 - val_loss: 3.6466e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4733e-04 - val_loss: 3.6277e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4621e-04 - val_loss: 3.6095e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4511e-04 - val_loss: 3.5917e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4401e-04 - val_loss: 3.5732e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4291e-04 - val_loss: 3.5555e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4183e-04 - val_loss: 3.5381e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4075e-04 - val_loss: 3.5203e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3967e-04 - val_loss: 3.5026e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3859e-04 - val_loss: 3.4853e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3753e-04 - val_loss: 3.4680e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3646e-04 - val_loss: 3.4508e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3541e-04 - val_loss: 3.4343e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3436e-04 - val_loss: 3.4171e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3331e-04 - val_loss: 3.4005e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3228e-04 - val_loss: 3.3837e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3124e-04 - val_loss: 3.3675e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3021e-04 - val_loss: 3.3514e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2919e-04 - val_loss: 3.3353e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2817e-04 - val_loss: 3.3192e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2715e-04 - val_loss: 3.3028e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2614e-04 - val_loss: 3.2869e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2514e-04 - val_loss: 3.2710e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2414e-04 - val_loss: 3.2556e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2315e-04 - val_loss: 3.2400e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2215e-04 - val_loss: 3.2244e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2118e-04 - val_loss: 3.2091e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2019e-04 - val_loss: 3.1943e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1922e-04 - val_loss: 3.1792e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1825e-04 - val_loss: 3.1644e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1728e-04 - val_loss: 3.1499e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1632e-04 - val_loss: 3.1352e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1537e-04 - val_loss: 3.1207e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1442e-04 - val_loss: 3.1065e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1347e-04 - val_loss: 3.0921e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1253e-04 - val_loss: 3.0781e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1159e-04 - val_loss: 3.0640e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1066e-04 - val_loss: 3.0502e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0973e-04 - val_loss: 3.0365e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0882e-04 - val_loss: 3.0227e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0789e-04 - val_loss: 3.0086e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0698e-04 - val_loss: 2.9953e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0607e-04 - val_loss: 2.9817e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0516e-04 - val_loss: 2.9685e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0426e-04 - val_loss: 2.9553e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0337e-04 - val_loss: 2.9424e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0248e-04 - val_loss: 2.9292e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0159e-04 - val_loss: 2.9163e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0071e-04 - val_loss: 2.9038e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9982e-04 - val_loss: 2.8906e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9895e-04 - val_loss: 2.8779e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9808e-04 - val_loss: 2.8653e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9722e-04 - val_loss: 2.8527e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9636e-04 - val_loss: 2.8404e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9550e-04 - val_loss: 2.8281e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9465e-04 - val_loss: 2.8161e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9379e-04 - val_loss: 2.8039e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9295e-04 - val_loss: 2.7921e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9210e-04 - val_loss: 2.7802e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9127e-04 - val_loss: 2.7685e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9044e-04 - val_loss: 2.7567e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8961e-04 - val_loss: 2.7451e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8879e-04 - val_loss: 2.7331e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8796e-04 - val_loss: 2.7216e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8715e-04 - val_loss: 2.7106e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8634e-04 - val_loss: 2.6993e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8552e-04 - val_loss: 2.6878e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8472e-04 - val_loss: 2.6768e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8391e-04 - val_loss: 2.6662e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8312e-04 - val_loss: 2.6552e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8233e-04 - val_loss: 2.6442e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8153e-04 - val_loss: 2.6333e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8075e-04 - val_loss: 2.6225e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7997e-04 - val_loss: 2.6116e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7919e-04 - val_loss: 2.6013e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7842e-04 - val_loss: 2.5906e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7764e-04 - val_loss: 2.5802e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7688e-04 - val_loss: 2.5696e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7612e-04 - val_loss: 2.5596e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7535e-04 - val_loss: 2.5495e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7460e-04 - val_loss: 2.5394e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7384e-04 - val_loss: 2.5289e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7310e-04 - val_loss: 2.5196e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7235e-04 - val_loss: 2.5102e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7161e-04 - val_loss: 2.5004e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7087e-04 - val_loss: 2.4906e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7014e-04 - val_loss: 2.4809e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6940e-04 - val_loss: 2.4708e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6868e-04 - val_loss: 2.4614e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6795e-04 - val_loss: 2.4519e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6723e-04 - val_loss: 2.4423e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6651e-04 - val_loss: 2.4329e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6580e-04 - val_loss: 2.4240e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6509e-04 - val_loss: 2.4147e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6438e-04 - val_loss: 2.4058e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6368e-04 - val_loss: 2.3965e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6297e-04 - val_loss: 2.3877e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6227e-04 - val_loss: 2.3789e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6158e-04 - val_loss: 2.3697e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6089e-04 - val_loss: 2.3609e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6020e-04 - val_loss: 2.3519e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5952e-04 - val_loss: 2.3433e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5884e-04 - val_loss: 2.3345e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5816e-04 - val_loss: 2.3261e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5749e-04 - val_loss: 2.3175e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5681e-04 - val_loss: 2.3093e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5615e-04 - val_loss: 2.3008e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5548e-04 - val_loss: 2.2928e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5482e-04 - val_loss: 2.2846e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5416e-04 - val_loss: 2.2764e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5350e-04 - val_loss: 2.2685e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5285e-04 - val_loss: 2.2603e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5220e-04 - val_loss: 2.2523e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5155e-04 - val_loss: 2.2444e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5091e-04 - val_loss: 2.2364e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5027e-04 - val_loss: 2.2282e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4963e-04 - val_loss: 2.2204e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4900e-04 - val_loss: 2.2127e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4836e-04 - val_loss: 2.2052e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4774e-04 - val_loss: 2.1975e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4711e-04 - val_loss: 2.1901e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4649e-04 - val_loss: 2.1823e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4587e-04 - val_loss: 2.1748e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4525e-04 - val_loss: 2.1674e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4464e-04 - val_loss: 2.1602e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4402e-04 - val_loss: 2.1527e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4341e-04 - val_loss: 2.1455e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4281e-04 - val_loss: 2.1382e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4220e-04 - val_loss: 2.1313e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4161e-04 - val_loss: 2.1241e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4101e-04 - val_loss: 2.1172e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4041e-04 - val_loss: 2.1099e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3982e-04 - val_loss: 2.1028e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3923e-04 - val_loss: 2.0959e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.3864e-04 - val_loss: 2.0888e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3806e-04 - val_loss: 2.0822e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3748e-04 - val_loss: 2.0752e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3690e-04 - val_loss: 2.0688e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3633e-04 - val_loss: 2.0625e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3575e-04 - val_loss: 2.0559e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3518e-04 - val_loss: 2.0495e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3461e-04 - val_loss: 2.0426e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3405e-04 - val_loss: 2.0361e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3349e-04 - val_loss: 2.0296e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3293e-04 - val_loss: 2.0234e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3237e-04 - val_loss: 2.0166e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3181e-04 - val_loss: 2.0101e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3126e-04 - val_loss: 2.0036e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3071e-04 - val_loss: 1.9976e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3016e-04 - val_loss: 1.9912e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2962e-04 - val_loss: 1.9852e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2908e-04 - val_loss: 1.9793e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2854e-04 - val_loss: 1.9727e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2800e-04 - val_loss: 1.9667e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2747e-04 - val_loss: 1.9611e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2694e-04 - val_loss: 1.9549e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2640e-04 - val_loss: 1.9493e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2588e-04 - val_loss: 1.9436e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2535e-04 - val_loss: 1.9375e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2483e-04 - val_loss: 1.9318e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2431e-04 - val_loss: 1.9260e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2379e-04 - val_loss: 1.9202e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2328e-04 - val_loss: 1.9144e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2276e-04 - val_loss: 1.9086e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2225e-04 - val_loss: 1.9031e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2174e-04 - val_loss: 1.8975e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2123e-04 - val_loss: 1.8920e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2073e-04 - val_loss: 1.8865e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2023e-04 - val_loss: 1.8815e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1973e-04 - val_loss: 1.8761e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1923e-04 - val_loss: 1.8706e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1874e-04 - val_loss: 1.8652e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1825e-04 - val_loss: 1.8599e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1776e-04 - val_loss: 1.8547e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1727e-04 - val_loss: 1.8493e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1678e-04 - val_loss: 1.8436e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1630e-04 - val_loss: 1.8387e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1581e-04 - val_loss: 1.8334e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1534e-04 - val_loss: 1.8281e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1486e-04 - val_loss: 1.8233e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.1438e-04 - val_loss: 1.8180e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1391e-04 - val_loss: 1.8130e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1344e-04 - val_loss: 1.8082e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1297e-04 - val_loss: 1.8035e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1251e-04 - val_loss: 1.7987e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1204e-04 - val_loss: 1.7941e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1158e-04 - val_loss: 1.7892e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.1112e-04 - val_loss: 1.7844e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1066e-04 - val_loss: 1.7792e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1020e-04 - val_loss: 1.7747e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0975e-04 - val_loss: 1.7699e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0930e-04 - val_loss: 1.7651e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0885e-04 - val_loss: 1.7602e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0840e-04 - val_loss: 1.7554e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0796e-04 - val_loss: 1.7508e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0751e-04 - val_loss: 1.7462e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0707e-04 - val_loss: 1.7417e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0663e-04 - val_loss: 1.7374e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0619e-04 - val_loss: 1.7329e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0576e-04 - val_loss: 1.7282e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0532e-04 - val_loss: 1.7239e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0489e-04 - val_loss: 1.7203e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0446e-04 - val_loss: 1.7154e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0403e-04 - val_loss: 1.7114e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0360e-04 - val_loss: 1.7068e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0318e-04 - val_loss: 1.7026e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0276e-04 - val_loss: 1.6983e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0233e-04 - val_loss: 1.6936e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0192e-04 - val_loss: 1.6895e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0150e-04 - val_loss: 1.6852e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0108e-04 - val_loss: 1.6811e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 1.0067e-04 - val_loss: 1.6768e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0026e-04 - val_loss: 1.6731e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9851e-05 - val_loss: 1.6689e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9446e-05 - val_loss: 1.6649e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9038e-05 - val_loss: 1.6608e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8634e-05 - val_loss: 1.6569e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8236e-05 - val_loss: 1.6528e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7828e-05 - val_loss: 1.6487e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7430e-05 - val_loss: 1.6450e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7034e-05 - val_loss: 1.6413e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6644e-05 - val_loss: 1.6375e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6245e-05 - val_loss: 1.6338e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.5854e-05 - val_loss: 1.6298e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5468e-05 - val_loss: 1.6258e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5077e-05 - val_loss: 1.6220e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4692e-05 - val_loss: 1.6178e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4304e-05 - val_loss: 1.6141e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.3922e-05 - val_loss: 1.6104e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3540e-05 - val_loss: 1.6066e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3159e-05 - val_loss: 1.6031e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 9.2782e-05 - val_loss: 1.5994e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2406e-05 - val_loss: 1.5958e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2031e-05 - val_loss: 1.5925e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1658e-05 - val_loss: 1.5891e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1287e-05 - val_loss: 1.5857e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0918e-05 - val_loss: 1.5822e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0552e-05 - val_loss: 1.5786e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0185e-05 - val_loss: 1.5750e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9819e-05 - val_loss: 1.5714e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9454e-05 - val_loss: 1.5679e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9091e-05 - val_loss: 1.5643e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8734e-05 - val_loss: 1.5607e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8376e-05 - val_loss: 1.5574e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.8018e-05 - val_loss: 1.5541e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7663e-05 - val_loss: 1.5508e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7310e-05 - val_loss: 1.5476e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6957e-05 - val_loss: 1.5441e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6609e-05 - val_loss: 1.5408e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6258e-05 - val_loss: 1.5377e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5909e-05 - val_loss: 1.5345e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5565e-05 - val_loss: 1.5313e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5222e-05 - val_loss: 1.5282e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4875e-05 - val_loss: 1.5250e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4535e-05 - val_loss: 1.5219e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4197e-05 - val_loss: 1.5188e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3859e-05 - val_loss: 1.5156e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3519e-05 - val_loss: 1.5123e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3181e-05 - val_loss: 1.5092e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.2848e-05 - val_loss: 1.5060e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2518e-05 - val_loss: 1.5029e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2186e-05 - val_loss: 1.4999e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.1856e-05 - val_loss: 1.4967e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1528e-05 - val_loss: 1.4938e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1200e-05 - val_loss: 1.4909e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0874e-05 - val_loss: 1.4878e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.0552e-05 - val_loss: 1.4850e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 8.0228e-05 - val_loss: 1.4816e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.9911e-05 - val_loss: 1.4789e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9590e-05 - val_loss: 1.4762e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9270e-05 - val_loss: 1.4735e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8955e-05 - val_loss: 1.4708e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8639e-05 - val_loss: 1.4680e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8323e-05 - val_loss: 1.4653e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8012e-05 - val_loss: 1.4621e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7700e-05 - val_loss: 1.4594e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7391e-05 - val_loss: 1.4563e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7081e-05 - val_loss: 1.4535e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6772e-05 - val_loss: 1.4509e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6465e-05 - val_loss: 1.4482e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6162e-05 - val_loss: 1.4454e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5859e-05 - val_loss: 1.4429e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5556e-05 - val_loss: 1.4401e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.5258e-05 - val_loss: 1.4375e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4955e-05 - val_loss: 1.4346e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.4657e-05 - val_loss: 1.4320e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4362e-05 - val_loss: 1.4293e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4065e-05 - val_loss: 1.4270e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3772e-05 - val_loss: 1.4243e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.3480e-05 - val_loss: 1.4218e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3185e-05 - val_loss: 1.4193e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2896e-05 - val_loss: 1.4168e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2607e-05 - val_loss: 1.4143e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2319e-05 - val_loss: 1.4115e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2036e-05 - val_loss: 1.4093e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1747e-05 - val_loss: 1.4066e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1464e-05 - val_loss: 1.4040e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1179e-05 - val_loss: 1.4015e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0897e-05 - val_loss: 1.3989e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0618e-05 - val_loss: 1.3966e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0338e-05 - val_loss: 1.3940e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0062e-05 - val_loss: 1.3918e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9784e-05 - val_loss: 1.3892e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9509e-05 - val_loss: 1.3868e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9234e-05 - val_loss: 1.3844e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8959e-05 - val_loss: 1.3824e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8687e-05 - val_loss: 1.3803e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8418e-05 - val_loss: 1.3779e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8146e-05 - val_loss: 1.3755e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7881e-05 - val_loss: 1.3734e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7609e-05 - val_loss: 1.3709e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7345e-05 - val_loss: 1.3688e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7081e-05 - val_loss: 1.3667e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6817e-05 - val_loss: 1.3643e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6550e-05 - val_loss: 1.3618e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6293e-05 - val_loss: 1.3596e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6030e-05 - val_loss: 1.3571e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5770e-05 - val_loss: 1.3551e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5513e-05 - val_loss: 1.3528e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5257e-05 - val_loss: 1.3508e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4999e-05 - val_loss: 1.3486e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4745e-05 - val_loss: 1.3466e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4491e-05 - val_loss: 1.3444e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4238e-05 - val_loss: 1.3423e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3985e-05 - val_loss: 1.3400e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3735e-05 - val_loss: 1.3380e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3486e-05 - val_loss: 1.3358e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3235e-05 - val_loss: 1.3338e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2990e-05 - val_loss: 1.3319e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2744e-05 - val_loss: 1.3299e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2501e-05 - val_loss: 1.3278e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.2254e-05 - val_loss: 1.3258e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2009e-05 - val_loss: 1.3238e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1767e-05 - val_loss: 1.3215e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1528e-05 - val_loss: 1.3195e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1283e-05 - val_loss: 1.3174e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1047e-05 - val_loss: 1.3156e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0809e-05 - val_loss: 1.3135e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0573e-05 - val_loss: 1.3118e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0335e-05 - val_loss: 1.3098e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0100e-05 - val_loss: 1.3079e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9864e-05 - val_loss: 1.3059e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9632e-05 - val_loss: 1.3041e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9401e-05 - val_loss: 1.3021e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9169e-05 - val_loss: 1.3000e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8938e-05 - val_loss: 1.2981e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8710e-05 - val_loss: 1.2965e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8484e-05 - val_loss: 1.2944e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8255e-05 - val_loss: 1.2927e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8029e-05 - val_loss: 1.2908e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7803e-05 - val_loss: 1.2891e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7579e-05 - val_loss: 1.2872e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7357e-05 - val_loss: 1.2855e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7137e-05 - val_loss: 1.2837e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6913e-05 - val_loss: 1.2820e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6690e-05 - val_loss: 1.2800e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6473e-05 - val_loss: 1.2785e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6255e-05 - val_loss: 1.2763e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6037e-05 - val_loss: 1.2747e-05\n",
      "1.540072298666928e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.94610345,  0.41327706,  0.7720632 , -0.4662407 , -0.98158497,\n",
       "         -1.0460271 ,  0.82337326, -1.0866001 ,  1.186878  , -0.73338014],\n",
       "        [ 0.30200973, -0.31318766,  0.39154273,  0.5153439 ,  1.1756387 ,\n",
       "          0.21598917, -0.4899142 ,  0.24489994, -0.55670434, -0.2375365 ],\n",
       "        [ 0.4298186 , -0.78177315,  1.788991  , -0.5736554 , -0.10270688,\n",
       "         -1.1737224 , -1.500764  , -0.43503585, -0.02571201, -0.37731332]],\n",
       "       dtype=float32),\n",
       " array([ 0.49049008,  0.546256  ,  0.55173004,  0.4475778 , -0.37681216,\n",
       "        -0.4844004 ,  0.7743582 ,  0.6425515 , -0.44952568,  0.04696493],\n",
       "       dtype=float32),\n",
       " array([[-0.05451885,  0.5881471 ,  0.34906703, -0.99869144,  0.64393485],\n",
       "        [-0.07821044,  0.519115  , -0.2415335 ,  0.26172388,  0.2598864 ],\n",
       "        [-0.32703453,  0.8575481 , -0.7181925 ,  0.12325826,  0.49079928],\n",
       "        [-0.10414832,  0.99715537, -0.22172897, -0.5627915 ,  0.28607908],\n",
       "        [ 0.32812244, -0.11278784, -0.49714422,  0.15351322,  0.2094685 ],\n",
       "        [ 0.6273136 , -0.25156903,  0.71160805,  0.28924143, -0.76616204],\n",
       "        [-1.1038526 ,  0.7675136 ,  0.27908933,  0.4913673 ,  0.19628389],\n",
       "        [-0.6595418 ,  0.7882617 ,  0.405442  , -0.69430596, -0.3104428 ],\n",
       "        [ 0.79200286, -0.20999148, -0.3535074 ,  0.56566185,  0.44480568],\n",
       "        [ 0.41384482,  0.8180333 ,  0.28760576, -0.33713248, -0.2808592 ]],\n",
       "       dtype=float32),\n",
       " array([-0.74610305,  0.7578238 , -0.5639843 , -0.44341236,  0.6842895 ],\n",
       "       dtype=float32),\n",
       " array([[-1.0556026e+00],\n",
       "        [ 1.2749535e+00],\n",
       "        [-9.1259085e-02],\n",
       "        [ 3.2600874e-04],\n",
       "        [ 4.1496891e-01]], dtype=float32),\n",
       " array([0.78955066], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_4(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure4_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.1858 - val_loss: 31.7049\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.4699 - val_loss: 27.1266\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 29.8799 - val_loss: 21.7593\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 24.3484 - val_loss: 15.3528\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 17.0612 - val_loss: 8.4339\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0318 - val_loss: 3.1980\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5454 - val_loss: 3.5589\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8934 - val_loss: 7.6380\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9375 - val_loss: 6.3796\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3183 - val_loss: 3.1713\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9839 - val_loss: 1.2356\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1286 - val_loss: 0.9479\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3317 - val_loss: 1.5240\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.9635 - val_loss: 2.2244\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9217 - val_loss: 2.6573\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5771 - val_loss: 2.6889\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7718 - val_loss: 2.3459\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5538 - val_loss: 1.7469\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0357 - val_loss: 1.0627\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3656 - val_loss: 0.4758\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7211 - val_loss: 0.1268\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2752 - val_loss: 0.0602\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1321 - val_loss: 0.2071\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2753 - val_loss: 0.4297\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.5765 - val_loss: 0.5944\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8538 - val_loss: 0.6311\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9513 - val_loss: 0.5488\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.8250 - val_loss: 0.4033\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.5649 - val_loss: 0.2517\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3115 - val_loss: 0.1317\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1549 - val_loss: 0.0644\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1077 - val_loss: 0.0578\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1393 - val_loss: 0.1038\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2117 - val_loss: 0.1755\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2891 - val_loss: 0.2368\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3397 - val_loss: 0.2587\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3426 - val_loss: 0.2336\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2974 - val_loss: 0.1760\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2227 - val_loss: 0.1116\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1453 - val_loss: 0.0632\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0861 - val_loss: 0.0408\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0548 - val_loss: 0.0420\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0520 - val_loss: 0.0568\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0718 - val_loss: 0.0735\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1014 - val_loss: 0.0833\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1248 - val_loss: 0.0817\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1302 - val_loss: 0.0696\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1165 - val_loss: 0.0511\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0912 - val_loss: 0.0317\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0634 - val_loss: 0.0162\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0402 - val_loss: 0.0077\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0261 - val_loss: 0.0069\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0117\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0288 - val_loss: 0.0184\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0385 - val_loss: 0.0234\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0463 - val_loss: 0.0247\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0489 - val_loss: 0.0223\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0459 - val_loss: 0.0172\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0388 - val_loss: 0.0111\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0295 - val_loss: 0.0055\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0205 - val_loss: 0.0020\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0011\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0118 - val_loss: 0.0025\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0130 - val_loss: 0.0051\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0078\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0097\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0195 - val_loss: 0.0102\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0188 - val_loss: 0.0093\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0164 - val_loss: 0.0074\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0130 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0033\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0035\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0088 - val_loss: 0.0030\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 6.4759e-04\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 4.1920e-04\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0028 - val_loss: 3.1463e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0027 - val_loss: 3.0599e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 3.5278e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 4.1154e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 4.5025e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0029 - val_loss: 4.5848e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0027 - val_loss: 4.4562e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 4.3084e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 4.3289e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.6289e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 5.1986e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 5.9011e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 6.5333e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 6.9276e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.0252e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 6.8774e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 6.5931e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 6.2858e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 6.0435e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 5.9144e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 5.9011e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 5.9667e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 6.0496e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 6.0836e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.0147e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 5.8208e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 5.5246e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 5.1879e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.8835e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 4.6570e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 4.5110e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 4.4163e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 4.3416e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 4.2734e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 4.2174e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 4.1871e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 4.1935e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 4.2396e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 4.3183e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 4.4152e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.5130e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 4.5959e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.6516e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.6717e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.6542e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.6035e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.5281e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 4.4382e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.3426e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.2472e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.1559e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.0712e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.9944e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.9268e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.8689e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.8205e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.7807e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.7471e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.7170e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.6874e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.6557e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.6202e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.5788e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.5305e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.4758e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.4155e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.3517e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 3.2869e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.2241e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 3.1654e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.1128e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0676e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9773e-04 - val_loss: 3.0298e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9005e-04 - val_loss: 2.9990e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8243e-04 - val_loss: 2.9735e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7485e-04 - val_loss: 2.9519e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6736e-04 - val_loss: 2.9324e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5998e-04 - val_loss: 2.9135e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5274e-04 - val_loss: 2.8937e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4566e-04 - val_loss: 2.8716e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3873e-04 - val_loss: 2.8464e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3188e-04 - val_loss: 2.8173e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2514e-04 - val_loss: 2.7843e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1848e-04 - val_loss: 2.7474e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1188e-04 - val_loss: 2.7075e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0536e-04 - val_loss: 2.6653e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9892e-04 - val_loss: 2.6220e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9256e-04 - val_loss: 2.5784e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8630e-04 - val_loss: 2.5359e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8015e-04 - val_loss: 2.4950e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7408e-04 - val_loss: 2.4563e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6808e-04 - val_loss: 2.4200e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6218e-04 - val_loss: 2.3858e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5633e-04 - val_loss: 2.3539e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5054e-04 - val_loss: 2.3236e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4483e-04 - val_loss: 2.2946e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3917e-04 - val_loss: 2.2669e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3360e-04 - val_loss: 2.2400e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2810e-04 - val_loss: 2.2135e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2266e-04 - val_loss: 2.1873e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1729e-04 - val_loss: 2.1608e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1199e-04 - val_loss: 2.1342e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0675e-04 - val_loss: 2.1069e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0156e-04 - val_loss: 2.0791e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9643e-04 - val_loss: 2.0510e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9135e-04 - val_loss: 2.0226e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8634e-04 - val_loss: 1.9943e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8138e-04 - val_loss: 1.9665e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7649e-04 - val_loss: 1.9391e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.7164e-04 - val_loss: 1.9127e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6685e-04 - val_loss: 1.8871e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6211e-04 - val_loss: 1.8622e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5743e-04 - val_loss: 1.8381e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5279e-04 - val_loss: 1.8146e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4820e-04 - val_loss: 1.7916e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4367e-04 - val_loss: 1.7689e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3917e-04 - val_loss: 1.7466e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3473e-04 - val_loss: 1.7243e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3032e-04 - val_loss: 1.7020e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2597e-04 - val_loss: 1.6796e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2168e-04 - val_loss: 1.6568e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1741e-04 - val_loss: 1.6341e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.1319e-04 - val_loss: 1.6111e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0901e-04 - val_loss: 1.5883e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0488e-04 - val_loss: 1.5655e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0079e-04 - val_loss: 1.5432e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9674e-04 - val_loss: 1.5211e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9273e-04 - val_loss: 1.4996e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8877e-04 - val_loss: 1.4786e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8483e-04 - val_loss: 1.4581e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8094e-04 - val_loss: 1.4380e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7708e-04 - val_loss: 1.4184e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7327e-04 - val_loss: 1.3992e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.6949e-04 - val_loss: 1.3805e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6574e-04 - val_loss: 1.3619e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6203e-04 - val_loss: 1.3438e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5835e-04 - val_loss: 1.3258e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5472e-04 - val_loss: 1.3080e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5111e-04 - val_loss: 1.2905e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4754e-04 - val_loss: 1.2729e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.4401e-04 - val_loss: 1.2555e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4050e-04 - val_loss: 1.2382e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3703e-04 - val_loss: 1.2210e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3359e-04 - val_loss: 1.2040e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3018e-04 - val_loss: 1.1871e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2681e-04 - val_loss: 1.1704e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2347e-04 - val_loss: 1.1540e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2014e-04 - val_loss: 1.1379e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1685e-04 - val_loss: 1.1219e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1360e-04 - val_loss: 1.1062e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1038e-04 - val_loss: 1.0907e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0717e-04 - val_loss: 1.0755e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0400e-04 - val_loss: 1.0605e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0085e-04 - val_loss: 1.0458e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9774e-04 - val_loss: 1.0312e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9465e-04 - val_loss: 1.0168e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9158e-04 - val_loss: 1.0027e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8856e-04 - val_loss: 9.8860e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8554e-04 - val_loss: 9.7468e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8256e-04 - val_loss: 9.6091e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.7960e-04 - val_loss: 9.4735e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7666e-04 - val_loss: 9.3394e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7375e-04 - val_loss: 9.2074e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7087e-04 - val_loss: 9.0768e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6802e-04 - val_loss: 8.9478e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6517e-04 - val_loss: 8.8213e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6235e-04 - val_loss: 8.6961e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5957e-04 - val_loss: 8.5737e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5681e-04 - val_loss: 8.4527e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5406e-04 - val_loss: 8.3333e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5134e-04 - val_loss: 8.2163e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4865e-04 - val_loss: 8.1011e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4597e-04 - val_loss: 7.9869e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4330e-04 - val_loss: 7.8743e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4067e-04 - val_loss: 7.7631e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3805e-04 - val_loss: 7.6539e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3546e-04 - val_loss: 7.5455e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3289e-04 - val_loss: 7.4391e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3034e-04 - val_loss: 7.3331e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.2781e-04 - val_loss: 7.2289e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2529e-04 - val_loss: 7.1256e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2280e-04 - val_loss: 7.0248e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2032e-04 - val_loss: 6.9245e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1788e-04 - val_loss: 6.8252e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.1544e-04 - val_loss: 6.7287e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.1302e-04 - val_loss: 6.6328e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.1062e-04 - val_loss: 6.5384e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0824e-04 - val_loss: 6.4448e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.0588e-04 - val_loss: 6.3533e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0354e-04 - val_loss: 6.2632e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0121e-04 - val_loss: 6.1742e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9890e-04 - val_loss: 6.0864e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9661e-04 - val_loss: 5.9997e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9433e-04 - val_loss: 5.9141e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9207e-04 - val_loss: 5.8299e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.8984e-04 - val_loss: 5.7470e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8761e-04 - val_loss: 5.6651e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8540e-04 - val_loss: 5.5844e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8320e-04 - val_loss: 5.5048e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.8103e-04 - val_loss: 5.4260e-05\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7886e-04 - val_loss: 5.3485e-05\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7672e-04 - val_loss: 5.2723e-05\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7458e-04 - val_loss: 5.1971e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.7247e-04 - val_loss: 5.1227e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.7036e-04 - val_loss: 5.0499e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6828e-04 - val_loss: 4.9775e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6621e-04 - val_loss: 4.9063e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6416e-04 - val_loss: 4.8367e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6212e-04 - val_loss: 4.7680e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6009e-04 - val_loss: 4.6999e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5807e-04 - val_loss: 4.6326e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5607e-04 - val_loss: 4.5669e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5409e-04 - val_loss: 4.5014e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5211e-04 - val_loss: 4.4371e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5015e-04 - val_loss: 4.3737e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4820e-04 - val_loss: 4.3115e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4626e-04 - val_loss: 4.2495e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4435e-04 - val_loss: 4.1889e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4244e-04 - val_loss: 4.1287e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4055e-04 - val_loss: 4.0700e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3866e-04 - val_loss: 4.0121e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3679e-04 - val_loss: 3.9543e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3494e-04 - val_loss: 3.8979e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3309e-04 - val_loss: 3.8425e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3126e-04 - val_loss: 3.7875e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2943e-04 - val_loss: 3.7332e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2763e-04 - val_loss: 3.6795e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2583e-04 - val_loss: 3.6271e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2404e-04 - val_loss: 3.5755e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2227e-04 - val_loss: 3.5245e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2051e-04 - val_loss: 3.4742e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1875e-04 - val_loss: 3.4245e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1700e-04 - val_loss: 3.3754e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1528e-04 - val_loss: 3.3270e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 4.1356e-04 - val_loss: 3.2795e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1186e-04 - val_loss: 3.2328e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1015e-04 - val_loss: 3.1867e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0847e-04 - val_loss: 3.1411e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0679e-04 - val_loss: 3.0964e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0512e-04 - val_loss: 3.0521e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0347e-04 - val_loss: 3.0086e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0182e-04 - val_loss: 2.9658e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0019e-04 - val_loss: 2.9234e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9856e-04 - val_loss: 2.8819e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9695e-04 - val_loss: 2.8404e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9533e-04 - val_loss: 2.8000e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9374e-04 - val_loss: 2.7599e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9215e-04 - val_loss: 2.7206e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9057e-04 - val_loss: 2.6819e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8901e-04 - val_loss: 2.6435e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8745e-04 - val_loss: 2.6056e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8590e-04 - val_loss: 2.5686e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8436e-04 - val_loss: 2.5321e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8283e-04 - val_loss: 2.4959e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.8131e-04 - val_loss: 2.4605e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7979e-04 - val_loss: 2.4256e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7829e-04 - val_loss: 2.3912e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7679e-04 - val_loss: 2.3573e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7530e-04 - val_loss: 2.3237e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7383e-04 - val_loss: 2.2905e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7235e-04 - val_loss: 2.2580e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7090e-04 - val_loss: 2.2260e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6944e-04 - val_loss: 2.1941e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6799e-04 - val_loss: 2.1630e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6656e-04 - val_loss: 2.1324e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6513e-04 - val_loss: 2.1025e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6371e-04 - val_loss: 2.0724e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6229e-04 - val_loss: 2.0430e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6089e-04 - val_loss: 2.0140e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5949e-04 - val_loss: 1.9850e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.5810e-04 - val_loss: 1.9573e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5671e-04 - val_loss: 1.9295e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.5534e-04 - val_loss: 1.9024e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 3.5398e-04 - val_loss: 1.8753e-05\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.5261e-04 - val_loss: 1.8488e-05\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5126e-04 - val_loss: 1.8226e-05\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4991e-04 - val_loss: 1.7969e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.4858e-04 - val_loss: 1.7717e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4725e-04 - val_loss: 1.7465e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4591e-04 - val_loss: 1.7219e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4460e-04 - val_loss: 1.6974e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4329e-04 - val_loss: 1.6736e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4199e-04 - val_loss: 1.6500e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4070e-04 - val_loss: 1.6266e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3940e-04 - val_loss: 1.6039e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3813e-04 - val_loss: 1.5812e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3684e-04 - val_loss: 1.5592e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3558e-04 - val_loss: 1.5373e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3432e-04 - val_loss: 1.5156e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3306e-04 - val_loss: 1.4943e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3181e-04 - val_loss: 1.4732e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3057e-04 - val_loss: 1.4530e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2933e-04 - val_loss: 1.4326e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2810e-04 - val_loss: 1.4123e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2688e-04 - val_loss: 1.3926e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2566e-04 - val_loss: 1.3732e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2445e-04 - val_loss: 1.3541e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2324e-04 - val_loss: 1.3352e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2204e-04 - val_loss: 1.3167e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2085e-04 - val_loss: 1.2982e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1966e-04 - val_loss: 1.2800e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1848e-04 - val_loss: 1.2623e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1730e-04 - val_loss: 1.2450e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1614e-04 - val_loss: 1.2276e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1497e-04 - val_loss: 1.2105e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1381e-04 - val_loss: 1.1938e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1266e-04 - val_loss: 1.1771e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1151e-04 - val_loss: 1.1611e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1038e-04 - val_loss: 1.1450e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0924e-04 - val_loss: 1.1291e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0811e-04 - val_loss: 1.1138e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0698e-04 - val_loss: 1.0983e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0586e-04 - val_loss: 1.0835e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0475e-04 - val_loss: 1.0684e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0364e-04 - val_loss: 1.0538e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0254e-04 - val_loss: 1.0393e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0144e-04 - val_loss: 1.0252e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0035e-04 - val_loss: 1.0112e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.9926e-04 - val_loss: 9.9737e-06\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9818e-04 - val_loss: 9.8368e-06\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9710e-04 - val_loss: 9.7025e-06\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9603e-04 - val_loss: 9.5719e-06\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9496e-04 - val_loss: 9.4415e-06\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9390e-04 - val_loss: 9.3144e-06\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9284e-04 - val_loss: 9.1871e-06\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9178e-04 - val_loss: 9.0636e-06\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9074e-04 - val_loss: 8.9398e-06\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8969e-04 - val_loss: 8.8198e-06\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8865e-04 - val_loss: 8.7028e-06\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8763e-04 - val_loss: 8.5836e-06\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8660e-04 - val_loss: 8.4689e-06\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8557e-04 - val_loss: 8.3559e-06\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8455e-04 - val_loss: 8.2445e-06\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8354e-04 - val_loss: 8.1349e-06\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8253e-04 - val_loss: 8.0266e-06\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8153e-04 - val_loss: 7.9209e-06\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8053e-04 - val_loss: 7.8153e-06\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7953e-04 - val_loss: 7.7101e-06\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7854e-04 - val_loss: 7.6087e-06\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7755e-04 - val_loss: 7.5081e-06\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7657e-04 - val_loss: 7.4079e-06\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7559e-04 - val_loss: 7.3123e-06\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7461e-04 - val_loss: 7.2170e-06\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7364e-04 - val_loss: 7.1206e-06\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7268e-04 - val_loss: 7.0286e-06\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.7172e-04 - val_loss: 6.9356e-06\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7077e-04 - val_loss: 6.8459e-06\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6981e-04 - val_loss: 6.7586e-06\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6886e-04 - val_loss: 6.6699e-06\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6792e-04 - val_loss: 6.5844e-06\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6697e-04 - val_loss: 6.4979e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6604e-04 - val_loss: 6.4136e-06\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6511e-04 - val_loss: 6.3307e-06\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6418e-04 - val_loss: 6.2498e-06\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6326e-04 - val_loss: 6.1696e-06\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6234e-04 - val_loss: 6.0912e-06\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6142e-04 - val_loss: 6.0158e-06\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6051e-04 - val_loss: 5.9380e-06\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5960e-04 - val_loss: 5.8626e-06\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5869e-04 - val_loss: 5.7885e-06\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5780e-04 - val_loss: 5.7157e-06\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5690e-04 - val_loss: 5.6449e-06\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5601e-04 - val_loss: 5.5730e-06\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5512e-04 - val_loss: 5.5033e-06\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5423e-04 - val_loss: 5.4349e-06\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5335e-04 - val_loss: 5.3680e-06\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5247e-04 - val_loss: 5.3014e-06\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5160e-04 - val_loss: 5.2349e-06\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5073e-04 - val_loss: 5.1717e-06\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4987e-04 - val_loss: 5.1087e-06\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4900e-04 - val_loss: 5.0442e-06\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4814e-04 - val_loss: 4.9845e-06\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4728e-04 - val_loss: 4.9242e-06\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4643e-04 - val_loss: 4.8629e-06\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4558e-04 - val_loss: 4.8041e-06\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4473e-04 - val_loss: 4.7463e-06\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4389e-04 - val_loss: 4.6898e-06\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4305e-04 - val_loss: 4.6335e-06\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4222e-04 - val_loss: 4.5789e-06\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4139e-04 - val_loss: 4.5237e-06\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4057e-04 - val_loss: 4.4699e-06\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3973e-04 - val_loss: 4.4177e-06\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3891e-04 - val_loss: 4.3658e-06\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3810e-04 - val_loss: 4.3148e-06\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3728e-04 - val_loss: 4.2635e-06\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3647e-04 - val_loss: 4.2142e-06\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3566e-04 - val_loss: 4.1662e-06\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.3486e-04 - val_loss: 4.1188e-06\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3406e-04 - val_loss: 4.0710e-06\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3326e-04 - val_loss: 4.0242e-06\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3245e-04 - val_loss: 3.9783e-06\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3167e-04 - val_loss: 3.9334e-06\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3088e-04 - val_loss: 3.8891e-06\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3009e-04 - val_loss: 3.8455e-06\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2931e-04 - val_loss: 3.8019e-06\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2853e-04 - val_loss: 3.7592e-06\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2776e-04 - val_loss: 3.7180e-06\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2698e-04 - val_loss: 3.6762e-06\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2621e-04 - val_loss: 3.6375e-06\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2545e-04 - val_loss: 3.5958e-06\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2468e-04 - val_loss: 3.5574e-06\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2392e-04 - val_loss: 3.5181e-06\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2316e-04 - val_loss: 3.4807e-06\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2240e-04 - val_loss: 3.4426e-06\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2165e-04 - val_loss: 3.4067e-06\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2091e-04 - val_loss: 3.3697e-06\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2015e-04 - val_loss: 3.3338e-06\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1941e-04 - val_loss: 3.2986e-06\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1867e-04 - val_loss: 3.2641e-06\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1794e-04 - val_loss: 3.2303e-06\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1720e-04 - val_loss: 3.1960e-06\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1647e-04 - val_loss: 3.1641e-06\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1574e-04 - val_loss: 3.1316e-06\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1501e-04 - val_loss: 3.0990e-06\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1429e-04 - val_loss: 3.0671e-06\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1356e-04 - val_loss: 3.0365e-06\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1285e-04 - val_loss: 3.0062e-06\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1214e-04 - val_loss: 2.9758e-06\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1142e-04 - val_loss: 2.9471e-06\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1071e-04 - val_loss: 2.9182e-06\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1000e-04 - val_loss: 2.8892e-06\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0930e-04 - val_loss: 2.8616e-06\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0860e-04 - val_loss: 2.8331e-06\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0790e-04 - val_loss: 2.8051e-06\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0720e-04 - val_loss: 2.7782e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0650e-04 - val_loss: 2.7517e-06\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0582e-04 - val_loss: 2.7266e-06\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0512e-04 - val_loss: 2.7007e-06\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0444e-04 - val_loss: 2.6762e-06\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0376e-04 - val_loss: 2.6499e-06\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0308e-04 - val_loss: 2.6267e-06\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0240e-04 - val_loss: 2.6027e-06\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0173e-04 - val_loss: 2.5788e-06\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0105e-04 - val_loss: 2.5553e-06\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0038e-04 - val_loss: 2.5311e-06\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9971e-04 - val_loss: 2.5099e-06\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9904e-04 - val_loss: 2.4865e-06\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9838e-04 - val_loss: 2.4650e-06\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9772e-04 - val_loss: 2.4437e-06\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9707e-04 - val_loss: 2.4226e-06\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9641e-04 - val_loss: 2.4009e-06\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9575e-04 - val_loss: 2.3808e-06\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9511e-04 - val_loss: 2.3607e-06\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9445e-04 - val_loss: 2.3414e-06\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9381e-04 - val_loss: 2.3222e-06\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9316e-04 - val_loss: 2.3020e-06\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.9253e-04 - val_loss: 2.2834e-06\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9188e-04 - val_loss: 2.2639e-06\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.9125e-04 - val_loss: 2.2462e-06\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.9061e-04 - val_loss: 2.2282e-06\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8998e-04 - val_loss: 2.2102e-06\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8935e-04 - val_loss: 2.1924e-06\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8872e-04 - val_loss: 2.1753e-06\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8810e-04 - val_loss: 2.1580e-06\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8748e-04 - val_loss: 2.1414e-06\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8686e-04 - val_loss: 2.1253e-06\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8624e-04 - val_loss: 2.1096e-06\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8562e-04 - val_loss: 2.0926e-06\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8501e-04 - val_loss: 2.0773e-06\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8439e-04 - val_loss: 2.0611e-06\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8378e-04 - val_loss: 2.0458e-06\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8318e-04 - val_loss: 2.0307e-06\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8257e-04 - val_loss: 2.0158e-06\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8197e-04 - val_loss: 2.0016e-06\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8137e-04 - val_loss: 1.9872e-06\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8077e-04 - val_loss: 1.9728e-06\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8018e-04 - val_loss: 1.9597e-06\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7958e-04 - val_loss: 1.9455e-06\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7899e-04 - val_loss: 1.9318e-06\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7840e-04 - val_loss: 1.9187e-06\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7781e-04 - val_loss: 1.9053e-06\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7723e-04 - val_loss: 1.8931e-06\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7664e-04 - val_loss: 1.8797e-06\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7606e-04 - val_loss: 1.8679e-06\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7548e-04 - val_loss: 1.8554e-06\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7490e-04 - val_loss: 1.8431e-06\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7433e-04 - val_loss: 1.8309e-06\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7375e-04 - val_loss: 1.8198e-06\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7319e-04 - val_loss: 1.8083e-06\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7261e-04 - val_loss: 1.7968e-06\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7205e-04 - val_loss: 1.7853e-06\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7149e-04 - val_loss: 1.7743e-06\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7092e-04 - val_loss: 1.7631e-06\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7036e-04 - val_loss: 1.7519e-06\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6980e-04 - val_loss: 1.7418e-06\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6924e-04 - val_loss: 1.7314e-06\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6869e-04 - val_loss: 1.7213e-06\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6814e-04 - val_loss: 1.7111e-06\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6758e-04 - val_loss: 1.7016e-06\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6704e-04 - val_loss: 1.6911e-06\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6649e-04 - val_loss: 1.6815e-06\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6594e-04 - val_loss: 1.6725e-06\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6540e-04 - val_loss: 1.6634e-06\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6486e-04 - val_loss: 1.6539e-06\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6432e-04 - val_loss: 1.6454e-06\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6378e-04 - val_loss: 1.6356e-06\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6324e-04 - val_loss: 1.6271e-06\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6271e-04 - val_loss: 1.6182e-06\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6218e-04 - val_loss: 1.6100e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6165e-04 - val_loss: 1.6016e-06\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6112e-04 - val_loss: 1.5931e-06\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6059e-04 - val_loss: 1.5849e-06\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6007e-04 - val_loss: 1.5762e-06\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.5955e-04 - val_loss: 1.5690e-06\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5902e-04 - val_loss: 1.5611e-06\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5851e-04 - val_loss: 1.5533e-06\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5799e-04 - val_loss: 1.5457e-06\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5747e-04 - val_loss: 1.5378e-06\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5696e-04 - val_loss: 1.5302e-06\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5645e-04 - val_loss: 1.5233e-06\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5594e-04 - val_loss: 1.5158e-06\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5543e-04 - val_loss: 1.5089e-06\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5492e-04 - val_loss: 1.5022e-06\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5442e-04 - val_loss: 1.4951e-06\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5392e-04 - val_loss: 1.4883e-06\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5341e-04 - val_loss: 1.4814e-06\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5291e-04 - val_loss: 1.4756e-06\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5242e-04 - val_loss: 1.4682e-06\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5192e-04 - val_loss: 1.4617e-06\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5143e-04 - val_loss: 1.4554e-06\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5093e-04 - val_loss: 1.4493e-06\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5044e-04 - val_loss: 1.4432e-06\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4995e-04 - val_loss: 1.4378e-06\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4946e-04 - val_loss: 1.4313e-06\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4898e-04 - val_loss: 1.4252e-06\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4850e-04 - val_loss: 1.4198e-06\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4801e-04 - val_loss: 1.4132e-06\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4753e-04 - val_loss: 1.4075e-06\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4705e-04 - val_loss: 1.4020e-06\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 1.4657e-04 - val_loss: 1.3966e-06\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 1.4610e-04 - val_loss: 1.3907e-06\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4563e-04 - val_loss: 1.3855e-06\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4515e-04 - val_loss: 1.3800e-06\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.4468e-04 - val_loss: 1.3747e-06\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4421e-04 - val_loss: 1.3698e-06\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4374e-04 - val_loss: 1.3641e-06\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4328e-04 - val_loss: 1.3599e-06\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4282e-04 - val_loss: 1.3545e-06\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.4235e-04 - val_loss: 1.3492e-06\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4189e-04 - val_loss: 1.3449e-06\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4143e-04 - val_loss: 1.3399e-06\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4097e-04 - val_loss: 1.3349e-06\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4051e-04 - val_loss: 1.3301e-06\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4006e-04 - val_loss: 1.3256e-06\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3960e-04 - val_loss: 1.3205e-06\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3916e-04 - val_loss: 1.3164e-06\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3870e-04 - val_loss: 1.3119e-06\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.3825e-04 - val_loss: 1.3070e-06\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3781e-04 - val_loss: 1.3029e-06\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3736e-04 - val_loss: 1.2981e-06\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3692e-04 - val_loss: 1.2944e-06\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3648e-04 - val_loss: 1.2899e-06\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3603e-04 - val_loss: 1.2859e-06\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3560e-04 - val_loss: 1.2816e-06\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3516e-04 - val_loss: 1.2779e-06\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3472e-04 - val_loss: 1.2733e-06\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3429e-04 - val_loss: 1.2698e-06\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3385e-04 - val_loss: 1.2651e-06\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3342e-04 - val_loss: 1.2612e-06\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3299e-04 - val_loss: 1.2575e-06\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3256e-04 - val_loss: 1.2540e-06\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3213e-04 - val_loss: 1.2506e-06\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3171e-04 - val_loss: 1.2468e-06\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3128e-04 - val_loss: 1.2427e-06\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3085e-04 - val_loss: 1.2388e-06\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3043e-04 - val_loss: 1.2344e-06\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3001e-04 - val_loss: 1.2314e-06\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2959e-04 - val_loss: 1.2276e-06\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2917e-04 - val_loss: 1.2238e-06\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2876e-04 - val_loss: 1.2206e-06\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2834e-04 - val_loss: 1.2169e-06\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2793e-04 - val_loss: 1.2139e-06\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2752e-04 - val_loss: 1.2104e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2711e-04 - val_loss: 1.2077e-06\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2670e-04 - val_loss: 1.2038e-06\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2629e-04 - val_loss: 1.2002e-06\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2588e-04 - val_loss: 1.1973e-06\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2548e-04 - val_loss: 1.1942e-06\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2507e-04 - val_loss: 1.1905e-06\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2467e-04 - val_loss: 1.1869e-06\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2427e-04 - val_loss: 1.1835e-06\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2387e-04 - val_loss: 1.1804e-06\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2348e-04 - val_loss: 1.1778e-06\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2308e-04 - val_loss: 1.1746e-06\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2268e-04 - val_loss: 1.1715e-06\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2229e-04 - val_loss: 1.1686e-06\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2189e-04 - val_loss: 1.1657e-06\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2150e-04 - val_loss: 1.1622e-06\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2111e-04 - val_loss: 1.1594e-06\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2073e-04 - val_loss: 1.1557e-06\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2034e-04 - val_loss: 1.1532e-06\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1995e-04 - val_loss: 1.1503e-06\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1956e-04 - val_loss: 1.1475e-06\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1918e-04 - val_loss: 1.1442e-06\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1880e-04 - val_loss: 1.1415e-06\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1842e-04 - val_loss: 1.1386e-06\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1804e-04 - val_loss: 1.1357e-06\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1766e-04 - val_loss: 1.1334e-06\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1728e-04 - val_loss: 1.1304e-06\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1690e-04 - val_loss: 1.1273e-06\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1653e-04 - val_loss: 1.1248e-06\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1616e-04 - val_loss: 1.1221e-06\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1578e-04 - val_loss: 1.1196e-06\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1541e-04 - val_loss: 1.1167e-06\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1505e-04 - val_loss: 1.1141e-06\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1468e-04 - val_loss: 1.1113e-06\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1431e-04 - val_loss: 1.1085e-06\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1394e-04 - val_loss: 1.1054e-06\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1358e-04 - val_loss: 1.1029e-06\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1322e-04 - val_loss: 1.1006e-06\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1285e-04 - val_loss: 1.0977e-06\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1249e-04 - val_loss: 1.0953e-06\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1213e-04 - val_loss: 1.0929e-06\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1177e-04 - val_loss: 1.0903e-06\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1142e-04 - val_loss: 1.0883e-06\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1106e-04 - val_loss: 1.0857e-06\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1070e-04 - val_loss: 1.0833e-06\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1035e-04 - val_loss: 1.0801e-06\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.1000e-04 - val_loss: 1.0779e-06\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0965e-04 - val_loss: 1.0755e-06\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0930e-04 - val_loss: 1.0726e-06\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0895e-04 - val_loss: 1.0698e-06\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0860e-04 - val_loss: 1.0676e-06\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0825e-04 - val_loss: 1.0655e-06\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0791e-04 - val_loss: 1.0628e-06\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0756e-04 - val_loss: 1.0610e-06\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0722e-04 - val_loss: 1.0581e-06\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0688e-04 - val_loss: 1.0561e-06\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0654e-04 - val_loss: 1.0529e-06\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0620e-04 - val_loss: 1.0512e-06\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0586e-04 - val_loss: 1.0485e-06\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0552e-04 - val_loss: 1.0458e-06\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0518e-04 - val_loss: 1.0436e-06\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0485e-04 - val_loss: 1.0416e-06\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0452e-04 - val_loss: 1.0394e-06\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0419e-04 - val_loss: 1.0373e-06\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0385e-04 - val_loss: 1.0350e-06\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0352e-04 - val_loss: 1.0321e-06\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0319e-04 - val_loss: 1.0298e-06\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0287e-04 - val_loss: 1.0280e-06\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0254e-04 - val_loss: 1.0257e-06\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0221e-04 - val_loss: 1.0233e-06\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0189e-04 - val_loss: 1.0212e-06\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0157e-04 - val_loss: 1.0195e-06\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0124e-04 - val_loss: 1.0166e-06\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0092e-04 - val_loss: 1.0140e-06\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0059e-04 - val_loss: 1.0113e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0028e-04 - val_loss: 1.0092e-06\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9960e-05 - val_loss: 1.0073e-06\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9643e-05 - val_loss: 1.0053e-06\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9328e-05 - val_loss: 1.0027e-06\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9011e-05 - val_loss: 1.0007e-06\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8697e-05 - val_loss: 9.9848e-07\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8385e-05 - val_loss: 9.9607e-07\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8076e-05 - val_loss: 9.9405e-07\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7762e-05 - val_loss: 9.9245e-07\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7451e-05 - val_loss: 9.8994e-07\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7141e-05 - val_loss: 9.8792e-07\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6835e-05 - val_loss: 9.8527e-07\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6530e-05 - val_loss: 9.8337e-07\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.6224e-05 - val_loss: 9.8105e-07\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5918e-05 - val_loss: 9.7878e-07\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5613e-05 - val_loss: 9.7646e-07\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5312e-05 - val_loss: 9.7399e-07\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5010e-05 - val_loss: 9.7246e-07\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4708e-05 - val_loss: 9.7051e-07\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4410e-05 - val_loss: 9.6852e-07\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4113e-05 - val_loss: 9.6650e-07\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.3812e-05 - val_loss: 9.6394e-07\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3516e-05 - val_loss: 9.6224e-07\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3224e-05 - val_loss: 9.5955e-07\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2929e-05 - val_loss: 9.5789e-07\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2635e-05 - val_loss: 9.5602e-07\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2342e-05 - val_loss: 9.5371e-07\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2049e-05 - val_loss: 9.5205e-07\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1759e-05 - val_loss: 9.4989e-07\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1470e-05 - val_loss: 9.4708e-07\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1183e-05 - val_loss: 9.4507e-07\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0897e-05 - val_loss: 9.4297e-07\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0606e-05 - val_loss: 9.4133e-07\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0322e-05 - val_loss: 9.3905e-07\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0035e-05 - val_loss: 9.3723e-07\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9755e-05 - val_loss: 9.3449e-07\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9474e-05 - val_loss: 9.3262e-07\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9188e-05 - val_loss: 9.3068e-07\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8906e-05 - val_loss: 9.2844e-07\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8628e-05 - val_loss: 9.2643e-07\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8349e-05 - val_loss: 9.2492e-07\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8074e-05 - val_loss: 9.2252e-07\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7794e-05 - val_loss: 9.2046e-07\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7521e-05 - val_loss: 9.1827e-07\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7248e-05 - val_loss: 9.1638e-07\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6968e-05 - val_loss: 9.1395e-07\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6699e-05 - val_loss: 9.1220e-07\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6425e-05 - val_loss: 9.1017e-07\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6155e-05 - val_loss: 9.0812e-07\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5883e-05 - val_loss: 9.0615e-07\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 8.5614e-05 - val_loss: 9.0426e-07\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5346e-05 - val_loss: 9.0216e-07\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5077e-05 - val_loss: 9.0037e-07\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.4811e-05 - val_loss: 8.9827e-07\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4543e-05 - val_loss: 8.9617e-07\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4279e-05 - val_loss: 8.9435e-07\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4015e-05 - val_loss: 8.9199e-07\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3755e-05 - val_loss: 8.9100e-07\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3493e-05 - val_loss: 8.8856e-07\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3229e-05 - val_loss: 8.8593e-07\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2967e-05 - val_loss: 8.8445e-07\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2710e-05 - val_loss: 8.8219e-07\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 8.2450e-05 - val_loss: 8.7986e-07\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2192e-05 - val_loss: 8.7759e-07\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1938e-05 - val_loss: 8.7597e-07\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1678e-05 - val_loss: 8.7468e-07\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1427e-05 - val_loss: 8.7273e-07\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1170e-05 - val_loss: 8.7025e-07\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0917e-05 - val_loss: 8.6841e-07\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0665e-05 - val_loss: 8.6614e-07\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0411e-05 - val_loss: 8.6422e-07\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0161e-05 - val_loss: 8.6233e-07\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9912e-05 - val_loss: 8.6057e-07\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9665e-05 - val_loss: 8.5936e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9414e-05 - val_loss: 8.5696e-07\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9168e-05 - val_loss: 8.5526e-07\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.8921e-05 - val_loss: 8.5337e-07\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8680e-05 - val_loss: 8.5038e-07\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8431e-05 - val_loss: 8.4886e-07\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8188e-05 - val_loss: 8.4683e-07\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7943e-05 - val_loss: 8.4475e-07\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7703e-05 - val_loss: 8.4316e-07\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7461e-05 - val_loss: 8.4134e-07\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7222e-05 - val_loss: 8.3948e-07\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6979e-05 - val_loss: 8.3759e-07\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6742e-05 - val_loss: 8.3532e-07\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6503e-05 - val_loss: 8.3378e-07\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6267e-05 - val_loss: 8.3210e-07\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6032e-05 - val_loss: 8.3033e-07\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5794e-05 - val_loss: 8.2853e-07\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 7.5557e-05 - val_loss: 8.2625e-07\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.5327e-05 - val_loss: 8.2421e-07\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5091e-05 - val_loss: 8.2239e-07\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4858e-05 - val_loss: 8.2017e-07\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4627e-05 - val_loss: 8.1845e-07\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4396e-05 - val_loss: 8.1636e-07\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4168e-05 - val_loss: 8.1482e-07\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3936e-05 - val_loss: 8.1305e-07\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3710e-05 - val_loss: 8.1069e-07\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3481e-05 - val_loss: 8.0837e-07\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3255e-05 - val_loss: 8.0711e-07\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3029e-05 - val_loss: 8.0495e-07\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2803e-05 - val_loss: 8.0335e-07\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2581e-05 - val_loss: 8.0201e-07\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2355e-05 - val_loss: 8.0019e-07\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2133e-05 - val_loss: 7.9847e-07\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1908e-05 - val_loss: 7.9653e-07\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1688e-05 - val_loss: 7.9467e-07\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1468e-05 - val_loss: 7.9240e-07\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.1246e-05 - val_loss: 7.9084e-07\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.1029e-05 - val_loss: 7.8908e-07\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0810e-05 - val_loss: 7.8739e-07\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0593e-05 - val_loss: 7.8546e-07\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0376e-05 - val_loss: 7.8351e-07\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0160e-05 - val_loss: 7.8120e-07\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9942e-05 - val_loss: 7.7943e-07\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9729e-05 - val_loss: 7.7758e-07\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9514e-05 - val_loss: 7.7571e-07\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9303e-05 - val_loss: 7.7423e-07\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9090e-05 - val_loss: 7.7228e-07\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8878e-05 - val_loss: 7.7053e-07\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8667e-05 - val_loss: 7.6938e-07\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8456e-05 - val_loss: 7.6790e-07\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8246e-05 - val_loss: 7.6517e-07\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8038e-05 - val_loss: 7.6364e-07\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7831e-05 - val_loss: 7.6198e-07\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7624e-05 - val_loss: 7.6058e-07\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7416e-05 - val_loss: 7.5879e-07\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7210e-05 - val_loss: 7.5659e-07\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7006e-05 - val_loss: 7.5466e-07\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6801e-05 - val_loss: 7.5249e-07\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6598e-05 - val_loss: 7.5061e-07\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6396e-05 - val_loss: 7.4931e-07\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6189e-05 - val_loss: 7.4748e-07\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5990e-05 - val_loss: 7.4627e-07\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5789e-05 - val_loss: 7.4404e-07\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5589e-05 - val_loss: 7.4282e-07\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5392e-05 - val_loss: 7.4102e-07\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5191e-05 - val_loss: 7.3899e-07\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4994e-05 - val_loss: 7.3678e-07\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4796e-05 - val_loss: 7.3572e-07\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4600e-05 - val_loss: 7.3462e-07\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4403e-05 - val_loss: 7.3277e-07\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4210e-05 - val_loss: 7.3130e-07\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4011e-05 - val_loss: 7.2895e-07\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3820e-05 - val_loss: 7.2726e-07\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3629e-05 - val_loss: 7.2499e-07\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3433e-05 - val_loss: 7.2347e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3244e-05 - val_loss: 7.2125e-07\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3054e-05 - val_loss: 7.1970e-07\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2863e-05 - val_loss: 7.1810e-07\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2670e-05 - val_loss: 7.1620e-07\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2478e-05 - val_loss: 7.1507e-07\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2291e-05 - val_loss: 7.1339e-07\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2104e-05 - val_loss: 7.1201e-07\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1917e-05 - val_loss: 7.1023e-07\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1732e-05 - val_loss: 7.0853e-07\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1545e-05 - val_loss: 7.0729e-07\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1363e-05 - val_loss: 7.0513e-07\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1175e-05 - val_loss: 7.0378e-07\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0992e-05 - val_loss: 7.0262e-07\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0809e-05 - val_loss: 7.0096e-07\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0626e-05 - val_loss: 6.9835e-07\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0444e-05 - val_loss: 6.9628e-07\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0263e-05 - val_loss: 6.9503e-07\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0082e-05 - val_loss: 6.9370e-07\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9903e-05 - val_loss: 6.9154e-07\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9724e-05 - val_loss: 6.9046e-07\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9544e-05 - val_loss: 6.8922e-07\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9365e-05 - val_loss: 6.8731e-07\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9190e-05 - val_loss: 6.8512e-07\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9011e-05 - val_loss: 6.8396e-07\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8835e-05 - val_loss: 6.8221e-07\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8660e-05 - val_loss: 6.8099e-07\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8484e-05 - val_loss: 6.7895e-07\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8311e-05 - val_loss: 6.7833e-07\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8136e-05 - val_loss: 6.7669e-07\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7962e-05 - val_loss: 6.7480e-07\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7790e-05 - val_loss: 6.7313e-07\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7617e-05 - val_loss: 6.7129e-07\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7445e-05 - val_loss: 6.6982e-07\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7277e-05 - val_loss: 6.6820e-07\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7105e-05 - val_loss: 6.6682e-07\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6935e-05 - val_loss: 6.6530e-07\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6768e-05 - val_loss: 6.6375e-07\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6599e-05 - val_loss: 6.6199e-07\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6432e-05 - val_loss: 6.6024e-07\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6264e-05 - val_loss: 6.5887e-07\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6099e-05 - val_loss: 6.5767e-07\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5933e-05 - val_loss: 6.5641e-07\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5767e-05 - val_loss: 6.5438e-07\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5601e-05 - val_loss: 6.5305e-07\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5438e-05 - val_loss: 6.5148e-07\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5274e-05 - val_loss: 6.4979e-07\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5112e-05 - val_loss: 6.4796e-07\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4950e-05 - val_loss: 6.4704e-07\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4787e-05 - val_loss: 6.4569e-07\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4625e-05 - val_loss: 6.4364e-07\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4465e-05 - val_loss: 6.4243e-07\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4304e-05 - val_loss: 6.4096e-07\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4147e-05 - val_loss: 6.3967e-07\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3986e-05 - val_loss: 6.3770e-07\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3826e-05 - val_loss: 6.3651e-07\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3670e-05 - val_loss: 6.3541e-07\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3513e-05 - val_loss: 6.3440e-07\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.3357e-05 - val_loss: 6.3226e-07\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3204e-05 - val_loss: 6.3076e-07\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3043e-05 - val_loss: 6.2964e-07\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2889e-05 - val_loss: 6.2818e-07\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2737e-05 - val_loss: 6.2630e-07\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2582e-05 - val_loss: 6.2504e-07\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2429e-05 - val_loss: 6.2398e-07\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2278e-05 - val_loss: 6.2222e-07\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2123e-05 - val_loss: 6.2055e-07\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1972e-05 - val_loss: 6.1920e-07\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1819e-05 - val_loss: 6.1823e-07\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1670e-05 - val_loss: 6.1673e-07\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1519e-05 - val_loss: 6.1508e-07\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1369e-05 - val_loss: 6.1366e-07\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1221e-05 - val_loss: 6.1282e-07\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1075e-05 - val_loss: 6.1116e-07\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0926e-05 - val_loss: 6.0985e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0777e-05 - val_loss: 6.0812e-07\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0632e-05 - val_loss: 6.0708e-07\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0484e-05 - val_loss: 6.0564e-07\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0337e-05 - val_loss: 6.0446e-07\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0193e-05 - val_loss: 6.0278e-07\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0048e-05 - val_loss: 6.0179e-07\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9905e-05 - val_loss: 6.0041e-07\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9761e-05 - val_loss: 5.9855e-07\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9619e-05 - val_loss: 5.9735e-07\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9473e-05 - val_loss: 5.9652e-07\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9334e-05 - val_loss: 5.9542e-07\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9192e-05 - val_loss: 5.9367e-07\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9048e-05 - val_loss: 5.9246e-07\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8910e-05 - val_loss: 5.9132e-07\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8768e-05 - val_loss: 5.8971e-07\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8629e-05 - val_loss: 5.8915e-07\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8491e-05 - val_loss: 5.8729e-07\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8351e-05 - val_loss: 5.8663e-07\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8215e-05 - val_loss: 5.8444e-07\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8076e-05 - val_loss: 5.8275e-07\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7939e-05 - val_loss: 5.8172e-07\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7803e-05 - val_loss: 5.8091e-07\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7666e-05 - val_loss: 5.7967e-07\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7530e-05 - val_loss: 5.7848e-07\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.7398e-05 - val_loss: 5.7741e-07\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7262e-05 - val_loss: 5.7646e-07\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7128e-05 - val_loss: 5.7470e-07\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6996e-05 - val_loss: 5.7305e-07\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6862e-05 - val_loss: 5.7164e-07\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6728e-05 - val_loss: 5.7063e-07\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6598e-05 - val_loss: 5.6978e-07\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6465e-05 - val_loss: 5.6887e-07\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6333e-05 - val_loss: 5.6743e-07\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6203e-05 - val_loss: 5.6638e-07\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6074e-05 - val_loss: 5.6507e-07\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5943e-05 - val_loss: 5.6384e-07\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5813e-05 - val_loss: 5.6228e-07\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5685e-05 - val_loss: 5.6163e-07\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5557e-05 - val_loss: 5.6027e-07\n",
      "5.136536856298335e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.3325261 , -0.844683  ,  0.97657955,  0.4105869 ,  0.5725055 ,\n",
       "         -0.579156  , -0.8026457 ,  0.7976244 ,  0.6541244 ,  0.8291424 ],\n",
       "        [ 0.0207253 , -0.20953079,  0.3695538 ,  0.43669868, -0.45147455,\n",
       "         -0.07348356,  0.42713615,  0.26468226,  0.5323617 , -0.59026766],\n",
       "        [ 0.6849398 , -0.88367456,  1.0675265 , -0.84761286, -1.1646522 ,\n",
       "         -1.1898082 , -0.2433673 , -0.15657163,  0.13903186,  0.05548193]],\n",
       "       dtype=float32),\n",
       " array([-0.2768422 , -0.06329912, -0.08821055,  0.35606754,  0.37501922,\n",
       "        -0.5128035 ,  0.5762416 ,  0.1690545 , -0.50230074,  0.15018025],\n",
       "       dtype=float32),\n",
       " array([[-0.3266373 ,  0.12549192,  0.09959105,  0.0198029 ,  0.11573185,\n",
       "          0.5700498 , -0.24181782, -0.2895241 , -0.15913023, -0.24308196],\n",
       "        [ 0.09561577,  0.20467424,  0.19084473,  0.38947076,  0.19508551,\n",
       "          0.0207237 ,  0.47219488,  0.3960431 , -0.12616189, -0.49262142],\n",
       "        [ 0.41243988,  0.22956719, -0.4106159 , -0.46400768, -0.05519653,\n",
       "         -0.20294894, -0.26675737, -0.109154  ,  0.2640748 , -0.4565314 ],\n",
       "        [ 0.17669554,  0.37498748, -0.75066835,  0.45087323, -0.00222498,\n",
       "          0.40968448, -0.21478859,  0.34024513, -0.2555486 , -0.15094708],\n",
       "        [-0.4344132 ,  0.4008058 ,  0.2077457 ,  0.72608405, -0.4383566 ,\n",
       "         -0.36594707, -0.21917363,  0.0252932 ,  0.33223784,  0.4657037 ],\n",
       "        [-0.06262408,  0.5237767 ,  0.4593378 , -0.64877796,  0.7979874 ,\n",
       "         -0.92628586,  0.20640758, -0.06478418, -0.10171577, -0.596599  ],\n",
       "        [ 0.43729314, -0.10722732, -0.5409186 ,  0.24234794,  0.27187598,\n",
       "          0.32345486,  0.30578485,  0.46611616,  0.0426955 ,  0.20001952],\n",
       "        [-0.20607728,  0.13904808, -0.281695  ,  0.24991126, -0.15256664,\n",
       "         -0.21170777, -0.6788883 ,  0.32672513, -0.20128739,  0.12200776],\n",
       "        [-0.623578  , -0.02814919,  0.17717645, -0.08308962, -0.41915798,\n",
       "         -0.45983467,  0.01839462, -0.43338075, -0.26356754, -0.32765755],\n",
       "        [ 0.29947105,  0.5536379 ,  0.45543018, -0.11064367, -0.2003585 ,\n",
       "          0.04964482, -0.19634646,  0.3223996 ,  0.50047326,  0.268809  ]],\n",
       "       dtype=float32),\n",
       " array([-0.02013837, -0.45935705, -0.7235236 ,  0.72219455, -0.65458065,\n",
       "         0.6913338 ,  0.34882534,  0.7042792 ,  0.6817368 ,  0.72102237],\n",
       "       dtype=float32),\n",
       " array([[ 0.06784484],\n",
       "        [-0.13155669],\n",
       "        [-0.787755  ],\n",
       "        [ 0.83486444],\n",
       "        [-0.4360886 ],\n",
       "        [ 0.5704148 ],\n",
       "        [ 0.05309429],\n",
       "        [ 0.6164458 ],\n",
       "        [ 0.50237745],\n",
       "        [ 0.8338613 ]], dtype=float32),\n",
       " array([0.7781367], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_5(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure5_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.2999 - val_loss: 30.8739\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.6676 - val_loss: 26.1168\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.3324 - val_loss: 19.3419\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 19.8112 - val_loss: 11.1378\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.9578 - val_loss: 3.4698\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.4277 - val_loss: 1.6582\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8706 - val_loss: 7.8755\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7490 - val_loss: 7.9011\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4671 - val_loss: 3.4190\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0350 - val_loss: 0.7058\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2615 - val_loss: 0.8257\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6883 - val_loss: 2.3062\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3914 - val_loss: 3.6092\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1257 - val_loss: 4.0481\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3400 - val_loss: 3.5918\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0327 - val_loss: 2.5304\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4117 - val_loss: 1.3100\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.7361 - val_loss: 0.4179\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2584 - val_loss: 0.2118\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1683 - val_loss: 0.6720\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4748 - val_loss: 1.2706\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.8894 - val_loss: 1.3848\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0129 - val_loss: 0.9538\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7650 - val_loss: 0.4107\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3966 - val_loss: 0.1368\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1542 - val_loss: 0.1980\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1034 - val_loss: 0.4480\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1828 - val_loss: 0.7097\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.3038 - val_loss: 0.8678\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3991 - val_loss: 0.8813\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4306 - val_loss: 0.7659\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3887 - val_loss: 0.5722\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2902 - val_loss: 0.3636\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1727 - val_loss: 0.1958\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0809 - val_loss: 0.1004\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0462 - val_loss: 0.0774\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0705 - val_loss: 0.1005\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1252 - val_loss: 0.1332\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1692 - val_loss: 0.1470\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1750 - val_loss: 0.1330\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1429 - val_loss: 0.1006\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0945 - val_loss: 0.0677\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0542 - val_loss: 0.0499\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0350 - val_loss: 0.0538\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.0759\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0501 - val_loss: 0.1056\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0653 - val_loss: 0.1298\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0740 - val_loss: 0.1384\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0720 - val_loss: 0.1284\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0599 - val_loss: 0.1047\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0425 - val_loss: 0.0773\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0267 - val_loss: 0.0558\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0184 - val_loss: 0.0448\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0195 - val_loss: 0.0428\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0268 - val_loss: 0.0444\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0345 - val_loss: 0.0447\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0376 - val_loss: 0.0416\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.0346 - val_loss: 0.0361\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0276 - val_loss: 0.0308\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0201 - val_loss: 0.0278\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0150 - val_loss: 0.0276\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0131 - val_loss: 0.0294\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0317\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0165 - val_loss: 0.0328\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0189 - val_loss: 0.0319\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0199 - val_loss: 0.0289\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0188 - val_loss: 0.0248\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0161 - val_loss: 0.0207\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0130 - val_loss: 0.0176\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0097 - val_loss: 0.0160\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0165\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0168\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0163\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0112 - val_loss: 0.0158\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0156\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0170\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0183\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0194\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0197\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0085 - val_loss: 0.0190\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0173\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0126\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0069 - val_loss: 0.0106\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0090\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0091\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0053 - val_loss: 0.0083\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 9.9691e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.9234e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.8781e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.0012 - val_loss: 9.8329e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0012 - val_loss: 9.7882e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.7440e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.6999e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.6565e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.6130e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 9.5702e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 9.5281e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.4863e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 9.4448e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0012 - val_loss: 9.4035e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.3628e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.3224e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 9.2823e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 9.2426e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0011 - val_loss: 9.2035e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.1643e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.1258e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.0872e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.0495e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.0117e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.9740e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.9373e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.9007e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 8.8640e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.8280e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 8.7922e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.7571e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.7219e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.6873e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.6526e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 8.6187e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.5847e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.5512e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.5178e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.4847e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.4519e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.4192e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.3869e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 8.3551e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.3232e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.2918e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 8.2607e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.2296e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9871e-04 - val_loss: 8.1993e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9450e-04 - val_loss: 8.1689e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9028e-04 - val_loss: 8.1389e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8611e-04 - val_loss: 8.1089e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8195e-04 - val_loss: 8.0792e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7781e-04 - val_loss: 8.0498e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7371e-04 - val_loss: 8.0209e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6960e-04 - val_loss: 7.9916e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6552e-04 - val_loss: 7.9629e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6149e-04 - val_loss: 7.9345e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5747e-04 - val_loss: 7.9062e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5344e-04 - val_loss: 7.8781e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4946e-04 - val_loss: 7.8505e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4549e-04 - val_loss: 7.8229e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4154e-04 - val_loss: 7.7957e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3762e-04 - val_loss: 7.7687e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.3372e-04 - val_loss: 7.7418e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2983e-04 - val_loss: 7.7152e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2597e-04 - val_loss: 7.6886e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2212e-04 - val_loss: 7.6622e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1829e-04 - val_loss: 7.6364e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1449e-04 - val_loss: 7.6107e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1072e-04 - val_loss: 7.5849e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0694e-04 - val_loss: 7.5596e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0320e-04 - val_loss: 7.5343e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9947e-04 - val_loss: 7.5094e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9576e-04 - val_loss: 7.4845e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9207e-04 - val_loss: 7.4598e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8840e-04 - val_loss: 7.4356e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8474e-04 - val_loss: 7.4113e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8111e-04 - val_loss: 7.3872e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7751e-04 - val_loss: 7.3634e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7391e-04 - val_loss: 7.3398e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7034e-04 - val_loss: 7.3161e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6677e-04 - val_loss: 7.2929e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6324e-04 - val_loss: 7.2695e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5972e-04 - val_loss: 7.2465e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5621e-04 - val_loss: 7.2238e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5273e-04 - val_loss: 7.2011e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4925e-04 - val_loss: 7.1787e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4580e-04 - val_loss: 7.1564e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4237e-04 - val_loss: 7.1347e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.3895e-04 - val_loss: 7.1126e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3555e-04 - val_loss: 7.0908e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3217e-04 - val_loss: 7.0694e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 8.2881e-04 - val_loss: 7.0479e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2545e-04 - val_loss: 7.0267e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2212e-04 - val_loss: 7.0054e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1881e-04 - val_loss: 6.9844e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1551e-04 - val_loss: 6.9635e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1223e-04 - val_loss: 6.9431e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0897e-04 - val_loss: 6.9224e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0573e-04 - val_loss: 6.9020e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0248e-04 - val_loss: 6.8817e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9928e-04 - val_loss: 6.8617e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9607e-04 - val_loss: 6.8419e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9289e-04 - val_loss: 6.8223e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8972e-04 - val_loss: 6.8027e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8657e-04 - val_loss: 6.7833e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8345e-04 - val_loss: 6.7640e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8031e-04 - val_loss: 6.7447e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7721e-04 - val_loss: 6.7259e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7412e-04 - val_loss: 6.7069e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.7106e-04 - val_loss: 6.6881e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.6800e-04 - val_loss: 6.6694e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.6495e-04 - val_loss: 6.6510e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6192e-04 - val_loss: 6.6326e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 7.5890e-04 - val_loss: 6.6142e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5591e-04 - val_loss: 6.5960e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5293e-04 - val_loss: 6.5781e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4995e-04 - val_loss: 6.5603e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4701e-04 - val_loss: 6.5425e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4407e-04 - val_loss: 6.5248e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4113e-04 - val_loss: 6.5075e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.3823e-04 - val_loss: 6.4902e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3534e-04 - val_loss: 6.4731e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3245e-04 - val_loss: 6.4561e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.2958e-04 - val_loss: 6.4390e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.2674e-04 - val_loss: 6.4224e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2390e-04 - val_loss: 6.4053e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2107e-04 - val_loss: 6.3887e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1826e-04 - val_loss: 6.3723e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1547e-04 - val_loss: 6.3557e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1268e-04 - val_loss: 6.3395e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0992e-04 - val_loss: 6.3233e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0716e-04 - val_loss: 6.3071e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0442e-04 - val_loss: 6.2915e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0169e-04 - val_loss: 6.2755e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9898e-04 - val_loss: 6.2597e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 6.9628e-04 - val_loss: 6.2442e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9358e-04 - val_loss: 6.2285e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9091e-04 - val_loss: 6.2129e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.8824e-04 - val_loss: 6.1977e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8560e-04 - val_loss: 6.1824e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8296e-04 - val_loss: 6.1675e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8034e-04 - val_loss: 6.1523e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7773e-04 - val_loss: 6.1377e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.7513e-04 - val_loss: 6.1229e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7255e-04 - val_loss: 6.1081e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6997e-04 - val_loss: 6.0936e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6741e-04 - val_loss: 6.0790e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6486e-04 - val_loss: 6.0645e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6233e-04 - val_loss: 6.0501e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5981e-04 - val_loss: 6.0361e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.5730e-04 - val_loss: 6.0218e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5479e-04 - val_loss: 6.0076e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5231e-04 - val_loss: 5.9939e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4984e-04 - val_loss: 5.9798e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4738e-04 - val_loss: 5.9661e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4493e-04 - val_loss: 5.9523e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4248e-04 - val_loss: 5.9387e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4006e-04 - val_loss: 5.9253e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3765e-04 - val_loss: 5.9120e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3524e-04 - val_loss: 5.8985e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 6.3286e-04 - val_loss: 5.8853e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3047e-04 - val_loss: 5.8721e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2810e-04 - val_loss: 5.8590e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.2575e-04 - val_loss: 5.8461e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2341e-04 - val_loss: 5.8332e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2108e-04 - val_loss: 5.8204e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1875e-04 - val_loss: 5.8075e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1645e-04 - val_loss: 5.7949e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1413e-04 - val_loss: 5.7823e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1186e-04 - val_loss: 5.7699e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0957e-04 - val_loss: 5.7574e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0731e-04 - val_loss: 5.7450e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0506e-04 - val_loss: 5.7326e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0281e-04 - val_loss: 5.7204e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.0058e-04 - val_loss: 5.7081e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9835e-04 - val_loss: 5.6960e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.9614e-04 - val_loss: 5.6842e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9394e-04 - val_loss: 5.6725e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9175e-04 - val_loss: 5.6606e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8957e-04 - val_loss: 5.6487e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8740e-04 - val_loss: 5.6369e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8524e-04 - val_loss: 5.6253e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.8309e-04 - val_loss: 5.6137e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8095e-04 - val_loss: 5.6023e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7882e-04 - val_loss: 5.5907e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7671e-04 - val_loss: 5.5793e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7460e-04 - val_loss: 5.5684e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7250e-04 - val_loss: 5.5569e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7041e-04 - val_loss: 5.5456e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6834e-04 - val_loss: 5.5345e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6627e-04 - val_loss: 5.5233e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6420e-04 - val_loss: 5.5126e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6216e-04 - val_loss: 5.5018e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6013e-04 - val_loss: 5.4909e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5810e-04 - val_loss: 5.4802e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.5608e-04 - val_loss: 5.4695e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5408e-04 - val_loss: 5.4588e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5207e-04 - val_loss: 5.4481e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5008e-04 - val_loss: 5.4377e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4810e-04 - val_loss: 5.4272e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4614e-04 - val_loss: 5.4170e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4417e-04 - val_loss: 5.4066e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.4222e-04 - val_loss: 5.3962e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4027e-04 - val_loss: 5.3860e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3834e-04 - val_loss: 5.3760e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3642e-04 - val_loss: 5.3655e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3451e-04 - val_loss: 5.3554e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3260e-04 - val_loss: 5.3454e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 5.3070e-04 - val_loss: 5.3354e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 5.2882e-04 - val_loss: 5.3258e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.2694e-04 - val_loss: 5.3160e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2508e-04 - val_loss: 5.3062e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.2321e-04 - val_loss: 5.2963e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.2136e-04 - val_loss: 5.2866e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.1952e-04 - val_loss: 5.2772e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.1768e-04 - val_loss: 5.2676e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.1586e-04 - val_loss: 5.2581e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1405e-04 - val_loss: 5.2486e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1224e-04 - val_loss: 5.2392e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.1043e-04 - val_loss: 5.2299e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0864e-04 - val_loss: 5.2206e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0687e-04 - val_loss: 5.2110e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0509e-04 - val_loss: 5.2021e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0333e-04 - val_loss: 5.1927e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.0157e-04 - val_loss: 5.1837e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9982e-04 - val_loss: 5.1746e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9809e-04 - val_loss: 5.1655e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9635e-04 - val_loss: 5.1565e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9464e-04 - val_loss: 5.1477e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9291e-04 - val_loss: 5.1389e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9120e-04 - val_loss: 5.1299e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8952e-04 - val_loss: 5.1209e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8782e-04 - val_loss: 5.1122e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8614e-04 - val_loss: 5.1036e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8447e-04 - val_loss: 5.0950e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8279e-04 - val_loss: 5.0863e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8114e-04 - val_loss: 5.0777e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7949e-04 - val_loss: 5.0693e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7785e-04 - val_loss: 5.0609e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7622e-04 - val_loss: 5.0524e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7459e-04 - val_loss: 5.0440e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7296e-04 - val_loss: 5.0355e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7135e-04 - val_loss: 5.0272e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6975e-04 - val_loss: 5.0191e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.6814e-04 - val_loss: 5.0108e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6656e-04 - val_loss: 5.0026e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6498e-04 - val_loss: 4.9943e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6341e-04 - val_loss: 4.9860e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6184e-04 - val_loss: 4.9780e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6028e-04 - val_loss: 4.9700e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5873e-04 - val_loss: 4.9620e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5718e-04 - val_loss: 4.9541e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5565e-04 - val_loss: 4.9462e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5412e-04 - val_loss: 4.9385e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5259e-04 - val_loss: 4.9304e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5107e-04 - val_loss: 4.9229e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4957e-04 - val_loss: 4.9150e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4807e-04 - val_loss: 4.9073e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4657e-04 - val_loss: 4.8997e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4510e-04 - val_loss: 4.8917e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4361e-04 - val_loss: 4.8841e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4214e-04 - val_loss: 4.8765e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4068e-04 - val_loss: 4.8689e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.3922e-04 - val_loss: 4.8615e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3776e-04 - val_loss: 4.8540e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3631e-04 - val_loss: 4.8466e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3488e-04 - val_loss: 4.8391e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3345e-04 - val_loss: 4.8319e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3203e-04 - val_loss: 4.8245e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3061e-04 - val_loss: 4.8172e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2920e-04 - val_loss: 4.8100e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2779e-04 - val_loss: 4.8027e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2639e-04 - val_loss: 4.7955e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2500e-04 - val_loss: 4.7883e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2361e-04 - val_loss: 4.7810e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2223e-04 - val_loss: 4.7739e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2086e-04 - val_loss: 4.7669e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1950e-04 - val_loss: 4.7597e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1814e-04 - val_loss: 4.7527e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1679e-04 - val_loss: 4.7457e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1544e-04 - val_loss: 4.7389e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1411e-04 - val_loss: 4.7320e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1277e-04 - val_loss: 4.7251e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1144e-04 - val_loss: 4.7181e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.1012e-04 - val_loss: 4.7112e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0881e-04 - val_loss: 4.7043e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0749e-04 - val_loss: 4.6976e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0619e-04 - val_loss: 4.6908e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.0490e-04 - val_loss: 4.6842e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0361e-04 - val_loss: 4.6773e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0233e-04 - val_loss: 4.6707e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0105e-04 - val_loss: 4.6639e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9976e-04 - val_loss: 4.6572e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9851e-04 - val_loss: 4.6507e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9724e-04 - val_loss: 4.6442e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9599e-04 - val_loss: 4.6379e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9475e-04 - val_loss: 4.6314e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9351e-04 - val_loss: 4.6248e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9227e-04 - val_loss: 4.6184e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9103e-04 - val_loss: 4.6119e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8981e-04 - val_loss: 4.6056e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8859e-04 - val_loss: 4.5993e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8738e-04 - val_loss: 4.5928e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8617e-04 - val_loss: 4.5863e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8497e-04 - val_loss: 4.5800e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8377e-04 - val_loss: 4.5735e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8258e-04 - val_loss: 4.5673e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8139e-04 - val_loss: 4.5611e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8021e-04 - val_loss: 4.5550e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7904e-04 - val_loss: 4.5487e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7787e-04 - val_loss: 4.5427e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7671e-04 - val_loss: 4.5366e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7555e-04 - val_loss: 4.5305e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7440e-04 - val_loss: 4.5246e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7325e-04 - val_loss: 4.5185e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7211e-04 - val_loss: 4.5122e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7097e-04 - val_loss: 4.5063e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6984e-04 - val_loss: 4.5002e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6871e-04 - val_loss: 4.4943e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6759e-04 - val_loss: 4.4884e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6648e-04 - val_loss: 4.4824e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6536e-04 - val_loss: 4.4766e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6426e-04 - val_loss: 4.4705e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6317e-04 - val_loss: 4.4647e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6207e-04 - val_loss: 4.4588e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6097e-04 - val_loss: 4.4530e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5989e-04 - val_loss: 4.4471e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5881e-04 - val_loss: 4.4415e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5773e-04 - val_loss: 4.4357e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.5667e-04 - val_loss: 4.4299e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5560e-04 - val_loss: 4.4243e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5454e-04 - val_loss: 4.4186e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5349e-04 - val_loss: 4.4131e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5245e-04 - val_loss: 4.4072e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5140e-04 - val_loss: 4.4016e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5036e-04 - val_loss: 4.3960e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4932e-04 - val_loss: 4.3905e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4829e-04 - val_loss: 4.3849e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4726e-04 - val_loss: 4.3792e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4625e-04 - val_loss: 4.3737e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.4522e-04 - val_loss: 4.3682e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4422e-04 - val_loss: 4.3629e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4321e-04 - val_loss: 4.3573e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4221e-04 - val_loss: 4.3519e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4121e-04 - val_loss: 4.3463e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4022e-04 - val_loss: 4.3409e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3923e-04 - val_loss: 4.3354e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3824e-04 - val_loss: 4.3301e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3727e-04 - val_loss: 4.3246e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3629e-04 - val_loss: 4.3193e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3532e-04 - val_loss: 4.3140e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3435e-04 - val_loss: 4.3087e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3339e-04 - val_loss: 4.3033e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3243e-04 - val_loss: 4.2980e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3148e-04 - val_loss: 4.2928e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3054e-04 - val_loss: 4.2878e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2959e-04 - val_loss: 4.2826e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2865e-04 - val_loss: 4.2772e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2771e-04 - val_loss: 4.2721e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2679e-04 - val_loss: 4.2668e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2586e-04 - val_loss: 4.2615e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2494e-04 - val_loss: 4.2564e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2401e-04 - val_loss: 4.2511e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2311e-04 - val_loss: 4.2460e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2220e-04 - val_loss: 4.2412e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2130e-04 - val_loss: 4.2360e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2039e-04 - val_loss: 4.2309e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1950e-04 - val_loss: 4.2260e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1860e-04 - val_loss: 4.2208e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1771e-04 - val_loss: 4.2159e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1682e-04 - val_loss: 4.2108e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1595e-04 - val_loss: 4.2058e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1507e-04 - val_loss: 4.2008e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1420e-04 - val_loss: 4.1961e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1333e-04 - val_loss: 4.1909e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1247e-04 - val_loss: 4.1860e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1160e-04 - val_loss: 4.1811e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1075e-04 - val_loss: 4.1761e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0989e-04 - val_loss: 4.1714e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0904e-04 - val_loss: 4.1665e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0820e-04 - val_loss: 4.1617e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0736e-04 - val_loss: 4.1567e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0652e-04 - val_loss: 4.1518e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0569e-04 - val_loss: 4.1470e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0486e-04 - val_loss: 4.1422e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0403e-04 - val_loss: 4.1373e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0321e-04 - val_loss: 4.1328e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0240e-04 - val_loss: 4.1279e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0158e-04 - val_loss: 4.1233e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0077e-04 - val_loss: 4.1187e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9997e-04 - val_loss: 4.1139e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9916e-04 - val_loss: 4.1093e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9836e-04 - val_loss: 4.1044e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9756e-04 - val_loss: 4.0996e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9676e-04 - val_loss: 4.0950e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9598e-04 - val_loss: 4.0903e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9519e-04 - val_loss: 4.0856e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9441e-04 - val_loss: 4.0810e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9363e-04 - val_loss: 4.0765e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.9286e-04 - val_loss: 4.0717e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9208e-04 - val_loss: 4.0672e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9132e-04 - val_loss: 4.0626e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9055e-04 - val_loss: 4.0581e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8979e-04 - val_loss: 4.0538e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8904e-04 - val_loss: 4.0491e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8828e-04 - val_loss: 4.0447e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8753e-04 - val_loss: 4.0401e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8678e-04 - val_loss: 4.0356e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8604e-04 - val_loss: 4.0311e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8530e-04 - val_loss: 4.0265e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8456e-04 - val_loss: 4.0220e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8382e-04 - val_loss: 4.0175e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8310e-04 - val_loss: 4.0130e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8237e-04 - val_loss: 4.0085e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8165e-04 - val_loss: 4.0043e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8092e-04 - val_loss: 3.9999e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8021e-04 - val_loss: 3.9955e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7949e-04 - val_loss: 3.9911e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7878e-04 - val_loss: 3.9866e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7807e-04 - val_loss: 3.9824e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7737e-04 - val_loss: 3.9780e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7667e-04 - val_loss: 3.9737e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7597e-04 - val_loss: 3.9693e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7527e-04 - val_loss: 3.9651e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7458e-04 - val_loss: 3.9609e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7389e-04 - val_loss: 3.9564e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7320e-04 - val_loss: 3.9521e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7252e-04 - val_loss: 3.9477e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7184e-04 - val_loss: 3.9437e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7117e-04 - val_loss: 3.9394e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7049e-04 - val_loss: 3.9351e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6982e-04 - val_loss: 3.9307e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6915e-04 - val_loss: 3.9266e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6848e-04 - val_loss: 3.9223e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6783e-04 - val_loss: 3.9182e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6717e-04 - val_loss: 3.9139e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6651e-04 - val_loss: 3.9096e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6585e-04 - val_loss: 3.9056e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6520e-04 - val_loss: 3.9014e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6456e-04 - val_loss: 3.8974e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6391e-04 - val_loss: 3.8933e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6327e-04 - val_loss: 3.8892e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6263e-04 - val_loss: 3.8848e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6200e-04 - val_loss: 3.8807e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6136e-04 - val_loss: 3.8766e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6072e-04 - val_loss: 3.8724e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6010e-04 - val_loss: 3.8685e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5947e-04 - val_loss: 3.8644e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5885e-04 - val_loss: 3.8603e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5823e-04 - val_loss: 3.8563e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5762e-04 - val_loss: 3.8523e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5700e-04 - val_loss: 3.8482e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5639e-04 - val_loss: 3.8441e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5578e-04 - val_loss: 3.8401e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5518e-04 - val_loss: 3.8363e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5458e-04 - val_loss: 3.8321e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5397e-04 - val_loss: 3.8281e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5337e-04 - val_loss: 3.8243e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5278e-04 - val_loss: 3.8202e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5218e-04 - val_loss: 3.8163e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5160e-04 - val_loss: 3.8123e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5101e-04 - val_loss: 3.8083e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5042e-04 - val_loss: 3.8044e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4984e-04 - val_loss: 3.8003e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4926e-04 - val_loss: 3.7965e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4868e-04 - val_loss: 3.7925e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4810e-04 - val_loss: 3.7887e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4753e-04 - val_loss: 3.7847e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4696e-04 - val_loss: 3.7808e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4639e-04 - val_loss: 3.7770e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.4582e-04 - val_loss: 3.7731e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4526e-04 - val_loss: 3.7692e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4471e-04 - val_loss: 3.7654e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 2.4414e-04 - val_loss: 3.7617e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4359e-04 - val_loss: 3.7579e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4304e-04 - val_loss: 3.7540e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4249e-04 - val_loss: 3.7502e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4194e-04 - val_loss: 3.7462e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4139e-04 - val_loss: 3.7424e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4084e-04 - val_loss: 3.7385e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4030e-04 - val_loss: 3.7350e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3976e-04 - val_loss: 3.7311e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3924e-04 - val_loss: 3.7272e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3869e-04 - val_loss: 3.7236e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3817e-04 - val_loss: 3.7197e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3763e-04 - val_loss: 3.7160e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3711e-04 - val_loss: 3.7121e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3658e-04 - val_loss: 3.7086e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3606e-04 - val_loss: 3.7048e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3553e-04 - val_loss: 3.7011e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3502e-04 - val_loss: 3.6975e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3450e-04 - val_loss: 3.6939e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3399e-04 - val_loss: 3.6900e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3347e-04 - val_loss: 3.6863e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3296e-04 - val_loss: 3.6826e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3246e-04 - val_loss: 3.6789e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3195e-04 - val_loss: 3.6751e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3144e-04 - val_loss: 3.6716e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.3094e-04 - val_loss: 3.6679e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3044e-04 - val_loss: 3.6644e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2995e-04 - val_loss: 3.6605e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2945e-04 - val_loss: 3.6570e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2896e-04 - val_loss: 3.6534e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2847e-04 - val_loss: 3.6498e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2798e-04 - val_loss: 3.6461e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2749e-04 - val_loss: 3.6427e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2701e-04 - val_loss: 3.6388e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2653e-04 - val_loss: 3.6353e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2604e-04 - val_loss: 3.6316e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2556e-04 - val_loss: 3.6283e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2509e-04 - val_loss: 3.6248e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2461e-04 - val_loss: 3.6211e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.2414e-04 - val_loss: 3.6176e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2367e-04 - val_loss: 3.6141e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2320e-04 - val_loss: 3.6104e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2273e-04 - val_loss: 3.6069e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2227e-04 - val_loss: 3.6033e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2180e-04 - val_loss: 3.5999e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2135e-04 - val_loss: 3.5964e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2088e-04 - val_loss: 3.5929e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2042e-04 - val_loss: 3.5893e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1997e-04 - val_loss: 3.5857e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1951e-04 - val_loss: 3.5825e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1907e-04 - val_loss: 3.5789e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1862e-04 - val_loss: 3.5754e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1817e-04 - val_loss: 3.5719e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 2.1772e-04 - val_loss: 3.5685e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 2.1728e-04 - val_loss: 3.5649e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1683e-04 - val_loss: 3.5616e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1640e-04 - val_loss: 3.5582e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1596e-04 - val_loss: 3.5547e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1552e-04 - val_loss: 3.5511e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1508e-04 - val_loss: 3.5478e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1465e-04 - val_loss: 3.5444e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1422e-04 - val_loss: 3.5411e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1379e-04 - val_loss: 3.5377e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1336e-04 - val_loss: 3.5343e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1293e-04 - val_loss: 3.5308e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1251e-04 - val_loss: 3.5275e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1209e-04 - val_loss: 3.5240e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1166e-04 - val_loss: 3.5207e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1125e-04 - val_loss: 3.5172e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.1083e-04 - val_loss: 3.5140e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1041e-04 - val_loss: 3.5106e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0999e-04 - val_loss: 3.5072e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0958e-04 - val_loss: 3.5040e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0917e-04 - val_loss: 3.5006e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0876e-04 - val_loss: 3.4972e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0835e-04 - val_loss: 3.4940e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0795e-04 - val_loss: 3.4905e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0754e-04 - val_loss: 3.4873e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0714e-04 - val_loss: 3.4839e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0673e-04 - val_loss: 3.4806e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0634e-04 - val_loss: 3.4775e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0594e-04 - val_loss: 3.4742e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0554e-04 - val_loss: 3.4709e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.0515e-04 - val_loss: 3.4676e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0475e-04 - val_loss: 3.4644e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0436e-04 - val_loss: 3.4612e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0397e-04 - val_loss: 3.4578e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0358e-04 - val_loss: 3.4544e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0320e-04 - val_loss: 3.4513e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0281e-04 - val_loss: 3.4480e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0242e-04 - val_loss: 3.4446e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0204e-04 - val_loss: 3.4415e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0166e-04 - val_loss: 3.4382e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0128e-04 - val_loss: 3.4350e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0090e-04 - val_loss: 3.4319e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0052e-04 - val_loss: 3.4287e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0014e-04 - val_loss: 3.4256e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9977e-04 - val_loss: 3.4222e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9940e-04 - val_loss: 3.4190e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9903e-04 - val_loss: 3.4159e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9866e-04 - val_loss: 3.4128e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9829e-04 - val_loss: 3.4096e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9793e-04 - val_loss: 3.4064e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9756e-04 - val_loss: 3.4031e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9720e-04 - val_loss: 3.4001e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9684e-04 - val_loss: 3.3969e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9647e-04 - val_loss: 3.3936e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9612e-04 - val_loss: 3.3905e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9576e-04 - val_loss: 3.3875e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9540e-04 - val_loss: 3.3842e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9504e-04 - val_loss: 3.3812e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9469e-04 - val_loss: 3.3781e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9434e-04 - val_loss: 3.3750e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9398e-04 - val_loss: 3.3717e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9363e-04 - val_loss: 3.3686e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9328e-04 - val_loss: 3.3655e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9294e-04 - val_loss: 3.3624e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9259e-04 - val_loss: 3.3592e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9225e-04 - val_loss: 3.3563e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9190e-04 - val_loss: 3.3532e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9156e-04 - val_loss: 3.3501e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9122e-04 - val_loss: 3.3469e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9088e-04 - val_loss: 3.3439e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9054e-04 - val_loss: 3.3410e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9020e-04 - val_loss: 3.3379e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8987e-04 - val_loss: 3.3348e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8953e-04 - val_loss: 3.3318e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8920e-04 - val_loss: 3.3287e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8887e-04 - val_loss: 3.3255e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8853e-04 - val_loss: 3.3226e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.8820e-04 - val_loss: 3.3195e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8788e-04 - val_loss: 3.3166e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8755e-04 - val_loss: 3.3135e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8722e-04 - val_loss: 3.3105e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8690e-04 - val_loss: 3.3076e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8657e-04 - val_loss: 3.3044e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8625e-04 - val_loss: 3.3015e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8593e-04 - val_loss: 3.2986e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8561e-04 - val_loss: 3.2956e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8530e-04 - val_loss: 3.2926e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8498e-04 - val_loss: 3.2895e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8466e-04 - val_loss: 3.2865e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8435e-04 - val_loss: 3.2834e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8403e-04 - val_loss: 3.2806e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8372e-04 - val_loss: 3.2776e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8340e-04 - val_loss: 3.2747e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8310e-04 - val_loss: 3.2717e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8278e-04 - val_loss: 3.2688e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8247e-04 - val_loss: 3.2657e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8217e-04 - val_loss: 3.2629e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8186e-04 - val_loss: 3.2599e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8155e-04 - val_loss: 3.2569e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8125e-04 - val_loss: 3.2541e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8095e-04 - val_loss: 3.2513e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8065e-04 - val_loss: 3.2481e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8035e-04 - val_loss: 3.2455e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8005e-04 - val_loss: 3.2424e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7975e-04 - val_loss: 3.2396e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7945e-04 - val_loss: 3.2366e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7916e-04 - val_loss: 3.2338e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7886e-04 - val_loss: 3.2308e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7856e-04 - val_loss: 3.2280e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7827e-04 - val_loss: 3.2252e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 1.7798e-04 - val_loss: 3.2221e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7769e-04 - val_loss: 3.2193e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7740e-04 - val_loss: 3.2165e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7711e-04 - val_loss: 3.2136e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7682e-04 - val_loss: 3.2107e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7653e-04 - val_loss: 3.2078e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7625e-04 - val_loss: 3.2050e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7596e-04 - val_loss: 3.2021e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7568e-04 - val_loss: 3.1993e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7539e-04 - val_loss: 3.1965e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7511e-04 - val_loss: 3.1937e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7483e-04 - val_loss: 3.1908e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7455e-04 - val_loss: 3.1879e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7427e-04 - val_loss: 3.1851e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7399e-04 - val_loss: 3.1823e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7371e-04 - val_loss: 3.1794e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7344e-04 - val_loss: 3.1767e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7316e-04 - val_loss: 3.1738e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7289e-04 - val_loss: 3.1710e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7262e-04 - val_loss: 3.1682e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7234e-04 - val_loss: 3.1656e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7207e-04 - val_loss: 3.1627e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7180e-04 - val_loss: 3.1600e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7153e-04 - val_loss: 3.1571e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7126e-04 - val_loss: 3.1544e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7099e-04 - val_loss: 3.1517e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7072e-04 - val_loss: 3.1488e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7046e-04 - val_loss: 3.1459e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7019e-04 - val_loss: 3.1432e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6993e-04 - val_loss: 3.1405e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6967e-04 - val_loss: 3.1379e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6940e-04 - val_loss: 3.1350e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6914e-04 - val_loss: 3.1323e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6888e-04 - val_loss: 3.1295e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6862e-04 - val_loss: 3.1269e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6837e-04 - val_loss: 3.1242e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6811e-04 - val_loss: 3.1214e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6785e-04 - val_loss: 3.1187e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6759e-04 - val_loss: 3.1160e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6733e-04 - val_loss: 3.1132e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6707e-04 - val_loss: 3.1105e-04\n",
      "0.00044088956201449037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.02840035,  0.7275514 , -0.06116987,  0.7246465 ,  0.8211368 ,\n",
       "          0.74275017,  0.03093249,  0.11779617,  0.12036306,  0.4074682 ],\n",
       "        [ 0.62594575,  0.42679614, -1.0505158 , -0.5349287 ,  0.05530798,\n",
       "         -0.9914377 ,  1.126905  , -0.15398486, -1.0946863 , -0.24366997],\n",
       "        [-0.6145034 , -0.09637294, -0.48746818,  0.34285298,  1.0209967 ,\n",
       "         -0.40930632,  0.5718359 ,  0.41562778,  0.59960085, -0.8076888 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.32418174, -0.40026075,  0.30656138, -0.26804993,  0.5152698 ,\n",
       "         0.1537482 , -0.02761584,  0.11173016, -0.15709357,  0.2966469 ],\n",
       "       dtype=float32),\n",
       " array([[-0.66298807, -0.00501132, -0.41127336,  0.20148064,  0.3841239 ,\n",
       "          0.18888931, -0.54989773, -0.36166343,  0.31015155, -0.02591513,\n",
       "          0.47445273, -0.02532476, -0.5555552 ,  0.12766576, -0.44596863],\n",
       "        [-0.05212485, -0.2886192 , -0.17973769, -0.1962559 , -0.22687879,\n",
       "          0.09936856,  0.23724389,  0.4743854 ,  0.4132825 , -0.28578502,\n",
       "          0.06154305,  0.19377744,  0.17034832,  0.3250084 ,  0.4552993 ],\n",
       "        [ 0.03021642,  0.3656079 , -0.0393087 , -0.22200459,  0.31799755,\n",
       "          0.1003171 , -0.25439224, -0.5099321 ,  0.18997078,  0.5825294 ,\n",
       "          0.04368865,  0.49624187,  0.26105058, -0.06044482, -0.52406234],\n",
       "        [ 0.28400683,  0.31449082,  0.01547694, -0.27455202, -0.22847152,\n",
       "          0.48826206, -0.3580573 ,  0.12171587,  0.43209305,  0.23970549,\n",
       "         -0.51389384, -0.5352105 ,  0.19468164, -0.4183272 , -0.08322764],\n",
       "        [-0.6463077 ,  0.16345966, -0.30287907, -0.14878339, -0.18005407,\n",
       "         -0.09685453, -0.57672817, -0.3020876 , -0.19528182,  0.15362646,\n",
       "          0.4474032 , -0.03974719, -0.590951  ,  0.2458014 , -0.07769313],\n",
       "        [-0.10550343, -0.26938283, -0.0595863 , -0.34646446, -0.3634371 ,\n",
       "         -0.26602185, -0.18461314, -0.36901456,  0.06997558, -0.54152745,\n",
       "         -0.3901524 ,  0.28024206,  0.15855977, -0.18312718, -0.3649031 ],\n",
       "        [-0.19857831,  0.22591045,  0.7429767 , -0.16174202,  0.43857196,\n",
       "          0.47608063,  0.23020397, -0.19980612, -0.47717908, -0.21683499,\n",
       "          0.13973935, -0.10049522,  0.01231221,  0.32114202, -0.06022961],\n",
       "        [ 0.24090312,  0.19681938,  0.16576739, -0.5521691 ,  0.41396025,\n",
       "          0.47601274, -0.10357507,  0.16192614,  0.02626836,  0.11863896,\n",
       "         -0.08417696, -0.6893913 , -0.38728637,  0.4266864 ,  0.02942999],\n",
       "        [ 0.16999525, -0.3600426 ,  0.31657356,  0.15832229,  0.16613805,\n",
       "          0.580078  , -0.22205235, -0.48090827, -0.09342382,  0.12771435,\n",
       "         -0.07793391,  0.00204753,  0.112289  , -0.14985445, -0.5284258 ],\n",
       "        [-0.277026  , -0.36177546, -0.47793192, -0.31112134, -0.11245157,\n",
       "          0.32269704,  0.33082342, -0.32097027,  0.05825763,  0.47388178,\n",
       "          0.5839348 , -0.10247508, -0.11660632, -0.01106394, -0.21519983]],\n",
       "       dtype=float32),\n",
       " array([-0.63444227, -0.6142743 ,  0.25891027, -0.6351391 ,  0.5827866 ,\n",
       "         0.30226883, -0.57931244, -0.64688474, -0.585439  ,  0.648409  ,\n",
       "         0.6593393 , -0.22879909, -0.6354694 ,  0.6215072 , -0.6369841 ],\n",
       "       dtype=float32),\n",
       " array([[-0.5396009 ],\n",
       "        [-0.33029076],\n",
       "        [ 0.0233638 ],\n",
       "        [-0.55017054],\n",
       "        [ 0.3423154 ],\n",
       "        [ 0.04699848],\n",
       "        [-0.30234948],\n",
       "        [-0.6221926 ],\n",
       "        [-0.35388246],\n",
       "        [ 0.6241873 ],\n",
       "        [ 0.7663574 ],\n",
       "        [ 0.01850872],\n",
       "        [-0.5421421 ],\n",
       "        [ 0.4822547 ],\n",
       "        [-0.5200085 ]], dtype=float32),\n",
       " array([0.70582885], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_6(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure6_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
