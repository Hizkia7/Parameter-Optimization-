{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 420us/step - loss: 15309.0739 - val_loss: 14742.3347\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12558.4507 - val_loss: 9041.1066\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4852.8266 - val_loss: 1017.4114\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 229.8844 - val_loss: 51.4398\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 34.3918 - val_loss: 26.9219\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.2596 - val_loss: 25.7703\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.2389 - val_loss: 26.0714\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.9154 - val_loss: 26.2406\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.7397 - val_loss: 26.0389\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4663 - val_loss: 26.2159\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2331 - val_loss: 25.7258\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1137 - val_loss: 25.4167\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0295 - val_loss: 26.9206\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 22.26 - 0s 84us/step - loss: 21.8973 - val_loss: 25.3906\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.7014 - val_loss: 25.7663\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6329 - val_loss: 25.5387\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8076 - val_loss: 25.8878\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6007 - val_loss: 25.7407\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1504 - val_loss: 25.6565\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6836 - val_loss: 26.1428\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6246 - val_loss: 26.5860\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5930 - val_loss: 25.8254\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.6719 - val_loss: 25.9833\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6463 - val_loss: 25.5183\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7270 - val_loss: 25.4842\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9102 - val_loss: 25.3636\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8640 - val_loss: 25.2803\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6004 - val_loss: 25.3151\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6047 - val_loss: 25.3922\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4427 - val_loss: 26.1064\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9467 - val_loss: 26.9665\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5035 - val_loss: 25.3915\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5766 - val_loss: 25.8311\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9492 - val_loss: 25.9161\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6377 - val_loss: 26.0562\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3613 - val_loss: 25.2401\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5473 - val_loss: 25.4028\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8454 - val_loss: 25.6599\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6157 - val_loss: 25.8407\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0226 - val_loss: 25.0412\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1557 - val_loss: 25.6867\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4204 - val_loss: 25.2536\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7881 - val_loss: 25.3567\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4155 - val_loss: 25.5939\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4643 - val_loss: 25.8087\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3986 - val_loss: 25.7279\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5928 - val_loss: 26.5947\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4619 - val_loss: 25.5334\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.4277 - val_loss: 25.4190\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5379 - val_loss: 25.6212\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7721 - val_loss: 25.3620\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6885 - val_loss: 26.2949\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7092 - val_loss: 25.5901\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7039 - val_loss: 25.2640\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4889 - val_loss: 24.7576\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.4569 - val_loss: 25.4380\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.4780 - val_loss: 25.4495\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.2985 - val_loss: 25.1693\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.3008 - val_loss: 24.8641\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5178 - val_loss: 24.5862\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5585 - val_loss: 24.7428\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.7744 - val_loss: 24.7639\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.0957 - val_loss: 24.6017\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.6297 - val_loss: 24.8784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.1829 - val_loss: 25.2356\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5806 - val_loss: 24.7603\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.3824 - val_loss: 24.6392\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9315 - val_loss: 24.4788\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.6757 - val_loss: 24.1428\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.8446 - val_loss: 23.9535\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1835 - val_loss: 24.4217\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2706 - val_loss: 24.0228\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1056 - val_loss: 24.3468\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0251 - val_loss: 23.3843\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4675 - val_loss: 24.5575\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5928 - val_loss: 24.8122\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2392 - val_loss: 22.8937\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9182 - val_loss: 22.3862\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0660 - val_loss: 22.7759\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8761 - val_loss: 23.4363\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4712 - val_loss: 22.7689\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9442 - val_loss: 22.2569\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0926 - val_loss: 23.0548\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7130 - val_loss: 23.5220\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8408 - val_loss: 21.3939\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6515 - val_loss: 21.4867\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2678 - val_loss: 20.7472\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2461 - val_loss: 22.0932\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2825 - val_loss: 20.6885\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9479 - val_loss: 22.6085\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1035 - val_loss: 19.9170\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1049 - val_loss: 20.3711\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1465 - val_loss: 21.2594\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9572 - val_loss: 20.5237\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.5561 - val_loss: 19.3057\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.4747 - val_loss: 20.0877\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.5708 - val_loss: 18.9297\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.3401 - val_loss: 19.9895\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3724 - val_loss: 19.7454\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.6093 - val_loss: 18.8005\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.3776 - val_loss: 19.3902\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9325 - val_loss: 18.1729\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.6655 - val_loss: 18.4285\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0762 - val_loss: 19.1244\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.2129 - val_loss: 19.3309\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.6800 - val_loss: 19.5062\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9513 - val_loss: 18.3004\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.4363 - val_loss: 19.6284\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9697 - val_loss: 19.2690\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.4639 - val_loss: 18.5751\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.7039 - val_loss: 18.7062\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.9540 - val_loss: 19.5038\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.7302 - val_loss: 18.3936\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.7814 - val_loss: 17.8274\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.5528 - val_loss: 18.9353\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.3097 - val_loss: 18.9593\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4655 - val_loss: 18.0217\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9273 - val_loss: 18.4145\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3925 - val_loss: 17.7836\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2421 - val_loss: 17.3662\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5036 - val_loss: 18.5176\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.7825 - val_loss: 18.3967\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3971 - val_loss: 18.2843\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.4465 - val_loss: 18.2878\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2538 - val_loss: 17.6397\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 15.4245 - val_loss: 18.3847\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1972 - val_loss: 17.4782\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.0959 - val_loss: 17.6217\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 15.3491 - val_loss: 17.4832\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.9126 - val_loss: 17.1181\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.7250 - val_loss: 17.9234\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0751 - val_loss: 18.8125\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9730 - val_loss: 17.3145\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6399 - val_loss: 17.8341\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.2073 - val_loss: 20.2305\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0983 - val_loss: 19.2498\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.3557 - val_loss: 19.3334\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.7646 - val_loss: 17.3065\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7037 - val_loss: 17.4271\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9962 - val_loss: 17.3028\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.9825 - val_loss: 20.6548\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4370 - val_loss: 16.8122\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.2323 - val_loss: 19.4010\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.3286 - val_loss: 17.1199\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8039 - val_loss: 16.6718\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3275 - val_loss: 17.0968\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8075 - val_loss: 17.2084\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9035 - val_loss: 17.0453\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.9690 - val_loss: 17.0725\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8770 - val_loss: 17.8289\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1618 - val_loss: 16.7829\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.2909 - val_loss: 20.0346\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3288 - val_loss: 19.6198\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6326 - val_loss: 19.7171\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.8214 - val_loss: 20.7302\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0186 - val_loss: 16.3191\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2001 - val_loss: 17.0282\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.1561 - val_loss: 17.6225\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3938 - val_loss: 16.0444\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6111 - val_loss: 17.5093\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1570 - val_loss: 18.3671\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1483 - val_loss: 17.1808\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1337 - val_loss: 16.4826\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.0592 - val_loss: 17.2526\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3972 - val_loss: 16.8158\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.0195 - val_loss: 15.4285\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2334 - val_loss: 15.4048\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3183 - val_loss: 16.6890\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7264 - val_loss: 16.8370\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5902 - val_loss: 14.7560\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0281 - val_loss: 16.2190\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.2504 - val_loss: 16.0773\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8671 - val_loss: 16.0383\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.2101 - val_loss: 16.7770\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5117 - val_loss: 15.7095\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1990 - val_loss: 17.2788\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6662 - val_loss: 15.2442\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0383 - val_loss: 14.2019\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0931 - val_loss: 15.9237\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0788 - val_loss: 14.9128\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8041 - val_loss: 15.7852\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8479 - val_loss: 14.1753\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0789 - val_loss: 15.4999\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6210 - val_loss: 14.6710\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3890 - val_loss: 13.8607\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2246 - val_loss: 14.5928\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4946 - val_loss: 15.8468\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6526 - val_loss: 15.8219\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6948 - val_loss: 13.5830\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5068 - val_loss: 14.5869\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5143 - val_loss: 16.2738\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3004 - val_loss: 15.3962\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3704 - val_loss: 14.2848\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3573 - val_loss: 14.9742\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1384 - val_loss: 14.0932\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1673 - val_loss: 15.1188\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4279 - val_loss: 15.8358\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0537 - val_loss: 15.2725\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0049 - val_loss: 15.3016\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2780 - val_loss: 13.9745\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7644 - val_loss: 14.0352\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0792 - val_loss: 13.5182\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6560 - val_loss: 12.6451\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9141 - val_loss: 13.6007\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6584 - val_loss: 15.0471\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4222 - val_loss: 13.2259\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6377 - val_loss: 13.4874\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5366 - val_loss: 12.6032\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6644 - val_loss: 14.5265\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4141 - val_loss: 12.4095\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5842 - val_loss: 12.8314\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4149 - val_loss: 15.0725\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.1398 - val_loss: 13.7742\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9483 - val_loss: 13.6771\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2314 - val_loss: 12.4930\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3607 - val_loss: 12.7176\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3303 - val_loss: 12.8130\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6977 - val_loss: 12.4748\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3313 - val_loss: 12.7448\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2369 - val_loss: 15.0917\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7919 - val_loss: 13.3972\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1603 - val_loss: 12.3522\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7808 - val_loss: 12.6873\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3215 - val_loss: 15.5713\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9809 - val_loss: 12.0093\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0976 - val_loss: 12.8383\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1631 - val_loss: 12.6912\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1810 - val_loss: 12.4268\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3765 - val_loss: 12.6577\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0545 - val_loss: 12.7882\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8861 - val_loss: 13.4397\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7456 - val_loss: 12.2475\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8459 - val_loss: 11.8687\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1629 - val_loss: 12.7180\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2233 - val_loss: 12.6067\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7520 - val_loss: 12.3120\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9948 - val_loss: 13.6982\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9570 - val_loss: 12.9889\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2577 - val_loss: 12.2884\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6226 - val_loss: 11.7876\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0334 - val_loss: 11.9116\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3184 - val_loss: 12.9332\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9494 - val_loss: 11.8199\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7158 - val_loss: 12.0134\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9852 - val_loss: 12.2737\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5312 - val_loss: 14.5703\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9327 - val_loss: 12.8793\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8044 - val_loss: 12.2855\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7473 - val_loss: 13.0556\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3070 - val_loss: 12.4002\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2316 - val_loss: 13.5181\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1276 - val_loss: 12.1991\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8605 - val_loss: 12.7986\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8520 - val_loss: 11.7194\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6037 - val_loss: 12.2022\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9022 - val_loss: 14.0956\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0756 - val_loss: 14.0967\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2110 - val_loss: 12.4094\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4286 - val_loss: 11.6251\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0488 - val_loss: 11.9492\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4919 - val_loss: 13.2198\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2136 - val_loss: 11.6740\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6208 - val_loss: 12.8981\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8168 - val_loss: 12.5532\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1613 - val_loss: 12.2520\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0211 - val_loss: 12.8645\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7799 - val_loss: 11.7874\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9432 - val_loss: 12.0104\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7734 - val_loss: 12.1178\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5491 - val_loss: 11.9781\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8199 - val_loss: 11.6723\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0274 - val_loss: 12.0486\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5215 - val_loss: 11.7047\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0388 - val_loss: 11.6824\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2073 - val_loss: 13.0681\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5891 - val_loss: 13.5753\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0669 - val_loss: 12.3369\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7111 - val_loss: 11.3562\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3825 - val_loss: 11.9747\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9737 - val_loss: 12.1680\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6054 - val_loss: 12.6152\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7010 - val_loss: 11.8457\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4508 - val_loss: 11.8661\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9921 - val_loss: 13.2903\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6009 - val_loss: 11.9101\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1986 - val_loss: 12.5398\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3467 - val_loss: 11.3727\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4860 - val_loss: 12.6393\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7192 - val_loss: 13.2561\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7582 - val_loss: 13.4484\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8179 - val_loss: 12.1772\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.7995 - val_loss: 14.1703\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5206 - val_loss: 12.3166\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.0416 - val_loss: 13.9973\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8746 - val_loss: 11.5598\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0741 - val_loss: 12.1147\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9077 - val_loss: 11.4144\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8057 - val_loss: 12.1838\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5562 - val_loss: 11.7908\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0996 - val_loss: 12.0716\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.3661 - val_loss: 11.9507\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 10.0487 - val_loss: 15.5974\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.9006 - val_loss: 12.2243\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7489 - val_loss: 12.8845\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1315 - val_loss: 11.9632\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4659 - val_loss: 11.7498\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3140 - val_loss: 11.7190\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8455 - val_loss: 12.6567\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6863 - val_loss: 11.8685\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1543 - val_loss: 12.2756\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7035 - val_loss: 11.9449\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7022 - val_loss: 12.3371\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6455 - val_loss: 11.2906\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2478 - val_loss: 11.4645\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4951 - val_loss: 11.4269\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5610 - val_loss: 12.0862\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4466 - val_loss: 12.2513\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6962 - val_loss: 13.0790\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9939 - val_loss: 12.2377\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3735 - val_loss: 11.5699\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6028 - val_loss: 13.0139\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.9078 - val_loss: 11.4770\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3323 - val_loss: 11.2923\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3089 - val_loss: 12.8963\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4987 - val_loss: 11.9777\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4367 - val_loss: 11.4924\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8261 - val_loss: 12.4276\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7730 - val_loss: 11.9034\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3267 - val_loss: 11.9926\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5966 - val_loss: 12.9501\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0450 - val_loss: 12.0670\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4084 - val_loss: 11.9059\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6974 - val_loss: 11.9238\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2860 - val_loss: 13.7767\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6802 - val_loss: 11.9150\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4451 - val_loss: 11.9466\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4973 - val_loss: 12.7980\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4590 - val_loss: 12.3030\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9009 - val_loss: 12.0710\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6443 - val_loss: 11.6703\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8655 - val_loss: 12.3257\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3686 - val_loss: 11.7547\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3684 - val_loss: 11.2023\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3891 - val_loss: 11.1818\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1870 - val_loss: 12.3361\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2712 - val_loss: 11.5117\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4271 - val_loss: 11.9692\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4846 - val_loss: 12.4115\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7570 - val_loss: 11.3312\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3163 - val_loss: 13.4524\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7911 - val_loss: 11.0787\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8394 - val_loss: 13.7623\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.2950 - val_loss: 11.9619\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4162 - val_loss: 13.1614\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1593 - val_loss: 11.1840\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3435 - val_loss: 11.8259\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3806 - val_loss: 11.2100\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1177 - val_loss: 11.3332\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4104 - val_loss: 12.0400\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2882 - val_loss: 11.1473\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6403 - val_loss: 11.9136\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5270 - val_loss: 11.9449\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2160 - val_loss: 11.6413\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3615 - val_loss: 11.3028\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5023 - val_loss: 11.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6530 - val_loss: 11.0838\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1003 - val_loss: 13.5458\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4238 - val_loss: 11.1573\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8405 - val_loss: 11.5505\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8712 - val_loss: 12.7308\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4549 - val_loss: 11.5038\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1912 - val_loss: 11.6680\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4739 - val_loss: 12.0974\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3064 - val_loss: 12.2338\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3901 - val_loss: 12.6478\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6023 - val_loss: 11.2407\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0317 - val_loss: 11.4087\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2685 - val_loss: 11.1529\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5805 - val_loss: 11.5831\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6117 - val_loss: 11.0496\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6015 - val_loss: 12.3644\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4963 - val_loss: 11.3885\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6764 - val_loss: 11.4166\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3530 - val_loss: 11.1623\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7145 - val_loss: 12.2028\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5768 - val_loss: 11.9697\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9086 - val_loss: 14.8408\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2730 - val_loss: 10.9013\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4111 - val_loss: 11.5105\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3493 - val_loss: 11.4770\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4551 - val_loss: 12.3629\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3794 - val_loss: 11.5545\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9623 - val_loss: 12.2219\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6370 - val_loss: 10.9315\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1397 - val_loss: 11.8405\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8295 - val_loss: 11.3590\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1940 - val_loss: 12.8024\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3870 - val_loss: 11.5681\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4818 - val_loss: 11.5366\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0804 - val_loss: 11.2976\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9281 - val_loss: 12.9546\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2971 - val_loss: 12.1679\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1975 - val_loss: 13.0755\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1153 - val_loss: 11.2087\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4122 - val_loss: 12.4274\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4100 - val_loss: 11.0827\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0449 - val_loss: 11.7438\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5575 - val_loss: 11.2025\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4788 - val_loss: 11.6639\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3123 - val_loss: 10.9138\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2818 - val_loss: 12.7157\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4761 - val_loss: 11.8807\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4418 - val_loss: 11.1199\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5494 - val_loss: 11.1866\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7060 - val_loss: 12.3678\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7523 - val_loss: 11.8250\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1439 - val_loss: 11.4709\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1294 - val_loss: 12.3730\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4558 - val_loss: 11.1240\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4644 - val_loss: 11.5617\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4433 - val_loss: 11.6066\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1094 - val_loss: 11.2835\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0215 - val_loss: 12.2197\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1675 - val_loss: 11.1876\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1234 - val_loss: 10.8312\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0132 - val_loss: 11.2077\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7973 - val_loss: 12.3564\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0781 - val_loss: 11.0524\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5094 - val_loss: 12.1304\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4544 - val_loss: 13.6707\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2300 - val_loss: 11.9184\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6380 - val_loss: 11.2445\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3705 - val_loss: 11.4732\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2698 - val_loss: 11.7073\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3403 - val_loss: 11.9527\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3298 - val_loss: 10.9415\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2132 - val_loss: 11.5429\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5006 - val_loss: 10.9392\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3904 - val_loss: 11.7958\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1410 - val_loss: 12.1961\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6702 - val_loss: 12.5514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5977 - val_loss: 12.1981\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4331 - val_loss: 10.8042\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0293 - val_loss: 11.5177\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0918 - val_loss: 10.8570\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1345 - val_loss: 12.0462\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1469 - val_loss: 11.9558\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5383 - val_loss: 11.2365\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3242 - val_loss: 11.6032\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5435 - val_loss: 11.6296\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5907 - val_loss: 10.9400\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1674 - val_loss: 10.8971\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0189 - val_loss: 10.9367\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1012 - val_loss: 12.6740\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8812 - val_loss: 12.2217\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4629 - val_loss: 11.7666\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2842 - val_loss: 11.1394\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5476 - val_loss: 10.9186\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3729 - val_loss: 12.7043\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5193 - val_loss: 12.4363\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2836 - val_loss: 11.6495\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2219 - val_loss: 11.8775\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4287 - val_loss: 12.7943\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5880 - val_loss: 11.2306\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4928 - val_loss: 11.1203\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4413 - val_loss: 10.8375\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5544 - val_loss: 11.3969\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5151 - val_loss: 11.8795\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5241 - val_loss: 12.0608\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.4974 - val_loss: 11.8394\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.1396 - val_loss: 11.7310\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2759 - val_loss: 10.8694\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7073 - val_loss: 11.4802\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7698 - val_loss: 11.2057\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2698 - val_loss: 11.1232\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2267 - val_loss: 12.0768\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.5095 - val_loss: 13.7072\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2321 - val_loss: 11.2343\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1783 - val_loss: 10.8159\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1569 - val_loss: 11.6557\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9999 - val_loss: 11.6076\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9144 - val_loss: 11.4393\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1267 - val_loss: 11.7593\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2608 - val_loss: 10.9006\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9531 - val_loss: 11.1462\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2210 - val_loss: 10.7909\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2042 - val_loss: 11.6208\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9632 - val_loss: 11.4712\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9052 - val_loss: 10.9331\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2563 - val_loss: 12.2460\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4671 - val_loss: 11.3513\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0749 - val_loss: 12.7972\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4068 - val_loss: 11.2040\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1450 - val_loss: 10.7494\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8505 - val_loss: 12.0643\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3729 - val_loss: 11.4697\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1015 - val_loss: 12.2496\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0979 - val_loss: 13.6609\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6065 - val_loss: 10.7280\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0718 - val_loss: 11.3673\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4050 - val_loss: 11.0545\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4088 - val_loss: 11.5516\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4993 - val_loss: 12.1816\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4934 - val_loss: 11.9665\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1759 - val_loss: 11.3998\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2610 - val_loss: 11.2612\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1984 - val_loss: 10.9987\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4239 - val_loss: 12.1355\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3031 - val_loss: 13.1696\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1594 - val_loss: 11.7253\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5307 - val_loss: 11.3848\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9082 - val_loss: 11.3434\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2072 - val_loss: 12.7730\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2969 - val_loss: 12.5924\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3723 - val_loss: 11.2390\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0157 - val_loss: 10.6965\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1667 - val_loss: 13.2928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4898 - val_loss: 12.7131\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9750 - val_loss: 12.4996\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3633 - val_loss: 12.7002\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3624 - val_loss: 11.0979\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5355 - val_loss: 11.1738\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2977 - val_loss: 11.8297\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1094 - val_loss: 11.2581\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1850 - val_loss: 11.7337\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8796 - val_loss: 10.8845\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4046 - val_loss: 13.1199\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5151 - val_loss: 11.4550\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9701 - val_loss: 11.4035\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9436 - val_loss: 12.0850\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0429 - val_loss: 11.0511\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0894 - val_loss: 10.8695\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9276 - val_loss: 12.1397\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1708 - val_loss: 10.8433\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5602 - val_loss: 10.9163\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0832 - val_loss: 10.9043\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0339 - val_loss: 11.3088\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2015 - val_loss: 11.2858\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5132 - val_loss: 11.3152\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3553 - val_loss: 11.0916\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1749 - val_loss: 11.2851\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5616 - val_loss: 13.1136\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4509 - val_loss: 12.2368\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0789 - val_loss: 11.1324\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2485 - val_loss: 13.0912\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3946 - val_loss: 11.3544\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4090 - val_loss: 11.8099\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2272 - val_loss: 11.0215\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2020 - val_loss: 12.3340\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4061 - val_loss: 11.2715\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3339 - val_loss: 11.0900\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3218 - val_loss: 10.8136\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3034 - val_loss: 11.2639\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1602 - val_loss: 12.4708\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1655 - val_loss: 11.3552\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6561 - val_loss: 11.2815\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1898 - val_loss: 11.8846\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0129 - val_loss: 11.4479\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0464 - val_loss: 11.2003\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1795 - val_loss: 10.9823\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4254 - val_loss: 10.6023\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2549 - val_loss: 11.9203\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2111 - val_loss: 11.0993\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1967 - val_loss: 11.9054\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0628 - val_loss: 11.3898\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0980 - val_loss: 10.7049\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7862 - val_loss: 10.7516\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7464 - val_loss: 12.0533\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1641 - val_loss: 10.7024\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8263 - val_loss: 11.1276\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9360 - val_loss: 10.7146\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9939 - val_loss: 11.2295\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2678 - val_loss: 11.0929\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1290 - val_loss: 11.8645\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0743 - val_loss: 12.3492\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8287 - val_loss: 14.9861\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8268 - val_loss: 12.7435\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9086 - val_loss: 12.8740\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4200 - val_loss: 11.2666\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3199 - val_loss: 11.5621\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9395 - val_loss: 11.0061\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0415 - val_loss: 12.7381\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3211 - val_loss: 10.9076\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1860 - val_loss: 13.7213\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1803 - val_loss: 10.8633\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8306 - val_loss: 10.8114\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7675 - val_loss: 11.9162\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2273 - val_loss: 11.3620\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5619 - val_loss: 11.5632\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2057 - val_loss: 10.8142\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4647 - val_loss: 11.1513\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2143 - val_loss: 11.2744\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0231 - val_loss: 11.9301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0433 - val_loss: 11.0635\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4097 - val_loss: 11.3152\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9280 - val_loss: 10.8576\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0008 - val_loss: 10.9012\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9225 - val_loss: 10.9864\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0640 - val_loss: 11.2713\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2187 - val_loss: 11.1885\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0698 - val_loss: 11.5847\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0694 - val_loss: 11.1285\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3079 - val_loss: 11.5089\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8673 - val_loss: 11.0111\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0601 - val_loss: 10.6502\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0834 - val_loss: 11.4008\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0370 - val_loss: 11.3612\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0024 - val_loss: 11.9242\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9108 - val_loss: 11.0188\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3831 - val_loss: 11.0173\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2099 - val_loss: 12.1430\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1352 - val_loss: 10.8976\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2306 - val_loss: 11.4803\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4285 - val_loss: 12.2883\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0314 - val_loss: 10.7010\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8504 - val_loss: 10.8598\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0434 - val_loss: 11.1187\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1386 - val_loss: 11.3682\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2433 - val_loss: 11.4275\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2373 - val_loss: 11.0895\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4568 - val_loss: 11.7911\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5042 - val_loss: 11.8985\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0135 - val_loss: 11.4174\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5829 - val_loss: 11.4487\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.773 - 0s 88us/step - loss: 10.1131 - val_loss: 13.2429\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4665 - val_loss: 12.9649\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9518 - val_loss: 12.8260\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3197 - val_loss: 11.3530\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3653 - val_loss: 10.9696\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1853 - val_loss: 11.2790\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2995 - val_loss: 11.4182\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2211 - val_loss: 12.8054\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9575 - val_loss: 12.4856\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0353 - val_loss: 10.6802\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3664 - val_loss: 11.9727\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9476 - val_loss: 11.6402\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2438 - val_loss: 11.1667\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2226 - val_loss: 10.8594\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9610 - val_loss: 11.9461\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1684 - val_loss: 11.4149\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8471 - val_loss: 10.6855\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9255 - val_loss: 11.3639\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1662 - val_loss: 11.5533\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0653 - val_loss: 11.3628\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0832 - val_loss: 10.7606\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0863 - val_loss: 10.9804\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0184 - val_loss: 10.8081\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2543 - val_loss: 11.1865\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4011 - val_loss: 12.2643\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6095 - val_loss: 11.7705\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5616 - val_loss: 12.1313\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4541 - val_loss: 11.0501\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7667 - val_loss: 10.5194\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6721 - val_loss: 14.5166\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8690 - val_loss: 11.5371\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4458 - val_loss: 12.9188\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3945 - val_loss: 10.7339\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0321 - val_loss: 11.4917\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0747 - val_loss: 11.0169\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2947 - val_loss: 12.4313\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1319 - val_loss: 10.9694\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0871 - val_loss: 11.3772\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3711 - val_loss: 10.7018\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7508 - val_loss: 11.0022\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8304 - val_loss: 10.9317\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8765 - val_loss: 11.0987\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8125 - val_loss: 13.2920\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1001 - val_loss: 11.2395\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0523 - val_loss: 11.0914\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0283 - val_loss: 12.0899\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6636 - val_loss: 11.2283\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5227 - val_loss: 10.9115\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0850 - val_loss: 10.9836\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3002 - val_loss: 11.1859\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9398 - val_loss: 11.3207\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.432 - 0s 88us/step - loss: 9.6730 - val_loss: 13.1242\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5405 - val_loss: 13.8407\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4255 - val_loss: 12.1035\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5435 - val_loss: 11.1986\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1226 - val_loss: 13.8485\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7561 - val_loss: 11.1423\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9179 - val_loss: 11.8322\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0883 - val_loss: 15.3287\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3801 - val_loss: 10.6036\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9263 - val_loss: 11.6710\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8955 - val_loss: 11.5132\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0518 - val_loss: 10.7190\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9996 - val_loss: 10.8810\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0379 - val_loss: 11.2209\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9029 - val_loss: 11.1588\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7467 - val_loss: 11.0548\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8198 - val_loss: 12.1110\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8613 - val_loss: 11.2377\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9059 - val_loss: 11.3949\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4678 - val_loss: 10.9634\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0255 - val_loss: 10.7625\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6157 - val_loss: 10.8227\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1376 - val_loss: 10.8864\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2915 - val_loss: 11.0874\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2895 - val_loss: 10.6728\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8593 - val_loss: 10.7592\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7942 - val_loss: 11.0240\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2103 - val_loss: 11.4552\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1309 - val_loss: 11.2477\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7712 - val_loss: 10.7046\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3593 - val_loss: 11.0780\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0456 - val_loss: 11.7088\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8886 - val_loss: 10.8806\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0371 - val_loss: 11.5324\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1588 - val_loss: 11.0690\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9180 - val_loss: 11.3255\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0279 - val_loss: 10.7831\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0763 - val_loss: 10.9090\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6617 - val_loss: 11.1753\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6137 - val_loss: 10.7605\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3789 - val_loss: 11.6149\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5673 - val_loss: 10.8763\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7328 - val_loss: 11.0759\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9122 - val_loss: 10.4797\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8778 - val_loss: 11.5996\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3738 - val_loss: 12.4767\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8194 - val_loss: 11.0574\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7364 - val_loss: 11.4679\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3137 - val_loss: 12.0913\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6558 - val_loss: 11.1029\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8316 - val_loss: 10.6580\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2376 - val_loss: 10.6972\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1341 - val_loss: 11.2943\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0927 - val_loss: 12.2206\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1178 - val_loss: 10.7635\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4795 - val_loss: 12.9069\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0437 - val_loss: 10.5406\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0260 - val_loss: 11.3095\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5172 - val_loss: 10.7468\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8922 - val_loss: 10.8489\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0328 - val_loss: 11.3065\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6280 - val_loss: 12.0885\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9706 - val_loss: 10.9013\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6939 - val_loss: 10.6751\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1247 - val_loss: 11.3875\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1692 - val_loss: 11.4401\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8566 - val_loss: 12.2242\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8778 - val_loss: 10.4260\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0595 - val_loss: 10.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9129 - val_loss: 10.5765\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8752 - val_loss: 11.1720\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8731 - val_loss: 11.6696\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8808 - val_loss: 10.8189\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0036 - val_loss: 10.5767\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8718 - val_loss: 11.5525\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7337 - val_loss: 12.0573\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6786 - val_loss: 10.7428\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2469 - val_loss: 12.2670\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0013 - val_loss: 10.8759\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3752 - val_loss: 11.6243\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2990 - val_loss: 11.4446\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6483 - val_loss: 11.1083\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9321 - val_loss: 11.4989\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8102 - val_loss: 10.9905\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8842 - val_loss: 10.6743\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0387 - val_loss: 10.6154\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8241 - val_loss: 11.7625\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9409 - val_loss: 11.4164\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9114 - val_loss: 11.5458\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0078 - val_loss: 10.6669\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0155 - val_loss: 10.8197\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0698 - val_loss: 11.0196\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8396 - val_loss: 11.8275\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1911 - val_loss: 12.7837\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7001 - val_loss: 11.0983\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8191 - val_loss: 11.0161\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9324 - val_loss: 10.8255\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1330 - val_loss: 10.6889\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0616 - val_loss: 10.9110\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0875 - val_loss: 10.9447\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6438 - val_loss: 11.1287\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3010 - val_loss: 10.7916\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 9.1451 - val_loss: 11.0357\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9768 - val_loss: 12.4014\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6586 - val_loss: 10.9638\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3095 - val_loss: 10.4944\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8792 - val_loss: 11.0608\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9552 - val_loss: 11.0989\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9574 - val_loss: 10.8077\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3931 - val_loss: 11.1256\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8140 - val_loss: 10.9196\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2013 - val_loss: 11.5670\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1628 - val_loss: 11.1695\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2503 - val_loss: 11.3374\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8878 - val_loss: 12.5489\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9437 - val_loss: 10.2888\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8885 - val_loss: 10.5191\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6332 - val_loss: 11.8930\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4757 - val_loss: 10.6818\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7370 - val_loss: 10.5060\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8646 - val_loss: 10.7345\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8216 - val_loss: 11.3052\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4277 - val_loss: 12.3277\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2514 - val_loss: 10.6144\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9420 - val_loss: 10.6778\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8475 - val_loss: 10.3830\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9363 - val_loss: 11.9524\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9388 - val_loss: 11.6261\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0280 - val_loss: 10.4413\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9095 - val_loss: 10.9413\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0585 - val_loss: 11.0953\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8874 - val_loss: 10.7875\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9365 - val_loss: 10.2203\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0402 - val_loss: 10.7087\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8327 - val_loss: 10.5216\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1600 - val_loss: 10.5795\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9284 - val_loss: 11.4841\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3588 - val_loss: 10.3645\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1541 - val_loss: 11.1491\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1095 - val_loss: 10.6189\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9426 - val_loss: 10.2407\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.047 - 0s 97us/step - loss: 8.8951 - val_loss: 10.8629\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8455 - val_loss: 10.8016\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8998 - val_loss: 10.6980\n",
      "Epoch 820/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7438 - val_loss: 11.2455\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7134 - val_loss: 11.4666\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3446 - val_loss: 10.9787\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6197 - val_loss: 10.6678\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9619 - val_loss: 11.2323\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7002 - val_loss: 11.5809\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8551 - val_loss: 10.5741\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7548 - val_loss: 11.8369\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4709 - val_loss: 10.7573\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2044 - val_loss: 10.9856\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7890 - val_loss: 10.0874\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0433 - val_loss: 10.2451\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8498 - val_loss: 10.3181\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6978 - val_loss: 11.5610\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0135 - val_loss: 10.4851\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8294 - val_loss: 11.6806\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1173 - val_loss: 11.9045\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9358 - val_loss: 10.8047\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7520 - val_loss: 11.5887\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1006 - val_loss: 11.3134\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7981 - val_loss: 11.5356\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2150 - val_loss: 12.0390\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1564 - val_loss: 11.2635\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0822 - val_loss: 11.1420\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6674 - val_loss: 11.4229\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0866 - val_loss: 11.7341\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5473 - val_loss: 10.3007\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2457 - val_loss: 10.8833\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9886 - val_loss: 10.3909\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2215 - val_loss: 10.5778\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1538 - val_loss: 11.1510\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6514 - val_loss: 10.6783\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3697 - val_loss: 11.8994\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9454 - val_loss: 10.4186\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7014 - val_loss: 11.8138\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8622 - val_loss: 10.4707\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1461 - val_loss: 10.9966\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2250 - val_loss: 10.4393\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8023 - val_loss: 10.4074\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8813 - val_loss: 10.6312\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1758 - val_loss: 12.6138\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3409 - val_loss: 10.7188\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4740 - val_loss: 13.5346\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2372 - val_loss: 11.6893\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5882 - val_loss: 14.7857\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1820 - val_loss: 10.5694\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0528 - val_loss: 10.6846\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1933 - val_loss: 10.8883\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9341 - val_loss: 10.8412\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6596 - val_loss: 11.1732\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8388 - val_loss: 11.5655\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5282 - val_loss: 11.3904\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3673 - val_loss: 12.5764\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0804 - val_loss: 10.4386\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8791 - val_loss: 10.9601\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5811 - val_loss: 10.5824\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9302 - val_loss: 11.6059\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2198 - val_loss: 10.8420\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2316 - val_loss: 10.4119\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9884 - val_loss: 10.4381\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1810 - val_loss: 10.8889\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7644 - val_loss: 10.8832\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6734 - val_loss: 10.9037\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6271 - val_loss: 11.6976\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2156 - val_loss: 10.5549\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9574 - val_loss: 10.7343\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0139 - val_loss: 10.4467\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8760 - val_loss: 10.4813\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1583 - val_loss: 11.4062\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3392 - val_loss: 10.3012\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9960 - val_loss: 11.3998\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2062 - val_loss: 11.4131\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0373 - val_loss: 10.5504\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7544 - val_loss: 10.4403\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5493 - val_loss: 10.2542\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2551 - val_loss: 10.7863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9614 - val_loss: 10.1383\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6338 - val_loss: 11.1691\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1390 - val_loss: 10.7284\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8307 - val_loss: 10.5593\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7624 - val_loss: 11.5662\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2717 - val_loss: 10.4144\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9335 - val_loss: 10.2773\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9660 - val_loss: 11.4704\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8767 - val_loss: 10.0714\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2908 - val_loss: 11.7088\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9141 - val_loss: 10.7379\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7149 - val_loss: 10.3309\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9197 - val_loss: 10.5686\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9596 - val_loss: 10.8647\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2061 - val_loss: 10.7256\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0135 - val_loss: 10.5942\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1441 - val_loss: 10.9608\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2815 - val_loss: 11.5462\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0009 - val_loss: 10.4171\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8515 - val_loss: 12.4521\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8847 - val_loss: 10.0357\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1179 - val_loss: 11.1164\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6747 - val_loss: 10.3827\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9221 - val_loss: 10.7546\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4753 - val_loss: 10.5398\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6178 - val_loss: 11.8903\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1607 - val_loss: 10.8836\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1781 - val_loss: 10.3874\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0019 - val_loss: 9.9449\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2704 - val_loss: 11.4391\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9512 - val_loss: 10.3730\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7676 - val_loss: 13.3651\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6385 - val_loss: 10.7297\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6333 - val_loss: 12.7119\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1329 - val_loss: 10.7376\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.481 - 0s 87us/step - loss: 8.8495 - val_loss: 11.0419\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1890 - val_loss: 11.7135\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7736 - val_loss: 10.7724\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6766 - val_loss: 10.3056\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2375 - val_loss: 11.5132\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8159 - val_loss: 11.0456\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0299 - val_loss: 11.1178\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9986 - val_loss: 10.6632\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7493 - val_loss: 10.3183\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4976 - val_loss: 11.1066\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5902 - val_loss: 12.5445\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7182 - val_loss: 10.1932\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8108 - val_loss: 10.0342\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8317 - val_loss: 11.2578\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9184 - val_loss: 10.8525\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9593 - val_loss: 9.9341\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1540 - val_loss: 10.3588\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0420 - val_loss: 10.2623\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0295 - val_loss: 11.2037\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2320 - val_loss: 10.3412\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4554 - val_loss: 10.1962\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0476 - val_loss: 10.6886\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5201 - val_loss: 11.1643\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8802 - val_loss: 10.8597\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3850 - val_loss: 12.3957\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9853 - val_loss: 10.8438\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6633 - val_loss: 11.0617\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0781 - val_loss: 10.1210\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8357 - val_loss: 10.1477\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8705 - val_loss: 10.1574\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7485 - val_loss: 11.0235\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8501 - val_loss: 10.9942\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9484 - val_loss: 10.9155\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0854 - val_loss: 10.8841\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0915 - val_loss: 10.7921\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0731 - val_loss: 10.7285\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6460 - val_loss: 11.3674\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0061 - val_loss: 10.1965\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7973 - val_loss: 10.9996\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8925 - val_loss: 9.9864\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5246 - val_loss: 10.0580\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5952 - val_loss: 10.7451\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6209 - val_loss: 10.6469\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2501 - val_loss: 10.8181\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9684 - val_loss: 12.6000\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9152 - val_loss: 9.9837\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8568 - val_loss: 10.4143\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2613 - val_loss: 12.1647\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3593 - val_loss: 13.0724\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7357 - val_loss: 10.3693\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1982 - val_loss: 10.7437\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1532 - val_loss: 10.6255\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6090 - val_loss: 10.6690\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7858 - val_loss: 10.4319\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4639 - val_loss: 10.9034\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6738 - val_loss: 9.9240\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9976 - val_loss: 10.5639\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8494 - val_loss: 13.6244\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8219 - val_loss: 10.3097\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5809 - val_loss: 11.6046\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9757 - val_loss: 10.6238\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0533 - val_loss: 11.4025\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0754 - val_loss: 10.3518\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2538 - val_loss: 11.0968\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5994 - val_loss: 10.9082\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9490 - val_loss: 11.4433\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1590 - val_loss: 11.5070\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3958 - val_loss: 11.3942\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8477 - val_loss: 10.9378\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8138 - val_loss: 10.3921\n",
      "8.52591307922802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.5961688 , -3.6006153 , -0.18909729, -3.933795  ,  1.0522664 ],\n",
       "        [ 0.35881877,  0.08211656, -0.26257172,  0.34114894,  0.13741073],\n",
       "        [ 0.27578136,  0.09264594, -0.37078285, -0.55793333,  0.37737206],\n",
       "        [ 0.0615519 ,  0.09321787,  0.08592814,  0.15876016, -0.13260473],\n",
       "        [-0.18115026, -2.2455835 , -0.20941421, -0.452171  ,  1.1600504 ]],\n",
       "       dtype=float32),\n",
       " array([-1.2705213, -5.0634174, -0.1854675, -4.797664 ,  3.2226675],\n",
       "       dtype=float32),\n",
       " array([[-0.9808444 , -0.7647816 , -0.3112274 ,  0.615847  , -1.0096334 ,\n",
       "         -0.8339291 , -0.40412965, -0.78470594, -1.0249192 , -0.4282521 ],\n",
       "        [ 1.597721  ,  2.0967634 ,  1.9138441 , -1.4256531 ,  1.717231  ,\n",
       "          1.5768399 ,  1.6048434 ,  1.6139784 ,  2.1336641 ,  1.6569222 ],\n",
       "        [-1.4329431 , -1.4877272 , -0.48921087,  0.73444855, -0.765679  ,\n",
       "         -0.49142256, -1.1565211 , -0.9261735 , -0.66788226, -1.3124042 ],\n",
       "        [ 1.2024214 ,  2.0747173 ,  1.5491068 , -1.709986  ,  2.1760516 ,\n",
       "          2.3825467 ,  2.3759649 ,  2.2595012 ,  2.1483285 ,  1.559229  ],\n",
       "        [-1.9566953 , -2.1613758 , -1.680676  ,  1.24086   , -2.232331  ,\n",
       "         -1.3539072 , -1.3194911 , -2.1613739 , -1.5057509 , -2.0596662 ]],\n",
       "       dtype=float32),\n",
       " array([-1.5743495, -1.6170139, -1.7008036,  1.615456 , -1.608937 ,\n",
       "        -1.6264647, -1.6229814, -1.6351104, -1.7679139, -1.6331407],\n",
       "       dtype=float32),\n",
       " array([[-1.9940147],\n",
       "        [-2.0862684],\n",
       "        [-1.7858545],\n",
       "        [ 2.108879 ],\n",
       "        [-2.084075 ],\n",
       "        [-2.030935 ],\n",
       "        [-2.0577042],\n",
       "        [-1.5496285],\n",
       "        [-1.736522 ],\n",
       "        [-1.9830035]], dtype=float32),\n",
       " array([1.5361468], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_adam_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 167us/step - loss: 15395.7526 - val_loss: 15090.9761\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14199.5177 - val_loss: 12716.3638\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8313.7281 - val_loss: 2255.1773\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 415.3224 - val_loss: 90.5844\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 56.2862 - val_loss: 45.3543\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 42.9219 - val_loss: 39.8993\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 38.9226 - val_loss: 37.2643\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 35.3622 - val_loss: 34.2743\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 32.3952 - val_loss: 31.6571\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 30.1657 - val_loss: 30.1893\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 28.4875 - val_loss: 28.8491\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 27.3009 - val_loss: 28.2553\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 26.2573 - val_loss: 27.5831\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 25.5482 - val_loss: 27.0421\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 24.8803 - val_loss: 26.7777\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 24.2933 - val_loss: 26.4289\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.8970 - val_loss: 26.1740\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.5271 - val_loss: 26.0101\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.2767 - val_loss: 25.8366\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 23.0515 - val_loss: 25.8904\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.8084 - val_loss: 25.7453\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 22.6387 - val_loss: 25.6173\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.4905 - val_loss: 25.4774\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 22.3935 - val_loss: 25.4501\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 22.1738 - val_loss: 25.4212\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 22.0659 - val_loss: 25.3170\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.9656 - val_loss: 25.3014\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.9168 - val_loss: 25.2486\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.7919 - val_loss: 25.2312\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.7238 - val_loss: 25.1715\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 21.6128 - val_loss: 25.1570\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 21.5459 - val_loss: 25.0856\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 21.17 - 0s 75us/step - loss: 21.4534 - val_loss: 25.0690\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 21.4513 - val_loss: 25.1381\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 21.3601 - val_loss: 25.0705\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 21.2580 - val_loss: 25.0063\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 21.2115 - val_loss: 24.9573\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.1837 - val_loss: 24.9166\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 21.1136 - val_loss: 24.9746\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.1020 - val_loss: 25.0305\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.0184 - val_loss: 24.9717\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.9547 - val_loss: 24.8667\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.9218 - val_loss: 24.8741\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.8519 - val_loss: 24.8131\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 20.7774 - val_loss: 24.8416\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.7603 - val_loss: 24.8244\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.7157 - val_loss: 24.7914\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.6780 - val_loss: 24.7250\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.6790 - val_loss: 24.8410\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 20.5741 - val_loss: 24.6952\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.5557 - val_loss: 24.7222\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.5842 - val_loss: 24.7658\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 20.5012 - val_loss: 24.7377\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.4428 - val_loss: 24.7580\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.4040 - val_loss: 24.7149\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.3824 - val_loss: 24.6897\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.3325 - val_loss: 24.6840\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.3011 - val_loss: 24.7078\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.2886 - val_loss: 24.7026\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.2778 - val_loss: 24.6148\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.2349 - val_loss: 24.6936\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 20.2038 - val_loss: 24.6486\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 20.2073 - val_loss: 24.7111\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 20.1795 - val_loss: 24.6709\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.1131 - val_loss: 24.6107\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.1279 - val_loss: 24.6064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.1263 - val_loss: 24.5755\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 20.0319 - val_loss: 24.6252\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 20.0378 - val_loss: 24.6148\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.1085 - val_loss: 24.5932\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.9947 - val_loss: 24.5853\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.0093 - val_loss: 24.6281\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.9308 - val_loss: 24.5837\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.9596 - val_loss: 24.5835\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.9382 - val_loss: 24.6193\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.8706 - val_loss: 24.6224\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.8583 - val_loss: 24.5569\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.8527 - val_loss: 24.5129\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 19.8341 - val_loss: 24.5961\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.8042 - val_loss: 24.5105\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.7645 - val_loss: 24.5309\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.7804 - val_loss: 24.5669\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.7389 - val_loss: 24.5005\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.7418 - val_loss: 24.5572\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.7284 - val_loss: 24.5540\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.7136 - val_loss: 24.5576\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.6753 - val_loss: 24.5183\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.6533 - val_loss: 24.5623\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.6435 - val_loss: 24.5262\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 19.6715 - val_loss: 24.5164\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.5948 - val_loss: 24.5067\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.5976 - val_loss: 24.5274\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 19.74 - 0s 72us/step - loss: 19.5654 - val_loss: 24.4762\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.5670 - val_loss: 24.5541\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.5548 - val_loss: 24.5346\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.5251 - val_loss: 24.5073\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.5449 - val_loss: 24.5040\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.5254 - val_loss: 24.5108\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.5280 - val_loss: 24.4777\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.4780 - val_loss: 24.4619\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.4492 - val_loss: 24.4761\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.4656 - val_loss: 24.4685\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.4128 - val_loss: 24.5055\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.4273 - val_loss: 24.5072\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.4103 - val_loss: 24.4585\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.3809 - val_loss: 24.4803\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.3750 - val_loss: 24.4618\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.3788 - val_loss: 24.5314\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.3407 - val_loss: 24.4116\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.3287 - val_loss: 24.4433\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.3132 - val_loss: 24.4512\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 19.3195 - val_loss: 24.4306\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.2895 - val_loss: 24.4637\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.2801 - val_loss: 24.4659\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.2608 - val_loss: 24.4349\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.2635 - val_loss: 24.4206\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.2334 - val_loss: 24.4563\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.2278 - val_loss: 24.3820\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.2098 - val_loss: 24.4034\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.2059 - val_loss: 24.4077\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.1924 - val_loss: 24.4260\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.1603 - val_loss: 24.4187\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 19.1565 - val_loss: 24.4635\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.1343 - val_loss: 24.4102\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.1160 - val_loss: 24.3666\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.1338 - val_loss: 24.4328\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 19.1154 - val_loss: 24.4016\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.0962 - val_loss: 24.4137\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0739 - val_loss: 24.3751\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0939 - val_loss: 24.3787\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0609 - val_loss: 24.4009\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0495 - val_loss: 24.3523\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.0286 - val_loss: 24.4044\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.0182 - val_loss: 24.3771\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 19.0102 - val_loss: 24.3909\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9914 - val_loss: 24.3912\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.9823 - val_loss: 24.3847\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.9672 - val_loss: 24.3483\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.9452 - val_loss: 24.3711\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.9618 - val_loss: 24.3556\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9501 - val_loss: 24.3406\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.9082 - val_loss: 24.3046\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9240 - val_loss: 24.3663\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.8950 - val_loss: 24.3764\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.8994 - val_loss: 24.3111\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.8967 - val_loss: 24.3189\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.8756 - val_loss: 24.3531\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.8319 - val_loss: 24.3399\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.8433 - val_loss: 24.3001\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8330 - val_loss: 24.2955\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.7875 - val_loss: 24.2999\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.8039 - val_loss: 24.3255\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7908 - val_loss: 24.3071\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7807 - val_loss: 24.2831\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7496 - val_loss: 24.2668\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.7423 - val_loss: 24.2699\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7130 - val_loss: 24.2682\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.7224 - val_loss: 24.2565\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.7003 - val_loss: 24.2289\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7067 - val_loss: 24.2141\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.6997 - val_loss: 24.2685\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6570 - val_loss: 24.2303\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.6727 - val_loss: 24.2734\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.6323 - val_loss: 24.1963\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.6426 - val_loss: 24.2130\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.6422 - val_loss: 24.2316\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.6215 - val_loss: 24.2401\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5829 - val_loss: 24.1908\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5724 - val_loss: 24.1887\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.5799 - val_loss: 24.1716\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5746 - val_loss: 24.2149\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.5694 - val_loss: 24.1203\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.5388 - val_loss: 24.1556\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.5360 - val_loss: 24.1420\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.5012 - val_loss: 24.1695\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.5103 - val_loss: 24.1388\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.4830 - val_loss: 24.1259\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.4748 - val_loss: 24.1224\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.4675 - val_loss: 24.1532\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4538 - val_loss: 24.1040\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.4427 - val_loss: 24.0859\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.4156 - val_loss: 24.1066\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4488 - val_loss: 24.0772\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.4303 - val_loss: 24.0878\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.4195 - val_loss: 24.0862\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4070 - val_loss: 24.0745\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.3788 - val_loss: 24.0561\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.3786 - val_loss: 24.0025\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.3420 - val_loss: 24.0149\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3291 - val_loss: 24.0272\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.3362 - val_loss: 24.0747\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.3059 - val_loss: 23.9995\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.3362 - val_loss: 23.9564\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.3132 - val_loss: 23.9565\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.2871 - val_loss: 23.9712\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.2901 - val_loss: 24.0228\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.2677 - val_loss: 23.9898\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.2645 - val_loss: 23.9576\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2153 - val_loss: 23.9121\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.2163 - val_loss: 23.9160\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2152 - val_loss: 23.8937\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1985 - val_loss: 23.9042\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 18.1880 - val_loss: 23.9220\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 62us/step - loss: 18.1839 - val_loss: 23.9208\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.1854 - val_loss: 23.8837\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.1867 - val_loss: 23.8446\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.1524 - val_loss: 23.8883\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.1454 - val_loss: 23.8338\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1293 - val_loss: 23.8318\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.1274 - val_loss: 23.8715\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.1138 - val_loss: 23.8421\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1040 - val_loss: 23.7924\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0735 - val_loss: 23.8032\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0699 - val_loss: 23.7958\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0788 - val_loss: 23.7459\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0524 - val_loss: 23.7127\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0661 - val_loss: 23.7152\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0517 - val_loss: 23.7281\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0331 - val_loss: 23.6940\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0204 - val_loss: 23.7363\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.9958 - val_loss: 23.6570\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.9890 - val_loss: 23.6821\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.9766 - val_loss: 23.6419\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9596 - val_loss: 23.6532\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9561 - val_loss: 23.6575\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.9770 - val_loss: 23.7023\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.9620 - val_loss: 23.6254\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9337 - val_loss: 23.5819\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9372 - val_loss: 23.5999\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.9289 - val_loss: 23.6098\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.9151 - val_loss: 23.5592\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8887 - val_loss: 23.5892\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.8714 - val_loss: 23.5204\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.8704 - val_loss: 23.5240\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8598 - val_loss: 23.5308\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8526 - val_loss: 23.5395\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.8320 - val_loss: 23.4703\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8254 - val_loss: 23.5070\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8227 - val_loss: 23.4683\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8026 - val_loss: 23.3938\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.8194 - val_loss: 23.4439\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.8053 - val_loss: 23.4229\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.7928 - val_loss: 23.3560\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8183 - val_loss: 23.3746\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.7809 - val_loss: 23.3751\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7679 - val_loss: 23.3848\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7373 - val_loss: 23.3253\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7265 - val_loss: 23.3642\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.7204 - val_loss: 23.3312\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.7090 - val_loss: 23.3018\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7069 - val_loss: 23.3111\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.7040 - val_loss: 23.3362\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6832 - val_loss: 23.2655\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 61us/step - loss: 17.6982 - val_loss: 23.3084\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6673 - val_loss: 23.2615\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6586 - val_loss: 23.2403\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6497 - val_loss: 23.2175\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6243 - val_loss: 23.2061\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6427 - val_loss: 23.1957\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6193 - val_loss: 23.1935\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.6125 - val_loss: 23.1599\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.6051 - val_loss: 23.1556\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6034 - val_loss: 23.1716\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5741 - val_loss: 23.1515\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5761 - val_loss: 23.1132\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5440 - val_loss: 23.0959\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5626 - val_loss: 23.1181\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5616 - val_loss: 23.0873\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.5278 - val_loss: 23.0531\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.5182 - val_loss: 23.0583\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5046 - val_loss: 23.0110\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.4984 - val_loss: 23.0146\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4956 - val_loss: 23.0232\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4788 - val_loss: 23.0002\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.4780 - val_loss: 22.9437\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.4568 - val_loss: 22.9926\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4806 - val_loss: 22.9509\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.4523 - val_loss: 22.8455\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.4433 - val_loss: 22.8869\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.4309 - val_loss: 22.9013\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4219 - val_loss: 22.8921\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.4013 - val_loss: 22.8894\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.3866 - val_loss: 22.8441\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3869 - val_loss: 22.8116\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3894 - val_loss: 22.8453\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3785 - val_loss: 22.7978\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3642 - val_loss: 22.8243\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3581 - val_loss: 22.7552\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.3272 - val_loss: 22.7884\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.3476 - val_loss: 22.7371\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.3380 - val_loss: 22.7229\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.3109 - val_loss: 22.6924\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.3040 - val_loss: 22.6882\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.2959 - val_loss: 22.7080\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2781 - val_loss: 22.6986\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.2715 - val_loss: 22.6366\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.2888 - val_loss: 22.6846\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2601 - val_loss: 22.6453\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.2444 - val_loss: 22.5955\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2532 - val_loss: 22.6292\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.2243 - val_loss: 22.5669\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2167 - val_loss: 22.5518\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.2201 - val_loss: 22.5865\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1866 - val_loss: 22.5317\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.1921 - val_loss: 22.5019\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.1887 - val_loss: 22.4744\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.1670 - val_loss: 22.5165\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.1711 - val_loss: 22.4874\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.1570 - val_loss: 22.5189\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1374 - val_loss: 22.4164\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1430 - val_loss: 22.4531\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.1729 - val_loss: 22.4601\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1198 - val_loss: 22.4229\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0917 - val_loss: 22.3699\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.0871 - val_loss: 22.3713\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0948 - val_loss: 22.3705\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.0757 - val_loss: 22.3422\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.0752 - val_loss: 22.3415\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.0490 - val_loss: 22.3010\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.0696 - val_loss: 22.3112\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.0747 - val_loss: 22.2713\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.0197 - val_loss: 22.2925\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0427 - val_loss: 22.2822\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.0158 - val_loss: 22.2229\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.0124 - val_loss: 22.2327\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9892 - val_loss: 22.2596\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.9902 - val_loss: 22.1828\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9770 - val_loss: 22.1706\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.9597 - val_loss: 22.1612\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.9543 - val_loss: 22.1292\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.9465 - val_loss: 22.1482\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9362 - val_loss: 22.1130\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.9447 - val_loss: 22.0890\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.9113 - val_loss: 22.0990\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.9139 - val_loss: 22.0941\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.9182 - val_loss: 22.0471\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.9083 - val_loss: 22.0724\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.8828 - val_loss: 22.0292\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8641 - val_loss: 22.0261\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.8668 - val_loss: 22.0158\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.8553 - val_loss: 21.9925\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.8501 - val_loss: 21.9857\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8341 - val_loss: 21.9379\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.8301 - val_loss: 21.9831\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.8104 - val_loss: 21.8824\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.8036 - val_loss: 21.9111\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8070 - val_loss: 21.9075\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7861 - val_loss: 21.8813\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7761 - val_loss: 21.8503\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7804 - val_loss: 21.8808\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7876 - val_loss: 21.8357\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 16.7539 - val_loss: 21.8496\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.7424 - val_loss: 21.8282\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.7289 - val_loss: 21.7917\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.7254 - val_loss: 21.8163\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.7118 - val_loss: 21.7216\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.6938 - val_loss: 21.7538\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.6982 - val_loss: 21.7808\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.7062 - val_loss: 21.7457\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.6868 - val_loss: 21.7202\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6511 - val_loss: 21.6712\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.6509 - val_loss: 21.6322\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.6338 - val_loss: 21.6409\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6531 - val_loss: 21.6609\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.6622 - val_loss: 21.5672\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.6163 - val_loss: 21.6514\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.6012 - val_loss: 21.6250\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.6112 - val_loss: 21.6443\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5978 - val_loss: 21.5711\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5945 - val_loss: 21.5543\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.5703 - val_loss: 21.5497\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5507 - val_loss: 21.5165\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5577 - val_loss: 21.5383\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5444 - val_loss: 21.5030\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5192 - val_loss: 21.4882\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5189 - val_loss: 21.4643\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4982 - val_loss: 21.4678\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5035 - val_loss: 21.4400\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.4918 - val_loss: 21.4357\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4919 - val_loss: 21.4024\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4657 - val_loss: 21.3591\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.4552 - val_loss: 21.4032\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.4557 - val_loss: 21.3503\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4354 - val_loss: 21.3503\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4537 - val_loss: 21.3555\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.4173 - val_loss: 21.3259\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4046 - val_loss: 21.2806\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.3957 - val_loss: 21.2832\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4043 - val_loss: 21.2764\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3910 - val_loss: 21.2712\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.3815 - val_loss: 21.2162\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 16.67 - 0s 69us/step - loss: 16.3663 - val_loss: 21.2809\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.3727 - val_loss: 21.2202\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.3931 - val_loss: 21.2670\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.3359 - val_loss: 21.1726\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.3324 - val_loss: 21.1658\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.3333 - val_loss: 21.1528\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3532 - val_loss: 21.1513\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.3102 - val_loss: 21.1175\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.3073 - val_loss: 21.0682\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.2814 - val_loss: 21.1047\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.2773 - val_loss: 21.1118\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.2752 - val_loss: 21.0665\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.2403 - val_loss: 21.0477\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.2446 - val_loss: 21.0625\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2222 - val_loss: 21.0099\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2220 - val_loss: 21.0196\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2086 - val_loss: 21.0143\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2113 - val_loss: 20.9533\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1901 - val_loss: 20.9755\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1907 - val_loss: 20.9900\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.1624 - val_loss: 20.9231\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1621 - val_loss: 20.9580\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1537 - val_loss: 20.9426\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1539 - val_loss: 20.9000\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1332 - val_loss: 20.8919\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1195 - val_loss: 20.9328\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1266 - val_loss: 20.8731\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1038 - val_loss: 20.8686\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.1130 - val_loss: 20.8493\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1101 - val_loss: 20.8212\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0714 - val_loss: 20.8400\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0551 - val_loss: 20.7962\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0602 - val_loss: 20.7526\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0405 - val_loss: 20.7895\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0462 - val_loss: 20.7867\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0356 - val_loss: 20.7418\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0117 - val_loss: 20.7265\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0033 - val_loss: 20.7085\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9907 - val_loss: 20.6985\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0033 - val_loss: 20.6530\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9906 - val_loss: 20.6622\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9603 - val_loss: 20.6489\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9623 - val_loss: 20.6224\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9826 - val_loss: 20.6360\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9367 - val_loss: 20.5848\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9380 - val_loss: 20.5707\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9231 - val_loss: 20.6347\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9236 - val_loss: 20.5791\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8947 - val_loss: 20.5640\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8934 - val_loss: 20.5496\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8941 - val_loss: 20.5489\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8730 - val_loss: 20.5003\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8565 - val_loss: 20.5253\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.8643 - val_loss: 20.4863\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.8452 - val_loss: 20.4810\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8638 - val_loss: 20.4624\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8384 - val_loss: 20.3918\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8092 - val_loss: 20.4583\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.8076 - val_loss: 20.4096\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8238 - val_loss: 20.4340\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8135 - val_loss: 20.3869\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.7741 - val_loss: 20.3840\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7695 - val_loss: 20.3761\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7822 - val_loss: 20.3759\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7490 - val_loss: 20.2899\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.7382 - val_loss: 20.3477\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7223 - val_loss: 20.3199\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7214 - val_loss: 20.2960\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7262 - val_loss: 20.2438\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7042 - val_loss: 20.3017\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7383 - val_loss: 20.2494\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6763 - val_loss: 20.2933\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6776 - val_loss: 20.2504\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6581 - val_loss: 20.2124\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6570 - val_loss: 20.2249\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6474 - val_loss: 20.1987\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6520 - val_loss: 20.1681\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6313 - val_loss: 20.1488\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6584 - val_loss: 20.1191\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.6063 - val_loss: 20.1366\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.6114 - val_loss: 20.1227\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.5809 - val_loss: 20.1156\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5908 - val_loss: 20.0871\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5713 - val_loss: 20.1282\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5930 - val_loss: 20.0442\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5593 - val_loss: 20.0681\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5564 - val_loss: 20.0206\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5376 - val_loss: 20.0635\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5352 - val_loss: 19.9774\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5238 - val_loss: 20.0228\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.5176 - val_loss: 19.9535\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5153 - val_loss: 20.0107\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4986 - val_loss: 19.9916\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4856 - val_loss: 19.9833\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4828 - val_loss: 19.9422\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4647 - val_loss: 19.9313\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4696 - val_loss: 19.9593\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4434 - val_loss: 19.8447\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.4414 - val_loss: 19.8939\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4314 - val_loss: 19.8634\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4180 - val_loss: 19.8810\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4148 - val_loss: 19.8835\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4033 - val_loss: 19.8505\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.3875 - val_loss: 19.7985\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3925 - val_loss: 19.8129\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3778 - val_loss: 19.7836\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3679 - val_loss: 19.8208\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3660 - val_loss: 19.7877\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3536 - val_loss: 19.7695\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3628 - val_loss: 19.7398\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3259 - val_loss: 19.7931\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3332 - val_loss: 19.7475\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3244 - val_loss: 19.7268\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3017 - val_loss: 19.7096\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.2934 - val_loss: 19.6958\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3111 - val_loss: 19.6465\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2908 - val_loss: 19.7087\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2705 - val_loss: 19.7059\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2655 - val_loss: 19.6601\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2473 - val_loss: 19.6448\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2458 - val_loss: 19.6483\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2314 - val_loss: 19.6151\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2410 - val_loss: 19.5532\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2254 - val_loss: 19.5897\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2179 - val_loss: 19.5959\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2105 - val_loss: 19.5750\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1929 - val_loss: 19.5939\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.1849 - val_loss: 19.5392\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.1885 - val_loss: 19.5471\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1740 - val_loss: 19.5028\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1651 - val_loss: 19.5321\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1610 - val_loss: 19.4617\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.1447 - val_loss: 19.4900\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1490 - val_loss: 19.5184\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1236 - val_loss: 19.4931\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1220 - val_loss: 19.4151\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1126 - val_loss: 19.4314\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1103 - val_loss: 19.4489\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.0975 - val_loss: 19.4029\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0801 - val_loss: 19.4087\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0828 - val_loss: 19.4267\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0617 - val_loss: 19.3651\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0651 - val_loss: 19.3434\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0596 - val_loss: 19.3723\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0521 - val_loss: 19.3887\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0385 - val_loss: 19.3047\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0253 - val_loss: 19.3062\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.0179 - val_loss: 19.3148\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0126 - val_loss: 19.3088\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0170 - val_loss: 19.2931\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.9944 - val_loss: 19.2615\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9850 - val_loss: 19.2630\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9735 - val_loss: 19.2752\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9712 - val_loss: 19.2301\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9818 - val_loss: 19.2570\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9733 - val_loss: 19.2279\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9548 - val_loss: 19.1710\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9458 - val_loss: 19.2357\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9359 - val_loss: 19.1710\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9338 - val_loss: 19.1880\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9268 - val_loss: 19.1616\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.9115 - val_loss: 19.1882\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9106 - val_loss: 19.1797\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8940 - val_loss: 19.1154\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9095 - val_loss: 19.1182\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8829 - val_loss: 19.0911\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8780 - val_loss: 19.1087\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8634 - val_loss: 19.0993\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8650 - val_loss: 19.0507\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8511 - val_loss: 19.0812\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8538 - val_loss: 19.0823\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8404 - val_loss: 19.0238\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8338 - val_loss: 19.0757\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8423 - val_loss: 19.0912\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8160 - val_loss: 19.0200\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8002 - val_loss: 18.9641\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7925 - val_loss: 18.9787\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7896 - val_loss: 19.0149\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7853 - val_loss: 19.0000\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7850 - val_loss: 18.9641\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7833 - val_loss: 18.9439\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7626 - val_loss: 18.9893\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7545 - val_loss: 18.9265\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7397 - val_loss: 18.9427\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7413 - val_loss: 18.9026\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.7398 - val_loss: 18.8931\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7405 - val_loss: 18.8956\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7307 - val_loss: 18.8425\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7257 - val_loss: 18.8644\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7055 - val_loss: 18.9083\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6982 - val_loss: 18.8677\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6819 - val_loss: 18.8234\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.6915 - val_loss: 18.8281\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6856 - val_loss: 18.8250\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6681 - val_loss: 18.7974\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.6613 - val_loss: 18.8331\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.6574 - val_loss: 18.7876\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.6553 - val_loss: 18.7977\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6457 - val_loss: 18.7558\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.6243 - val_loss: 18.8012\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6271 - val_loss: 18.7804\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6160 - val_loss: 18.7476\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6059 - val_loss: 18.7668\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.6115 - val_loss: 18.7468\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6008 - val_loss: 18.6906\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5813 - val_loss: 18.7483\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5815 - val_loss: 18.7173\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.5959 - val_loss: 18.6777\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5738 - val_loss: 18.6597\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5655 - val_loss: 18.6467\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5525 - val_loss: 18.7177\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.5520 - val_loss: 18.6664\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5699 - val_loss: 18.6636\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.5489 - val_loss: 18.7087\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5371 - val_loss: 18.6275\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.5222 - val_loss: 18.6621\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.5171 - val_loss: 18.6428\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.5133 - val_loss: 18.5651\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.5183 - val_loss: 18.6402\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4997 - val_loss: 18.5703\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.5006 - val_loss: 18.6057\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.4822 - val_loss: 18.5255\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.4786 - val_loss: 18.5343\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.4724 - val_loss: 18.5014\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4639 - val_loss: 18.5319\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.4561 - val_loss: 18.5584\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4609 - val_loss: 18.5411\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.4411 - val_loss: 18.5383\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4435 - val_loss: 18.5379\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.4279 - val_loss: 18.5240\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4240 - val_loss: 18.4598\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.4349 - val_loss: 18.5452\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.4000 - val_loss: 18.4503\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4053 - val_loss: 18.4085\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4006 - val_loss: 18.4378\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.3838 - val_loss: 18.4677\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.3864 - val_loss: 18.4152\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.3797 - val_loss: 18.4236\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.3895 - val_loss: 18.3757\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3672 - val_loss: 18.4075\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.3658 - val_loss: 18.4192\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.3478 - val_loss: 18.3826\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.3504 - val_loss: 18.3735\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.3536 - val_loss: 18.3832\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.3299 - val_loss: 18.4008\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.3301 - val_loss: 18.3453\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3165 - val_loss: 18.3859\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.3097 - val_loss: 18.3283\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.3039 - val_loss: 18.3358\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.3064 - val_loss: 18.3703\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.2936 - val_loss: 18.3127\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.2963 - val_loss: 18.3348\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.2938 - val_loss: 18.2581\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.2757 - val_loss: 18.2864\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.2808 - val_loss: 18.3260\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.2675 - val_loss: 18.2833\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.2559 - val_loss: 18.2956\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 14.2705 - val_loss: 18.2469\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.2498 - val_loss: 18.2491\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.2362 - val_loss: 18.2685\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.2284 - val_loss: 18.2386\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.2382 - val_loss: 18.2766\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.2210 - val_loss: 18.2393\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.2149 - val_loss: 18.1876\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.2074 - val_loss: 18.2129\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1996 - val_loss: 18.1965\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.2058 - val_loss: 18.2241\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.2003 - val_loss: 18.2104\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.1862 - val_loss: 18.1509\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.2064 - val_loss: 18.1362\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.1723 - val_loss: 18.1922\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1755 - val_loss: 18.1822\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.1528 - val_loss: 18.1242\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.1522 - val_loss: 18.1422\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.1638 - val_loss: 18.1502\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.1410 - val_loss: 18.1062\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.1429 - val_loss: 18.0956\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.1392 - val_loss: 18.0537\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1341 - val_loss: 18.1437\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.1256 - val_loss: 18.1141\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.1284 - val_loss: 18.0871\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1196 - val_loss: 18.0611\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.1125 - val_loss: 18.0190\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.1137 - val_loss: 18.0940\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0901 - val_loss: 18.0622\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.1057 - val_loss: 18.0337\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.0781 - val_loss: 18.0378\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0680 - val_loss: 18.0301\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0711 - val_loss: 18.0493\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.0611 - val_loss: 17.9980\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.0571 - val_loss: 17.9761\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0636 - val_loss: 18.0589\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.0583 - val_loss: 17.9798\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.0471 - val_loss: 18.0367\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0419 - val_loss: 17.9653\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0321 - val_loss: 17.9851\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.0281 - val_loss: 17.9606\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.0223 - val_loss: 17.9719\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.0272 - val_loss: 17.9417\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0129 - val_loss: 17.9374\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0027 - val_loss: 17.9449\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9924 - val_loss: 17.9480\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0138 - val_loss: 17.9997\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.9757 - val_loss: 17.9453\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9897 - val_loss: 17.9561\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.9740 - val_loss: 17.9098\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.9641 - val_loss: 17.9181\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.9662 - val_loss: 17.8933\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.9512 - val_loss: 17.9221\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.9531 - val_loss: 17.8688\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.9414 - val_loss: 17.8373\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9369 - val_loss: 17.8488\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.9454 - val_loss: 17.8358\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.9405 - val_loss: 17.8885\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.9249 - val_loss: 17.8069\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.9113 - val_loss: 17.8483\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 13.9162 - val_loss: 17.8584\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9074 - val_loss: 17.8758\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.9041 - val_loss: 17.7640\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.8973 - val_loss: 17.8498\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.8891 - val_loss: 17.7804\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.8755 - val_loss: 17.8110\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.8798 - val_loss: 17.7783\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.8662 - val_loss: 17.8082\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.8649 - val_loss: 17.8077\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.8616 - val_loss: 17.7474\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.8486 - val_loss: 17.7519\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.8442 - val_loss: 17.7717\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.8396 - val_loss: 17.7513\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.8376 - val_loss: 17.7291\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.8325 - val_loss: 17.7553\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.8307 - val_loss: 17.7136\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.8226 - val_loss: 17.7251\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.8378 - val_loss: 17.7413\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.8146 - val_loss: 17.6860\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.8124 - val_loss: 17.6981\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.8021 - val_loss: 17.7212\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.7873 - val_loss: 17.6473\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7841 - val_loss: 17.6731\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.7818 - val_loss: 17.6662\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.7778 - val_loss: 17.6737\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.7762 - val_loss: 17.6438\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.7641 - val_loss: 17.6282\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7871 - val_loss: 17.6835\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7543 - val_loss: 17.5815\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.7535 - val_loss: 17.6186\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.7444 - val_loss: 17.6328\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.7594 - val_loss: 17.5580\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.7384 - val_loss: 17.6603\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.7412 - val_loss: 17.6629\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.7188 - val_loss: 17.5815\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.7173 - val_loss: 17.6036\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7082 - val_loss: 17.5756\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7104 - val_loss: 17.5805\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7006 - val_loss: 17.5872\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.7169 - val_loss: 17.6109\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6877 - val_loss: 17.5294\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.6914 - val_loss: 17.5809\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.7003 - val_loss: 17.5506\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6731 - val_loss: 17.5428\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6624 - val_loss: 17.5363\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.6715 - val_loss: 17.5064\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.6574 - val_loss: 17.5259\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.6496 - val_loss: 17.5406\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6441 - val_loss: 17.5367\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.6420 - val_loss: 17.4925\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6388 - val_loss: 17.4716\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.6344 - val_loss: 17.4692\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6272 - val_loss: 17.4983\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6222 - val_loss: 17.4852\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.6106 - val_loss: 17.4560\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6135 - val_loss: 17.4472\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.6041 - val_loss: 17.4597\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.6008 - val_loss: 17.4441\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5990 - val_loss: 17.4109\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.5955 - val_loss: 17.3993\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.5795 - val_loss: 17.4325\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.5790 - val_loss: 17.4193\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.5755 - val_loss: 17.4072\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.5715 - val_loss: 17.4028\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.5631 - val_loss: 17.3793\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.5561 - val_loss: 17.4077\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.5466 - val_loss: 17.3895\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.5451 - val_loss: 17.3578\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.5459 - val_loss: 17.4146\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5523 - val_loss: 17.3481\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.5224 - val_loss: 17.3544\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.5281 - val_loss: 17.3337\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.5209 - val_loss: 17.3425\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.5239 - val_loss: 17.3701\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.5017 - val_loss: 17.3098\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.4997 - val_loss: 17.3380\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4981 - val_loss: 17.3098\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.4922 - val_loss: 17.3370\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4869 - val_loss: 17.3404\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.4887 - val_loss: 17.2783\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.4814 - val_loss: 17.3154\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.4693 - val_loss: 17.2702\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4625 - val_loss: 17.3014\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.4547 - val_loss: 17.3034\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.4495 - val_loss: 17.2763\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.4415 - val_loss: 17.2804\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 13.4404 - val_loss: 17.2290\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.4352 - val_loss: 17.2490\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.4383 - val_loss: 17.2620\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.4202 - val_loss: 17.2312\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.4179 - val_loss: 17.2340\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.4128 - val_loss: 17.2442\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.4251 - val_loss: 17.1882\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4262 - val_loss: 17.2313\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4090 - val_loss: 17.2362\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.3940 - val_loss: 17.2087\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.3843 - val_loss: 17.1571\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.3805 - val_loss: 17.1947\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.3709 - val_loss: 17.1840\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.3676 - val_loss: 17.1554\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.3644 - val_loss: 17.1736\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.3596 - val_loss: 17.1579\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3561 - val_loss: 17.1442\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.3470 - val_loss: 17.1474\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3403 - val_loss: 17.1185\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3400 - val_loss: 17.1614\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.3328 - val_loss: 17.1595\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.3297 - val_loss: 17.1311\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.3208 - val_loss: 17.1026\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.3154 - val_loss: 17.1077\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.3125 - val_loss: 17.1079\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.3079 - val_loss: 17.0765\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.2949 - val_loss: 17.0655\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.2902 - val_loss: 17.0721\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.2896 - val_loss: 17.0363\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.2760 - val_loss: 17.0482\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.2718 - val_loss: 17.0587\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.2669 - val_loss: 17.0540\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.2722 - val_loss: 17.0997\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.2623 - val_loss: 17.0262\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.2534 - val_loss: 17.0318\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 13.2429 - val_loss: 17.0187\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2389 - val_loss: 17.0025\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.2384 - val_loss: 16.9928\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.2509 - val_loss: 17.0552\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2405 - val_loss: 16.9742\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.2321 - val_loss: 16.9905\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.2238 - val_loss: 16.9663\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.2024 - val_loss: 16.9540\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.2043 - val_loss: 16.9695\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.2055 - val_loss: 16.9831\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.49 - 0s 71us/step - loss: 13.1915 - val_loss: 16.9463\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.1844 - val_loss: 16.9523\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.1869 - val_loss: 16.9278\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1773 - val_loss: 16.9557\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1715 - val_loss: 16.9333\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.1681 - val_loss: 16.9268\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1628 - val_loss: 16.8878\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1598 - val_loss: 16.9269\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.1530 - val_loss: 16.9038\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.1457 - val_loss: 16.8898\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.1522 - val_loss: 16.8598\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.1784 - val_loss: 16.9107\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.1341 - val_loss: 16.8492\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.1171 - val_loss: 16.8798\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.1159 - val_loss: 16.8285\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.1115 - val_loss: 16.8375\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.1248 - val_loss: 16.8805\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.0992 - val_loss: 16.8048\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.0887 - val_loss: 16.8278\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.0914 - val_loss: 16.8322\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0913 - val_loss: 16.8456\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.0786 - val_loss: 16.7759\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.0719 - val_loss: 16.8089\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.0770 - val_loss: 16.7645\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.0603 - val_loss: 16.7835\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.0628 - val_loss: 16.7818\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.0564 - val_loss: 16.7641\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.0468 - val_loss: 16.7628\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.0405 - val_loss: 16.7803\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.0506 - val_loss: 16.7531\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.0377 - val_loss: 16.7397\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.0324 - val_loss: 16.7575\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.0262 - val_loss: 16.6992\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.0159 - val_loss: 16.7263\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.0056 - val_loss: 16.7315\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0124 - val_loss: 16.7060\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0059 - val_loss: 16.7387\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.9898 - val_loss: 16.6650\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.9929 - val_loss: 16.7064\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9867 - val_loss: 16.6725\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9876 - val_loss: 16.6361\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9759 - val_loss: 16.7122\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.9642 - val_loss: 16.6397\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9573 - val_loss: 16.6697\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.9694 - val_loss: 16.6351\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9449 - val_loss: 16.6681\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9519 - val_loss: 16.6336\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9437 - val_loss: 16.6018\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9604 - val_loss: 16.6711\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9215 - val_loss: 16.6061\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9282 - val_loss: 16.5988\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9108 - val_loss: 16.6147\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.9161 - val_loss: 16.5733\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.9139 - val_loss: 16.6234\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.9117 - val_loss: 16.5774\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8953 - val_loss: 16.5995\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8909 - val_loss: 16.5387\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8856 - val_loss: 16.5718\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8895 - val_loss: 16.5924\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8774 - val_loss: 16.5501\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8697 - val_loss: 16.5501\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.8647 - val_loss: 16.5378\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8565 - val_loss: 16.5075\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8560 - val_loss: 16.5175\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 60us/step - loss: 12.8471 - val_loss: 16.5177\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.8520 - val_loss: 16.4979\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.8380 - val_loss: 16.5201\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8299 - val_loss: 16.5028\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.8318 - val_loss: 16.4662\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.8262 - val_loss: 16.5143\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.8283 - val_loss: 16.4467\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.8078 - val_loss: 16.4824\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8073 - val_loss: 16.4745\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.8070 - val_loss: 16.4689\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8000 - val_loss: 16.4349\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7932 - val_loss: 16.4717\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.7887 - val_loss: 16.4341\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7817 - val_loss: 16.4313\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.7781 - val_loss: 16.4111\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7807 - val_loss: 16.4574\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.7660 - val_loss: 16.4107\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7644 - val_loss: 16.4020\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7577 - val_loss: 16.4163\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7505 - val_loss: 16.4016\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7457 - val_loss: 16.4086\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.7494 - val_loss: 16.3922\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7336 - val_loss: 16.3998\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7309 - val_loss: 16.3766\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7359 - val_loss: 16.3787\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.7282 - val_loss: 16.3684\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7175 - val_loss: 16.3547\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.7132 - val_loss: 16.3351\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7042 - val_loss: 16.3315\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7095 - val_loss: 16.3173\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7056 - val_loss: 16.3327\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.6907 - val_loss: 16.3293\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6987 - val_loss: 16.3338\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.6857 - val_loss: 16.3081\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6792 - val_loss: 16.3078\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.6893 - val_loss: 16.2918\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.6777 - val_loss: 16.2627\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.6666 - val_loss: 16.2957\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.6746 - val_loss: 16.2778\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.6627 - val_loss: 16.2783\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 12.6491 - val_loss: 16.2648\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.6516 - val_loss: 16.2624\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.6429 - val_loss: 16.2857\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.6437 - val_loss: 16.2422\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.6340 - val_loss: 16.2641\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6289 - val_loss: 16.2525\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.6211 - val_loss: 16.1906\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6328 - val_loss: 16.2404\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.6144 - val_loss: 16.2174\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.6322 - val_loss: 16.2246\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6073 - val_loss: 16.1445\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6032 - val_loss: 16.1906\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6002 - val_loss: 16.2504\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.5909 - val_loss: 16.2151\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5929 - val_loss: 16.1544\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.5976 - val_loss: 16.1510\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5819 - val_loss: 16.2203\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.5794 - val_loss: 16.1609\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.5725 - val_loss: 16.1428\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.5726 - val_loss: 16.1541\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5599 - val_loss: 16.1477\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5540 - val_loss: 16.1529\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.5497 - val_loss: 16.1408\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5466 - val_loss: 16.1243\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5433 - val_loss: 16.1456\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.5365 - val_loss: 16.1196\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5329 - val_loss: 16.1129\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.5364 - val_loss: 16.0699\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5298 - val_loss: 16.1036\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.5264 - val_loss: 16.1010\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.5130 - val_loss: 16.0925\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5116 - val_loss: 16.0948\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5092 - val_loss: 16.0812\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.4995 - val_loss: 16.0650\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4956 - val_loss: 16.0704\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 12.4988 - val_loss: 16.0838\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 12.4953 - val_loss: 16.0579\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 12.4893 - val_loss: 16.0812\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 12.4859 - val_loss: 16.0563\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.4767 - val_loss: 16.0609\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 12.4739 - val_loss: 16.0554\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.4741 - val_loss: 16.0079\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4791 - val_loss: 16.0515\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.4692 - val_loss: 16.0167\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.4598 - val_loss: 16.0022\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4550 - val_loss: 16.0246\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.4599 - val_loss: 16.0402\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4488 - val_loss: 15.9645\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4534 - val_loss: 16.0187\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4358 - val_loss: 15.9841\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4372 - val_loss: 15.9964\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4322 - val_loss: 15.9884\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.4256 - val_loss: 15.9594\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4216 - val_loss: 15.9588\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.4213 - val_loss: 15.9603\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.4120 - val_loss: 15.9448\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.4091 - val_loss: 15.9394\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4112 - val_loss: 15.9755\n",
      "12.185987656095387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.7860088 , -0.547399  , -0.18206193,  1.1447119 ,  0.5612367 ],\n",
       "        [-0.05468532, -0.7320833 , -0.04239535, -0.13386248,  0.23411496],\n",
       "        [-0.475015  , -0.46610197, -0.25590572,  0.34989074,  0.03716087],\n",
       "        [ 0.10180421,  0.09249778,  0.27593103, -0.03799843, -0.00934391],\n",
       "        [-0.22076379, -0.44906273, -0.2450681 ,  0.5002356 ,  0.33811197]],\n",
       "       dtype=float32),\n",
       " array([-0.31743318,  0.21013595,  2.018742  ,  1.8935071 ,  1.5870582 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.6810596 ,  0.19435947, -0.33184138, -0.17054054,  0.2774041 ,\n",
       "         -0.40704322,  0.24098921, -0.25961542, -0.08791018,  1.0353488 ],\n",
       "        [ 0.6882836 ,  0.10551952, -0.17652287,  0.12700604,  0.45058215,\n",
       "          0.17648332,  0.23190835, -0.90741485,  0.07853812,  0.41600972],\n",
       "        [ 1.1799165 , -0.18928814,  0.17938834, -1.5282763 ,  1.750538  ,\n",
       "         -1.3069583 ,  1.0096296 , -1.3503089 ,  1.6176054 ,  1.6447333 ],\n",
       "        [ 0.9116343 ,  0.527254  , -0.35860318, -1.0547178 ,  1.1241007 ,\n",
       "         -0.98023766,  0.8601705 , -1.4658692 ,  0.52945036,  1.1069229 ],\n",
       "        [ 0.9068894 , -0.266075  , -0.49572742, -1.230609  ,  1.1516762 ,\n",
       "         -0.46926057, -0.02215655, -1.9187624 ,  1.4290836 ,  1.6525383 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.03985   ,  0.04325986, -0.18352072, -1.741448  ,  2.3561268 ,\n",
       "        -1.1439031 ,  1.012473  , -2.6652355 ,  1.8850161 ,  2.127834  ],\n",
       "       dtype=float32),\n",
       " array([[ 2.7918203 ],\n",
       "        [ 0.04191726],\n",
       "        [-0.42659447],\n",
       "        [-2.7540169 ],\n",
       "        [ 3.360133  ],\n",
       "        [-1.9302664 ],\n",
       "        [ 1.4957772 ],\n",
       "        [-3.8681688 ],\n",
       "        [ 2.799971  ],\n",
       "        [ 3.4460864 ]], dtype=float32),\n",
       " array([2.2422845], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, sgd, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sgd_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 182us/step - loss: 14663.1765 - val_loss: 12905.7444\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9945.0032 - val_loss: 6434.0812\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3547.6847 - val_loss: 1181.2273\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 354.2881 - val_loss: 31.2358\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.2849 - val_loss: 26.1965\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 24.4869 - val_loss: 26.5246\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8675 - val_loss: 28.4189\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.6475 - val_loss: 29.6829\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.6866 - val_loss: 29.5449\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.1139 - val_loss: 39.1543\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.0082 - val_loss: 26.3469\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.9979 - val_loss: 27.7527\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.5721 - val_loss: 26.3591\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.6799 - val_loss: 25.8711\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.9383 - val_loss: 30.1274\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.5300 - val_loss: 26.9347\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.5833 - val_loss: 26.8168\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.5677 - val_loss: 31.6558\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.4030 - val_loss: 34.2903\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 24.3904 - val_loss: 27.4777\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1801 - val_loss: 29.0317\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.8988 - val_loss: 29.6997\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.0651 - val_loss: 28.8682\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7724 - val_loss: 33.1476\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3642 - val_loss: 25.4294\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.9826 - val_loss: 29.5780\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.2882 - val_loss: 25.8695\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6233 - val_loss: 26.4110\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.3121 - val_loss: 26.4017\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.6288 - val_loss: 26.1638\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.4773 - val_loss: 27.4043\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.8797 - val_loss: 27.3331\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.8973 - val_loss: 25.8304\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.9333 - val_loss: 31.9715\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.7662 - val_loss: 25.3057\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.0626 - val_loss: 27.7776\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.7999 - val_loss: 30.1125\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.7148 - val_loss: 25.4942\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 24.5587 - val_loss: 25.6428\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4058 - val_loss: 25.8683\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0770 - val_loss: 25.8352\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 24.0957 - val_loss: 25.8519\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5953 - val_loss: 26.6433\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.3821 - val_loss: 25.7335\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.4433 - val_loss: 27.1601\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8668 - val_loss: 27.4645\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.4023 - val_loss: 26.8425\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.9818 - val_loss: 28.4522\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7355 - val_loss: 27.6832\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.8085 - val_loss: 30.6712\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.9836 - val_loss: 25.7838\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 23.8055 - val_loss: 26.3039\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.6153 - val_loss: 25.8076\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2275 - val_loss: 27.4821\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.5828 - val_loss: 27.2713\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 24.2968 - val_loss: 25.8948\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.0539 - val_loss: 28.6784\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7972 - val_loss: 27.4490\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.0999 - val_loss: 25.9928\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.8633 - val_loss: 30.0961\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.9435 - val_loss: 26.5005\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.0608 - val_loss: 26.6101\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7879 - val_loss: 29.6185\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 23.3610 - val_loss: 27.5101\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.7050 - val_loss: 27.0225\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.6438 - val_loss: 26.2505\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 24.1487 - val_loss: 26.8067\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.7696 - val_loss: 27.3871\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5703 - val_loss: 26.9707\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1304 - val_loss: 28.9144\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.0529 - val_loss: 29.0377\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.5308 - val_loss: 25.6649\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8632 - val_loss: 27.0498\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.9534 - val_loss: 25.3903\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.4602 - val_loss: 26.3573\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2888 - val_loss: 26.9856\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.5594 - val_loss: 25.9199\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.3896 - val_loss: 28.1855\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.7031 - val_loss: 25.7665\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.7884 - val_loss: 25.7387\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.7113 - val_loss: 28.1366\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0646 - val_loss: 29.0818\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.9037 - val_loss: 25.7501\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2788 - val_loss: 26.1593\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.7308 - val_loss: 27.4960\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.4245 - val_loss: 27.4585\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.8830 - val_loss: 25.8578\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.2993 - val_loss: 26.4450\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.9691 - val_loss: 26.0188\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.6124 - val_loss: 32.0228\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.0266 - val_loss: 26.2390\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.9892 - val_loss: 25.5299\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.5180 - val_loss: 25.5882\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.8135 - val_loss: 28.7066\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.7517 - val_loss: 25.2104\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.0279 - val_loss: 25.7339\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.5022 - val_loss: 27.0107\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.8198 - val_loss: 25.8557\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.5846 - val_loss: 27.1397\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.6130 - val_loss: 30.0571\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.4966 - val_loss: 25.8695\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.5029 - val_loss: 26.6438\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.6464 - val_loss: 25.7187\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 22.5972 - val_loss: 25.4385\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.6818 - val_loss: 25.8425\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 22.0972 - val_loss: 24.6659\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.6650 - val_loss: 25.5641\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.5963 - val_loss: 24.4446\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.6656 - val_loss: 24.9613\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.6911 - val_loss: 25.2141\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.8507 - val_loss: 24.7468\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.4159 - val_loss: 25.1143\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.2423 - val_loss: 30.0297\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.3224 - val_loss: 29.4760\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.0397 - val_loss: 27.0401\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.7024 - val_loss: 24.1363\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.8780 - val_loss: 24.3623\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 20.6092 - val_loss: 26.1439\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 20.2365 - val_loss: 24.9083\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.1365 - val_loss: 24.0119\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 19.6922 - val_loss: 23.2513\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.7192 - val_loss: 23.2284\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 19.0143 - val_loss: 24.8814\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.2371 - val_loss: 21.8671\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.4147 - val_loss: 27.0544\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.5378 - val_loss: 23.0289\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.6935 - val_loss: 21.7299\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.8556 - val_loss: 22.7634\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.0055 - val_loss: 30.5678\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.1719 - val_loss: 22.2286\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.0841 - val_loss: 19.8471\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.0603 - val_loss: 21.1128\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6088 - val_loss: 19.4472\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.8916 - val_loss: 19.5919\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.6616 - val_loss: 22.4705\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6457 - val_loss: 19.7103\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.0347 - val_loss: 19.4219\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.4661 - val_loss: 19.5835\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.7900 - val_loss: 18.6285\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.2053 - val_loss: 19.0281\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.3819 - val_loss: 19.4597\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.5034 - val_loss: 18.8728\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.2101 - val_loss: 18.4343\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.9409 - val_loss: 19.1442\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.9463 - val_loss: 18.6446\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.8088 - val_loss: 17.9835\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.9286 - val_loss: 18.7600\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.5490 - val_loss: 22.6085\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.5144 - val_loss: 20.3677\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.8780 - val_loss: 18.1309\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.2314 - val_loss: 21.2928\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.0008 - val_loss: 17.3791\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1623 - val_loss: 20.5880\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.9807 - val_loss: 17.5510\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.3356 - val_loss: 18.0684\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.2006 - val_loss: 17.5403\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.0263 - val_loss: 19.6321\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.7550 - val_loss: 18.7528\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.0589 - val_loss: 18.7881\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.9669 - val_loss: 17.6921\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.3432 - val_loss: 20.8490\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.8695 - val_loss: 17.0677\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.6444 - val_loss: 17.2909\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1209 - val_loss: 18.3576\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.8511 - val_loss: 17.6779\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.0253 - val_loss: 20.3369\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.7066 - val_loss: 17.8366\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.4835 - val_loss: 17.9349\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.9757 - val_loss: 18.1661\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.9742 - val_loss: 19.0578\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.6959 - val_loss: 16.7517\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.6506 - val_loss: 19.5988\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3468 - val_loss: 17.0487\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5027 - val_loss: 17.9627\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.0041 - val_loss: 18.9997\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.8844 - val_loss: 22.4000\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.3661 - val_loss: 17.7471\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.5292 - val_loss: 19.2421\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.4141 - val_loss: 18.2515\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.8118 - val_loss: 21.3893\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.4942 - val_loss: 17.9020\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.4000 - val_loss: 16.4145\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.3766 - val_loss: 16.6521\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.4326 - val_loss: 18.2405\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.7647 - val_loss: 17.7232\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9824 - val_loss: 19.5031\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.9471 - val_loss: 17.0597\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.9737 - val_loss: 16.8839\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7471 - val_loss: 17.2150\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.5280 - val_loss: 17.2057\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.0387 - val_loss: 16.5617\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.9221 - val_loss: 17.1403\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.7317 - val_loss: 17.3941\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.9388 - val_loss: 18.0333\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.2533 - val_loss: 19.8177\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.8497 - val_loss: 18.4901\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1555 - val_loss: 16.9045\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4175 - val_loss: 20.6148\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.8287 - val_loss: 16.1917\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4907 - val_loss: 17.0663\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4186 - val_loss: 17.0569\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2660 - val_loss: 18.0759\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.4834 - val_loss: 16.8895\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4800 - val_loss: 16.2764\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.6894 - val_loss: 18.9718\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9517 - val_loss: 17.8493\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 14.0777 - val_loss: 28.0149\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1185 - val_loss: 16.5540\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.1509 - val_loss: 16.7082\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.3441 - val_loss: 20.5040\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.5372 - val_loss: 17.1019\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.2156 - val_loss: 17.2005\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5099 - val_loss: 15.9708\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.3549 - val_loss: 16.6945\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.9327 - val_loss: 26.6736\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.3401 - val_loss: 17.4769\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9647 - val_loss: 16.4738\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.5671 - val_loss: 15.4198\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3700 - val_loss: 24.6590\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.8314 - val_loss: 16.5588\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9549 - val_loss: 16.8776\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.9094 - val_loss: 16.6132\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.1719 - val_loss: 16.5368\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.5706 - val_loss: 15.7942\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.7159 - val_loss: 15.5028\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.3777 - val_loss: 17.1571\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.2762 - val_loss: 15.4305\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.0375 - val_loss: 18.1733\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.4226 - val_loss: 17.0271\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.9400 - val_loss: 17.3074\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.7113 - val_loss: 19.7087\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.5957 - val_loss: 16.2346\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.6793 - val_loss: 17.0708\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.5536 - val_loss: 20.5502\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.5854 - val_loss: 15.8512\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.8844 - val_loss: 16.6762\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3640 - val_loss: 15.1265\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.9583 - val_loss: 16.8627\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.9844 - val_loss: 14.6240\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.7120 - val_loss: 15.8408\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.2844 - val_loss: 20.0942\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.1814 - val_loss: 15.3336\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.5164 - val_loss: 16.0223\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.0274 - val_loss: 14.8277\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.5550 - val_loss: 16.3838\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.1365 - val_loss: 15.9076\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.6719 - val_loss: 14.7002\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.8249 - val_loss: 14.9815\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.7237 - val_loss: 18.0726\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.0568 - val_loss: 14.7986\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.8419 - val_loss: 16.7106\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.1160 - val_loss: 15.1632\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.4228 - val_loss: 14.0100\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.0054 - val_loss: 13.9018\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.7219 - val_loss: 15.6850\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.8104 - val_loss: 18.8649\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.3277 - val_loss: 15.5843\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.6173 - val_loss: 19.2475\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.5424 - val_loss: 18.5482\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.2784 - val_loss: 14.4025\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.7697 - val_loss: 16.1805\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.0590 - val_loss: 16.5830\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.3310 - val_loss: 15.4209\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9485 - val_loss: 17.4108\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.4417 - val_loss: 14.3342\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.5809 - val_loss: 14.4741\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.6528 - val_loss: 18.6983\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.4749 - val_loss: 15.4703\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.0991 - val_loss: 15.1815\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.6019 - val_loss: 13.8381\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.2309 - val_loss: 16.6499\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.3635 - val_loss: 15.6271\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.5811 - val_loss: 14.3260\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1835 - val_loss: 17.2546\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.8679 - val_loss: 15.0501\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.4656 - val_loss: 15.1156\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.8677 - val_loss: 14.0307\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.5128 - val_loss: 14.7003\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9738 - val_loss: 15.6079\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.1179 - val_loss: 19.3777\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.4637 - val_loss: 13.7293\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.1364 - val_loss: 12.9767\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.1438 - val_loss: 16.7045\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.0853 - val_loss: 15.0232\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.5260 - val_loss: 18.7927\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.2451 - val_loss: 16.6967\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.7207 - val_loss: 15.2392\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.1520 - val_loss: 14.9981\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.5430 - val_loss: 13.3480\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.0147 - val_loss: 18.9314\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.7142 - val_loss: 14.1134\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.3747 - val_loss: 13.1504\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.8700 - val_loss: 13.4301\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5397 - val_loss: 12.8531\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.2153 - val_loss: 14.2406\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.6471 - val_loss: 16.9928\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6147 - val_loss: 13.8726\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9792 - val_loss: 13.6197\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.7587 - val_loss: 19.0031\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.7579 - val_loss: 14.2481\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.3067 - val_loss: 13.6512\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.8915 - val_loss: 13.7362\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.3328 - val_loss: 16.4692\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.0889 - val_loss: 13.7571\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.1980 - val_loss: 14.9461\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.5355 - val_loss: 12.9922\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4022 - val_loss: 17.5381\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.4945 - val_loss: 13.6701\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.0999 - val_loss: 14.8504\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6032 - val_loss: 15.7345\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6063 - val_loss: 15.1606\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1229 - val_loss: 14.5806\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4772 - val_loss: 14.2504\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9669 - val_loss: 16.0446\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9981 - val_loss: 12.6330\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2697 - val_loss: 19.4322\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.0171 - val_loss: 13.2315\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.8825 - val_loss: 13.0951\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4926 - val_loss: 16.1756\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4724 - val_loss: 17.2506\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8170 - val_loss: 15.9538\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.9246 - val_loss: 15.1071\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.7005 - val_loss: 15.6989\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.5675 - val_loss: 16.4706\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9192 - val_loss: 15.2639\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6260 - val_loss: 13.4531\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6895 - val_loss: 14.3412\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.8661 - val_loss: 15.0770\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6832 - val_loss: 12.3889\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.6542 - val_loss: 15.4057\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6975 - val_loss: 15.3940\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5671 - val_loss: 13.8298\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8344 - val_loss: 12.8013\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0817 - val_loss: 14.7740\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.7849 - val_loss: 17.6863\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9210 - val_loss: 17.0516\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.7393 - val_loss: 17.2771\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.7675 - val_loss: 13.4578\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.9326 - val_loss: 12.3851\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.6017 - val_loss: 15.4295\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.0227 - val_loss: 13.2222\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.3628 - val_loss: 14.0037\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.5294 - val_loss: 13.0281\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9384 - val_loss: 11.8496\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.9993 - val_loss: 17.1587\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.6422 - val_loss: 15.0645\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.6740 - val_loss: 13.7055\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9579 - val_loss: 20.1376\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.7672 - val_loss: 14.3622\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3987 - val_loss: 15.3276\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6191 - val_loss: 19.0617\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4444 - val_loss: 14.3717\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.7943 - val_loss: 13.8507\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5231 - val_loss: 14.2540\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6455 - val_loss: 12.7108\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.7702 - val_loss: 13.3575\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.6073 - val_loss: 15.7969\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.8969 - val_loss: 14.3525\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0890 - val_loss: 13.6064\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.6162 - val_loss: 12.3518\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.2120 - val_loss: 16.4245\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8038 - val_loss: 12.0934\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.8530 - val_loss: 12.7738\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.1972 - val_loss: 12.9070\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.1396 - val_loss: 12.9887\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.0459 - val_loss: 11.8384\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2194 - val_loss: 13.1359\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4085 - val_loss: 14.2614\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.1815 - val_loss: 14.5473\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5627 - val_loss: 20.9603\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.5549 - val_loss: 13.3350\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2374 - val_loss: 11.8519\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.6000 - val_loss: 16.1214\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8994 - val_loss: 16.5070\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.9136 - val_loss: 12.9756\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9846 - val_loss: 12.0089\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5048 - val_loss: 12.6094\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.0569 - val_loss: 13.3724\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3898 - val_loss: 13.8269\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.0755 - val_loss: 14.2747\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9080 - val_loss: 16.8156\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.7312 - val_loss: 18.3308\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.2189 - val_loss: 15.2710\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.5889 - val_loss: 12.8781\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.2025 - val_loss: 13.2074\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5465 - val_loss: 21.0283\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3669 - val_loss: 13.1952\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0812 - val_loss: 13.1094\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3443 - val_loss: 19.2851\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.3093 - val_loss: 13.4977\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3917 - val_loss: 12.4182\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.1388 - val_loss: 13.5535\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.3378 - val_loss: 14.7688\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4630 - val_loss: 12.1827\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5518 - val_loss: 18.5647\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5734 - val_loss: 15.5311\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0668 - val_loss: 13.0816\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.6582 - val_loss: 12.8538\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.7161 - val_loss: 12.9448\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4897 - val_loss: 15.6013\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.1318 - val_loss: 12.2623\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.1080 - val_loss: 13.3325\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.6398 - val_loss: 12.1273\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5567 - val_loss: 15.8380\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.5977 - val_loss: 13.2575\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3475 - val_loss: 14.0907\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5920 - val_loss: 15.2093\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3664 - val_loss: 11.7688\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4247 - val_loss: 17.4693\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.5659 - val_loss: 13.3160\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4786 - val_loss: 12.9612\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.3168 - val_loss: 14.2237\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.1117 - val_loss: 13.1845\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.2361 - val_loss: 13.2928\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.4955 - val_loss: 11.7646\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.2718 - val_loss: 17.3122\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3592 - val_loss: 12.3003\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.6683 - val_loss: 12.3776\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0497 - val_loss: 12.4183\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9177 - val_loss: 15.2591\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.0734 - val_loss: 15.5300\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0785 - val_loss: 13.7600\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2245 - val_loss: 13.0708\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.1650 - val_loss: 13.5372\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.8881 - val_loss: 12.7296\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.2970 - val_loss: 17.4328\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0488 - val_loss: 11.9547\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.1462 - val_loss: 12.7411\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.6673 - val_loss: 13.1957\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.2953 - val_loss: 17.2726\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.8809 - val_loss: 14.8439\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2298 - val_loss: 14.5381\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.0361 - val_loss: 14.0879\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.9625 - val_loss: 11.5949\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.2298 - val_loss: 17.5085\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.8860 - val_loss: 11.7985\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.8881 - val_loss: 12.9256\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.7800 - val_loss: 12.5904\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2669 - val_loss: 12.2398\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.6837 - val_loss: 11.5513\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8655 - val_loss: 12.3640\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.1326 - val_loss: 21.6336\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8505 - val_loss: 12.8853\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.5690 - val_loss: 14.4811\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.0628 - val_loss: 12.5084\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.7786 - val_loss: 12.0006\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.8567 - val_loss: 11.3681\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.7992 - val_loss: 14.1023\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.7085 - val_loss: 13.5941\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.9197 - val_loss: 12.1283\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.9535 - val_loss: 12.3308\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3807 - val_loss: 13.5035\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8223 - val_loss: 13.1669\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.9463 - val_loss: 11.5260\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.7489 - val_loss: 11.2605\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.5625 - val_loss: 12.2540\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.8771 - val_loss: 12.2987\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5473 - val_loss: 13.8371\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.9797 - val_loss: 13.0405\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0789 - val_loss: 13.2331\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.7243 - val_loss: 11.8292\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.8394 - val_loss: 11.4586\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.9937 - val_loss: 11.9340\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.0704 - val_loss: 16.5161\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.7251 - val_loss: 14.0305\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4520 - val_loss: 12.0703\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.3901 - val_loss: 12.0535\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.1676 - val_loss: 16.9168\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.2868 - val_loss: 11.3653\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.6107 - val_loss: 12.5123\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.7386 - val_loss: 12.2650\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3971 - val_loss: 10.8217\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.2646 - val_loss: 11.5747\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.2734 - val_loss: 12.1805\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.2115 - val_loss: 11.5089\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.4946 - val_loss: 16.9736\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8669 - val_loss: 12.2763\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6225 - val_loss: 11.7487\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.1829 - val_loss: 13.8122\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.4428 - val_loss: 15.3422\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2534 - val_loss: 11.3610\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4313 - val_loss: 13.6382\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4519 - val_loss: 11.8369\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2865 - val_loss: 11.2840\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.2777 - val_loss: 11.8109\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2992 - val_loss: 12.6444\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.1750 - val_loss: 12.8870\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1803 - val_loss: 14.4585\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6358 - val_loss: 13.6023\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.4232 - val_loss: 16.0198\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.5340 - val_loss: 11.5963\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7153 - val_loss: 11.9662\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2114 - val_loss: 12.2422\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9689 - val_loss: 11.4431\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9100 - val_loss: 13.3514\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.4280 - val_loss: 11.9837\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.1274 - val_loss: 11.2385\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7822 - val_loss: 11.2163\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6312 - val_loss: 13.7471\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8070 - val_loss: 11.8079\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6717 - val_loss: 10.7535\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5752 - val_loss: 12.3927\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1130 - val_loss: 11.5204\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8364 - val_loss: 10.7412\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8886 - val_loss: 11.6641\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6168 - val_loss: 16.1571\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9041 - val_loss: 10.8232\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5730 - val_loss: 11.7800\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3425 - val_loss: 18.6522\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9062 - val_loss: 10.3839\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4570 - val_loss: 12.5576\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0196 - val_loss: 10.5898\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4516 - val_loss: 11.5402\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6459 - val_loss: 10.6405\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2939 - val_loss: 10.2923\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5454 - val_loss: 13.1098\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6722 - val_loss: 11.3457\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5294 - val_loss: 12.1064\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6485 - val_loss: 12.7865\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4909 - val_loss: 11.0323\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5761 - val_loss: 13.0791\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8940 - val_loss: 10.5820\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4402 - val_loss: 17.0708\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8117 - val_loss: 10.7540\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2044 - val_loss: 9.9134\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4894 - val_loss: 10.7774\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1316 - val_loss: 10.8062\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6074 - val_loss: 12.5360\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0655 - val_loss: 19.5505\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0170 - val_loss: 11.6493\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9498 - val_loss: 10.6047\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2775 - val_loss: 10.4852\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1428 - val_loss: 11.4407\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6966 - val_loss: 10.8979\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1524 - val_loss: 15.5941\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.7886 - val_loss: 13.5927\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3736 - val_loss: 10.5442\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3913 - val_loss: 10.2756\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3321 - val_loss: 14.4817\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6408 - val_loss: 13.1491\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2902 - val_loss: 10.5985\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2158 - val_loss: 11.3866\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4865 - val_loss: 10.9181\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.4168 - val_loss: 9.8937\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6609 - val_loss: 11.6870\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0918 - val_loss: 12.2295\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5300 - val_loss: 10.4832\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3296 - val_loss: 10.3908\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3311 - val_loss: 11.9454\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5919 - val_loss: 12.2841\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1031 - val_loss: 10.4815\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7830 - val_loss: 10.8526\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3934 - val_loss: 13.9183\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4836 - val_loss: 9.9667\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9181 - val_loss: 10.3479\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0712 - val_loss: 9.7584\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0606 - val_loss: 11.2597\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6212 - val_loss: 10.5948\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9481 - val_loss: 11.7725\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7443 - val_loss: 11.0913\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1148 - val_loss: 10.6221\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2433 - val_loss: 10.3196\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1282 - val_loss: 11.0637\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5540 - val_loss: 13.5649\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3551 - val_loss: 12.3225\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4600 - val_loss: 10.1369\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1842 - val_loss: 11.1044\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6563 - val_loss: 10.4023\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8932 - val_loss: 11.6448\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2962 - val_loss: 9.9349\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6066 - val_loss: 13.3649\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5688 - val_loss: 12.1525\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3238 - val_loss: 9.8094\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4984 - val_loss: 10.2418\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5791 - val_loss: 10.5432\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2507 - val_loss: 10.0490\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9387 - val_loss: 10.9957\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3551 - val_loss: 11.5529\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2689 - val_loss: 10.2792\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6241 - val_loss: 10.7027\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7470 - val_loss: 11.2682\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8916 - val_loss: 9.6501\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1632 - val_loss: 9.9701\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9286 - val_loss: 10.5926\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1656 - val_loss: 13.3600\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5432 - val_loss: 9.5477\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2604 - val_loss: 11.7494\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6126 - val_loss: 9.7714\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1605 - val_loss: 9.8042\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0583 - val_loss: 11.7021\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3514 - val_loss: 9.8313\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4212 - val_loss: 9.9140\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5063 - val_loss: 10.2085\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0720 - val_loss: 10.7605\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1904 - val_loss: 10.8077\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0549 - val_loss: 19.9481\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2734 - val_loss: 9.8869\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4499 - val_loss: 12.5558\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2538 - val_loss: 10.3755\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3258 - val_loss: 9.5563\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4626 - val_loss: 9.4562\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4766 - val_loss: 11.4941\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 9.1289 - val_loss: 13.5660\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2656 - val_loss: 10.6995\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0111 - val_loss: 9.9862\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2897 - val_loss: 11.8393\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8906 - val_loss: 9.8244\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2520 - val_loss: 9.9618\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2232 - val_loss: 12.7545\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0660 - val_loss: 11.0097\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2589 - val_loss: 9.9399\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2720 - val_loss: 11.4006\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9971 - val_loss: 11.3046\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4009 - val_loss: 10.5701\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2903 - val_loss: 12.9156\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1606 - val_loss: 10.3407\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1270 - val_loss: 11.9472\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5261 - val_loss: 11.8452\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5353 - val_loss: 9.5228\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1923 - val_loss: 10.7180\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3043 - val_loss: 13.2245\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9328 - val_loss: 9.9177\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5308 - val_loss: 9.6713\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9454 - val_loss: 10.9653\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0606 - val_loss: 12.3864\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3613 - val_loss: 10.7854\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.4173 - val_loss: 10.9423\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3193 - val_loss: 9.8554\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1856 - val_loss: 9.8454\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1324 - val_loss: 10.1888\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1837 - val_loss: 9.6763\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2119 - val_loss: 11.2809\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8834 - val_loss: 16.0429\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4873 - val_loss: 9.4853\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2368 - val_loss: 9.7420\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9858 - val_loss: 12.7086\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2413 - val_loss: 10.8315\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6893 - val_loss: 9.6489\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2485 - val_loss: 11.0416\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8387 - val_loss: 12.2100\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1409 - val_loss: 9.8004\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2417 - val_loss: 9.8739\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0332 - val_loss: 9.9493\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1334 - val_loss: 10.1345\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0459 - val_loss: 14.8268\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9252 - val_loss: 10.8081\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5212 - val_loss: 10.7277\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2274 - val_loss: 9.6548\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2338 - val_loss: 9.9670\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3540 - val_loss: 12.1140\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9859 - val_loss: 9.6116\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0938 - val_loss: 13.6452\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5355 - val_loss: 10.7335\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2171 - val_loss: 10.7474\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1753 - val_loss: 10.5878\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6246 - val_loss: 9.9194\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6981 - val_loss: 12.4130\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5067 - val_loss: 9.8179\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3387 - val_loss: 10.6045\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8304 - val_loss: 11.4054\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4660 - val_loss: 10.2792\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7739 - val_loss: 20.5091\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2612 - val_loss: 10.0085\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4225 - val_loss: 11.0374\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3346 - val_loss: 20.2328\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7352 - val_loss: 9.8289\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8840 - val_loss: 13.6413\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3713 - val_loss: 10.3956\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1416 - val_loss: 9.7214\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1778 - val_loss: 16.6642\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1807 - val_loss: 10.9594\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2646 - val_loss: 9.9200\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3555 - val_loss: 11.4511\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1398 - val_loss: 13.6197\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0065 - val_loss: 10.8912\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4204 - val_loss: 9.7382\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6896 - val_loss: 10.8754\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0145 - val_loss: 14.0385\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4091 - val_loss: 10.0786\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0834 - val_loss: 10.8200\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.0563 - val_loss: 12.3705\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0289 - val_loss: 9.7467\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5306 - val_loss: 9.9865\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3547 - val_loss: 9.7388\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6895 - val_loss: 14.8228\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7669 - val_loss: 9.4958\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8654 - val_loss: 9.6218\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2475 - val_loss: 9.4597\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9037 - val_loss: 9.9364\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1069 - val_loss: 9.9283\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2769 - val_loss: 15.0259\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1243 - val_loss: 14.2148\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8422 - val_loss: 11.4473\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1127 - val_loss: 10.3968\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3562 - val_loss: 9.5088\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2950 - val_loss: 9.7777\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5488 - val_loss: 9.9623\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7994 - val_loss: 9.6197\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5053 - val_loss: 11.6449\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8845 - val_loss: 11.9164\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3905 - val_loss: 10.1164\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3433 - val_loss: 12.4689\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1396 - val_loss: 12.5930\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0850 - val_loss: 10.2545\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3864 - val_loss: 9.9670\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3803 - val_loss: 10.0231\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0766 - val_loss: 10.8715\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3570 - val_loss: 9.8279\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8805 - val_loss: 9.6527\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3473 - val_loss: 11.9093\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0071 - val_loss: 11.2313\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3489 - val_loss: 9.6504\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1606 - val_loss: 16.7204\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3308 - val_loss: 9.9728\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2935 - val_loss: 9.8695\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.7202 - val_loss: 15.2714\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7381 - val_loss: 10.6640\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0301 - val_loss: 10.0804\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2781 - val_loss: 11.8146\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7384 - val_loss: 10.8922\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4427 - val_loss: 11.1535\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3501 - val_loss: 9.4944\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0046 - val_loss: 9.3190\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9256 - val_loss: 9.6177\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4989 - val_loss: 9.4901\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2702 - val_loss: 13.6484\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1781 - val_loss: 9.9868\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1116 - val_loss: 10.1070\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4045 - val_loss: 10.1058\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0875 - val_loss: 11.1941\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0550 - val_loss: 11.0055\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9191 - val_loss: 9.7198\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1394 - val_loss: 9.4473\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2295 - val_loss: 12.7194\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7821 - val_loss: 10.1911\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3786 - val_loss: 10.0564\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 8.6934 - val_loss: 10.9634\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2417 - val_loss: 10.1711\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7404 - val_loss: 9.9022\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6234 - val_loss: 11.4491\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1453 - val_loss: 9.7295\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8764 - val_loss: 10.9308\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1746 - val_loss: 14.2050\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3705 - val_loss: 10.8597\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6751 - val_loss: 9.3545\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6299 - val_loss: 11.8947\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2250 - val_loss: 13.2207\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1041 - val_loss: 9.8892\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9999 - val_loss: 10.3578\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2955 - val_loss: 12.4673\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9030 - val_loss: 9.7086\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4933 - val_loss: 10.0292\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1707 - val_loss: 9.7463\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2284 - val_loss: 9.7695\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0072 - val_loss: 9.5334\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2216 - val_loss: 9.6218\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8284 - val_loss: 9.6610\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0156 - val_loss: 10.1159\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1865 - val_loss: 9.8902\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1353 - val_loss: 13.2986\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9698 - val_loss: 10.1666\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0161 - val_loss: 13.6602\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0117 - val_loss: 9.6592\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8091 - val_loss: 10.1205\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5775 - val_loss: 9.6202\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8211 - val_loss: 10.1564\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0116 - val_loss: 11.9963\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0839 - val_loss: 9.4824\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9988 - val_loss: 12.3839\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2078 - val_loss: 9.7850\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3673 - val_loss: 9.5975\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1684 - val_loss: 9.7209\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.6180 - val_loss: 10.5456\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0727 - val_loss: 9.8916\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3949 - val_loss: 9.4390\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1373 - val_loss: 10.1774\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8370 - val_loss: 9.3376\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6495 - val_loss: 9.3086\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 8.7665 - val_loss: 12.9547\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0962 - val_loss: 14.6161\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4366 - val_loss: 9.9612\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2356 - val_loss: 10.8394\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2473 - val_loss: 10.7310\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9497 - val_loss: 9.8160\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1866 - val_loss: 10.3634\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0130 - val_loss: 10.0092\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3057 - val_loss: 9.5323\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0145 - val_loss: 9.5150\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1973 - val_loss: 9.8386\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2177 - val_loss: 9.7610\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8681 - val_loss: 10.6233\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3149 - val_loss: 10.6439\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3075 - val_loss: 9.7556\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2451 - val_loss: 10.2914\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0921 - val_loss: 9.6560\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0878 - val_loss: 10.2591\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3852 - val_loss: 9.5348\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8804 - val_loss: 9.7452\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6819 - val_loss: 9.5072\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6305 - val_loss: 11.5649\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1067 - val_loss: 9.5694\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2419 - val_loss: 11.1886\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5720 - val_loss: 10.4812\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5384 - val_loss: 9.7742\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8800 - val_loss: 9.7887\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9254 - val_loss: 11.9496\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0695 - val_loss: 11.2949\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8029 - val_loss: 13.1012\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3042 - val_loss: 9.6184\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8833 - val_loss: 10.5774\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.6809 - val_loss: 11.5182\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2559 - val_loss: 12.1075\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1509 - val_loss: 11.7025\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1148 - val_loss: 9.8224\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9848 - val_loss: 9.3112\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9331 - val_loss: 9.7692\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0543 - val_loss: 10.0735\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9616 - val_loss: 10.2793\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3087 - val_loss: 11.5235\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0037 - val_loss: 9.4298\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3767 - val_loss: 9.7620\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1103 - val_loss: 10.3335\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4060 - val_loss: 9.5248\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2683 - val_loss: 11.5620\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6277 - val_loss: 10.4773\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0179 - val_loss: 11.3303\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3852 - val_loss: 10.4122\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1907 - val_loss: 9.7339\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8974 - val_loss: 11.6256\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3617 - val_loss: 9.6753\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0520 - val_loss: 9.4844\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1621 - val_loss: 11.1018\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1424 - val_loss: 9.4296\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2526 - val_loss: 12.1859\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3959 - val_loss: 12.2398\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8897 - val_loss: 13.1048\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1354 - val_loss: 9.6566\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1213 - val_loss: 11.9877\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9956 - val_loss: 11.2540\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3842 - val_loss: 9.4758\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9602 - val_loss: 11.1254\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4858 - val_loss: 9.9069\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0685 - val_loss: 11.0000\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2385 - val_loss: 9.5980\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3117 - val_loss: 11.2778\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9113 - val_loss: 10.5797\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4164 - val_loss: 10.6715\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1778 - val_loss: 9.4711\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9238 - val_loss: 10.3644\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0818 - val_loss: 11.4406\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9863 - val_loss: 15.9681\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2884 - val_loss: 12.1961\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3945 - val_loss: 9.2391\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5958 - val_loss: 12.4326\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5955 - val_loss: 10.1610\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0400 - val_loss: 10.2717\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7913 - val_loss: 9.3567\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5195 - val_loss: 10.6816\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0286 - val_loss: 10.3159\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9408 - val_loss: 10.8141\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0626 - val_loss: 12.5385\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5664 - val_loss: 11.3507\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8082 - val_loss: 10.2985\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0611 - val_loss: 9.4927\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1509 - val_loss: 11.0530\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2689 - val_loss: 9.5426\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1619 - val_loss: 9.7594\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3348 - val_loss: 9.1997\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0100 - val_loss: 10.3490\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3589 - val_loss: 12.1197\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2089 - val_loss: 9.9782\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8698 - val_loss: 9.7960\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1781 - val_loss: 10.2078\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0377 - val_loss: 11.0702\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2174 - val_loss: 9.4202\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1988 - val_loss: 9.7242\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2217 - val_loss: 10.1783\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1413 - val_loss: 9.3173\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1284 - val_loss: 10.6009\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6905 - val_loss: 10.3810\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0775 - val_loss: 10.7120\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1507 - val_loss: 9.3077\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2510 - val_loss: 13.7295\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4066 - val_loss: 9.8330\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8825 - val_loss: 9.5247\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3009 - val_loss: 9.9309\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0352 - val_loss: 9.2299\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3676 - val_loss: 9.7537\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8736 - val_loss: 9.7598\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1624 - val_loss: 10.4296\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0886 - val_loss: 10.3297\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2387 - val_loss: 9.4629\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3969 - val_loss: 12.2505\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9810 - val_loss: 9.7548\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9801 - val_loss: 11.3238\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9538 - val_loss: 11.1071\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3785 - val_loss: 10.2078\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9778 - val_loss: 9.3904\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8416 - val_loss: 17.4381\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4672 - val_loss: 9.1812\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8276 - val_loss: 12.2596\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2868 - val_loss: 10.6706\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1570 - val_loss: 10.8533\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2380 - val_loss: 12.3924\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3252 - val_loss: 9.7254\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8692 - val_loss: 10.1481\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1464 - val_loss: 9.1723\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9502 - val_loss: 11.6394\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3223 - val_loss: 11.3674\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0003 - val_loss: 10.5820\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6538 - val_loss: 9.5384\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2488 - val_loss: 11.2838\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3608 - val_loss: 9.1843\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0089 - val_loss: 9.6499\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3887 - val_loss: 10.9151\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9562 - val_loss: 9.8300\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0954 - val_loss: 10.8370\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1707 - val_loss: 13.8815\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0545 - val_loss: 10.6529\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2691 - val_loss: 10.4504\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.0843 - val_loss: 9.4946\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0526 - val_loss: 10.7261\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8257 - val_loss: 16.0629\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3320 - val_loss: 10.4296\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8474 - val_loss: 9.8626\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9090 - val_loss: 11.0320\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2480 - val_loss: 9.4666\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9152 - val_loss: 14.3659\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5647 - val_loss: 9.2803\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3554 - val_loss: 9.3742\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.3592 - val_loss: 9.8810\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.0109 - val_loss: 9.8319\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9343 - val_loss: 10.8593\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3421 - val_loss: 11.4498\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3631 - val_loss: 10.7916\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9382 - val_loss: 11.6744\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0256 - val_loss: 12.1843\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9682 - val_loss: 9.6712\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1738 - val_loss: 11.0674\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1613 - val_loss: 9.8806\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3051 - val_loss: 10.5275\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2090 - val_loss: 10.2114\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8684 - val_loss: 10.5809\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1995 - val_loss: 9.6361\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1343 - val_loss: 9.1178\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0373 - val_loss: 11.2184\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2728 - val_loss: 9.7695\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9024 - val_loss: 10.5766\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9198 - val_loss: 10.9195\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1112 - val_loss: 10.2000\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1935 - val_loss: 11.3442\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9970 - val_loss: 9.3077\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6439 - val_loss: 9.5183\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8890 - val_loss: 10.4302\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3601 - val_loss: 10.9257\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9230 - val_loss: 9.6862\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0860 - val_loss: 9.8432\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9859 - val_loss: 10.3483\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0597 - val_loss: 10.6896\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4217 - val_loss: 10.2429\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0104 - val_loss: 9.2935\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1814 - val_loss: 9.8524\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1009 - val_loss: 9.3245\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1042 - val_loss: 9.2465\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8635 - val_loss: 9.9166\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9813 - val_loss: 9.3602\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2638 - val_loss: 9.5144\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9283 - val_loss: 10.8515\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5674 - val_loss: 10.3083\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1688 - val_loss: 9.2375\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0264 - val_loss: 10.3238\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4254 - val_loss: 11.9105\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8823 - val_loss: 11.9815\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1457 - val_loss: 9.6507\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1078 - val_loss: 12.7680\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8648 - val_loss: 10.6131\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8196 - val_loss: 9.6597\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9919 - val_loss: 12.8627\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2773 - val_loss: 9.2700\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9882 - val_loss: 9.7748\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8564 - val_loss: 9.8148\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.5355 - val_loss: 12.0197\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.1586 - val_loss: 10.2783\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1249 - val_loss: 13.0517\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1535 - val_loss: 11.2011\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9443 - val_loss: 10.4277\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1991 - val_loss: 13.3868\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.7376 - val_loss: 9.4557\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3517 - val_loss: 9.4033\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9175 - val_loss: 12.6421\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2151 - val_loss: 10.0441\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1645 - val_loss: 14.9282\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4261 - val_loss: 10.3284\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8121 - val_loss: 9.5869\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9819 - val_loss: 14.4693\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1483 - val_loss: 10.4646\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4240 - val_loss: 9.6447\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0461 - val_loss: 10.5284\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9271 - val_loss: 9.5465\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6883 - val_loss: 9.8378\n",
      "8.185115457636066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.2302649 , -3.97331   ,  0.63084215, -1.9847475 ,  3.2233388 ],\n",
       "        [-0.27515176,  0.19444647,  1.1118668 ,  0.48282054, -0.05107445],\n",
       "        [-0.39600155, -0.72132504,  1.3608668 ,  0.4297108 , -0.01219113],\n",
       "        [ 0.18915212,  0.17059492, -0.21388571,  0.0339576 , -0.07747869],\n",
       "        [-0.23181646, -0.3591916 , -0.08566522, -0.29420462,  2.5180795 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.5570226 , -4.9057674 ,  0.67366976, -1.2789114 ,  4.863223  ],\n",
       "       dtype=float32),\n",
       " array([[-0.9601603 ,  0.72588295, -1.4677371 ,  1.4341422 ,  1.1197554 ,\n",
       "         -0.69501907, -1.5342631 ,  0.77839696,  1.0789837 ,  1.5213062 ],\n",
       "        [ 1.4833688 , -1.9004036 ,  1.2655417 , -2.5006552 , -1.7641214 ,\n",
       "          2.2216558 ,  2.1828544 , -1.7521191 , -2.472325  , -2.3168318 ],\n",
       "        [ 0.49374238, -0.50299215,  0.7508968 , -0.47755063,  0.28167087,\n",
       "          0.4474679 ,  0.5066853 ,  0.08460659, -0.12034156, -0.6250875 ],\n",
       "        [-0.3407948 ,  0.6176681 , -0.82031447,  0.9746479 , -0.03283072,\n",
       "         -0.26188472, -0.67136127,  0.39257723,  0.26612288,  0.9441135 ],\n",
       "        [-1.4726268 ,  2.3750205 , -1.3587217 ,  1.6639514 ,  1.7636917 ,\n",
       "         -2.1621826 , -1.6980517 ,  1.1941149 ,  1.6554745 ,  2.1303601 ]],\n",
       "       dtype=float32),\n",
       " array([-2.2297108,  2.2995253, -2.2075505,  2.2583854,  2.1890712,\n",
       "        -2.2844431, -2.3195465,  2.209831 ,  2.2984052,  2.2842727],\n",
       "       dtype=float32),\n",
       " array([[-1.6029757],\n",
       "        [ 2.0795598],\n",
       "        [-1.6340235],\n",
       "        [ 1.8258128],\n",
       "        [ 1.5925213],\n",
       "        [-1.9875984],\n",
       "        [-2.1326911],\n",
       "        [ 1.6785406],\n",
       "        [ 2.0423067],\n",
       "        [ 1.9789155]], dtype=float32),\n",
       " array([2.8380194], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, RMSprop, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_rmsprop_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 640us/step - loss: 526.5602 - val_loss: 313.7543\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 183.3618 - val_loss: 54.7357\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 54.5684 - val_loss: 35.1865\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 24.6247 - val_loss: 22.1060\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 18.9131 - val_loss: 18.7218\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.8979 - val_loss: 17.1944\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 14.4366 - val_loss: 16.0928\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 12.7396 - val_loss: 14.2641\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.4105 - val_loss: 11.3979\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.4112 - val_loss: 10.7728\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 8.8805 - val_loss: 11.3048\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.7295 - val_loss: 11.4704\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.5073 - val_loss: 12.3459\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 8.4260 - val_loss: 10.8304\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 8.0330 - val_loss: 10.8548\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8456 - val_loss: 11.1917\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8840 - val_loss: 12.8474\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.0301 - val_loss: 11.0487\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8377 - val_loss: 11.0124\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5066 - val_loss: 10.5547\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6696 - val_loss: 10.9025\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4250 - val_loss: 10.5380\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5432 - val_loss: 11.2203\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4223 - val_loss: 10.5224\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2227 - val_loss: 10.7504\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2364 - val_loss: 10.5676\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.2758 - val_loss: 10.6317\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4020 - val_loss: 11.0324\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.3382 - val_loss: 10.4037\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1264 - val_loss: 10.9009\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0928 - val_loss: 10.5599\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1778 - val_loss: 10.5596\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9347 - val_loss: 10.5001\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0512 - val_loss: 10.6098\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.2760 - val_loss: 10.0147\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2954 - val_loss: 10.5940\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3992 - val_loss: 10.1965\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2408 - val_loss: 10.3839\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8716 - val_loss: 10.1356\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7744 - val_loss: 9.8482\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8403 - val_loss: 10.4089\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9889 - val_loss: 9.8198\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9608 - val_loss: 10.0561\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7731 - val_loss: 9.8882\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7054 - val_loss: 9.9728\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8454 - val_loss: 9.9345\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0233 - val_loss: 9.7125\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9645 - val_loss: 10.2505\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2432 - val_loss: 9.8824\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8783 - val_loss: 10.3210\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9123 - val_loss: 9.9316\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.7311 - val_loss: 9.9883\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0769 - val_loss: 9.6629\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2079 - val_loss: 9.8109\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9444 - val_loss: 9.7163\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8075 - val_loss: 9.5997\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7782 - val_loss: 9.6785\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.8965 - val_loss: 9.6202\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9362 - val_loss: 9.7257\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1573 - val_loss: 9.6701\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.7052 - val_loss: 9.7448\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7271 - val_loss: 9.5926\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7830 - val_loss: 9.6961\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7809 - val_loss: 9.5066\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4905 - val_loss: 9.7709\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5817 - val_loss: 9.4330\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8364 - val_loss: 9.6516\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 7.0347 - val_loss: 9.8262\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6585 - val_loss: 9.7644\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.5831 - val_loss: 9.2996\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5821 - val_loss: 9.3149\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6539 - val_loss: 9.3789\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5702 - val_loss: 9.7010\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5268 - val_loss: 9.4154\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5497 - val_loss: 9.3861\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5219 - val_loss: 9.3606\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7095 - val_loss: 9.3714\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7270 - val_loss: 9.5369\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5416 - val_loss: 9.3431\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4571 - val_loss: 9.2321\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4510 - val_loss: 9.4602\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4651 - val_loss: 9.3189\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4797 - val_loss: 9.4548\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4697 - val_loss: 9.3556\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5462 - val_loss: 9.3401\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4992 - val_loss: 9.4865\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6202 - val_loss: 9.2651\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4284 - val_loss: 9.2798\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4511 - val_loss: 9.1866\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5518 - val_loss: 9.2627\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5080 - val_loss: 9.4076\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3996 - val_loss: 9.6314\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4987 - val_loss: 9.2637\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5378 - val_loss: 9.3517\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6150 - val_loss: 9.3193\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7614 - val_loss: 9.1949\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.5108 - val_loss: 9.4459\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.5459 - val_loss: 9.3212\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.9291 - val_loss: 9.2798\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.8417 - val_loss: 9.2668\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 6.3176 - val_loss: 9.5568\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4114 - val_loss: 9.1283\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5893 - val_loss: 9.4158\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8034 - val_loss: 9.2440\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.5041 - val_loss: 9.2750\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3790 - val_loss: 9.5299\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.4092 - val_loss: 9.2505\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4704 - val_loss: 9.2934\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3649 - val_loss: 9.3545\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5551 - val_loss: 9.5248\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5411 - val_loss: 9.1891\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4253 - val_loss: 9.1490\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4152 - val_loss: 9.3403\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6020 - val_loss: 9.2559\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3927 - val_loss: 9.2438\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3921 - val_loss: 9.2382\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3342 - val_loss: 9.2151\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3090 - val_loss: 8.9930\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3596 - val_loss: 9.1621\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4976 - val_loss: 9.0961\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3009 - val_loss: 9.1037\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3490 - val_loss: 9.2204\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3591 - val_loss: 9.1289\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4968 - val_loss: 9.4354\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4185 - val_loss: 9.0349\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3374 - val_loss: 9.0626\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3567 - val_loss: 9.1240\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3151 - val_loss: 9.3329\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4451 - val_loss: 9.2588\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5835 - val_loss: 9.1996\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6480 - val_loss: 9.3092\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5197 - val_loss: 9.1690\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6946 - val_loss: 9.4074\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4122 - val_loss: 9.0834\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7612 - val_loss: 9.2328\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7820 - val_loss: 9.2050\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4550 - val_loss: 9.2669\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2921 - val_loss: 9.1145\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2239 - val_loss: 9.2840\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3523 - val_loss: 9.0569\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2222 - val_loss: 9.0510\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3520 - val_loss: 9.2181\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2848 - val_loss: 9.0292\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2484 - val_loss: 9.1477\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3448 - val_loss: 9.0869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3614 - val_loss: 9.0932\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4549 - val_loss: 9.1301\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2410 - val_loss: 8.9687\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2604 - val_loss: 9.1778\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4146 - val_loss: 9.1156\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4418 - val_loss: 9.4285\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2414 - val_loss: 9.2058\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3471 - val_loss: 9.4081\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2424 - val_loss: 9.0697\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4790 - val_loss: 8.9863\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9028 - val_loss: 9.3263\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.4526 - val_loss: 9.2451\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4747 - val_loss: 9.1683\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3423 - val_loss: 9.0138\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2711 - val_loss: 8.9750\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3835 - val_loss: 9.0310\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3938 - val_loss: 9.1385\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3592 - val_loss: 9.0619\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2879 - val_loss: 9.0575\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2947 - val_loss: 8.9385\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1645 - val_loss: 8.9111\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1844 - val_loss: 8.8795\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1270 - val_loss: 8.7272\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2112 - val_loss: 8.9614\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1544 - val_loss: 8.8725\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1306 - val_loss: 9.0063\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0460 - val_loss: 9.1599\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1012 - val_loss: 8.6842\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0657 - val_loss: 8.8535\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0601 - val_loss: 8.8563\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1848 - val_loss: 8.8128\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9986 - val_loss: 9.0379\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0381 - val_loss: 8.9996\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0394 - val_loss: 8.8118\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1157 - val_loss: 8.6300\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1133 - val_loss: 9.0106\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0815 - val_loss: 9.2538\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3639 - val_loss: 8.7641\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1552 - val_loss: 9.1277\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9858 - val_loss: 8.8042\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1378 - val_loss: 8.8442\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0393 - val_loss: 8.7482\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0528 - val_loss: 9.1341\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9638 - val_loss: 8.9268\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9831 - val_loss: 8.9049\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9880 - val_loss: 8.7588\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2404 - val_loss: 9.1166\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0096 - val_loss: 8.7820\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9710 - val_loss: 8.8543\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9799 - val_loss: 8.9381\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9428 - val_loss: 9.1102\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0034 - val_loss: 8.8708\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.9560 - val_loss: 8.8597\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9190 - val_loss: 8.9728\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9131 - val_loss: 8.7473\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9430 - val_loss: 8.9186\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9141 - val_loss: 8.8392\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9123 - val_loss: 8.9321\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8687 - val_loss: 8.9289\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8881 - val_loss: 8.9112\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8824 - val_loss: 8.9779\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8901 - val_loss: 8.8353\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9181 - val_loss: 8.9608\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8674 - val_loss: 9.2317\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0037 - val_loss: 8.9763\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1276 - val_loss: 9.1890\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0774 - val_loss: 8.8328\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9172 - val_loss: 9.0985\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0806 - val_loss: 9.3495\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3342 - val_loss: 9.2129\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8136 - val_loss: 9.4948\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9124 - val_loss: 9.2088\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7989 - val_loss: 9.0799\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7413 - val_loss: 9.0021\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8373 - val_loss: 9.1856\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9662 - val_loss: 9.0496\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2017 - val_loss: 9.5773\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8765 - val_loss: 9.0288\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7289 - val_loss: 9.1734\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6970 - val_loss: 9.2256\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7759 - val_loss: 9.2208\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7134 - val_loss: 9.0993\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8429 - val_loss: 9.2171\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7353 - val_loss: 9.3124\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6788 - val_loss: 9.3859\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8326 - val_loss: 9.2654\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7837 - val_loss: 9.2830\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8759 - val_loss: 9.3788\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6695 - val_loss: 9.3654\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6716 - val_loss: 9.2544\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8922 - val_loss: 9.3582\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6099 - val_loss: 9.2586\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6698 - val_loss: 9.2715\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9020 - val_loss: 9.3183\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9822 - val_loss: 9.1110\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6976 - val_loss: 9.0250\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7544 - val_loss: 9.0601\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5717 - val_loss: 9.2850\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6712 - val_loss: 9.1401\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7947 - val_loss: 9.5122\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6529 - val_loss: 9.2574\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5787 - val_loss: 9.3497\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6209 - val_loss: 9.1562\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6309 - val_loss: 9.2241\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5416 - val_loss: 9.3002\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6257 - val_loss: 9.1881\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6608 - val_loss: 9.2466\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6274 - val_loss: 9.2357\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6630 - val_loss: 8.9725\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7464 - val_loss: 9.2906\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8476 - val_loss: 9.1607\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5220 - val_loss: 9.2369\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6083 - val_loss: 9.1131\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7229 - val_loss: 9.1485\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5195 - val_loss: 8.8857\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5777 - val_loss: 9.1666\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5423 - val_loss: 9.0882\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7235 - val_loss: 9.4486\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8688 - val_loss: 8.9489\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0336 - val_loss: 9.3876\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9125 - val_loss: 9.0283\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7555 - val_loss: 9.1357\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5213 - val_loss: 9.2493\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5799 - val_loss: 9.0617\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6916 - val_loss: 8.9813\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6809 - val_loss: 9.2746\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8640 - val_loss: 8.9552\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7055 - val_loss: 9.1863\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7833 - val_loss: 9.1122\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7366 - val_loss: 9.3629\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5856 - val_loss: 9.0101\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5517 - val_loss: 9.1199\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6162 - val_loss: 9.2641\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5521 - val_loss: 9.0840\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5496 - val_loss: 9.1412\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5867 - val_loss: 9.1052\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5719 - val_loss: 9.0552\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6114 - val_loss: 9.0035\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5145 - val_loss: 9.2933\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5503 - val_loss: 9.0144\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6906 - val_loss: 9.1523\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5763 - val_loss: 9.1134\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4675 - val_loss: 9.0176\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8055 - val_loss: 9.1940\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7238 - val_loss: 9.0161\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7184 - val_loss: 9.0992\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5414 - val_loss: 9.0374\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6274 - val_loss: 9.0410\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8035 - val_loss: 9.0808\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7008 - val_loss: 9.1567\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5794 - val_loss: 9.0929\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5444 - val_loss: 9.1258\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6227 - val_loss: 9.1505\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5958 - val_loss: 9.2623\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4866 - val_loss: 9.0781\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5172 - val_loss: 9.0759\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6298 - val_loss: 9.0283\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7492 - val_loss: 9.0670\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8722 - val_loss: 9.3194\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7718 - val_loss: 9.0129\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6887 - val_loss: 9.4101\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7772 - val_loss: 9.1289\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5854 - val_loss: 9.3151\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5021 - val_loss: 9.0268\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4600 - val_loss: 9.0347\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4701 - val_loss: 9.0339\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5528 - val_loss: 9.0722\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5466 - val_loss: 9.0851\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5967 - val_loss: 9.2021\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5461 - val_loss: 9.0396\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6751 - val_loss: 9.2192\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5765 - val_loss: 9.0694\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.29 - 0s 98us/step - loss: 5.5858 - val_loss: 9.2798\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8305 - val_loss: 9.0990\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7561 - val_loss: 9.3645\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5950 - val_loss: 9.0887\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7209 - val_loss: 9.0778\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6826 - val_loss: 9.0274\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4952 - val_loss: 9.1183\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5233 - val_loss: 9.0736\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7421 - val_loss: 9.0424\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6461 - val_loss: 9.2832\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9647 - val_loss: 9.1000\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7333 - val_loss: 9.3445\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6072 - val_loss: 9.1095\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6315 - val_loss: 8.9959\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4581 - val_loss: 8.8724\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4975 - val_loss: 8.7435\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4631 - val_loss: 8.9173\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4986 - val_loss: 9.1458\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4516 - val_loss: 9.0525\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4472 - val_loss: 9.0307\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6343 - val_loss: 9.0695\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5373 - val_loss: 9.0435\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5453 - val_loss: 8.9330\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6673 - val_loss: 9.0690\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6724 - val_loss: 9.0678\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6730 - val_loss: 9.0100\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5969 - val_loss: 9.2470\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4728 - val_loss: 8.9644\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5114 - val_loss: 9.2171\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5233 - val_loss: 9.0798\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8456 - val_loss: 9.1039\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8475 - val_loss: 9.3510\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9148 - val_loss: 8.9682\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6423 - val_loss: 8.9558\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5192 - val_loss: 8.8673\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5635 - val_loss: 9.0894\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5765 - val_loss: 9.2794\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5349 - val_loss: 9.3368\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4998 - val_loss: 8.9882\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4421 - val_loss: 9.0589\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4748 - val_loss: 9.1042\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6333 - val_loss: 9.1846\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4878 - val_loss: 9.3085\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4524 - val_loss: 8.9618\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5190 - val_loss: 9.1171\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4263 - val_loss: 8.9346\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4881 - val_loss: 8.9841\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7025 - val_loss: 9.0983\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6617 - val_loss: 9.1035\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3950 - val_loss: 9.1111\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5191 - val_loss: 8.8723\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4999 - val_loss: 9.1172\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5129 - val_loss: 9.1809\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4587 - val_loss: 9.1069\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4835 - val_loss: 9.1934\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4355 - val_loss: 8.9871\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6099 - val_loss: 9.0373\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4817 - val_loss: 9.3548\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5598 - val_loss: 9.0680\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 127us/step - loss: 5.5960 - val_loss: 9.1600\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.4549 - val_loss: 9.2746\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.5512 - val_loss: 9.2209\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5168 - val_loss: 9.2058\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5094 - val_loss: 9.0955\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4610 - val_loss: 9.1844\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4828 - val_loss: 9.1567\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5708 - val_loss: 9.2739\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4037 - val_loss: 9.1145\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5019 - val_loss: 9.3055\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4370 - val_loss: 9.0883\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4716 - val_loss: 9.2160\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4922 - val_loss: 8.9820\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4660 - val_loss: 9.0846\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5282 - val_loss: 8.9156\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4771 - val_loss: 9.1351\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5028 - val_loss: 9.0646\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4554 - val_loss: 9.1900\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4813 - val_loss: 9.0122\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4521 - val_loss: 9.3034\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4325 - val_loss: 9.1321\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4458 - val_loss: 9.0093\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4110 - val_loss: 9.2567\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4127 - val_loss: 9.0328\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5033 - val_loss: 9.0974\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4614 - val_loss: 9.2689\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4748 - val_loss: 9.0141\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6937 - val_loss: 9.3301\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5015 - val_loss: 9.1039\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6077 - val_loss: 9.1908\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6229 - val_loss: 9.4183\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4925 - val_loss: 9.2160\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4932 - val_loss: 9.1302\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5038 - val_loss: 9.2340\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4139 - val_loss: 9.3605\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4168 - val_loss: 9.3343\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3908 - val_loss: 9.3123\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4855 - val_loss: 9.1052\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4352 - val_loss: 9.1900\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4985 - val_loss: 9.2767\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4921 - val_loss: 9.2306\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4875 - val_loss: 9.1737\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3885 - val_loss: 9.2010\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5299 - val_loss: 9.2296\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3963 - val_loss: 9.2497\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4532 - val_loss: 9.2502\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4711 - val_loss: 9.0835\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4166 - val_loss: 9.1943\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4351 - val_loss: 9.1847\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3334 - val_loss: 9.1785\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4621 - val_loss: 9.1886\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4623 - val_loss: 9.2603\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5116 - val_loss: 9.3128\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4349 - val_loss: 9.1850\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5371 - val_loss: 9.2244\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6347 - val_loss: 9.2037\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9200 - val_loss: 9.4326\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8506 - val_loss: 8.9632\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5033 - val_loss: 9.0915\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3389 - val_loss: 9.2248\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4847 - val_loss: 9.4651\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5084 - val_loss: 9.1535\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4045 - val_loss: 9.3470\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4607 - val_loss: 9.3217\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4820 - val_loss: 9.1797\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3745 - val_loss: 9.3438\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5042 - val_loss: 9.3503\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5321 - val_loss: 9.4111\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3767 - val_loss: 9.2728\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4581 - val_loss: 9.1789\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4664 - val_loss: 9.0740\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4142 - val_loss: 9.0406\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4409 - val_loss: 9.2511\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4427 - val_loss: 9.2692\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3976 - val_loss: 9.2726\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4509 - val_loss: 9.1451\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4395 - val_loss: 9.2954\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.6400 - val_loss: 9.8801\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5821 - val_loss: 9.3624\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4896 - val_loss: 9.3437\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5988 - val_loss: 9.0858\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8196 - val_loss: 9.0443\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4971 - val_loss: 9.3740\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5505 - val_loss: 9.1149\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4321 - val_loss: 9.3396\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3764 - val_loss: 9.2767\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3652 - val_loss: 9.2656\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4291 - val_loss: 9.1327\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4417 - val_loss: 9.2550\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4714 - val_loss: 9.4311\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4261 - val_loss: 9.5104\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4133 - val_loss: 9.3826\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4493 - val_loss: 9.3560\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4516 - val_loss: 9.3232\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3572 - val_loss: 9.4034\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5853 - val_loss: 9.1492\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3849 - val_loss: 9.4982\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4503 - val_loss: 9.2222\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4581 - val_loss: 9.2364\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5496 - val_loss: 9.3989\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6129 - val_loss: 9.1004\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4232 - val_loss: 9.0174\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4323 - val_loss: 9.0285\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4425 - val_loss: 9.2947\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3966 - val_loss: 9.3476\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4319 - val_loss: 9.4347\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3491 - val_loss: 9.3987\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4223 - val_loss: 9.4198\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6412 - val_loss: 9.4980\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6055 - val_loss: 9.7221\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1743 - val_loss: 9.4889\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9756 - val_loss: 9.8017\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5601 - val_loss: 9.3500\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4231 - val_loss: 9.4508\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6781 - val_loss: 9.4751\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5559 - val_loss: 9.4475\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4747 - val_loss: 9.3611\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5816 - val_loss: 9.1246\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4369 - val_loss: 9.3984\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4964 - val_loss: 9.3488\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5458 - val_loss: 9.5045\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4734 - val_loss: 9.4044\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4325 - val_loss: 9.4832\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3653 - val_loss: 9.2659\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4435 - val_loss: 9.1631\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4153 - val_loss: 9.1790\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5832 - val_loss: 9.5033\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5152 - val_loss: 9.3240\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6390 - val_loss: 9.5256\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6209 - val_loss: 9.4541\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5470 - val_loss: 9.6007\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4714 - val_loss: 9.4994\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3563 - val_loss: 9.5735\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4012 - val_loss: 9.5825\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5597 - val_loss: 9.4577\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4624 - val_loss: 9.6456\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4596 - val_loss: 9.3225\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4400 - val_loss: 9.4857\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3828 - val_loss: 9.6618\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4938 - val_loss: 9.7607\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4504 - val_loss: 9.6624\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3504 - val_loss: 9.4875\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4308 - val_loss: 9.5241\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3526 - val_loss: 9.4915\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4090 - val_loss: 9.5958\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3363 - val_loss: 9.5880\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.754 - 0s 91us/step - loss: 5.5473 - val_loss: 9.4877\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6010 - val_loss: 9.7116\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5309 - val_loss: 9.4831\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6921 - val_loss: 9.8666\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4931 - val_loss: 9.7496\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5325 - val_loss: 9.9135\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3961 - val_loss: 9.7591\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4482 - val_loss: 9.5869\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.4182 - val_loss: 9.3917\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6699 - val_loss: 9.4507\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5198 - val_loss: 9.5927\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4520 - val_loss: 9.4739\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3383 - val_loss: 9.8001\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4047 - val_loss: 9.7329\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4841 - val_loss: 9.7230\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5310 - val_loss: 9.8386\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4688 - val_loss: 9.5337\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5397 - val_loss: 9.6663\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9667 - val_loss: 9.4757\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8879 - val_loss: 9.7914\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9225 - val_loss: 9.8792\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4176 - val_loss: 10.1295\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4669 - val_loss: 9.8071\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3739 - val_loss: 9.7475\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3426 - val_loss: 9.7640\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4691 - val_loss: 9.6816\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3443 - val_loss: 9.7183\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3872 - val_loss: 9.7161\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3860 - val_loss: 9.7925\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4040 - val_loss: 9.8415\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4023 - val_loss: 9.6258\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3463 - val_loss: 9.7276\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3355 - val_loss: 9.7544\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5713 - val_loss: 9.5399\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3475 - val_loss: 9.8727\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4568 - val_loss: 9.9997\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4924 - val_loss: 10.1226\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3850 - val_loss: 10.0220\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4577 - val_loss: 9.9178\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3707 - val_loss: 9.7557\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6072 - val_loss: 9.8456\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6993 - val_loss: 10.1363\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4027 - val_loss: 9.6333\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4159 - val_loss: 9.9618\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5568 - val_loss: 9.8720\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4169 - val_loss: 10.0021\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2707 - val_loss: 10.0494\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4749 - val_loss: 10.1318\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5673 - val_loss: 9.8541\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2955 - val_loss: 10.1199\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4155 - val_loss: 9.9162\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3874 - val_loss: 10.1040\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2696 - val_loss: 9.9907\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4422 - val_loss: 10.0266\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3329 - val_loss: 9.9421\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2522 - val_loss: 9.8669\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2932 - val_loss: 9.9073\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3289 - val_loss: 10.0201\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2751 - val_loss: 10.2421\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3048 - val_loss: 10.0152\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3309 - val_loss: 10.2530\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3717 - val_loss: 9.9219\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3730 - val_loss: 10.1874\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2797 - val_loss: 10.2710\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4638 - val_loss: 10.2478\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4112 - val_loss: 10.1616\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4019 - val_loss: 10.1093\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3344 - val_loss: 10.0327\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4330 - val_loss: 10.0150\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5554 - val_loss: 10.1079\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4601 - val_loss: 10.2777\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4174 - val_loss: 10.5118\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4890 - val_loss: 10.2337\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4159 - val_loss: 10.1223\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3292 - val_loss: 10.1639\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2713 - val_loss: 10.0519\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2927 - val_loss: 10.3089\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2060 - val_loss: 10.1248\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3255 - val_loss: 10.0621\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2997 - val_loss: 10.2282\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3315 - val_loss: 10.1657\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3397 - val_loss: 9.9957\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3356 - val_loss: 10.0602\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4223 - val_loss: 10.2354\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2375 - val_loss: 9.9863\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.2356 - val_loss: 10.4619\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2295 - val_loss: 10.3615\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2263 - val_loss: 10.1596\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2442 - val_loss: 10.1205\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2636 - val_loss: 9.9162\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2367 - val_loss: 10.0606\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2469 - val_loss: 10.2693\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2938 - val_loss: 10.1171\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2361 - val_loss: 10.2271\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2436 - val_loss: 10.2677\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2681 - val_loss: 10.0397\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2282 - val_loss: 9.9299\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1884 - val_loss: 10.1187\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2562 - val_loss: 10.2158\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3710 - val_loss: 10.2717\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3937 - val_loss: 10.4478\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3229 - val_loss: 10.1965\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2765 - val_loss: 10.2848\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2143 - val_loss: 10.4659\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3106 - val_loss: 10.2559\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2826 - val_loss: 10.1509\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1715 - val_loss: 10.3413\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2306 - val_loss: 10.3432\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3599 - val_loss: 10.3903\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2114 - val_loss: 10.2592\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4429 - val_loss: 10.2310\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5756 - val_loss: 10.3847\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2450 - val_loss: 10.2073\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3003 - val_loss: 10.1147\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2205 - val_loss: 10.0218\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2425 - val_loss: 10.1966\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1610 - val_loss: 10.0732\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3023 - val_loss: 10.0604\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2603 - val_loss: 10.3204\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4765 - val_loss: 10.3714\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4484 - val_loss: 10.3407\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3069 - val_loss: 10.0062\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3232 - val_loss: 10.3183\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3122 - val_loss: 10.0988\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2703 - val_loss: 10.3527\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2273 - val_loss: 10.0315\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.3507 - val_loss: 10.2179\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5496 - val_loss: 10.3479\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4133 - val_loss: 10.1855\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1218 - val_loss: 10.3409\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3099 - val_loss: 10.3764\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3781 - val_loss: 10.5089\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4360 - val_loss: 10.0996\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1637 - val_loss: 10.1371\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3829 - val_loss: 10.2593\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3503 - val_loss: 10.3306\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2914 - val_loss: 10.0506\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.2879 - val_loss: 10.0990\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3857 - val_loss: 9.9214\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2320 - val_loss: 10.0052\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1538 - val_loss: 10.1564\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2548 - val_loss: 10.2510\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2375 - val_loss: 10.4065\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2057 - val_loss: 10.2671\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2695 - val_loss: 10.2718\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3428 - val_loss: 10.2672\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2784 - val_loss: 9.9670\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1714 - val_loss: 10.0717\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2013 - val_loss: 10.2404\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1530 - val_loss: 10.5661\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1330 - val_loss: 10.3507\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1591 - val_loss: 10.1968\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1710 - val_loss: 10.2133\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2605 - val_loss: 10.4369\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1826 - val_loss: 10.2641\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2208 - val_loss: 10.2320\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3295 - val_loss: 10.3549\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2406 - val_loss: 10.2552\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3379 - val_loss: 10.2422\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1493 - val_loss: 10.1616\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1713 - val_loss: 10.3614\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1822 - val_loss: 10.4150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1898 - val_loss: 10.1970\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2591 - val_loss: 10.2193\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1777 - val_loss: 10.6147\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2236 - val_loss: 10.3395\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1452 - val_loss: 10.2758\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1826 - val_loss: 10.4108\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2027 - val_loss: 10.2902\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3373 - val_loss: 10.0718\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4914 - val_loss: 10.1503\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3048 - val_loss: 10.4699\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1416 - val_loss: 10.3776\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1827 - val_loss: 10.2188\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1717 - val_loss: 10.1837\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1978 - val_loss: 10.5220\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3224 - val_loss: 10.4602\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1954 - val_loss: 10.4058\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2234 - val_loss: 10.3468\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1657 - val_loss: 10.2368\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3413 - val_loss: 10.5177\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1473 - val_loss: 10.1469\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3000 - val_loss: 10.6230\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4315 - val_loss: 10.5738\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5159 - val_loss: 10.2551\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1016 - val_loss: 10.3994\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1754 - val_loss: 10.2689\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1866 - val_loss: 10.5178\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1539 - val_loss: 10.4085\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2092 - val_loss: 10.7692\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2903 - val_loss: 10.3081\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1970 - val_loss: 10.5954\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1686 - val_loss: 10.2647\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2504 - val_loss: 10.1874\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1481 - val_loss: 10.5428\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1996 - val_loss: 10.2910\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2113 - val_loss: 10.4693\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0934 - val_loss: 10.3127\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2252 - val_loss: 10.2901\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1392 - val_loss: 10.0642\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0902 - val_loss: 10.3797\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1432 - val_loss: 10.4519\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1582 - val_loss: 10.2679\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1843 - val_loss: 10.5143\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1664 - val_loss: 10.5187\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1747 - val_loss: 10.5291\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1435 - val_loss: 10.4868\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0917 - val_loss: 10.5324\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1216 - val_loss: 10.4749\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1335 - val_loss: 10.3626\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1467 - val_loss: 10.1859\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1247 - val_loss: 10.2015\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1510 - val_loss: 10.4671\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1301 - val_loss: 10.6405\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1916 - val_loss: 10.4483\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1673 - val_loss: 10.4954\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1413 - val_loss: 10.5253\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1341 - val_loss: 10.3707\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5261 - val_loss: 10.1890\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2477 - val_loss: 10.4896\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1190 - val_loss: 10.6266\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0895 - val_loss: 10.5665\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1898 - val_loss: 10.3155\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4887 - val_loss: 10.4175\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3040 - val_loss: 10.1465\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1620 - val_loss: 10.4111\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1322 - val_loss: 10.4620\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4182 - val_loss: 10.5718\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3614 - val_loss: 10.7993\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2457 - val_loss: 10.3633\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1451 - val_loss: 10.3395\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0822 - val_loss: 10.4482\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1744 - val_loss: 10.6533\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2997 - val_loss: 10.3503\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1553 - val_loss: 10.6402\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2158 - val_loss: 10.4649\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1005 - val_loss: 10.5609\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3163 - val_loss: 10.3540\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5502 - val_loss: 10.7768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6612 - val_loss: 10.5110\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2869 - val_loss: 10.6499\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1000 - val_loss: 10.3780\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1723 - val_loss: 10.5457\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0882 - val_loss: 10.3938\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2533 - val_loss: 10.4972\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1421 - val_loss: 10.4340\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1617 - val_loss: 10.6694\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1900 - val_loss: 10.5407\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2494 - val_loss: 10.4761\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2195 - val_loss: 10.3886\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0679 - val_loss: 10.4402\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2201 - val_loss: 10.4373\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1931 - val_loss: 10.4957\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1215 - val_loss: 10.7582\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2375 - val_loss: 10.4781\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3116 - val_loss: 10.6578\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1232 - val_loss: 10.4961\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1374 - val_loss: 10.5990\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0874 - val_loss: 10.6835\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1363 - val_loss: 10.4912\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1498 - val_loss: 10.3798\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1935 - val_loss: 10.3592\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1553 - val_loss: 10.4636\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1202 - val_loss: 10.3491\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1535 - val_loss: 10.3403\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1289 - val_loss: 10.8464\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2321 - val_loss: 10.6966\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2310 - val_loss: 10.7002\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0879 - val_loss: 10.5982\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1979 - val_loss: 10.6620\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1091 - val_loss: 10.6896\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2647 - val_loss: 10.5025\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3580 - val_loss: 10.7356\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3997 - val_loss: 10.4388\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1600 - val_loss: 10.5088\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1389 - val_loss: 10.4082\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1282 - val_loss: 10.6082\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2384 - val_loss: 10.5389\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1450 - val_loss: 10.8358\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1397 - val_loss: 10.6516\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1759 - val_loss: 10.6174\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2009 - val_loss: 10.4190\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3707 - val_loss: 10.7436\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3646 - val_loss: 10.5960\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1497 - val_loss: 10.7924\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1036 - val_loss: 10.7077\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3278 - val_loss: 10.6657\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3367 - val_loss: 10.4720\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1363 - val_loss: 10.4939\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1327 - val_loss: 10.6450\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0944 - val_loss: 10.7677\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1040 - val_loss: 10.5857\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1245 - val_loss: 10.6977\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1224 - val_loss: 10.4253\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3722 - val_loss: 10.6213\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1750 - val_loss: 10.5423\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2402 - val_loss: 10.5820\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1764 - val_loss: 10.5125\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1620 - val_loss: 10.8190\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1061 - val_loss: 10.6005\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1559 - val_loss: 10.6929\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2209 - val_loss: 10.4212\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0847 - val_loss: 10.6673\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0813 - val_loss: 10.5780\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1090 - val_loss: 10.6146\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0906 - val_loss: 10.4581\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1094 - val_loss: 10.5587\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2309 - val_loss: 10.7412\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0315 - val_loss: 10.6774\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1950 - val_loss: 10.5747\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0670 - val_loss: 10.5598\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1428 - val_loss: 10.4853\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2018 - val_loss: 10.6458\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2076 - val_loss: 10.5144\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0581 - val_loss: 10.8670\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0933 - val_loss: 10.6480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0569 - val_loss: 10.3996\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.0799 - val_loss: 10.5952\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1122 - val_loss: 10.4059\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0786 - val_loss: 10.5999\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0934 - val_loss: 10.7097\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0828 - val_loss: 10.6486\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1722 - val_loss: 10.4368\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0858 - val_loss: 10.6383\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2344 - val_loss: 10.4806\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0835 - val_loss: 10.3601\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3010 - val_loss: 10.4547\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3682 - val_loss: 10.4649\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2259 - val_loss: 10.8752\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0919 - val_loss: 10.4024\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0332 - val_loss: 10.5646\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1608 - val_loss: 10.6417\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1291 - val_loss: 10.5167\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1515 - val_loss: 10.6066\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1213 - val_loss: 10.4948\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0972 - val_loss: 10.7387\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2065 - val_loss: 10.7362\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5061 - val_loss: 10.6756\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3176 - val_loss: 11.1409\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0523 - val_loss: 10.7637\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2124 - val_loss: 10.6509\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0951 - val_loss: 10.5027\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0015 - val_loss: 10.5017\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0647 - val_loss: 10.6756\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2321 - val_loss: 10.6446\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1474 - val_loss: 10.7520\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1263 - val_loss: 10.5362\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0320 - val_loss: 10.9054\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1043 - val_loss: 10.6568\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0560 - val_loss: 10.6359\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0619 - val_loss: 10.5948\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1240 - val_loss: 10.4169\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0272 - val_loss: 10.6049\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1391 - val_loss: 10.6956\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0902 - val_loss: 10.9142\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1037 - val_loss: 10.7679\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0824 - val_loss: 10.7416\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1207 - val_loss: 10.6064\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1217 - val_loss: 10.8719\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1774 - val_loss: 10.6155\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0809 - val_loss: 10.6951\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1174 - val_loss: 10.7073\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1237 - val_loss: 10.8203\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1582 - val_loss: 10.6450\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1898 - val_loss: 10.9018\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3880 - val_loss: 10.8383\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3729 - val_loss: 10.6203\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1162 - val_loss: 10.6852\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1096 - val_loss: 10.7719\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0711 - val_loss: 10.7500\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0765 - val_loss: 10.7562\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1167 - val_loss: 10.4798\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1364 - val_loss: 10.8046\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1467 - val_loss: 10.4932\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1931 - val_loss: 10.9505\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1326 - val_loss: 10.6736\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1593 - val_loss: 10.6146\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0805 - val_loss: 10.3825\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1916 - val_loss: 10.4219\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0782 - val_loss: 10.5390\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0977 - val_loss: 10.5971\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2211 - val_loss: 10.7457\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2823 - val_loss: 10.7959\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3719 - val_loss: 10.5691\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.0857 - val_loss: 10.6365\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1333 - val_loss: 10.5558\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1759 - val_loss: 10.6332\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2139 - val_loss: 10.8472\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1155 - val_loss: 10.8031\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0520 - val_loss: 10.6388\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1328 - val_loss: 10.6877\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0910 - val_loss: 10.6658\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1448 - val_loss: 10.5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0496 - val_loss: 10.7711\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0659 - val_loss: 10.6515\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0851 - val_loss: 10.4574\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1106 - val_loss: 10.7078\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2830 - val_loss: 10.5303\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1110 - val_loss: 10.7695\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0876 - val_loss: 10.5609\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0364 - val_loss: 10.8071\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1353 - val_loss: 10.7497\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1087 - val_loss: 10.8744\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0293 - val_loss: 10.6404\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0592 - val_loss: 10.5485\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0666 - val_loss: 10.5396\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0144 - val_loss: 10.6225\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0973 - val_loss: 10.5664\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1379 - val_loss: 10.9598\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2615 - val_loss: 10.6281\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0677 - val_loss: 10.8622\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1139 - val_loss: 10.6130\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.0472 - val_loss: 10.6120\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1538 - val_loss: 10.6735\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1129 - val_loss: 10.9041\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1200 - val_loss: 10.6051\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0849 - val_loss: 10.7488\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0287 - val_loss: 10.4110\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0121 - val_loss: 10.5598\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0510 - val_loss: 10.5405\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0731 - val_loss: 10.7610\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2862 - val_loss: 10.8064\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2005 - val_loss: 10.7845\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1138 - val_loss: 11.0615\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2820 - val_loss: 10.5086\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2223 - val_loss: 10.3762\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3391 - val_loss: 10.5875\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0487 - val_loss: 10.5270\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0359 - val_loss: 10.6273\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2188 - val_loss: 10.7573\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1235 - val_loss: 10.9216\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0625 - val_loss: 10.6490\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2322 - val_loss: 10.8043\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0512 - val_loss: 10.6493\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.1353 - val_loss: 10.5614\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1474 - val_loss: 10.7900\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2204 - val_loss: 10.6876\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0144 - val_loss: 10.7994\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0631 - val_loss: 10.6400\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1493 - val_loss: 10.7739\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2465 - val_loss: 10.8084\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3899 - val_loss: 10.6956\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1767 - val_loss: 10.6752\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0372 - val_loss: 10.6822\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0395 - val_loss: 10.7341\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0492 - val_loss: 10.5525\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9846 - val_loss: 10.4901\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2290 - val_loss: 10.4914\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0577 - val_loss: 10.6489\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0386 - val_loss: 10.7240\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0238 - val_loss: 10.9170\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0438 - val_loss: 10.9530\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0553 - val_loss: 10.5932\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0475 - val_loss: 10.5161\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3077 - val_loss: 10.9663\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1964 - val_loss: 10.6796\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2694 - val_loss: 10.8380\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1828 - val_loss: 10.7078\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0272 - val_loss: 10.6539\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2027 - val_loss: 10.7622\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0292 - val_loss: 10.8263\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0539 - val_loss: 10.4685\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0447 - val_loss: 10.6379\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1188 - val_loss: 10.7060\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0982 - val_loss: 10.5890\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0289 - val_loss: 10.7501\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0403 - val_loss: 10.5690\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0323 - val_loss: 10.7335\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0894 - val_loss: 10.7138\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.1257 - val_loss: 10.8620\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0605 - val_loss: 10.8669\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0831 - val_loss: 10.5481\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0453 - val_loss: 10.9285\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1022 - val_loss: 10.7318\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0606 - val_loss: 10.4800\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0373 - val_loss: 10.7699\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0259 - val_loss: 10.7002\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0232 - val_loss: 10.6545\n",
      "7.788502499208612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0817424 ,  2.9780128 ,  0.8902802 ,  2.1889203 ,  1.4394155 ],\n",
       "        [-0.4769123 , -2.3045018 ,  0.5825157 , -2.2376568 , -0.64197856],\n",
       "        [-0.37907726,  2.2984297 , -0.7056434 ,  0.23430349,  0.16449597],\n",
       "        [-0.41197366,  2.3706481 , -1.7816945 ,  2.6886096 ,  0.80522037],\n",
       "        [-0.68378866,  0.02428338,  0.01787698, -1.628269  ,  0.44999048],\n",
       "        [ 0.3437196 , -1.2218002 ,  1.3378663 , -1.2520794 , -1.0812557 ],\n",
       "        [ 1.4439223 , -0.827776  ,  0.7537029 ,  0.62198   , -1.2509274 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.6387322,  2.5258436, -2.3701496, -2.1621914,  2.8753843],\n",
       "       dtype=float32),\n",
       " array([[-0.06682646,  0.25623688,  0.1394079 ,  0.25296515, -0.23508807,\n",
       "          0.03978946,  0.2139449 ,  0.66538095, -0.45425263,  0.72813016],\n",
       "        [ 0.72415364,  0.22388478, -0.38523257, -0.7043643 ,  0.04338961,\n",
       "         -0.18492943, -0.46247217, -0.628875  , -0.28383246, -0.57251287],\n",
       "        [-1.0293243 ,  1.2387242 ,  1.1569691 ,  0.09119947, -0.719187  ,\n",
       "          0.12577946,  0.6101014 ,  1.0981504 , -1.1698076 ,  0.5694642 ],\n",
       "        [-0.16842307, -0.43731648,  0.24705116, -0.41832   , -0.43205842,\n",
       "         -0.4097179 , -0.18518192, -0.5634009 ,  0.46821156, -0.7593979 ],\n",
       "        [-0.75380373, -0.05920107,  0.6515961 ,  0.07602677, -0.13822791,\n",
       "          0.80369127,  0.39808947,  0.61041534, -0.23051135,  0.91169214]],\n",
       "       dtype=float32),\n",
       " array([-1.7857901,  1.908653 ,  1.7623512,  1.7491642, -1.6682564,\n",
       "         1.7494043,  1.803401 ,  1.8334936, -1.8584508,  1.7858492],\n",
       "       dtype=float32),\n",
       " array([[-1.3142247 ],\n",
       "        [ 1.1427082 ],\n",
       "        [ 1.120979  ],\n",
       "        [ 1.459721  ],\n",
       "        [-0.66146004],\n",
       "        [ 1.5398006 ],\n",
       "        [ 1.2651116 ],\n",
       "        [ 1.064705  ],\n",
       "        [-0.99773496],\n",
       "        [ 1.0410106 ]], dtype=float32),\n",
       " array([1.7010081], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_adam_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 528us/step - loss: 600.7637 - val_loss: 641.8189\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 599.6982 - val_loss: 640.3924\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 598.2566 - val_loss: 638.7297\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 596.6470 - val_loss: 636.9828\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 594.9825 - val_loss: 635.1916\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 593.2978 - val_loss: 633.3901\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 591.5871 - val_loss: 631.6023\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 589.9507 - val_loss: 629.7513\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 588.2024 - val_loss: 627.9597\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 586.5186 - val_loss: 626.1600\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 584.8236 - val_loss: 624.3555\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 583.1312 - val_loss: 622.5238\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 581.3963 - val_loss: 620.7066\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 579.7074 - val_loss: 618.8577\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 577.9652 - val_loss: 617.0462\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 576.2660 - val_loss: 615.2012\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 574.5335 - val_loss: 613.3527\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 572.7797 - val_loss: 611.5075\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 571.0528 - val_loss: 609.6023\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 569.2676 - val_loss: 607.7249\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 567.5202 - val_loss: 605.8234\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 565.7224 - val_loss: 603.9476\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 563.9334 - val_loss: 602.0516\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 562.1626 - val_loss: 600.1093\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 560.3458 - val_loss: 598.1688\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 558.5230 - val_loss: 596.2095\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 556.6848 - val_loss: 594.2268\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 554.8263 - val_loss: 592.2419\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 552.9650 - val_loss: 590.2470\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 551.0684 - val_loss: 588.2453\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 549.1728 - val_loss: 586.1950\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 547.2770 - val_loss: 584.1048\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 545.2998 - val_loss: 582.0442\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 543.3635 - val_loss: 579.9494\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 541.3936 - val_loss: 577.8136\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 539.3796 - val_loss: 575.6567\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 537.3422 - val_loss: 573.4974\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 535.3126 - val_loss: 571.2788\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 533.2242 - val_loss: 569.0711\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 531.1551 - val_loss: 566.8097\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 529.0487 - val_loss: 564.5100\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 526.8866 - val_loss: 562.2023\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 524.7075 - val_loss: 559.8735\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 522.4936 - val_loss: 557.5088\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 520.2788 - val_loss: 555.0569\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 517.9900 - val_loss: 552.5951\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 515.6877 - val_loss: 550.1278\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 513.3413 - val_loss: 547.6555\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 511.0371 - val_loss: 545.0805\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 508.6245 - val_loss: 542.4860\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 506.1732 - val_loss: 539.8706\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 503.7141 - val_loss: 537.2051\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 501.2176 - val_loss: 534.4822\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 498.6515 - val_loss: 531.7337\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 496.0671 - val_loss: 528.9315\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 493.4302 - val_loss: 526.0769\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 490.7631 - val_loss: 523.1838\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 488.0537 - val_loss: 520.2480\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 485.3137 - val_loss: 517.2533\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 482.4946 - val_loss: 514.2538\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 479.6780 - val_loss: 511.1761\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 476.8016 - val_loss: 508.0476\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 473.8553 - val_loss: 504.8945\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 470.8932 - val_loss: 501.6609\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 467.8568 - val_loss: 498.3980\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 464.8536 - val_loss: 495.0214\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 461.6372 - val_loss: 491.6884\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 458.5077 - val_loss: 488.2437\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 455.2509 - val_loss: 484.7440\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 451.9789 - val_loss: 481.1447\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 448.6233 - val_loss: 477.5210\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 445.2111 - val_loss: 473.8710\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 441.8422 - val_loss: 470.0860\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 438.2898 - val_loss: 466.3189\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 434.7525 - val_loss: 462.5008\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 431.1498 - val_loss: 458.6245\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 427.5527 - val_loss: 454.6443\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 423.8313 - val_loss: 450.6602\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 420.0781 - val_loss: 446.5966\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 416.2040 - val_loss: 442.4918\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 412.3721 - val_loss: 438.2436\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 408.3645 - val_loss: 434.0007\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 404.3926 - val_loss: 429.6565\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 400.3038 - val_loss: 425.2740\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 396.1847 - val_loss: 420.8348\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 392.0811 - val_loss: 416.2824\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 387.8064 - val_loss: 411.7281\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 383.5413 - val_loss: 407.1197\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 379.1138 - val_loss: 402.5392\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 374.8062 - val_loss: 397.7626\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 370.3376 - val_loss: 392.9242\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 365.7813 - val_loss: 388.0855\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 361.2347 - val_loss: 383.2029\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 356.6285 - val_loss: 378.2557\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 351.9620 - val_loss: 373.2255\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 347.2310 - val_loss: 368.1327\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 342.4387 - val_loss: 363.0061\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 337.6324 - val_loss: 357.7648\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 332.6743 - val_loss: 352.5620\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 327.7765 - val_loss: 347.2499\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 322.8133 - val_loss: 341.8885\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 317.7695 - val_loss: 336.5431\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 312.7191 - val_loss: 331.1625\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 307.6272 - val_loss: 325.7402\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 302.4899 - val_loss: 320.3238\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 297.3471 - val_loss: 314.8105\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 292.2339 - val_loss: 309.2102\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 286.9599 - val_loss: 303.7130\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 281.7651 - val_loss: 298.1281\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 276.4569 - val_loss: 292.5668\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 271.2469 - val_loss: 286.9129\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 265.9310 - val_loss: 281.3237\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 260.6829 - val_loss: 275.6994\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 255.2740 - val_loss: 270.1771\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 250.0526 - val_loss: 264.4960\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 244.7219 - val_loss: 258.8106\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 239.3772 - val_loss: 253.1780\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 234.0718 - val_loss: 247.5342\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 228.6981 - val_loss: 241.9609\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 223.4864 - val_loss: 236.3218\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 218.2148 - val_loss: 230.7113\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 212.9568 - val_loss: 225.1531\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 207.7305 - val_loss: 219.6219\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 202.4790 - val_loss: 214.2093\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 197.3676 - val_loss: 208.7585\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 192.2542 - val_loss: 203.3564\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 187.1426 - val_loss: 198.0696\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 182.1522 - val_loss: 192.7822\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 177.1735 - val_loss: 187.5342\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 172.2381 - val_loss: 182.3320\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 167.3143 - val_loss: 177.2044\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 162.5431 - val_loss: 172.1087\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 157.7452 - val_loss: 167.1308\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 153.0503 - val_loss: 162.2124\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 148.4617 - val_loss: 157.3194\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 143.8543 - val_loss: 152.5961\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 139.4612 - val_loss: 147.8828\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 135.0504 - val_loss: 143.2820\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 130.7293 - val_loss: 138.8102\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 126.5258 - val_loss: 134.3919\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 122.3540 - val_loss: 130.0998\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 118.3736 - val_loss: 125.8284\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 114.3878 - val_loss: 121.6681\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 110.4922 - val_loss: 117.6609\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 106.7474 - val_loss: 113.6891\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 103.0189 - val_loss: 109.8839\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 99.4495 - val_loss: 106.1803\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 96.0139 - val_loss: 102.4956\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 92.5680 - val_loss: 98.9796\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 89.3217 - val_loss: 95.5660\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 86.1017 - val_loss: 92.3033\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 83.0773 - val_loss: 89.0602\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 80.0571 - val_loss: 85.9496\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 77.1783 - val_loss: 82.9061\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 74.3828 - val_loss: 79.9734\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 71.6468 - val_loss: 77.1955\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 69.0286 - val_loss: 74.5425\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 66.6449 - val_loss: 71.8964\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 64.1843 - val_loss: 69.4284\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 61.9233 - val_loss: 67.0367\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 59.6980 - val_loss: 64.7916\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 57.6097 - val_loss: 62.6571\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 55.6726 - val_loss: 60.5461\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 53.7135 - val_loss: 58.5665\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 51.8985 - val_loss: 56.6712\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 50.1510 - val_loss: 54.8595\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 48.4839 - val_loss: 53.1416\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 46.9402 - val_loss: 51.4847\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 45.4006 - val_loss: 49.9538\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 44.0021 - val_loss: 48.4612\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 42.6283 - val_loss: 47.0428\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 41.3511 - val_loss: 45.6761\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 40.1439 - val_loss: 44.3767\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 38.9369 - val_loss: 43.1902\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 37.8714 - val_loss: 41.9960\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 36.7862 - val_loss: 40.9341\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 35.8442 - val_loss: 39.8907\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 34.9038 - val_loss: 38.9003\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 34.0026 - val_loss: 37.9847\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 33.1596 - val_loss: 37.1007\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 32.3829 - val_loss: 36.2431\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 31.6425 - val_loss: 35.4398\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 30.9444 - val_loss: 34.6770\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 30.2597 - val_loss: 33.9886\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 29.6722 - val_loss: 33.2974\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 29.0533 - val_loss: 32.6867\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 28.5117 - val_loss: 32.1108\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 28.0167 - val_loss: 31.5503\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 27.5370 - val_loss: 31.0156\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 27.0675 - val_loss: 30.5343\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 26.6597 - val_loss: 30.0474\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 26.2337 - val_loss: 29.6238\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 25.8720 - val_loss: 29.2083\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 25.5204 - val_loss: 28.8135\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 25.1832 - val_loss: 28.4412\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 24.8699 - val_loss: 28.0913\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 24.5687 - val_loss: 27.7746\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 24.2969 - val_loss: 27.4648\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 24.0272 - val_loss: 27.1751\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 23.7971 - val_loss: 26.8855\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.5550 - val_loss: 26.6247\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 23.3370 - val_loss: 26.3780\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 23.1377 - val_loss: 26.1353\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 22.9388 - val_loss: 25.9195\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.7602 - val_loss: 25.7160\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.5903 - val_loss: 25.5123\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.4370 - val_loss: 25.3171\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.2841 - val_loss: 25.1278\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.1350 - val_loss: 24.9659\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 22.0016 - val_loss: 24.8061\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 21.8772 - val_loss: 24.6550\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.7555 - val_loss: 24.5189\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.6504 - val_loss: 24.3734\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 21.5352 - val_loss: 24.2368\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.4260 - val_loss: 24.1147\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 21.3366 - val_loss: 23.9864\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.2372 - val_loss: 23.8712\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 21.1486 - val_loss: 23.7643\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 21.0713 - val_loss: 23.6534\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.9917 - val_loss: 23.5504\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.9117 - val_loss: 23.4576\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.8453 - val_loss: 23.3715\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.7801 - val_loss: 23.2921\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 20.7196 - val_loss: 23.2151\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.6571 - val_loss: 23.1398\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.6092 - val_loss: 23.0556\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.5427 - val_loss: 22.9823\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.4869 - val_loss: 22.9210\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.4445 - val_loss: 22.8457\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.3838 - val_loss: 22.7834\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.3491 - val_loss: 22.7091\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.2855 - val_loss: 22.6530\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.2417 - val_loss: 22.5946\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.2010 - val_loss: 22.5261\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.1535 - val_loss: 22.4682\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.1102 - val_loss: 22.4173\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.0730 - val_loss: 22.3631\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.0384 - val_loss: 22.3103\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.9952 - val_loss: 22.2697\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.9607 - val_loss: 22.2198\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 19.9252 - val_loss: 22.1668\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.8883 - val_loss: 22.1226\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.8598 - val_loss: 22.0650\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.8211 - val_loss: 22.0194\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.7871 - val_loss: 21.9756\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.7544 - val_loss: 21.9397\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 19.7260 - val_loss: 21.8987\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 19.6939 - val_loss: 21.8609\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.6650 - val_loss: 21.8232\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.6381 - val_loss: 21.7855\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.6126 - val_loss: 21.7431\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.5823 - val_loss: 21.7190\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 19.5576 - val_loss: 21.6766\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.5336 - val_loss: 21.6377\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.5000 - val_loss: 21.6109\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.4748 - val_loss: 21.5798\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.4473 - val_loss: 21.5490\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.4244 - val_loss: 21.5136\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.3999 - val_loss: 21.4839\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.3742 - val_loss: 21.4556\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.3507 - val_loss: 21.4249\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.3277 - val_loss: 21.3909\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.3021 - val_loss: 21.3595\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.2805 - val_loss: 21.3274\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.2556 - val_loss: 21.2975\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.2344 - val_loss: 21.2639\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.2100 - val_loss: 21.2325\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 19.1890 - val_loss: 21.2031\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.1667 - val_loss: 21.1770\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 19.1437 - val_loss: 21.1463\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.1253 - val_loss: 21.1143\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.1015 - val_loss: 21.0863\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.0804 - val_loss: 21.0625\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.0614 - val_loss: 21.0338\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.0367 - val_loss: 21.0101\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.0168 - val_loss: 20.9813\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.9970 - val_loss: 20.9535\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.9797 - val_loss: 20.9283\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.9562 - val_loss: 20.8995\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.9349 - val_loss: 20.8762\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.9138 - val_loss: 20.8558\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.8944 - val_loss: 20.8325\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.8764 - val_loss: 20.8069\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.8545 - val_loss: 20.7833\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.8352 - val_loss: 20.7594\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.8147 - val_loss: 20.7328\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.7971 - val_loss: 20.7103\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.7773 - val_loss: 20.6909\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.7577 - val_loss: 20.6637\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.7406 - val_loss: 20.6355\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.7208 - val_loss: 20.6134\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.6999 - val_loss: 20.5900\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.6810 - val_loss: 20.5696\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 18.6645 - val_loss: 20.5482\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 18.6441 - val_loss: 20.5210\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.6259 - val_loss: 20.5005\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.6069 - val_loss: 20.4831\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.5908 - val_loss: 20.4592\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.5719 - val_loss: 20.4392\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.5540 - val_loss: 20.4110\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.5350 - val_loss: 20.3903\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.5171 - val_loss: 20.3699\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.4983 - val_loss: 20.3454\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.4800 - val_loss: 20.3229\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.4620 - val_loss: 20.2981\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.4457 - val_loss: 20.2723\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.4289 - val_loss: 20.2500\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.4101 - val_loss: 20.2277\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.3927 - val_loss: 20.2102\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.3742 - val_loss: 20.1926\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.3605 - val_loss: 20.1757\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.3412 - val_loss: 20.1529\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 18.3231 - val_loss: 20.1333\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.3073 - val_loss: 20.1118\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.2911 - val_loss: 20.0919\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.2744 - val_loss: 20.0750\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.2573 - val_loss: 20.0528\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.2425 - val_loss: 20.0333\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.2258 - val_loss: 20.0141\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.2104 - val_loss: 19.9958\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.1934 - val_loss: 19.9739\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 18.1778 - val_loss: 19.9534\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.1625 - val_loss: 19.9306\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.1460 - val_loss: 19.9122\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.1291 - val_loss: 19.8947\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.1133 - val_loss: 19.8732\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0979 - val_loss: 19.8522\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.0811 - val_loss: 19.8311\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0668 - val_loss: 19.8111\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.0507 - val_loss: 19.7951\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.0370 - val_loss: 19.7733\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.0195 - val_loss: 19.7550\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.0039 - val_loss: 19.7365\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.9890 - val_loss: 19.7199\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.9739 - val_loss: 19.7010\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.9589 - val_loss: 19.6790\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.9458 - val_loss: 19.6616\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 17.9272 - val_loss: 19.6390\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.9119 - val_loss: 19.6200\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 17.8957 - val_loss: 19.6029\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.8820 - val_loss: 19.5848\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.8655 - val_loss: 19.5695\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.8507 - val_loss: 19.5500\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.8364 - val_loss: 19.5322\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.8199 - val_loss: 19.5123\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.8057 - val_loss: 19.4944\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.7910 - val_loss: 19.4708\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7753 - val_loss: 19.4507\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.7623 - val_loss: 19.4320\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.7479 - val_loss: 19.4138\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7323 - val_loss: 19.4014\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7191 - val_loss: 19.3846\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7028 - val_loss: 19.3655\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6876 - val_loss: 19.3482\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6745 - val_loss: 19.3309\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6592 - val_loss: 19.3121\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.6450 - val_loss: 19.2927\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 13.21 - 0s 87us/step - loss: 17.6297 - val_loss: 19.2720\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.6174 - val_loss: 19.2523\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6023 - val_loss: 19.2337\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5868 - val_loss: 19.2172\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5727 - val_loss: 19.2019\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5603 - val_loss: 19.1814\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5452 - val_loss: 19.1659\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.5321 - val_loss: 19.1540\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5181 - val_loss: 19.1329\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.5027 - val_loss: 19.1165\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.4885 - val_loss: 19.0983\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.4757 - val_loss: 19.0797\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 17.4639 - val_loss: 19.0615\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.4489 - val_loss: 19.0493\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4355 - val_loss: 19.0299\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.4189 - val_loss: 19.0119\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.4071 - val_loss: 18.9940\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.3922 - val_loss: 18.9743\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.3797 - val_loss: 18.9580\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3657 - val_loss: 18.9375\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.3513 - val_loss: 18.9186\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 17.3371 - val_loss: 18.9006\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.3237 - val_loss: 18.8822\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3101 - val_loss: 18.8632\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2964 - val_loss: 18.8453\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2840 - val_loss: 18.8288\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.2690 - val_loss: 18.8134\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 17.2576 - val_loss: 18.7939\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2458 - val_loss: 18.7772\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2303 - val_loss: 18.7616\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2165 - val_loss: 18.7457\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.2043 - val_loss: 18.7294\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1920 - val_loss: 18.7159\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1781 - val_loss: 18.6983\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1648 - val_loss: 18.6817\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1533 - val_loss: 18.6657\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.1386 - val_loss: 18.6496\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1273 - val_loss: 18.6327\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.1123 - val_loss: 18.6153\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 17.1001 - val_loss: 18.5968\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0883 - val_loss: 18.5824\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.0748 - val_loss: 18.5639\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0625 - val_loss: 18.5447\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.0502 - val_loss: 18.5308\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.0367 - val_loss: 18.5149\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.0248 - val_loss: 18.4974\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.0112 - val_loss: 18.4824\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.9983 - val_loss: 18.4655\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9857 - val_loss: 18.4450\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.9724 - val_loss: 18.4301\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9626 - val_loss: 18.4100\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.9476 - val_loss: 18.3964\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.9354 - val_loss: 18.3813\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9236 - val_loss: 18.3636\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9102 - val_loss: 18.3463\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.8973 - val_loss: 18.3294\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8850 - val_loss: 18.3144\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8727 - val_loss: 18.2968\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8615 - val_loss: 18.2798\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8477 - val_loss: 18.2674\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.8352 - val_loss: 18.2532\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.8240 - val_loss: 18.2364\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.8137 - val_loss: 18.2201\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7995 - val_loss: 18.2049\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.7875 - val_loss: 18.1910\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7748 - val_loss: 18.1776\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7634 - val_loss: 18.1617\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.7517 - val_loss: 18.1458\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.7391 - val_loss: 18.1301\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7269 - val_loss: 18.1100\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.7148 - val_loss: 18.0910\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7037 - val_loss: 18.0750\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6894 - val_loss: 18.0599\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6784 - val_loss: 18.0451\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6677 - val_loss: 18.0297\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6555 - val_loss: 18.0161\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6440 - val_loss: 17.9982\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6297 - val_loss: 17.9831\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6184 - val_loss: 17.9638\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6061 - val_loss: 17.9468\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5935 - val_loss: 17.9316\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5825 - val_loss: 17.9198\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5706 - val_loss: 17.9023\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.5589 - val_loss: 17.8875\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.5472 - val_loss: 17.8742\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5344 - val_loss: 17.8581\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.5234 - val_loss: 17.8413\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5103 - val_loss: 17.8218\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 16.4992 - val_loss: 17.8021\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4867 - val_loss: 17.7853\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4741 - val_loss: 17.7688\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4631 - val_loss: 17.7515\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4514 - val_loss: 17.7339\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4396 - val_loss: 17.7185\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4282 - val_loss: 17.7008\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 16.4165 - val_loss: 17.6844\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4063 - val_loss: 17.6717\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 16.3933 - val_loss: 17.6582\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3829 - val_loss: 17.6433\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3717 - val_loss: 17.6276\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3600 - val_loss: 17.6116\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.3497 - val_loss: 17.5943\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3382 - val_loss: 17.5783\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3279 - val_loss: 17.5637\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 16.3164 - val_loss: 17.5453\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 16.3059 - val_loss: 17.5305\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2948 - val_loss: 17.5144\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2830 - val_loss: 17.5000\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2715 - val_loss: 17.4851\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2597 - val_loss: 17.4736\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2502 - val_loss: 17.4604\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2388 - val_loss: 17.4445\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2282 - val_loss: 17.4277\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2172 - val_loss: 17.4111\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2055 - val_loss: 17.3947\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1934 - val_loss: 17.3812\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1837 - val_loss: 17.3663\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1719 - val_loss: 17.3529\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.1615 - val_loss: 17.3391\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1510 - val_loss: 17.3260\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1425 - val_loss: 17.3054\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1290 - val_loss: 17.2929\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1189 - val_loss: 17.2760\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1075 - val_loss: 17.2594\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0960 - val_loss: 17.2460\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0863 - val_loss: 17.2343\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0749 - val_loss: 17.2189\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.0646 - val_loss: 17.2039\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0542 - val_loss: 17.1888\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0433 - val_loss: 17.1733\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0345 - val_loss: 17.1586\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0229 - val_loss: 17.1464\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0126 - val_loss: 17.1334\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 16.0014 - val_loss: 17.1219\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.9916 - val_loss: 17.1049\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.9814 - val_loss: 17.0919\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9694 - val_loss: 17.0744\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9592 - val_loss: 17.0592\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9484 - val_loss: 17.0443\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9379 - val_loss: 17.0305\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9272 - val_loss: 17.0169\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9169 - val_loss: 17.0027\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 15.9065 - val_loss: 16.9902\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 15.8968 - val_loss: 16.9733\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8870 - val_loss: 16.9603\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.8755 - val_loss: 16.9434\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8645 - val_loss: 16.9291\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8540 - val_loss: 16.9144\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8433 - val_loss: 16.9003\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8326 - val_loss: 16.8853\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 15.8218 - val_loss: 16.8714\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8128 - val_loss: 16.8602\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8017 - val_loss: 16.8436\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.7913 - val_loss: 16.8268\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.7815 - val_loss: 16.8109\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7706 - val_loss: 16.7980\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7605 - val_loss: 16.7848\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 15.7516 - val_loss: 16.7706\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7413 - val_loss: 16.7581\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7310 - val_loss: 16.7415\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7213 - val_loss: 16.7302\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.7112 - val_loss: 16.7141\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.7012 - val_loss: 16.6976\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6907 - val_loss: 16.6858\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 88us/step - loss: 15.6817 - val_loss: 16.6759\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.6705 - val_loss: 16.6621\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6600 - val_loss: 16.6475\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.6508 - val_loss: 16.6308\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6399 - val_loss: 16.6153\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6307 - val_loss: 16.5991\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6202 - val_loss: 16.5845\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6109 - val_loss: 16.5704\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.6006 - val_loss: 16.5579\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 15.5906 - val_loss: 16.5461\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5805 - val_loss: 16.5336\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5711 - val_loss: 16.5213\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5618 - val_loss: 16.5088\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5523 - val_loss: 16.4969\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5422 - val_loss: 16.4824\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.5338 - val_loss: 16.4680\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5238 - val_loss: 16.4546\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5125 - val_loss: 16.4399\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5033 - val_loss: 16.4256\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4949 - val_loss: 16.4104\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 15.4851 - val_loss: 16.3942\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4746 - val_loss: 16.3808\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 15.4642 - val_loss: 16.3670\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4553 - val_loss: 16.3546\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4463 - val_loss: 16.3387\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4356 - val_loss: 16.3257\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4256 - val_loss: 16.3127\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4163 - val_loss: 16.2985\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4067 - val_loss: 16.2841\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.3973 - val_loss: 16.2696\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3895 - val_loss: 16.2550\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3792 - val_loss: 16.2425\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.3690 - val_loss: 16.2295\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3587 - val_loss: 16.2157\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3491 - val_loss: 16.2032\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3406 - val_loss: 16.1909\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3315 - val_loss: 16.1743\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.3218 - val_loss: 16.1611\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3121 - val_loss: 16.1463\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.3036 - val_loss: 16.1370\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.2940 - val_loss: 16.1227\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.2833 - val_loss: 16.1093\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.2758 - val_loss: 16.0946\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.2652 - val_loss: 16.0811\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.2566 - val_loss: 16.0670\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.2473 - val_loss: 16.0518\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.2387 - val_loss: 16.0380\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.2289 - val_loss: 16.0233\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.2189 - val_loss: 16.0087\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.2100 - val_loss: 15.9973\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2017 - val_loss: 15.9816\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1922 - val_loss: 15.9699\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.1820 - val_loss: 15.9557\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.1721 - val_loss: 15.9435\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1639 - val_loss: 15.9309\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1553 - val_loss: 15.9171\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.1463 - val_loss: 15.9030\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.1369 - val_loss: 15.8903\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.1295 - val_loss: 15.8801\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.1189 - val_loss: 15.8656\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1092 - val_loss: 15.8524\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0991 - val_loss: 15.8402\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.0913 - val_loss: 15.8267\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.0837 - val_loss: 15.8121\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.0720 - val_loss: 15.8001\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.0642 - val_loss: 15.7859\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.0550 - val_loss: 15.7739\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.0456 - val_loss: 15.7623\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.0372 - val_loss: 15.7520\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.0288 - val_loss: 15.7385\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.0207 - val_loss: 15.7287\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0110 - val_loss: 15.7167\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.0024 - val_loss: 15.7054\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9927 - val_loss: 15.6918\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.9839 - val_loss: 15.6807\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9766 - val_loss: 15.6705\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 79us/step - loss: 14.9674 - val_loss: 15.6558\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.9582 - val_loss: 15.6410\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.9499 - val_loss: 15.6299\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.9400 - val_loss: 15.6178\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.9320 - val_loss: 15.6033\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.9221 - val_loss: 15.5916\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9141 - val_loss: 15.5784\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.9045 - val_loss: 15.5659\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8966 - val_loss: 15.5519\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8877 - val_loss: 15.5398\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8795 - val_loss: 15.5272\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8700 - val_loss: 15.5159\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8618 - val_loss: 15.5047\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8545 - val_loss: 15.4940\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8451 - val_loss: 15.4805\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8370 - val_loss: 15.4667\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8287 - val_loss: 15.4557\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8196 - val_loss: 15.4432\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8113 - val_loss: 15.4329\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8052 - val_loss: 15.4186\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7938 - val_loss: 15.4076\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7855 - val_loss: 15.3939\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7768 - val_loss: 15.3817\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.7686 - val_loss: 15.3710\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7602 - val_loss: 15.3568\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7528 - val_loss: 15.3468\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7436 - val_loss: 15.3364\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7354 - val_loss: 15.3222\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.7269 - val_loss: 15.3092\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7177 - val_loss: 15.2966\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7093 - val_loss: 15.2835\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7002 - val_loss: 15.2723\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.6955 - val_loss: 15.2592\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6861 - val_loss: 15.2478\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6757 - val_loss: 15.2360\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6674 - val_loss: 15.2221\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6601 - val_loss: 15.2074\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6513 - val_loss: 15.1960\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.6427 - val_loss: 15.1840\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6351 - val_loss: 15.1745\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.6270 - val_loss: 15.1625\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.6195 - val_loss: 15.1485\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6100 - val_loss: 15.1373\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6027 - val_loss: 15.1273\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5941 - val_loss: 15.1172\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5859 - val_loss: 15.1057\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 14.5794 - val_loss: 15.0973\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5698 - val_loss: 15.0843\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5620 - val_loss: 15.0697\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5532 - val_loss: 15.0552\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.5444 - val_loss: 15.0435\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5357 - val_loss: 15.0334\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 14.5280 - val_loss: 15.0220\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5196 - val_loss: 15.0122\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5128 - val_loss: 14.9994\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5036 - val_loss: 14.9879\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4953 - val_loss: 14.9781\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4873 - val_loss: 14.9668\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4790 - val_loss: 14.9556\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.4716 - val_loss: 14.9423\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4639 - val_loss: 14.9294\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4565 - val_loss: 14.9175\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4489 - val_loss: 14.9075\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4392 - val_loss: 14.8962\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4323 - val_loss: 14.8866\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4248 - val_loss: 14.8732\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4164 - val_loss: 14.8619\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 14.4074 - val_loss: 14.8513\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.4002 - val_loss: 14.8407\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3921 - val_loss: 14.8303\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3841 - val_loss: 14.8217\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3763 - val_loss: 14.8092\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3682 - val_loss: 14.7970\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3597 - val_loss: 14.7853\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3523 - val_loss: 14.7741\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3447 - val_loss: 14.7634\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 14.3371 - val_loss: 14.7517\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3302 - val_loss: 14.7416\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3216 - val_loss: 14.7302\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3136 - val_loss: 14.7222\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3065 - val_loss: 14.7132\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 14.2991 - val_loss: 14.7027\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2912 - val_loss: 14.6900\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 14.2836 - val_loss: 14.6801\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.2751 - val_loss: 14.6700\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2678 - val_loss: 14.6571\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2609 - val_loss: 14.6448\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.2526 - val_loss: 14.6342\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.2462 - val_loss: 14.6268\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.2375 - val_loss: 14.6146\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2305 - val_loss: 14.6037\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.2224 - val_loss: 14.5942\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2149 - val_loss: 14.5837\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2074 - val_loss: 14.5740\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.2008 - val_loss: 14.5600\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1916 - val_loss: 14.5509\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1848 - val_loss: 14.5427\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1766 - val_loss: 14.5339\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1709 - val_loss: 14.5243\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.1632 - val_loss: 14.5121\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1550 - val_loss: 14.5022\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1494 - val_loss: 14.4941\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1402 - val_loss: 14.4833\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.1319 - val_loss: 14.4740\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.1244 - val_loss: 14.4642\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1180 - val_loss: 14.4538\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1101 - val_loss: 14.4408\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.1024 - val_loss: 14.4298\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.0949 - val_loss: 14.4201\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.0876 - val_loss: 14.4107\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.0820 - val_loss: 14.4014\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.0728 - val_loss: 14.3904\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0666 - val_loss: 14.3801\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 14.0585 - val_loss: 14.3675\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.0517 - val_loss: 14.3572\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 14.0437 - val_loss: 14.3454\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.0370 - val_loss: 14.3366\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.0302 - val_loss: 14.3259\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0210 - val_loss: 14.3170\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.0144 - val_loss: 14.3057\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0075 - val_loss: 14.2963\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.0006 - val_loss: 14.2878\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9929 - val_loss: 14.2785\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9860 - val_loss: 14.2692\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.9782 - val_loss: 14.2609\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9714 - val_loss: 14.2492\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9633 - val_loss: 14.2374\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9564 - val_loss: 14.2258\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9501 - val_loss: 14.2155\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9416 - val_loss: 14.2053\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9342 - val_loss: 14.1942\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9263 - val_loss: 14.1830\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9200 - val_loss: 14.1737\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9124 - val_loss: 14.1636\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.9061 - val_loss: 14.1516\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8985 - val_loss: 14.1421\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8911 - val_loss: 14.1337\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8837 - val_loss: 14.1231\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8781 - val_loss: 14.1117\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8698 - val_loss: 14.1030\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8640 - val_loss: 14.0948\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8559 - val_loss: 14.0852\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8493 - val_loss: 14.0742\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8421 - val_loss: 14.0651\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.8347 - val_loss: 14.0553\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8278 - val_loss: 14.0460\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 13.8209 - val_loss: 14.0378\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.8137 - val_loss: 14.0299\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 13.8081 - val_loss: 14.0202\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8000 - val_loss: 14.0095\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7925 - val_loss: 14.0003\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7857 - val_loss: 13.9917\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 13.7799 - val_loss: 13.9835\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.7739 - val_loss: 13.9734\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7656 - val_loss: 13.9661\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7593 - val_loss: 13.9581\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7529 - val_loss: 13.9485\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7456 - val_loss: 13.9381\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7384 - val_loss: 13.9271\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7326 - val_loss: 13.9174\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7248 - val_loss: 13.9106\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7191 - val_loss: 13.8996\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7109 - val_loss: 13.8903\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7042 - val_loss: 13.8818\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.6971 - val_loss: 13.8724\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6905 - val_loss: 13.8636\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6829 - val_loss: 13.8547\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6772 - val_loss: 13.8441\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6692 - val_loss: 13.8357\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6631 - val_loss: 13.8286\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6564 - val_loss: 13.8198\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6493 - val_loss: 13.8084\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6417 - val_loss: 13.7992\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6352 - val_loss: 13.7908\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6297 - val_loss: 13.7832\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.6224 - val_loss: 13.7747\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.6153 - val_loss: 13.7664\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6091 - val_loss: 13.7585\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 13.6025 - val_loss: 13.7479\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5956 - val_loss: 13.7380\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5886 - val_loss: 13.7286\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5822 - val_loss: 13.7193\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5785 - val_loss: 13.7144\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5704 - val_loss: 13.7019\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5619 - val_loss: 13.6924\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5558 - val_loss: 13.6832\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5489 - val_loss: 13.6746\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5421 - val_loss: 13.6655\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.5365 - val_loss: 13.6551\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 13.5292 - val_loss: 13.6454\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5226 - val_loss: 13.6347\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5162 - val_loss: 13.6265\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 13.5098 - val_loss: 13.6205\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 13.5027 - val_loss: 13.6121\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 13.4972 - val_loss: 13.6004\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4902 - val_loss: 13.5921\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4842 - val_loss: 13.5829\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4777 - val_loss: 13.5732\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4721 - val_loss: 13.5635\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 13.4640 - val_loss: 13.5560\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4594 - val_loss: 13.5464\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4512 - val_loss: 13.5399\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4450 - val_loss: 13.5313\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 13.4396 - val_loss: 13.5259\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4364 - val_loss: 13.5150\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.4257 - val_loss: 13.5078\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.4191 - val_loss: 13.5018\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4130 - val_loss: 13.4944\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4060 - val_loss: 13.4852\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.4000 - val_loss: 13.4773\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 13.3950 - val_loss: 13.4682\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3872 - val_loss: 13.4593\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3817 - val_loss: 13.4504\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3750 - val_loss: 13.4439\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 13.3698 - val_loss: 13.4351\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3631 - val_loss: 13.4283\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3568 - val_loss: 13.4205\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3506 - val_loss: 13.4105\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3442 - val_loss: 13.4009\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3378 - val_loss: 13.3934\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.3329 - val_loss: 13.3837\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3244 - val_loss: 13.3781\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3185 - val_loss: 13.3726\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3123 - val_loss: 13.3643\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3062 - val_loss: 13.3588\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.2994 - val_loss: 13.3502\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2942 - val_loss: 13.3411\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2871 - val_loss: 13.3330\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 82us/step - loss: 13.2825 - val_loss: 13.3210\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.2746 - val_loss: 13.3149\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2691 - val_loss: 13.3082\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 13.2624 - val_loss: 13.2994\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2569 - val_loss: 13.2905\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 13.2504 - val_loss: 13.2822\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2457 - val_loss: 13.2734\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2377 - val_loss: 13.2668\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2331 - val_loss: 13.2605\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2264 - val_loss: 13.2514\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.2206 - val_loss: 13.2425\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2140 - val_loss: 13.2336\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2075 - val_loss: 13.2253\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2011 - val_loss: 13.2146\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1953 - val_loss: 13.2066\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1892 - val_loss: 13.1987\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1844 - val_loss: 13.1902\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1765 - val_loss: 13.1841\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 13.1717 - val_loss: 13.1781\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1655 - val_loss: 13.1699\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1589 - val_loss: 13.1635\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1538 - val_loss: 13.1565\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 13.1484 - val_loss: 13.1479\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 13.1412 - val_loss: 13.1421\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 13.1354 - val_loss: 13.1340\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1305 - val_loss: 13.1255\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.1232 - val_loss: 13.1177\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.1180 - val_loss: 13.1096\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1123 - val_loss: 13.1008\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1072 - val_loss: 13.0944\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0994 - val_loss: 13.0877\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0945 - val_loss: 13.0814\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.0880 - val_loss: 13.0722\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0821 - val_loss: 13.0643\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0764 - val_loss: 13.0555\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0703 - val_loss: 13.0475\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0644 - val_loss: 13.0390\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0584 - val_loss: 13.0321\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0535 - val_loss: 13.0254\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0466 - val_loss: 13.0167\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 13.0415 - val_loss: 13.0080\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0357 - val_loss: 13.0001\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0302 - val_loss: 12.9931\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.0234 - val_loss: 12.9857\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0172 - val_loss: 12.9780\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0126 - val_loss: 12.9705\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0050 - val_loss: 12.9633\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 12.9991 - val_loss: 12.9569\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9942 - val_loss: 12.9508\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9875 - val_loss: 12.9431\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.9820 - val_loss: 12.9351\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9780 - val_loss: 12.9260\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.9710 - val_loss: 12.9191\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9647 - val_loss: 12.9108\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9592 - val_loss: 12.9041\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9531 - val_loss: 12.8969\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9473 - val_loss: 12.8906\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 12.9418 - val_loss: 12.8849\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9358 - val_loss: 12.8782\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9310 - val_loss: 12.8696\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9252 - val_loss: 12.8641\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9186 - val_loss: 12.8568\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9132 - val_loss: 12.8494\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9080 - val_loss: 12.8432\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9022 - val_loss: 12.8351\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.8962 - val_loss: 12.8290\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.8914 - val_loss: 12.8227\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8850 - val_loss: 12.8138\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8790 - val_loss: 12.8067\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8739 - val_loss: 12.8004\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8680 - val_loss: 12.7953\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.8625 - val_loss: 12.7905\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8570 - val_loss: 12.7859\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.8516 - val_loss: 12.7792\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.8457 - val_loss: 12.7720\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.8429 - val_loss: 12.7642\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 12.8343 - val_loss: 12.7574\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.8299 - val_loss: 12.7507\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8254 - val_loss: 12.7432\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8179 - val_loss: 12.7368\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8126 - val_loss: 12.7306\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8070 - val_loss: 12.7247\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8021 - val_loss: 12.7181\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7960 - val_loss: 12.7118\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7904 - val_loss: 12.7058\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.7854 - val_loss: 12.6981\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7794 - val_loss: 12.6934\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7746 - val_loss: 12.6848\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7694 - val_loss: 12.6792\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7628 - val_loss: 12.6731\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 12.7577 - val_loss: 12.6661\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 12.7517 - val_loss: 12.6568\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7459 - val_loss: 12.6500\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7405 - val_loss: 12.6440\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7350 - val_loss: 12.6371\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.7311 - val_loss: 12.6318\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7236 - val_loss: 12.6263\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7189 - val_loss: 12.6189\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7133 - val_loss: 12.6104\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7087 - val_loss: 12.6025\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7025 - val_loss: 12.5978\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 12.6978 - val_loss: 12.5927\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.6917 - val_loss: 12.5862\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 12.6859 - val_loss: 12.5788\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6807 - val_loss: 12.5707\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6757 - val_loss: 12.5642\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6699 - val_loss: 12.5582\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.6643 - val_loss: 12.5503\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6607 - val_loss: 12.5415\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.6560 - val_loss: 12.5367\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.6477 - val_loss: 12.5300\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.6428 - val_loss: 12.5227\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 12.6382 - val_loss: 12.5152\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6329 - val_loss: 12.5094\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.6280 - val_loss: 12.5045\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6229 - val_loss: 12.4978\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.6167 - val_loss: 12.4910\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6110 - val_loss: 12.4845\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.6055 - val_loss: 12.4785\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 12.6008 - val_loss: 12.4717\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5955 - val_loss: 12.4679\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.5913 - val_loss: 12.4580\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5846 - val_loss: 12.4519\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5797 - val_loss: 12.4463\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.5743 - val_loss: 12.4410\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 12.5690 - val_loss: 12.4357\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5639 - val_loss: 12.4294\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5585 - val_loss: 12.4234\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5532 - val_loss: 12.4188\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.5484 - val_loss: 12.4122\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5432 - val_loss: 12.4057\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.5381 - val_loss: 12.4005\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5327 - val_loss: 12.3948\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5274 - val_loss: 12.3888\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5227 - val_loss: 12.3836\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5180 - val_loss: 12.3754\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5145 - val_loss: 12.3670\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5070 - val_loss: 12.3622\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.5022 - val_loss: 12.3554\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4981 - val_loss: 12.3489\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4915 - val_loss: 12.3446\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4865 - val_loss: 12.3384\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4819 - val_loss: 12.3303\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.4762 - val_loss: 12.3246\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.4707 - val_loss: 12.3181\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4655 - val_loss: 12.3128\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4607 - val_loss: 12.3079\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4556 - val_loss: 12.3012\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4513 - val_loss: 12.2938\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4451 - val_loss: 12.2871\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4400 - val_loss: 12.2808\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4346 - val_loss: 12.2756\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 12.4299 - val_loss: 12.2717\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.4251 - val_loss: 12.2650\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4196 - val_loss: 12.2590\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4145 - val_loss: 12.2539\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4097 - val_loss: 12.2468\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4052 - val_loss: 12.2409\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 12.4014 - val_loss: 12.2344\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3943 - val_loss: 12.2296\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3909 - val_loss: 12.2238\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3847 - val_loss: 12.2186\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3834 - val_loss: 12.2101\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3757 - val_loss: 12.2074\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3700 - val_loss: 12.2020\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3645 - val_loss: 12.1953\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3600 - val_loss: 12.1895\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.3545 - val_loss: 12.1847\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3512 - val_loss: 12.1775\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3456 - val_loss: 12.1708\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3404 - val_loss: 12.1683\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3353 - val_loss: 12.1649\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3311 - val_loss: 12.1592\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3247 - val_loss: 12.1533\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3211 - val_loss: 12.1455\n",
      "12.377374608637924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.11380088, -0.42094195,  0.7532695 , -0.61172146,  0.5396082 ],\n",
       "        [-0.11679897,  0.1834787 ,  0.14322117, -0.62558264, -0.22440511],\n",
       "        [-0.10415284, -0.0633937 , -0.20125364, -0.5518582 ,  0.29965374],\n",
       "        [ 0.16430552,  0.34165844, -0.32889494,  0.38772848,  0.46921068],\n",
       "        [-0.10892204,  0.15316896,  0.10988298, -0.37657747,  0.244739  ],\n",
       "        [-0.32914495, -0.15095642,  0.297942  ,  0.17218754,  0.1948211 ],\n",
       "        [-0.00881684, -0.12983917,  0.05096454,  0.4963237 , -0.42085904]],\n",
       "       dtype=float32),\n",
       " array([-0.5659236 , -1.2312715 ,  0.70134324,  0.4800585 , -0.22665653],\n",
       "       dtype=float32),\n",
       " array([[ 0.11289884, -0.69982374, -0.47021228,  0.19327365, -0.98451114,\n",
       "          0.74613345, -0.3855398 , -0.53793913, -0.29389274,  0.47359297],\n",
       "        [ 0.8753245 , -0.25687602,  0.18520978,  0.41818953, -0.44019747,\n",
       "          1.2134038 ,  0.69230264, -0.5812103 ,  0.34436142,  0.717147  ],\n",
       "        [-0.6743195 ,  0.83480436,  0.01753288,  0.32758728,  0.8011152 ,\n",
       "         -0.94829917, -0.02858089, -0.3164826 ,  0.14248292,  0.29173017],\n",
       "        [-0.5842652 , -0.01573697,  0.58365834, -0.19947143, -0.01196591,\n",
       "         -0.8559829 , -0.43467703,  0.5264103 , -0.6992765 , -0.36131263],\n",
       "        [ 0.7566992 , -0.23991704, -0.48804393,  0.47908777,  0.3387924 ,\n",
       "          0.06219549,  0.67421293, -0.4865354 , -0.08114927, -0.1490944 ]],\n",
       "       dtype=float32),\n",
       " array([-1.0729455 ,  0.7951752 ,  0.47992632, -0.6240131 ,  0.94470584,\n",
       "        -1.2896122 , -0.3221486 ,  0.5035472 , -0.29761568, -0.96117985],\n",
       "       dtype=float32),\n",
       " array([[-1.7172198 ],\n",
       "        [ 1.2400684 ],\n",
       "        [ 0.71089643],\n",
       "        [-0.84234184],\n",
       "        [ 1.42729   ],\n",
       "        [-2.1840718 ],\n",
       "        [-0.6182084 ],\n",
       "        [ 0.8985152 ],\n",
       "        [-0.42261276],\n",
       "        [-1.2895725 ]], dtype=float32),\n",
       " array([1.2529279], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, sgd, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sgd_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 587us/step - loss: 572.6298 - val_loss: 540.9955\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 473.8786 - val_loss: 422.1497\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 370.3304 - val_loss: 302.9728\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 261.3622 - val_loss: 182.7550\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 149.1655 - val_loss: 84.8689\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 68.3351 - val_loss: 33.4405\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 33.6223 - val_loss: 23.2488\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 25.4915 - val_loss: 17.9369\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 21.4291 - val_loss: 14.6194\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.9425 - val_loss: 15.2024\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.2951 - val_loss: 18.5591\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.9768 - val_loss: 13.7558\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9349 - val_loss: 11.8135\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.6772 - val_loss: 10.9428\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.5507 - val_loss: 11.1375\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.9241 - val_loss: 11.7549\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.2368 - val_loss: 10.2712\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2410 - val_loss: 10.8542\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.7808 - val_loss: 10.6484\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 10.8695 - val_loss: 9.2501\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.6108 - val_loss: 9.4477\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.8046 - val_loss: 10.1383\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.5936 - val_loss: 9.7603\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.3851 - val_loss: 10.7815\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.2211 - val_loss: 12.1194\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.7457 - val_loss: 10.9365\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.7742 - val_loss: 11.2082\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.4258 - val_loss: 10.6068\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0337 - val_loss: 10.2634\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.2289 - val_loss: 10.2178\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7771 - val_loss: 10.0779\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.1210 - val_loss: 10.1171\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9601 - val_loss: 10.9231\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.3386 - val_loss: 10.5372\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7192 - val_loss: 11.6943\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6414 - val_loss: 9.9531\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.0024 - val_loss: 11.3337\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3939 - val_loss: 11.8208\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7113 - val_loss: 12.7019\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4894 - val_loss: 10.1654\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.8793 - val_loss: 11.3497\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4329 - val_loss: 10.3804\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4226 - val_loss: 13.5061\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.1862 - val_loss: 10.7874\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.7195 - val_loss: 10.1210\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1424 - val_loss: 12.4822\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.7139 - val_loss: 10.9937\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2747 - val_loss: 11.0839\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5181 - val_loss: 10.5523\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8324 - val_loss: 11.4207\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2202 - val_loss: 12.7314\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9803 - val_loss: 10.3650\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6944 - val_loss: 12.0575\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.8175 - val_loss: 11.1276\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0599 - val_loss: 10.3335\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0321 - val_loss: 11.4973\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1117 - val_loss: 14.0253\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8314 - val_loss: 13.8093\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4563 - val_loss: 11.1081\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.7082 - val_loss: 10.7231\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8623 - val_loss: 10.2534\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8107 - val_loss: 12.9283\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0767 - val_loss: 14.1460\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8500 - val_loss: 11.4853\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4654 - val_loss: 10.5086\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7313 - val_loss: 12.7784\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2150 - val_loss: 11.8758\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 7.9491 - val_loss: 11.1131\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2887 - val_loss: 12.2274\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1602 - val_loss: 10.3124\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9453 - val_loss: 11.0328\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.8296 - val_loss: 10.8918\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2667 - val_loss: 10.5710\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1486 - val_loss: 10.6020\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1316 - val_loss: 10.5330\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9547 - val_loss: 10.4985\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1451 - val_loss: 12.6315\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8254 - val_loss: 10.9439\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7589 - val_loss: 11.4315\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0196 - val_loss: 10.7822\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9268 - val_loss: 12.3128\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4744 - val_loss: 12.0006\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5285 - val_loss: 13.5307\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3898 - val_loss: 12.9436\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7213 - val_loss: 10.6538\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.5882 - val_loss: 12.2051\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0942 - val_loss: 10.1308\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.7882 - val_loss: 10.8533\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7591 - val_loss: 10.7795\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0366 - val_loss: 12.8198\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8138 - val_loss: 10.7695\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.8601 - val_loss: 11.9980\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6420 - val_loss: 11.7240\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9029 - val_loss: 10.5507\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5795 - val_loss: 11.3783\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4974 - val_loss: 11.1050\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6794 - val_loss: 10.8877\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5328 - val_loss: 11.1864\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6145 - val_loss: 10.9936\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6758 - val_loss: 11.7119\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6171 - val_loss: 12.2717\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.8871 - val_loss: 11.4243\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2689 - val_loss: 11.3032\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8671 - val_loss: 10.9610\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8402 - val_loss: 12.9073\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5956 - val_loss: 13.8848\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5590 - val_loss: 11.4364\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9282 - val_loss: 10.8304\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5279 - val_loss: 11.7770\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.4289 - val_loss: 11.0624\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.1251 - val_loss: 11.0942\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7146 - val_loss: 11.0726\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6420 - val_loss: 11.3418\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4823 - val_loss: 10.7223\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7948 - val_loss: 10.7601\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3459 - val_loss: 11.9899\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4799 - val_loss: 11.7856\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0810 - val_loss: 10.6851\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6850 - val_loss: 11.6780\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5027 - val_loss: 10.9087\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.3098 - val_loss: 10.9240\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0061 - val_loss: 10.7786\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.3848 - val_loss: 11.9066\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5130 - val_loss: 11.3319\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9161 - val_loss: 12.6309\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4697 - val_loss: 10.9172\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.3819 - val_loss: 11.6210\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3916 - val_loss: 10.8326\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8842 - val_loss: 11.9981\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8937 - val_loss: 10.7626\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2477 - val_loss: 10.5958\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2889 - val_loss: 12.3582\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5094 - val_loss: 15.8740\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9943 - val_loss: 10.8726\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3654 - val_loss: 10.7534\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2594 - val_loss: 10.8278\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7500 - val_loss: 10.6457\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5863 - val_loss: 12.6329\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.8361 - val_loss: 10.7655\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.2831 - val_loss: 10.8240\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7296 - val_loss: 11.2541\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5995 - val_loss: 11.0003\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9238 - val_loss: 11.2194\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6998 - val_loss: 11.3649\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 7.9495 - val_loss: 10.4724\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8034 - val_loss: 10.3985\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7539 - val_loss: 11.3069\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0025 - val_loss: 11.4638\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6788 - val_loss: 10.6381\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4644 - val_loss: 10.3505\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.1472 - val_loss: 10.3285\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4156 - val_loss: 11.0320\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5627 - val_loss: 10.6087\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5260 - val_loss: 10.8716\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8440 - val_loss: 13.8207\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6338 - val_loss: 12.3209\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3006 - val_loss: 11.7601\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5939 - val_loss: 10.8633\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2388 - val_loss: 11.9646\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5009 - val_loss: 11.6617\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7221 - val_loss: 11.4995\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4492 - val_loss: 11.8587\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5870 - val_loss: 10.5682\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4981 - val_loss: 10.8192\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5282 - val_loss: 12.2877\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7069 - val_loss: 11.2686\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7113 - val_loss: 11.3034\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2774 - val_loss: 11.1463\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4112 - val_loss: 12.2265\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5588 - val_loss: 13.8608\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5217 - val_loss: 10.3752\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9031 - val_loss: 10.4093\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5890 - val_loss: 11.6985\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6520 - val_loss: 10.6650\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.0656 - val_loss: 11.5784\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.1677 - val_loss: 10.7514\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6630 - val_loss: 10.2039\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3123 - val_loss: 12.4544\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5104 - val_loss: 14.2655\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4604 - val_loss: 13.4867\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1905 - val_loss: 10.6760\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7276 - val_loss: 10.3351\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4925 - val_loss: 10.1400\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5677 - val_loss: 10.9654\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6281 - val_loss: 14.1335\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0114 - val_loss: 10.4200\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1528 - val_loss: 10.3776\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1227 - val_loss: 10.5290\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3977 - val_loss: 10.6586\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5874 - val_loss: 10.0306\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5907 - val_loss: 10.3549\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4442 - val_loss: 10.8223\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5529 - val_loss: 11.0107\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3425 - val_loss: 10.7390\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0606 - val_loss: 10.5544\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1855 - val_loss: 10.1602\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8662 - val_loss: 10.4147\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7257 - val_loss: 10.3917\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1588 - val_loss: 9.9088\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7541 - val_loss: 10.4054\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5953 - val_loss: 10.9166\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7480 - val_loss: 10.0338\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2400 - val_loss: 11.3828\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5857 - val_loss: 11.0785\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4627 - val_loss: 10.4025\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7603 - val_loss: 10.4249\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0787 - val_loss: 12.6586\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5670 - val_loss: 10.1361\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6229 - val_loss: 11.6789\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6667 - val_loss: 11.6027\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.5448 - val_loss: 11.8506\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.6603 - val_loss: 11.9182\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6611 - val_loss: 10.8983\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9603 - val_loss: 10.2939\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6158 - val_loss: 10.3161\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3728 - val_loss: 12.5104\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4533 - val_loss: 10.6064\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8983 - val_loss: 10.6301\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3174 - val_loss: 10.5157\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4945 - val_loss: 10.3707\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.4666 - val_loss: 10.3464\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.3618 - val_loss: 12.2057\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.4042 - val_loss: 10.8368\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9449 - val_loss: 12.7899\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.6102 - val_loss: 11.1360\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6872 - val_loss: 11.6701\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2570 - val_loss: 10.3954\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0123 - val_loss: 9.9633\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3968 - val_loss: 10.4457\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8930 - val_loss: 12.8510\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7046 - val_loss: 11.7797\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4015 - val_loss: 10.5393\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5444 - val_loss: 10.2720\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3009 - val_loss: 11.4733\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3888 - val_loss: 10.8074\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1335 - val_loss: 10.3020\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1617 - val_loss: 10.4908\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4705 - val_loss: 10.5976\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5023 - val_loss: 10.6772\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6413 - val_loss: 11.0340\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5256 - val_loss: 11.3826\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4203 - val_loss: 11.3436\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2538 - val_loss: 10.2071\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8914 - val_loss: 10.4615\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5090 - val_loss: 10.7600\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0489 - val_loss: 10.5253\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5679 - val_loss: 11.8927\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1668 - val_loss: 10.3840\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4094 - val_loss: 11.1689\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8124 - val_loss: 10.1480\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.8229 - val_loss: 10.7727\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1459 - val_loss: 10.1818\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6373 - val_loss: 10.2964\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4135 - val_loss: 11.8681\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9739 - val_loss: 10.2407\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5764 - val_loss: 11.7864\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6401 - val_loss: 10.0555\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1427 - val_loss: 10.5426\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6714 - val_loss: 12.4679\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5443 - val_loss: 9.9968\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1859 - val_loss: 11.4292\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9835 - val_loss: 11.7332\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3337 - val_loss: 10.5584\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1945 - val_loss: 10.1667\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2805 - val_loss: 10.7330\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6746 - val_loss: 11.6687\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8248 - val_loss: 10.5159\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5696 - val_loss: 10.3760\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4554 - val_loss: 11.8207\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4213 - val_loss: 11.1851\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5252 - val_loss: 10.0971\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2149 - val_loss: 10.1889\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4637 - val_loss: 11.0453\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8728 - val_loss: 10.8026\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6544 - val_loss: 10.0169\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3475 - val_loss: 10.5793\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.3024 - val_loss: 12.5926\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6254 - val_loss: 10.6557\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4022 - val_loss: 9.8849\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4775 - val_loss: 12.6208\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3802 - val_loss: 9.9279\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1658 - val_loss: 10.1735\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2059 - val_loss: 13.9698\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8492 - val_loss: 10.9443\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1607 - val_loss: 11.0166\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3119 - val_loss: 10.6473\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.4386 - val_loss: 11.3975\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5214 - val_loss: 10.5134\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4133 - val_loss: 13.3134\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7574 - val_loss: 10.3813\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.1460 - val_loss: 11.0601\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7049 - val_loss: 10.0440\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3529 - val_loss: 10.3792\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7785 - val_loss: 10.1196\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4553 - val_loss: 10.2496\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6037 - val_loss: 10.5404\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3282 - val_loss: 11.0378\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.3479 - val_loss: 10.3309\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.3178 - val_loss: 11.5167\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6300 - val_loss: 10.5697\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0434 - val_loss: 10.6898\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1930 - val_loss: 9.9564\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7208 - val_loss: 10.6082\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3634 - val_loss: 10.3165\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.1431 - val_loss: 10.5518\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.6994 - val_loss: 10.2090\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.3865 - val_loss: 10.6076\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0473 - val_loss: 10.3204\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5899 - val_loss: 10.1111\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.5350 - val_loss: 10.2457\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9675 - val_loss: 11.2386\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2831 - val_loss: 10.4202\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6088 - val_loss: 10.6580\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5869 - val_loss: 11.0051\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0555 - val_loss: 11.6303\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4421 - val_loss: 10.8027\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2727 - val_loss: 10.5822\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4608 - val_loss: 12.3660\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4029 - val_loss: 10.1521\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.3145 - val_loss: 10.7725\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2299 - val_loss: 12.7386\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4556 - val_loss: 10.4722\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3338 - val_loss: 10.0468\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2268 - val_loss: 11.4460\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6478 - val_loss: 10.4189\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3082 - val_loss: 9.6923\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6663 - val_loss: 10.0574\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4533 - val_loss: 10.4804\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1030 - val_loss: 14.9086\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8625 - val_loss: 11.4332\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3412 - val_loss: 11.7516\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2392 - val_loss: 10.3195\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8023 - val_loss: 10.2044\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.6136 - val_loss: 10.1023\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3532 - val_loss: 10.0878\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2210 - val_loss: 11.5951\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4064 - val_loss: 10.2295\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2048 - val_loss: 10.6556\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3816 - val_loss: 11.9573\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7680 - val_loss: 10.3402\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6500 - val_loss: 10.3710\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4115 - val_loss: 11.3928\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5278 - val_loss: 9.9731\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0561 - val_loss: 10.2772\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2461 - val_loss: 10.2900\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3963 - val_loss: 12.4890\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3225 - val_loss: 12.2433\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4544 - val_loss: 11.2667\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3294 - val_loss: 13.4769\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4883 - val_loss: 10.0359\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1929 - val_loss: 10.0751\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2176 - val_loss: 10.1895\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0854 - val_loss: 12.1037\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1604 - val_loss: 10.0098\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.8238 - val_loss: 11.3193\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1868 - val_loss: 10.1610\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3538 - val_loss: 10.0551\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4401 - val_loss: 10.3490\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3180 - val_loss: 10.4011\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9130 - val_loss: 10.1413\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1143 - val_loss: 10.9185\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5486 - val_loss: 10.6490\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1634 - val_loss: 10.9271\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2007 - val_loss: 11.0880\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2442 - val_loss: 12.0694\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2359 - val_loss: 11.8922\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0499 - val_loss: 10.1470\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.6699 - val_loss: 9.7853\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8702 - val_loss: 10.5754\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6295 - val_loss: 10.0792\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2278 - val_loss: 10.8415\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2992 - val_loss: 10.5013\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.3228 - val_loss: 9.9994\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7243 - val_loss: 10.0752\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1531 - val_loss: 10.2706\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 7.1471 - val_loss: 10.2220\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0739 - val_loss: 10.0670\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2496 - val_loss: 11.0969\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8544 - val_loss: 10.6863\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5763 - val_loss: 10.4036\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4176 - val_loss: 9.8993\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8836 - val_loss: 12.2670\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3896 - val_loss: 10.3327\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3758 - val_loss: 10.6367\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8746 - val_loss: 9.7646\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0463 - val_loss: 10.2601\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0106 - val_loss: 13.1315\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5068 - val_loss: 10.7415\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5489 - val_loss: 10.4781\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0327 - val_loss: 11.0852\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1677 - val_loss: 10.2735\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0343 - val_loss: 9.7179\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4940 - val_loss: 10.3038\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6195 - val_loss: 10.2066\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1838 - val_loss: 9.6590\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0634 - val_loss: 10.7105\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4581 - val_loss: 10.4361\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4897 - val_loss: 10.2015\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8685 - val_loss: 12.6031\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4269 - val_loss: 10.5194\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9858 - val_loss: 10.6809\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0754 - val_loss: 11.3234\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5075 - val_loss: 10.6683\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3010 - val_loss: 10.0890\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3159 - val_loss: 11.5920\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0935 - val_loss: 12.5955\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4032 - val_loss: 10.4280\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3126 - val_loss: 9.9704\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8642 - val_loss: 9.8474\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3133 - val_loss: 10.2704\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1058 - val_loss: 10.9936\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1250 - val_loss: 9.6315\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1909 - val_loss: 10.2339\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2105 - val_loss: 9.7529\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0669 - val_loss: 10.2039\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7379 - val_loss: 11.2370\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3008 - val_loss: 11.3551\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3217 - val_loss: 9.7242\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0020 - val_loss: 11.8812\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3152 - val_loss: 10.1692\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0209 - val_loss: 11.0047\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6135 - val_loss: 10.2667\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1419 - val_loss: 10.6239\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3741 - val_loss: 10.3306\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8621 - val_loss: 12.8816\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9622 - val_loss: 10.8527\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8805 - val_loss: 10.3534\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.1692 - val_loss: 9.9926\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.0588 - val_loss: 10.7086\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0859 - val_loss: 9.9217\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1115 - val_loss: 10.3004\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1633 - val_loss: 10.0291\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5571 - val_loss: 10.4063\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9144 - val_loss: 11.1705\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9216 - val_loss: 10.2583\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0414 - val_loss: 11.5777\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1617 - val_loss: 11.0673\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8773 - val_loss: 9.8326\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9749 - val_loss: 9.9905\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6818 - val_loss: 12.2733\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1859 - val_loss: 10.5893\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0386 - val_loss: 10.3644\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5017 - val_loss: 10.3961\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8142 - val_loss: 10.3662\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7516 - val_loss: 12.0058\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5240 - val_loss: 10.2713\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9262 - val_loss: 10.9442\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8492 - val_loss: 10.3905\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0474 - val_loss: 10.0607\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0956 - val_loss: 10.4395\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0309 - val_loss: 10.7998\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8883 - val_loss: 10.6545\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.9022 - val_loss: 10.9053\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0136 - val_loss: 9.9080\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9870 - val_loss: 9.9533\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 7.0278 - val_loss: 10.0587\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4498 - val_loss: 10.1375\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7791 - val_loss: 10.5408\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1828 - val_loss: 10.0863\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8056 - val_loss: 11.0574\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3279 - val_loss: 11.2001\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6655 - val_loss: 9.9930\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2946 - val_loss: 10.4392\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8984 - val_loss: 9.9568\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6262 - val_loss: 10.6090\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9938 - val_loss: 10.3066\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8228 - val_loss: 9.9852\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.8551 - val_loss: 11.3034\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1692 - val_loss: 10.7704\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8058 - val_loss: 10.7022\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9546 - val_loss: 10.0385\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7527 - val_loss: 10.6401\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0666 - val_loss: 10.8498\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0078 - val_loss: 10.6467\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6552 - val_loss: 9.9777\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0356 - val_loss: 9.8573\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4856 - val_loss: 9.5653\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2379 - val_loss: 10.0964\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5690 - val_loss: 11.3249\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.3011 - val_loss: 9.9026\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9736 - val_loss: 10.0072\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.5561 - val_loss: 11.6344\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0597 - val_loss: 11.8639\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8884 - val_loss: 10.8165\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0860 - val_loss: 10.0376\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2956 - val_loss: 11.3330\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7827 - val_loss: 11.2756\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8978 - val_loss: 12.7208\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0184 - val_loss: 10.4152\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6542 - val_loss: 11.4140\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.1753 - val_loss: 11.2349\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8362 - val_loss: 11.6405\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.5215 - val_loss: 10.8271\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0541 - val_loss: 11.0982\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1627 - val_loss: 10.2790\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9787 - val_loss: 10.9609\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6991 - val_loss: 10.0739\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6038 - val_loss: 11.4673\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1060 - val_loss: 10.4567\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7077 - val_loss: 11.3732\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5561 - val_loss: 10.4981\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7885 - val_loss: 10.8486\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9297 - val_loss: 10.6512\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5389 - val_loss: 10.9392\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4586 - val_loss: 10.9873\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7607 - val_loss: 11.9958\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0734 - val_loss: 10.3634\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5098 - val_loss: 10.4058\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1542 - val_loss: 10.5426\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2977 - val_loss: 10.6501\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9269 - val_loss: 13.9151\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9780 - val_loss: 10.1713\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8124 - val_loss: 10.2345\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7613 - val_loss: 10.6392\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6414 - val_loss: 11.0139\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5558 - val_loss: 11.0525\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5815 - val_loss: 10.4474\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6444 - val_loss: 10.3869\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5115 - val_loss: 10.5250\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6237 - val_loss: 10.6234\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5806 - val_loss: 10.9774\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7497 - val_loss: 11.1442\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6758 - val_loss: 11.5581\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3814 - val_loss: 10.4666\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5544 - val_loss: 10.5603\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6953 - val_loss: 10.4936\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7798 - val_loss: 10.8246\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8109 - val_loss: 10.8900\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5739 - val_loss: 11.7391\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.5778 - val_loss: 11.3471\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6356 - val_loss: 11.1579\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.3730 - val_loss: 10.9492\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2885 - val_loss: 14.4914\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.6149 - val_loss: 10.3874\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7339 - val_loss: 10.4942\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6595 - val_loss: 10.4615\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.377 - 0s 91us/step - loss: 6.3250 - val_loss: 11.2359\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.8795 - val_loss: 10.7225\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4817 - val_loss: 10.5626\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3987 - val_loss: 10.3170\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3535 - val_loss: 9.8902\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7270 - val_loss: 11.0947\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7932 - val_loss: 9.7968\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4763 - val_loss: 10.6102\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3152 - val_loss: 12.4945\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4375 - val_loss: 10.4166\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9148 - val_loss: 11.1352\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2047 - val_loss: 11.0584\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4569 - val_loss: 10.6435\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5772 - val_loss: 13.0367\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0578 - val_loss: 11.0400\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5367 - val_loss: 10.1218\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1260 - val_loss: 13.0676\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5295 - val_loss: 10.7881\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.3659 - val_loss: 10.1377\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6870 - val_loss: 11.0827\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6910 - val_loss: 10.4355\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0080 - val_loss: 9.9977\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5542 - val_loss: 10.1051\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2150 - val_loss: 10.8369\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1640 - val_loss: 13.7107\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0248 - val_loss: 10.0392\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5804 - val_loss: 9.9963\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4608 - val_loss: 10.0258\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2280 - val_loss: 9.8322\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4969 - val_loss: 10.5696\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3716 - val_loss: 11.0667\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4107 - val_loss: 10.3611\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2982 - val_loss: 10.7139\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.5860 - val_loss: 9.6412\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4882 - val_loss: 9.6350\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2596 - val_loss: 9.7770\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5141 - val_loss: 10.1028\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.2671 - val_loss: 9.6869\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2581 - val_loss: 9.7639\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3326 - val_loss: 12.1466\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6304 - val_loss: 10.7396\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3252 - val_loss: 9.9233\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2666 - val_loss: 9.7162\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1631 - val_loss: 9.9221\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5360 - val_loss: 9.7052\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4159 - val_loss: 10.1473\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4061 - val_loss: 10.1941\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9938 - val_loss: 9.7872\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0522 - val_loss: 9.9932\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4908 - val_loss: 9.9997\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9928 - val_loss: 10.8421\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4775 - val_loss: 9.9997\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4708 - val_loss: 10.4413\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0249 - val_loss: 10.4165\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2006 - val_loss: 13.0511\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2658 - val_loss: 11.1220\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6385 - val_loss: 12.0922\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3386 - val_loss: 10.6202\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2585 - val_loss: 10.0744\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1768 - val_loss: 11.6538\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3283 - val_loss: 10.5098\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1829 - val_loss: 12.2541\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3838 - val_loss: 10.2542\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.5729 - val_loss: 13.0426\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9731 - val_loss: 10.2928\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0232 - val_loss: 10.3870\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2343 - val_loss: 10.9432\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4708 - val_loss: 10.5138\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0740 - val_loss: 10.2246\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2421 - val_loss: 9.9390\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 5.9080 - val_loss: 10.6120\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3935 - val_loss: 10.7967\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1394 - val_loss: 10.6082\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1667 - val_loss: 10.2914\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1126 - val_loss: 10.9904\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3532 - val_loss: 10.2163\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9604 - val_loss: 9.9999\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9433 - val_loss: 9.7504\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4734 - val_loss: 9.8194\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5490 - val_loss: 10.0966\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2648 - val_loss: 12.9580\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4884 - val_loss: 10.8076\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1921 - val_loss: 10.7268\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1265 - val_loss: 10.1381\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9302 - val_loss: 10.4720\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2127 - val_loss: 11.7364\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3301 - val_loss: 10.0886\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9865 - val_loss: 10.0092\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5475 - val_loss: 10.3575\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1124 - val_loss: 10.5007\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8547 - val_loss: 9.8312\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6118 - val_loss: 9.8684\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0212 - val_loss: 10.1286\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1177 - val_loss: 10.2867\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3296 - val_loss: 9.9174\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1105 - val_loss: 10.0320\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2117 - val_loss: 9.7747\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8271 - val_loss: 11.0899\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3291 - val_loss: 10.8443\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9920 - val_loss: 10.3867\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7583 - val_loss: 10.3629\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0770 - val_loss: 10.1711\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9550 - val_loss: 10.5479\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4534 - val_loss: 10.2833\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8528 - val_loss: 10.2050\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8731 - val_loss: 10.8007\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0558 - val_loss: 9.5567\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3001 - val_loss: 9.9366\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9619 - val_loss: 10.6274\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0352 - val_loss: 10.4418\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5125 - val_loss: 9.8729\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0183 - val_loss: 10.5403\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0869 - val_loss: 10.4170\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1205 - val_loss: 10.7104\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8726 - val_loss: 10.0410\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2839 - val_loss: 9.8129\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5152 - val_loss: 10.8430\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0070 - val_loss: 10.1764\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9839 - val_loss: 9.9126\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0925 - val_loss: 10.3385\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3312 - val_loss: 11.3528\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3772 - val_loss: 10.3614\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7025 - val_loss: 10.2095\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9998 - val_loss: 9.8176\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2473 - val_loss: 9.4532\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9334 - val_loss: 11.1575\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3974 - val_loss: 10.5332\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1132 - val_loss: 9.8070\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0606 - val_loss: 10.1665\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8289 - val_loss: 10.1692\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0348 - val_loss: 11.5312\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1113 - val_loss: 10.2698\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9983 - val_loss: 10.1215\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.9896 - val_loss: 10.2595\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1379 - val_loss: 10.4747\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4044 - val_loss: 10.0426\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0671 - val_loss: 11.1260\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0238 - val_loss: 10.1607\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1389 - val_loss: 10.0458\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0372 - val_loss: 10.2190\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7567 - val_loss: 12.6775\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0279 - val_loss: 11.3368\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7815 - val_loss: 10.2782\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1780 - val_loss: 10.1317\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5401 - val_loss: 9.6351\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9816 - val_loss: 9.9370\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8713 - val_loss: 9.6468\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.1347 - val_loss: 10.0412\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0124 - val_loss: 9.8113\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0380 - val_loss: 10.1041\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1751 - val_loss: 11.8266\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4242 - val_loss: 9.8685\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9013 - val_loss: 11.3087\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0407 - val_loss: 11.4936\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9345 - val_loss: 9.9945\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3846 - val_loss: 11.0806\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2434 - val_loss: 10.7740\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2181 - val_loss: 11.8316\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0842 - val_loss: 10.3891\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4672 - val_loss: 11.3861\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9362 - val_loss: 9.9697\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8923 - val_loss: 10.6411\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2376 - val_loss: 10.5285\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7926 - val_loss: 10.4128\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1155 - val_loss: 10.3440\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6822 - val_loss: 10.9761\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0117 - val_loss: 9.9005\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9984 - val_loss: 9.5707\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8316 - val_loss: 10.0640\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8243 - val_loss: 9.7419\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1970 - val_loss: 9.9652\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7464 - val_loss: 9.4296\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9611 - val_loss: 9.7052\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.1139 - val_loss: 10.8047\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.7891 - val_loss: 11.3584\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8906 - val_loss: 10.1575\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8101 - val_loss: 10.1078\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9283 - val_loss: 9.6866\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8708 - val_loss: 10.8300\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9485 - val_loss: 9.9937\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1252 - val_loss: 10.6604\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0000 - val_loss: 9.9536\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7393 - val_loss: 10.8907\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1522 - val_loss: 10.5022\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4171 - val_loss: 10.4255\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8569 - val_loss: 10.0390\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9091 - val_loss: 10.9384\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6557 - val_loss: 10.3810\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.2547 - val_loss: 10.3781\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6858 - val_loss: 9.9189\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7995 - val_loss: 10.1534\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0175 - val_loss: 11.2424\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.4311 - val_loss: 10.0036\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8740 - val_loss: 10.2169\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8641 - val_loss: 10.5906\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8272 - val_loss: 9.7895\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3934 - val_loss: 10.0600\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9625 - val_loss: 10.9661\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8427 - val_loss: 10.4113\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8898 - val_loss: 10.4027\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9822 - val_loss: 11.5090\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0681 - val_loss: 10.1480\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6768 - val_loss: 10.5547\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9933 - val_loss: 10.4960\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0171 - val_loss: 10.5070\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6590 - val_loss: 9.9772\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1732 - val_loss: 12.4043\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1272 - val_loss: 10.3793\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6543 - val_loss: 10.1230\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0281 - val_loss: 10.6501\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7116 - val_loss: 9.9478\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0377 - val_loss: 9.9375\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6512 - val_loss: 10.5698\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5663 - val_loss: 11.5878\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0438 - val_loss: 9.8378\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0374 - val_loss: 9.9280\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0367 - val_loss: 10.5550\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0771 - val_loss: 10.3585\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6845 - val_loss: 10.5549\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1716 - val_loss: 10.5683\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7705 - val_loss: 11.5191\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1018 - val_loss: 10.6009\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7191 - val_loss: 10.0284\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6973 - val_loss: 10.2257\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 85us/step - loss: 5.6520 - val_loss: 10.7371\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0148 - val_loss: 10.4813\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8483 - val_loss: 10.5429\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8226 - val_loss: 11.6604\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8537 - val_loss: 10.2465\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.935 - 0s 91us/step - loss: 5.8165 - val_loss: 10.0162\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8716 - val_loss: 11.1794\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0591 - val_loss: 10.1749\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6067 - val_loss: 10.2381\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1483 - val_loss: 10.8817\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6614 - val_loss: 10.1093\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7163 - val_loss: 10.5057\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1267 - val_loss: 10.8628\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2825 - val_loss: 9.9490\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.783 - 0s 91us/step - loss: 5.6118 - val_loss: 11.5345\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7917 - val_loss: 11.3175\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9032 - val_loss: 9.9959\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7683 - val_loss: 10.2750\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9331 - val_loss: 10.2856\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8366 - val_loss: 9.9447\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9729 - val_loss: 10.5148\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9999 - val_loss: 10.9881\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2762 - val_loss: 10.5021\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5141 - val_loss: 10.3215\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7590 - val_loss: 10.2506\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8778 - val_loss: 10.9754\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7254 - val_loss: 11.3397\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9638 - val_loss: 11.8910\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9298 - val_loss: 10.0541\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6646 - val_loss: 10.4693\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1488 - val_loss: 9.8624\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8701 - val_loss: 9.7545\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8415 - val_loss: 10.1103\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8379 - val_loss: 10.2465\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6615 - val_loss: 10.3605\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7149 - val_loss: 10.5681\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7044 - val_loss: 10.1106\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7111 - val_loss: 10.6086\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8677 - val_loss: 11.0651\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6121 - val_loss: 10.3147\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8157 - val_loss: 11.5135\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7873 - val_loss: 11.2424\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8132 - val_loss: 11.0396\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8860 - val_loss: 9.6749\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5980 - val_loss: 10.3997\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1562 - val_loss: 10.4118\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7161 - val_loss: 11.0824\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0398 - val_loss: 11.2554\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6225 - val_loss: 12.7283\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9395 - val_loss: 11.7261\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1214 - val_loss: 10.8331\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6602 - val_loss: 10.0870\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5805 - val_loss: 9.8541\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6997 - val_loss: 10.1062\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8172 - val_loss: 9.7544\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1548 - val_loss: 9.8133\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5377 - val_loss: 10.2166\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5587 - val_loss: 10.5725\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3540 - val_loss: 10.0255\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 5.6547 - val_loss: 10.0757\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.7755 - val_loss: 10.5090\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8612 - val_loss: 10.4159\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8530 - val_loss: 9.9691\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9684 - val_loss: 10.7285\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7550 - val_loss: 10.6123\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6235 - val_loss: 10.2740\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8734 - val_loss: 11.7358\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9566 - val_loss: 11.1320\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6768 - val_loss: 11.5170\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.284 - 0s 91us/step - loss: 5.8932 - val_loss: 10.6620\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5220 - val_loss: 11.1505\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6984 - val_loss: 10.8545\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0680 - val_loss: 10.3834\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8770 - val_loss: 9.9679\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4556 - val_loss: 9.8663\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5141 - val_loss: 11.4201\n",
      "Epoch 837/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8718 - val_loss: 10.3083\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7278 - val_loss: 10.0578\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9379 - val_loss: 9.9283\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7006 - val_loss: 10.9383\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.7660 - val_loss: 11.0818\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7113 - val_loss: 11.8104\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8696 - val_loss: 11.1272\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8025 - val_loss: 10.0835\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9933 - val_loss: 9.9538\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5848 - val_loss: 9.9456\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7928 - val_loss: 10.7581\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7324 - val_loss: 11.2740\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 5.6422 - val_loss: 10.5211\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4583 - val_loss: 9.9839\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7630 - val_loss: 10.7960\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5209 - val_loss: 10.3151\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6011 - val_loss: 10.3371\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8462 - val_loss: 10.8502\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6088 - val_loss: 9.9856\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5782 - val_loss: 13.2945\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9134 - val_loss: 9.7897\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9314 - val_loss: 10.8635\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4771 - val_loss: 9.7379\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8119 - val_loss: 10.7179\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6964 - val_loss: 10.3646\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6260 - val_loss: 9.7033\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8974 - val_loss: 10.3104\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5666 - val_loss: 10.7466\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7856 - val_loss: 11.5070\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8368 - val_loss: 11.6613\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6158 - val_loss: 10.2732\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5581 - val_loss: 10.1874\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7517 - val_loss: 9.9186\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6847 - val_loss: 10.0805\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4304 - val_loss: 12.8372\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0745 - val_loss: 9.6246\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7808 - val_loss: 9.9128\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6757 - val_loss: 9.9720\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0150 - val_loss: 9.8510\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6769 - val_loss: 9.9050\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5409 - val_loss: 11.0899\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7625 - val_loss: 9.9603\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5069 - val_loss: 10.0871\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5010 - val_loss: 11.2554\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7877 - val_loss: 10.9779\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8022 - val_loss: 11.0342\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5346 - val_loss: 10.3520\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7839 - val_loss: 10.1563\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9365 - val_loss: 10.0254\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4109 - val_loss: 12.3910\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8609 - val_loss: 11.7495\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6396 - val_loss: 10.4441\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6858 - val_loss: 10.4191\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4617 - val_loss: 11.7230\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5541 - val_loss: 9.7945\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 5.6361 - val_loss: 10.7300\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6375 - val_loss: 10.2051\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4943 - val_loss: 11.2626\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9988 - val_loss: 9.8144\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3991 - val_loss: 11.0852\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4637 - val_loss: 12.0305\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8628 - val_loss: 11.0173\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6138 - val_loss: 11.1111\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 5.6821 - val_loss: 10.2785\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6518 - val_loss: 10.3958\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9783 - val_loss: 10.2089\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8319 - val_loss: 9.7751\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6207 - val_loss: 9.9576\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0549 - val_loss: 9.8205\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4539 - val_loss: 10.0449\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3095 - val_loss: 9.7074\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6168 - val_loss: 10.2460\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7885 - val_loss: 10.1691\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4317 - val_loss: 10.2812\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5563 - val_loss: 9.8068\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9780 - val_loss: 10.0805\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7675 - val_loss: 10.3656\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.4187 - val_loss: 9.9308\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.3926 - val_loss: 11.9036\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6413 - val_loss: 9.4011\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9212 - val_loss: 10.5113\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4440 - val_loss: 11.0352\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8266 - val_loss: 11.3423\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8738 - val_loss: 12.8338\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6881 - val_loss: 10.3660\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3103 - val_loss: 10.1912\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7099 - val_loss: 11.3815\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0042 - val_loss: 11.3336\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5381 - val_loss: 10.4785\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5831 - val_loss: 10.7261\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7940 - val_loss: 10.4000\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7376 - val_loss: 9.9831\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3719 - val_loss: 12.1725\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8687 - val_loss: 10.3439\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6909 - val_loss: 10.9143\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1309 - val_loss: 9.9113\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7490 - val_loss: 11.6834\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8321 - val_loss: 10.6417\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3188 - val_loss: 10.4966\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5175 - val_loss: 10.4686\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9574 - val_loss: 10.0656\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.5287 - val_loss: 10.5634\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7046 - val_loss: 11.0136\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5658 - val_loss: 10.1774\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6193 - val_loss: 10.4997\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7470 - val_loss: 9.9804\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8045 - val_loss: 9.8586\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5930 - val_loss: 10.4372\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5941 - val_loss: 9.5455\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3561 - val_loss: 10.6114\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8217 - val_loss: 10.7644\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5730 - val_loss: 11.9441\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9208 - val_loss: 10.0546\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6495 - val_loss: 11.6471\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3269 - val_loss: 10.3392\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.9260 - val_loss: 10.2016\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4698 - val_loss: 10.1366\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9113 - val_loss: 10.1640\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7212 - val_loss: 9.8860\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3492 - val_loss: 9.6942\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7218 - val_loss: 10.2779\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8462 - val_loss: 10.9608\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4210 - val_loss: 9.7175\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6834 - val_loss: 9.6250\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3129 - val_loss: 10.5241\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.3187 - val_loss: 9.6421\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.4726 - val_loss: 11.8309\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0173 - val_loss: 9.8248\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9305 - val_loss: 9.9492\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5609 - val_loss: 9.8808\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3851 - val_loss: 9.6845\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5036 - val_loss: 10.1665\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8168 - val_loss: 10.4379\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3900 - val_loss: 10.0800\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4623 - val_loss: 10.0578\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 5.5715 - val_loss: 10.6272\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5673 - val_loss: 11.9760\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8331 - val_loss: 10.4760\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3563 - val_loss: 10.2314\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6449 - val_loss: 10.0436\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6097 - val_loss: 10.6490\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6829 - val_loss: 10.3179\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6791 - val_loss: 10.7090\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5275 - val_loss: 10.3377\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3401 - val_loss: 13.0160\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3505 - val_loss: 10.5641\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4702 - val_loss: 10.6173\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5933 - val_loss: 10.4284\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3693 - val_loss: 10.8376\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5793 - val_loss: 10.0390\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4120 - val_loss: 11.6455\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6414 - val_loss: 11.8709\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7256 - val_loss: 9.3551\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6343 - val_loss: 10.9269\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.6248 - val_loss: 9.8954\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6656 - val_loss: 11.1691\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9644 - val_loss: 10.3481\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3845 - val_loss: 11.2993\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3191 - val_loss: 10.7927\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.4590 - val_loss: 9.8063\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6328 - val_loss: 13.2779\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7746 - val_loss: 9.6389\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5276 - val_loss: 10.1473\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4621 - val_loss: 10.5044\n",
      "6.895367832507118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.2319605 ,  1.9935802 , -2.0282888 , -6.257301  ,  1.0705557 ],\n",
       "        [-0.16251644, -2.1981363 , -0.32122812,  3.5041664 , -0.564827  ],\n",
       "        [-0.0923591 ,  0.32887274,  0.93221086, -1.7460452 , -0.12983538],\n",
       "        [-0.80078787,  2.3014646 , -0.43455797, -2.7002316 , -0.25145605],\n",
       "        [ 0.35079497, -1.425764  ,  0.14472388, -0.25879452, -0.4707508 ],\n",
       "        [-0.34118485, -0.7758662 , -1.1711121 ,  0.8148826 ,  0.19521472],\n",
       "        [-0.19109583, -0.44091418,  0.16165051,  0.44412947,  1.0168439 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.9159022, -2.3754754, -1.6497273, -1.6801256,  1.0722076],\n",
       "       dtype=float32),\n",
       " array([[-0.30650178, -0.82059425, -0.8845178 ,  0.6198854 ,  0.01670245,\n",
       "          0.91658044, -0.583803  ,  0.61051273,  1.0977648 , -0.2929295 ],\n",
       "        [-0.11417517,  0.7498607 ,  0.80962944, -0.62643665,  0.0893286 ,\n",
       "         -0.58019584,  0.7380129 , -0.62639546, -0.59378356, -0.14802209],\n",
       "        [ 0.44325912,  0.91800797,  0.5974282 , -0.03354135, -0.03097109,\n",
       "         -1.1928352 ,  1.1443042 , -0.664047  , -0.43579373,  0.8165987 ],\n",
       "        [-0.6219575 , -0.96571815, -1.2238073 ,  0.9329001 ,  0.07090285,\n",
       "          1.217397  , -0.5439484 ,  1.6637207 ,  1.288553  , -0.6523287 ],\n",
       "        [-0.71904683, -0.0321204 , -0.6275069 ,  0.8920239 , -0.03432462,\n",
       "          0.56099325, -0.15462817,  1.0909864 ,  0.90242106, -0.42269397]],\n",
       "       dtype=float32),\n",
       " array([-1.1070532 , -1.1147081 , -1.1510695 ,  1.0661819 ,  0.01544063,\n",
       "         1.0825015 , -1.0137852 ,  1.1499375 ,  1.0966268 , -1.0582838 ],\n",
       "       dtype=float32),\n",
       " array([[-1.0595638e+00],\n",
       "        [-1.2069633e+00],\n",
       "        [-1.3817688e+00],\n",
       "        [ 7.4356329e-01],\n",
       "        [ 2.6177615e-05],\n",
       "        [ 9.2643774e-01],\n",
       "        [-8.1262994e-01],\n",
       "        [ 1.3873074e+00],\n",
       "        [ 1.0209123e+00],\n",
       "        [-8.4470397e-01]], dtype=float32),\n",
       " array([1.3366573], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, RMSprop, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_rmsprop_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3426\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.1934 - val_loss: 0.0680\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0885 - val_loss: 0.0177\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0579 - val_loss: 0.0245\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0313 - val_loss: 0.0200\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0294 - val_loss: 0.0208\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0248 - val_loss: 0.0102\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0221 - val_loss: 0.0067\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0225 - val_loss: 0.0057\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0198 - val_loss: 0.0087\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0188 - val_loss: 0.0087\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0151 - val_loss: 0.0062\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0141 - val_loss: 0.0047\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0118 - val_loss: 0.0051\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0043\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0125 - val_loss: 0.0051\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0142 - val_loss: 0.0048\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0121 - val_loss: 0.0048\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0113 - val_loss: 0.0042\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0038\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0037\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0034\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0040\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0034\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0075 - val_loss: 0.0039\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0039\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0069\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 119us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 111us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 104us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "0.006766484584659338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.09280849e+00, -4.69725206e-02,  9.37820449e-02,\n",
       "          2.57516086e-01, -6.49350047e-01],\n",
       "        [ 2.28303820e-01, -3.09773743e-01, -8.27465832e-01,\n",
       "         -2.30400875e-01,  8.95458087e-02],\n",
       "        [-4.38138664e-01, -3.19319099e-01,  2.32274100e-01,\n",
       "         -6.41566992e-01, -3.93269286e-02],\n",
       "        [-3.20079923e-01,  3.61049771e-01,  9.77661967e-01,\n",
       "         -6.62049294e-01,  1.07967332e-01],\n",
       "        [-7.69383609e-02, -3.24509703e-02,  6.49848878e-02,\n",
       "          3.32513750e-02, -7.16576055e-02],\n",
       "        [ 3.68470073e-01, -6.69867575e-01, -8.99207473e-01,\n",
       "          3.47276688e-01, -4.22219038e-01],\n",
       "        [-8.05617452e-01, -3.33464295e-01,  1.42124921e-01,\n",
       "          1.10584922e-01, -3.86808425e-01],\n",
       "        [ 3.47541794e-02,  1.45341799e-01,  2.58539826e-01,\n",
       "          2.16535255e-01, -1.41095340e-01],\n",
       "        [-4.11290348e-01, -8.21884274e-01,  1.32257676e+00,\n",
       "          5.43036163e-01, -8.87208998e-01],\n",
       "        [ 1.43000782e+00, -1.12514324e-01, -3.90260994e-01,\n",
       "          2.59215962e-02, -5.47917187e-02],\n",
       "        [-7.48313785e-01, -1.22487165e-01,  4.86773252e-01,\n",
       "          7.59315193e-01,  3.18962932e-01],\n",
       "        [-9.21219110e-01,  9.82675433e-01,  4.37370129e-02,\n",
       "         -4.70256992e-03,  1.48404205e+00],\n",
       "        [ 9.27747488e-01,  4.05990481e-01, -5.02055407e-01,\n",
       "         -4.20610994e-01,  7.97190428e-01],\n",
       "        [ 1.45964491e+00,  3.15375626e-01,  5.41893661e-01,\n",
       "          2.74754703e-01,  1.00365329e+00],\n",
       "        [ 3.25175285e-01, -9.14612669e-04, -2.14267880e-01,\n",
       "          7.65021443e-02,  6.10644892e-02],\n",
       "        [ 5.04808009e-01,  4.30090904e-01, -7.09476709e-01,\n",
       "         -3.13097954e-01,  5.98447561e-01],\n",
       "        [-7.26395369e-01,  4.63529021e-01, -9.08696838e-03,\n",
       "          2.11364448e-01,  1.95376694e-01],\n",
       "        [-1.00892293e+00, -2.19931036e-01, -3.71392131e-01,\n",
       "          5.42741239e-01,  1.07075624e-01],\n",
       "        [ 5.44356070e-02, -1.35340348e-01, -7.84183323e-01,\n",
       "         -9.24785715e-03, -3.19900289e-02],\n",
       "        [ 3.60850126e-01, -1.97994322e-01, -3.97738427e-01,\n",
       "         -1.26410878e+00,  3.65244925e-01],\n",
       "        [-1.77969515e+00,  1.44871518e-01, -7.34711766e-01,\n",
       "         -7.51754999e-01, -1.29995853e-01],\n",
       "        [-1.56768656e+00, -6.69251680e-01,  1.87854934e-02,\n",
       "         -5.46941638e-01,  2.42491081e-01]], dtype=float32),\n",
       " array([-0.8737139 ,  0.0030091 , -0.1725047 , -0.20788462, -0.00971825],\n",
       "       dtype=float32),\n",
       " array([[-0.31306535, -0.5694788 ,  0.40687934, -0.32149544, -0.45787627,\n",
       "         -0.14362624,  0.2704509 , -0.76313084,  0.12978262, -0.24160603],\n",
       "        [ 0.3880081 ,  0.6641714 , -0.41716263, -0.23722833, -0.01308794,\n",
       "          0.06623464,  0.09036367,  0.50548697,  0.31284174, -0.39717576],\n",
       "        [-0.10030323, -0.37916788,  0.54789937,  0.47124547, -0.39172545,\n",
       "         -0.66924894, -0.33696344,  0.24875458, -0.06737924,  0.08487254],\n",
       "        [ 0.43752086, -0.495345  , -0.30547523, -0.37036502,  0.20617652,\n",
       "          0.290799  , -0.5219755 ,  0.04352276,  0.28930575, -0.12465325],\n",
       "        [-0.4197095 ,  0.3082345 ,  0.8400249 , -0.15075296, -0.9483402 ,\n",
       "         -0.1963997 , -0.24136588, -0.32628405, -0.5118862 , -0.4395875 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.37853244, -0.21940967, -0.15995955, -0.14816865,  0.05722217,\n",
       "        -0.18357664, -0.21643014, -0.10528459, -0.04928853, -0.13161919],\n",
       "       dtype=float32),\n",
       " array([[-0.00550399],\n",
       "        [-0.2561631 ],\n",
       "        [ 0.09337031],\n",
       "        [-0.05523155],\n",
       "        [-0.13679087],\n",
       "        [-0.13137299],\n",
       "        [-0.35032278],\n",
       "        [-0.29325935],\n",
       "        [-0.24617031],\n",
       "        [-0.09934961]], dtype=float32),\n",
       " array([0.17724445], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_adam_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0970 - val_loss: 0.0905\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0969 - val_loss: 0.0905\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0968 - val_loss: 0.0904\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0968 - val_loss: 0.0904\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0967 - val_loss: 0.0903\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0966 - val_loss: 0.0903\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0965 - val_loss: 0.0902\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0964 - val_loss: 0.0901\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0963 - val_loss: 0.0901\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0962 - val_loss: 0.0900\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0961 - val_loss: 0.0900\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0960 - val_loss: 0.0899\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0959 - val_loss: 0.0898\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0958 - val_loss: 0.0898\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0957 - val_loss: 0.0897\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0956 - val_loss: 0.0897\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0955 - val_loss: 0.0896\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0954 - val_loss: 0.0895\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0953 - val_loss: 0.0895\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0952 - val_loss: 0.0894\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0951 - val_loss: 0.0893\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0950 - val_loss: 0.0893\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0949 - val_loss: 0.0892\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0948 - val_loss: 0.0892\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.096 - 0s 91us/step - loss: 0.0947 - val_loss: 0.0891\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0946 - val_loss: 0.0891\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0945 - val_loss: 0.0890\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0944 - val_loss: 0.0889\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0943 - val_loss: 0.0889\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0942 - val_loss: 0.0888\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0941 - val_loss: 0.0888\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0940 - val_loss: 0.0887\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0939 - val_loss: 0.0886\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0938 - val_loss: 0.0886\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0937 - val_loss: 0.0885\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0936 - val_loss: 0.0885\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0935 - val_loss: 0.0884\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0934 - val_loss: 0.0884\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0933 - val_loss: 0.0883\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0932 - val_loss: 0.0882\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0931 - val_loss: 0.0882\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0930 - val_loss: 0.0881\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0929 - val_loss: 0.0881\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0928 - val_loss: 0.0880\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0928 - val_loss: 0.0880\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0927 - val_loss: 0.0879\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0926 - val_loss: 0.0879\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0925 - val_loss: 0.0878\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0924 - val_loss: 0.0878\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0923 - val_loss: 0.0877\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0922 - val_loss: 0.0876\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0921 - val_loss: 0.0876\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.094 - 0s 98us/step - loss: 0.0920 - val_loss: 0.0875\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0919 - val_loss: 0.0875\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0919 - val_loss: 0.0874\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0918 - val_loss: 0.0874\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0917 - val_loss: 0.0873\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0916 - val_loss: 0.0873\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0915 - val_loss: 0.0872\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0914 - val_loss: 0.0872\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0913 - val_loss: 0.0871\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0912 - val_loss: 0.0871\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0911 - val_loss: 0.0870\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0911 - val_loss: 0.0870\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0910 - val_loss: 0.0869\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0909 - val_loss: 0.0869\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0908 - val_loss: 0.0868\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0907 - val_loss: 0.0868\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0906 - val_loss: 0.0867\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0905 - val_loss: 0.0867\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0904 - val_loss: 0.0866\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0904 - val_loss: 0.0866\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0903 - val_loss: 0.0865\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0902 - val_loss: 0.0865\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0901 - val_loss: 0.0864\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0900 - val_loss: 0.0864\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0899 - val_loss: 0.0863\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0898 - val_loss: 0.0863\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0898 - val_loss: 0.0862\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0897 - val_loss: 0.0862\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0896 - val_loss: 0.0861\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0895 - val_loss: 0.0861\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0894 - val_loss: 0.0860\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0894 - val_loss: 0.0860\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0893 - val_loss: 0.0859\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0892 - val_loss: 0.0859\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0891 - val_loss: 0.0858\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0890 - val_loss: 0.0858\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0890 - val_loss: 0.0857\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0889 - val_loss: 0.0857\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0888 - val_loss: 0.0856\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0887 - val_loss: 0.0856\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0886 - val_loss: 0.0856\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0886 - val_loss: 0.0855\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0885 - val_loss: 0.0855\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0884 - val_loss: 0.0854\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0883 - val_loss: 0.0854\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0882 - val_loss: 0.0853\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0882 - val_loss: 0.0853\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0881 - val_loss: 0.0852\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0880 - val_loss: 0.0852\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0879 - val_loss: 0.0851\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0878 - val_loss: 0.0851\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0878 - val_loss: 0.0851\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0877 - val_loss: 0.0850\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0876 - val_loss: 0.0850\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0875 - val_loss: 0.0849\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0875 - val_loss: 0.0849\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0874 - val_loss: 0.0848\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0873 - val_loss: 0.0848\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0872 - val_loss: 0.0848\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0871 - val_loss: 0.0847\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0871 - val_loss: 0.0847\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0870 - val_loss: 0.0846\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0869 - val_loss: 0.0846\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0868 - val_loss: 0.0845\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0868 - val_loss: 0.0845\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0867 - val_loss: 0.0844\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0866 - val_loss: 0.0844\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0865 - val_loss: 0.0844\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0865 - val_loss: 0.0843\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0864 - val_loss: 0.0843\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0863 - val_loss: 0.0842\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0862 - val_loss: 0.0842\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0862 - val_loss: 0.0842\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0861 - val_loss: 0.0841\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0860 - val_loss: 0.0841\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0860 - val_loss: 0.0840\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0859 - val_loss: 0.0840\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0858 - val_loss: 0.0839\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0857 - val_loss: 0.0839\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0857 - val_loss: 0.0839\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0856 - val_loss: 0.0838\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0855 - val_loss: 0.0838\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0855 - val_loss: 0.0837\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0854 - val_loss: 0.0837\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0853 - val_loss: 0.0837\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0852 - val_loss: 0.0836\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0852 - val_loss: 0.0836\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0851 - val_loss: 0.0836\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0850 - val_loss: 0.0835\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0850 - val_loss: 0.0835\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0849 - val_loss: 0.0834\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0848 - val_loss: 0.0834\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0848 - val_loss: 0.0834\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0847 - val_loss: 0.0833\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0846 - val_loss: 0.0833\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0846 - val_loss: 0.0832\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0845 - val_loss: 0.0832\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0844 - val_loss: 0.0832\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0844 - val_loss: 0.0831\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0843 - val_loss: 0.0831\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0842 - val_loss: 0.0831\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0841 - val_loss: 0.0830\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0841 - val_loss: 0.0830\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0840 - val_loss: 0.0829\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0839 - val_loss: 0.0829\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0839 - val_loss: 0.0829\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0838 - val_loss: 0.0828\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.090 - 0s 105us/step - loss: 0.0837 - val_loss: 0.0828\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0837 - val_loss: 0.0827\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0836 - val_loss: 0.0827\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0835 - val_loss: 0.0827\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0835 - val_loss: 0.0826\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0834 - val_loss: 0.0826\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0833 - val_loss: 0.0826\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0833 - val_loss: 0.0825\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0832 - val_loss: 0.0825\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0831 - val_loss: 0.0825\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0831 - val_loss: 0.0824\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0830 - val_loss: 0.0824\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0830 - val_loss: 0.0824\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0829 - val_loss: 0.0823\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0828 - val_loss: 0.0823\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0828 - val_loss: 0.0823\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0827 - val_loss: 0.0822\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0826 - val_loss: 0.0821\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0825 - val_loss: 0.0821\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0825 - val_loss: 0.0821\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0824 - val_loss: 0.0820\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0823 - val_loss: 0.0820\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0823 - val_loss: 0.0820\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0822 - val_loss: 0.0819\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0821 - val_loss: 0.0819\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0821 - val_loss: 0.0819\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0820 - val_loss: 0.0818\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0820 - val_loss: 0.0818\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0819 - val_loss: 0.0818\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0818 - val_loss: 0.0817\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0818 - val_loss: 0.0817\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0817 - val_loss: 0.0817\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0817 - val_loss: 0.0817\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0816 - val_loss: 0.0816\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0815 - val_loss: 0.0816\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0815 - val_loss: 0.0816\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0814 - val_loss: 0.0815\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0814 - val_loss: 0.0815\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0813 - val_loss: 0.0815\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0813 - val_loss: 0.0814\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0812 - val_loss: 0.0814\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0811 - val_loss: 0.0814\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0811 - val_loss: 0.0813\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0810 - val_loss: 0.0813\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0810 - val_loss: 0.0813\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0809 - val_loss: 0.0812\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0809 - val_loss: 0.0812\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0808 - val_loss: 0.0812\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0807 - val_loss: 0.0811\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0807 - val_loss: 0.0811\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0806 - val_loss: 0.0811\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0806 - val_loss: 0.0811\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0805 - val_loss: 0.0810\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0805 - val_loss: 0.0810\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0804 - val_loss: 0.0810\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0803 - val_loss: 0.0809\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0803 - val_loss: 0.0809\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0802 - val_loss: 0.0809\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0802 - val_loss: 0.0808\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0801 - val_loss: 0.0808\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0801 - val_loss: 0.0808\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0800 - val_loss: 0.0808\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0800 - val_loss: 0.0807\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0799 - val_loss: 0.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0799 - val_loss: 0.0807\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0798 - val_loss: 0.0806\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0797 - val_loss: 0.0806\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0797 - val_loss: 0.0806\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0796 - val_loss: 0.0806\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0796 - val_loss: 0.0805\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0795 - val_loss: 0.0805\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0795 - val_loss: 0.0805\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0794 - val_loss: 0.0804\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0794 - val_loss: 0.0804\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0793 - val_loss: 0.0804\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0793 - val_loss: 0.0804\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.098 - 0s 91us/step - loss: 0.0792 - val_loss: 0.0803\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0792 - val_loss: 0.0803\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0791 - val_loss: 0.0803\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0791 - val_loss: 0.0802\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0790 - val_loss: 0.0802\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0790 - val_loss: 0.0802\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0789 - val_loss: 0.0802\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0789 - val_loss: 0.0801\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0788 - val_loss: 0.0801\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0788 - val_loss: 0.0801\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0787 - val_loss: 0.0801\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0787 - val_loss: 0.0800\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0786 - val_loss: 0.0800\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0785 - val_loss: 0.0800\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0785 - val_loss: 0.0799\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0784 - val_loss: 0.0799\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0784 - val_loss: 0.0799\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0783 - val_loss: 0.0799\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0783 - val_loss: 0.0798\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0782 - val_loss: 0.0798\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0782 - val_loss: 0.0798\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0781 - val_loss: 0.0798\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0781 - val_loss: 0.0797\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0780 - val_loss: 0.0797\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0780 - val_loss: 0.0797\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0779 - val_loss: 0.0797\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0779 - val_loss: 0.0796\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0778 - val_loss: 0.0796\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0778 - val_loss: 0.0796\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0777 - val_loss: 0.0795\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0777 - val_loss: 0.0795\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0776 - val_loss: 0.0795\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0776 - val_loss: 0.0795\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0775 - val_loss: 0.0794\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0775 - val_loss: 0.0794\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0774 - val_loss: 0.0794\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0774 - val_loss: 0.0794\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 76us/step - loss: 0.0773 - val_loss: 0.0793\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0773 - val_loss: 0.0793\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0772 - val_loss: 0.0793\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0772 - val_loss: 0.0793\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0772 - val_loss: 0.0792\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0771 - val_loss: 0.0792\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0771 - val_loss: 0.0792\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0770 - val_loss: 0.0792\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0770 - val_loss: 0.0791\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0769 - val_loss: 0.0791\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0769 - val_loss: 0.0791\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0768 - val_loss: 0.0791\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0768 - val_loss: 0.0790\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0767 - val_loss: 0.0790\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0767 - val_loss: 0.0790\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0766 - val_loss: 0.0790\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0766 - val_loss: 0.0789\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0765 - val_loss: 0.0789\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0765 - val_loss: 0.0789\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0764 - val_loss: 0.0789\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0764 - val_loss: 0.0788\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0763 - val_loss: 0.0788\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0763 - val_loss: 0.0788\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0763 - val_loss: 0.0788\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0762 - val_loss: 0.0788\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0762 - val_loss: 0.0787\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0761 - val_loss: 0.0787\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0761 - val_loss: 0.0787\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0760 - val_loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0760 - val_loss: 0.0786\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0759 - val_loss: 0.0786\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0759 - val_loss: 0.0786\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0759 - val_loss: 0.0786\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0758 - val_loss: 0.0785\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0758 - val_loss: 0.0785\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0757 - val_loss: 0.0785\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0757 - val_loss: 0.0785\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0756 - val_loss: 0.0785\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0756 - val_loss: 0.0784\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0755 - val_loss: 0.0784\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0755 - val_loss: 0.0784\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0755 - val_loss: 0.0784\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0754 - val_loss: 0.0783\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0754 - val_loss: 0.0783\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0753 - val_loss: 0.0783\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0753 - val_loss: 0.0783\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0752 - val_loss: 0.0783\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0752 - val_loss: 0.0782\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0752 - val_loss: 0.0782\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0751 - val_loss: 0.0782\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0751 - val_loss: 0.0782\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0750 - val_loss: 0.0781\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0750 - val_loss: 0.0781\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0749 - val_loss: 0.0781\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0749 - val_loss: 0.0781\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0749 - val_loss: 0.0781\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0748 - val_loss: 0.0780\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0748 - val_loss: 0.0780\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0747 - val_loss: 0.0780\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0747 - val_loss: 0.0780\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0746 - val_loss: 0.0780\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0746 - val_loss: 0.0779\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0746 - val_loss: 0.0779\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0745 - val_loss: 0.0779\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0745 - val_loss: 0.0779\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0744 - val_loss: 0.0778\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0744 - val_loss: 0.0778\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0744 - val_loss: 0.0778\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0743 - val_loss: 0.0778\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0743 - val_loss: 0.0778\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0742 - val_loss: 0.0777\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0742 - val_loss: 0.0777\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0742 - val_loss: 0.0777\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0741 - val_loss: 0.0777\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0741 - val_loss: 0.0777\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0741 - val_loss: 0.0776\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0740 - val_loss: 0.0776\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0740 - val_loss: 0.0776\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0739 - val_loss: 0.0776\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0739 - val_loss: 0.0776\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0738 - val_loss: 0.0775\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0738 - val_loss: 0.0775\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0738 - val_loss: 0.0775\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0737 - val_loss: 0.0775\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0737 - val_loss: 0.0775\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0736 - val_loss: 0.0774\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0736 - val_loss: 0.0774\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0736 - val_loss: 0.0774\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0735 - val_loss: 0.0774\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0735 - val_loss: 0.0774\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0735 - val_loss: 0.0773\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0734 - val_loss: 0.0773\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0734 - val_loss: 0.0773\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0733 - val_loss: 0.0773\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0733 - val_loss: 0.0773\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0733 - val_loss: 0.0773\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0732 - val_loss: 0.0772\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0732 - val_loss: 0.0772\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0731 - val_loss: 0.0772\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0731 - val_loss: 0.0772\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0731 - val_loss: 0.0772\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0730 - val_loss: 0.0771\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0730 - val_loss: 0.0771\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0730 - val_loss: 0.0771\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0729 - val_loss: 0.0771\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0729 - val_loss: 0.0771\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0729 - val_loss: 0.0771\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0728 - val_loss: 0.0770\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0728 - val_loss: 0.0770\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0727 - val_loss: 0.0770\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0727 - val_loss: 0.0770\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0727 - val_loss: 0.0770\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0726 - val_loss: 0.0769\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0726 - val_loss: 0.0769\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0726 - val_loss: 0.0769\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0725 - val_loss: 0.0769\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0725 - val_loss: 0.0769\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0725 - val_loss: 0.0769\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0724 - val_loss: 0.0768\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0724 - val_loss: 0.0768\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0723 - val_loss: 0.0768\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0723 - val_loss: 0.0768\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0723 - val_loss: 0.0768\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0722 - val_loss: 0.0767\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0722 - val_loss: 0.0767\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0722 - val_loss: 0.0767\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0721 - val_loss: 0.0767\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0721 - val_loss: 0.0767\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0721 - val_loss: 0.0767\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0720 - val_loss: 0.0766\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0720 - val_loss: 0.0766\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0720 - val_loss: 0.0766\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0719 - val_loss: 0.0766\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0719 - val_loss: 0.0766\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0719 - val_loss: 0.0766\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0718 - val_loss: 0.0765\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0718 - val_loss: 0.0765\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0718 - val_loss: 0.0765\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0717 - val_loss: 0.0765\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0717 - val_loss: 0.0765\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0717 - val_loss: 0.0765\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0764\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0764\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.075 - 0s 91us/step - loss: 0.0716 - val_loss: 0.0764\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0715 - val_loss: 0.0764\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0715 - val_loss: 0.0764\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0714 - val_loss: 0.0764\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0714 - val_loss: 0.0763\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0714 - val_loss: 0.0763\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0713 - val_loss: 0.0763\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0713 - val_loss: 0.0763\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0713 - val_loss: 0.0763\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0712 - val_loss: 0.0763\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0712 - val_loss: 0.0762\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0712 - val_loss: 0.0762\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0712 - val_loss: 0.0762\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0711 - val_loss: 0.0762\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0711 - val_loss: 0.0762\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0711 - val_loss: 0.0762\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0710 - val_loss: 0.0762\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0710 - val_loss: 0.0761\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0710 - val_loss: 0.0761\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0709 - val_loss: 0.0761\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0709 - val_loss: 0.0761\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0709 - val_loss: 0.0761\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0761\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0760\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0708 - val_loss: 0.0760\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0707 - val_loss: 0.0760\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0707 - val_loss: 0.0760\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0707 - val_loss: 0.0760\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0706 - val_loss: 0.0760\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0706 - val_loss: 0.0759\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0706 - val_loss: 0.0759\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0706 - val_loss: 0.0759\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0705 - val_loss: 0.0759\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0705 - val_loss: 0.0759\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0705 - val_loss: 0.0759\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0704 - val_loss: 0.0759\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0704 - val_loss: 0.0758\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0704 - val_loss: 0.0758\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0703 - val_loss: 0.0758\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0703 - val_loss: 0.0758\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0703 - val_loss: 0.0758\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0702 - val_loss: 0.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0702 - val_loss: 0.0758\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0702 - val_loss: 0.0757\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0702 - val_loss: 0.0757\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0701 - val_loss: 0.0757\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0701 - val_loss: 0.0757\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0701 - val_loss: 0.0757\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0700 - val_loss: 0.0757\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0700 - val_loss: 0.0757\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0700 - val_loss: 0.0756\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0699 - val_loss: 0.0756\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0699 - val_loss: 0.0756\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0699 - val_loss: 0.0756\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0698 - val_loss: 0.0756\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0698 - val_loss: 0.0756\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0698 - val_loss: 0.0756\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0698 - val_loss: 0.0755\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0697 - val_loss: 0.0755\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0697 - val_loss: 0.0755\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0697 - val_loss: 0.0755\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0696 - val_loss: 0.0755\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0696 - val_loss: 0.0755\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0696 - val_loss: 0.0755\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0695 - val_loss: 0.0754\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0754\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0695 - val_loss: 0.0754\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0754\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0694 - val_loss: 0.0754\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0694 - val_loss: 0.0754\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0694 - val_loss: 0.0754\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0693 - val_loss: 0.0753\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0693 - val_loss: 0.0753\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0693 - val_loss: 0.0753\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0693 - val_loss: 0.0753\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0692 - val_loss: 0.0753\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0692 - val_loss: 0.0753\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0692 - val_loss: 0.0753\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0752\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0691 - val_loss: 0.0752\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0752\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0691 - val_loss: 0.0752\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0690 - val_loss: 0.0752\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0690 - val_loss: 0.0752\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0690 - val_loss: 0.0752\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0690 - val_loss: 0.0752\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0689 - val_loss: 0.0751\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0689 - val_loss: 0.0751\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0689 - val_loss: 0.0751\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0688 - val_loss: 0.0751\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0751\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0751\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0688 - val_loss: 0.0751\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0687 - val_loss: 0.0751\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0750\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0750\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0687 - val_loss: 0.0750\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0686 - val_loss: 0.0750\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0686 - val_loss: 0.0750\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0686 - val_loss: 0.0750\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0686 - val_loss: 0.0750\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0685 - val_loss: 0.0749\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0749\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0685 - val_loss: 0.0749\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0749\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0684 - val_loss: 0.0749\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0684 - val_loss: 0.0749\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0684 - val_loss: 0.0749\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0683 - val_loss: 0.0749\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0683 - val_loss: 0.0748\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0683 - val_loss: 0.0748\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0683 - val_loss: 0.0748\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0682 - val_loss: 0.0748\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0682 - val_loss: 0.0748\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0682 - val_loss: 0.0748\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0682 - val_loss: 0.0748\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0681 - val_loss: 0.0748\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0681 - val_loss: 0.0747\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0681 - val_loss: 0.0747\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0681 - val_loss: 0.0747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0680 - val_loss: 0.0747\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0680 - val_loss: 0.0747\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0680 - val_loss: 0.0747\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0680 - val_loss: 0.0747\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0679 - val_loss: 0.0747\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0679 - val_loss: 0.0747\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0679 - val_loss: 0.0746\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0679 - val_loss: 0.0746\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0678 - val_loss: 0.0746\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0678 - val_loss: 0.0746\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0678 - val_loss: 0.0746\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0678 - val_loss: 0.0746\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0677 - val_loss: 0.0746\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0677 - val_loss: 0.0746\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0677 - val_loss: 0.0745\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0677 - val_loss: 0.0745\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0677 - val_loss: 0.0745\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0676 - val_loss: 0.0745\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0676 - val_loss: 0.0745\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0676 - val_loss: 0.0745\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0676 - val_loss: 0.0745\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0675 - val_loss: 0.0745\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0675 - val_loss: 0.0745\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0675 - val_loss: 0.0744\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0675 - val_loss: 0.0744\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0674 - val_loss: 0.0744\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0674 - val_loss: 0.0744\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0674 - val_loss: 0.0744\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0674 - val_loss: 0.0744\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0673 - val_loss: 0.0744\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0673 - val_loss: 0.0744\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0673 - val_loss: 0.0743\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0673 - val_loss: 0.0743\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0672 - val_loss: 0.0743\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0672 - val_loss: 0.0743\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0672 - val_loss: 0.0743\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0672 - val_loss: 0.0743\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0671 - val_loss: 0.0743\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0671 - val_loss: 0.0743\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0671 - val_loss: 0.0743\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0671 - val_loss: 0.0742\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0670 - val_loss: 0.0742\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0670 - val_loss: 0.0742\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0670 - val_loss: 0.0742\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0670 - val_loss: 0.0742\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0670 - val_loss: 0.0742\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0669 - val_loss: 0.0742\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0669 - val_loss: 0.0742\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0669 - val_loss: 0.0742\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0669 - val_loss: 0.0741\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0668 - val_loss: 0.0741\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0668 - val_loss: 0.0741\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0668 - val_loss: 0.0741\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0668 - val_loss: 0.0741\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0667 - val_loss: 0.0741\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0667 - val_loss: 0.0741\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0667 - val_loss: 0.0741\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0667 - val_loss: 0.0741\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0667 - val_loss: 0.0740\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0666 - val_loss: 0.0740\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0666 - val_loss: 0.0740\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0666 - val_loss: 0.0740\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0666 - val_loss: 0.0740\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0665 - val_loss: 0.0740\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0665 - val_loss: 0.0740\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0665 - val_loss: 0.0740\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0665 - val_loss: 0.0740\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0665 - val_loss: 0.0740\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0664 - val_loss: 0.0739\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0664 - val_loss: 0.0739\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0664 - val_loss: 0.0739\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0664 - val_loss: 0.0739\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0664 - val_loss: 0.0739\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0739\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0739\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0663 - val_loss: 0.0739\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0663 - val_loss: 0.0739\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 84us/step - loss: 0.0662 - val_loss: 0.0738\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0738\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0662 - val_loss: 0.0738\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0662 - val_loss: 0.0738\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0662 - val_loss: 0.0738\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0661 - val_loss: 0.0738\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0738\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0738\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0661 - val_loss: 0.0738\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0738\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0660 - val_loss: 0.0737\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0660 - val_loss: 0.0737\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0660 - val_loss: 0.0737\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0660 - val_loss: 0.0737\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0659 - val_loss: 0.0737\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0659 - val_loss: 0.0737\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0659 - val_loss: 0.0737\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0737\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0737\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0658 - val_loss: 0.0737\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0658 - val_loss: 0.0736\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0658 - val_loss: 0.0736\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0658 - val_loss: 0.0736\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0658 - val_loss: 0.0736\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0657 - val_loss: 0.0736\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0657 - val_loss: 0.0736\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0657 - val_loss: 0.0736\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0657 - val_loss: 0.0736\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0657 - val_loss: 0.0736\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0656 - val_loss: 0.0736\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0656 - val_loss: 0.0736\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0656 - val_loss: 0.0735\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0656 - val_loss: 0.0735\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0656 - val_loss: 0.0735\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0655 - val_loss: 0.0735\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0655 - val_loss: 0.0735\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0655 - val_loss: 0.0735\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0655 - val_loss: 0.0735\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0655 - val_loss: 0.0735\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0735\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0735\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0734\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0734\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0654 - val_loss: 0.0734\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0653 - val_loss: 0.0734\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0734\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0653 - val_loss: 0.0734\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0653 - val_loss: 0.0734\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.050 - 0s 98us/step - loss: 0.0653 - val_loss: 0.0734\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0652 - val_loss: 0.0734\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0652 - val_loss: 0.0734\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0652 - val_loss: 0.0734\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0652 - val_loss: 0.0733\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0652 - val_loss: 0.0733\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0651 - val_loss: 0.0733\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0651 - val_loss: 0.0733\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0651 - val_loss: 0.0733\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0651 - val_loss: 0.0733\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0651 - val_loss: 0.0733\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0650 - val_loss: 0.0733\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0650 - val_loss: 0.0733\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0650 - val_loss: 0.0733\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0650 - val_loss: 0.0732\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0650 - val_loss: 0.0732\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0650 - val_loss: 0.0732\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0648 - val_loss: 0.0732\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0648 - val_loss: 0.0732\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0648 - val_loss: 0.0732\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0648 - val_loss: 0.0731\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0648 - val_loss: 0.0731\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0647 - val_loss: 0.0731\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0647 - val_loss: 0.0731\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0647 - val_loss: 0.0731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0647 - val_loss: 0.0731\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0647 - val_loss: 0.0731\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0646 - val_loss: 0.0731\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0646 - val_loss: 0.0731\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0731\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0731\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0730\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.069 - 0s 91us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0729\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0642 - val_loss: 0.0729\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0729\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0729\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0729\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0728\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0641 - val_loss: 0.0728\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0641 - val_loss: 0.0728\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0641 - val_loss: 0.0728\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0641 - val_loss: 0.0728\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0641 - val_loss: 0.0728\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0640 - val_loss: 0.0728\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0728\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0728\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0728\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0728\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0640 - val_loss: 0.0728\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0727\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0727\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.0639 - val_loss: 0.0727\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0727\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0639 - val_loss: 0.0727\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0639 - val_loss: 0.0727\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0727\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0727\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0727\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0727\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0727\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0638 - val_loss: 0.0727\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0636 - val_loss: 0.0726\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0636 - val_loss: 0.0726\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0636 - val_loss: 0.0726\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0636 - val_loss: 0.0726\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0636 - val_loss: 0.0726\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0636 - val_loss: 0.0726\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0635 - val_loss: 0.0725\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0635 - val_loss: 0.0725\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0635 - val_loss: 0.0725\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0725\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0635 - val_loss: 0.0725\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0634 - val_loss: 0.0725\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0725\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0724\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0724\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0724\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0724\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0633 - val_loss: 0.0724\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0632 - val_loss: 0.0724\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0724\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0724\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0632 - val_loss: 0.0724\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0724\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0724\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0724\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0723\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0723\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0723\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0631 - val_loss: 0.0723\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0631 - val_loss: 0.0723\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 86us/step - loss: 0.0630 - val_loss: 0.0723\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0630 - val_loss: 0.0723\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0723\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0630 - val_loss: 0.0723\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0630 - val_loss: 0.0723\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0630 - val_loss: 0.0723\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0629 - val_loss: 0.0723\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0723\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0629 - val_loss: 0.0722\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0629 - val_loss: 0.0722\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0629 - val_loss: 0.0722\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0722\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0629 - val_loss: 0.0722\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0628 - val_loss: 0.0722\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0722\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0627 - val_loss: 0.0721\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0721\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0627 - val_loss: 0.0721\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0721\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0627 - val_loss: 0.0721\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0721\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0721\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0625 - val_loss: 0.0720\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0625 - val_loss: 0.0720\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0720\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0720\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0625 - val_loss: 0.0720\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0624 - val_loss: 0.0720\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0720\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0719\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0719\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0719\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0623 - val_loss: 0.0719\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0719\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0719\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0719\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0621 - val_loss: 0.0718\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 686us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0620 - val_loss: 0.0718\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0619 - val_loss: 0.0717\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0618 - val_loss: 0.0717\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0617 - val_loss: 0.0716\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0616 - val_loss: 0.0716\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0616 - val_loss: 0.0715\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0615 - val_loss: 0.0715\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0614 - val_loss: 0.0715\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0614 - val_loss: 0.0715\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0614 - val_loss: 0.0715\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0614 - val_loss: 0.0715\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0614 - val_loss: 0.0715\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0614 - val_loss: 0.0715\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0614 - val_loss: 0.0714\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0614 - val_loss: 0.0714\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0613 - val_loss: 0.0714\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0612 - val_loss: 0.0714\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0612 - val_loss: 0.0714\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0612 - val_loss: 0.0714\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0612 - val_loss: 0.0714\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0612 - val_loss: 0.0713\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0612 - val_loss: 0.0713\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0612 - val_loss: 0.0713\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0612 - val_loss: 0.0713\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0611 - val_loss: 0.0713\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0610 - val_loss: 0.0713\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0610 - val_loss: 0.0713\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0610 - val_loss: 0.0712\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0610 - val_loss: 0.0712\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0610 - val_loss: 0.0712\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0610 - val_loss: 0.0712\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0610 - val_loss: 0.0712\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0610 - val_loss: 0.0712\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0609 - val_loss: 0.0712\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0608 - val_loss: 0.0711\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0607 - val_loss: 0.0711\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0607 - val_loss: 0.0711\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0607 - val_loss: 0.0711\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0607 - val_loss: 0.0711\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0607 - val_loss: 0.0711\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0607 - val_loss: 0.0711\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0607 - val_loss: 0.0710\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0607 - val_loss: 0.0710\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0606 - val_loss: 0.0710\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0605 - val_loss: 0.0710\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0605 - val_loss: 0.0710\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0605 - val_loss: 0.0710\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0605 - val_loss: 0.0710\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0605 - val_loss: 0.0710\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0605 - val_loss: 0.0709\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0605 - val_loss: 0.0709\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0605 - val_loss: 0.0709\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0709\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0709\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0709\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0708\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0603 - val_loss: 0.0708\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0603 - val_loss: 0.0708\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0708\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0603 - val_loss: 0.0708\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0708\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0602 - val_loss: 0.0708\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0602 - val_loss: 0.0708\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0602 - val_loss: 0.0708\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0602 - val_loss: 0.0708\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.062 - 0s 105us/step - loss: 0.0602 - val_loss: 0.0708\n",
      "0.06595896184444427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.45197   , -0.18194647,  0.19040312,  0.13549015, -0.13787475],\n",
       "        [-0.35525405, -0.08197729,  0.26338264, -0.04371401,  0.24996547],\n",
       "        [ 0.3542493 , -0.4040447 , -0.05913693,  0.05483595,  0.15408912],\n",
       "        [ 0.00760729, -0.1966862 , -0.2202771 , -0.40061685, -0.2770086 ],\n",
       "        [ 0.4583157 ,  0.4571072 , -0.14390117,  0.10478602,  0.04813117],\n",
       "        [-0.42968318, -0.43324718,  0.29981327,  0.22062139,  0.25859982],\n",
       "        [ 0.43665075,  0.02570491, -0.00632085,  0.03287093, -0.24762739],\n",
       "        [ 0.437256  , -0.04783225,  0.22768451, -0.41456124, -0.43501008],\n",
       "        [ 0.27832022,  0.23796462,  0.05645671, -0.0660567 , -0.19204684],\n",
       "        [-0.36083192, -0.09220301,  0.24773034,  0.06004743,  0.26164725],\n",
       "        [-0.34205052,  0.17353325, -0.13583308,  0.3771883 , -0.23250557],\n",
       "        [-0.26113462,  0.15293707, -0.28178668,  0.20950551,  0.32894343],\n",
       "        [ 0.06508092,  0.14980057, -0.23753937, -0.12493879, -0.09655069],\n",
       "        [-0.12638728,  0.3488503 , -0.26134542, -0.02836722, -0.14132415],\n",
       "        [ 0.16599785, -0.18731087,  0.06414036, -0.3420433 , -0.3902691 ],\n",
       "        [-0.21013476, -0.06145939,  0.13486007,  0.3948532 ,  0.15653886],\n",
       "        [ 0.2581689 , -0.00367099, -0.06458698, -0.31276548, -0.33700976],\n",
       "        [-0.21836042, -0.3836884 ,  0.22122648,  0.34882662,  0.09931771],\n",
       "        [ 0.42597777,  0.36983347,  0.1652942 , -0.40802857, -0.31368408],\n",
       "        [ 0.07853629, -0.01647905,  0.15813404, -0.01329787, -0.20404576],\n",
       "        [-0.12142081,  0.31543997, -0.01573741, -0.06858789, -0.3202831 ],\n",
       "        [-0.07184634, -0.40104648, -0.22900204,  0.12031286, -0.2997949 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.0013584 ,  0.00208608,  0.00090162,  0.00970571, -0.00039535],\n",
       "       dtype=float32),\n",
       " array([[ 0.226951  , -0.46984982,  0.42266738,  0.35381308,  0.6278377 ,\n",
       "         -0.35478318,  0.55092716, -0.23261064, -0.27521694, -0.13404591],\n",
       "        [-0.39938927, -0.27804038,  0.15902834, -0.25094357, -0.53787035,\n",
       "         -0.55603635,  0.28941837,  0.39417234, -0.32902616,  0.43982124],\n",
       "        [ 0.5190317 ,  0.4672786 ,  0.16686049,  0.356379  , -0.14854984,\n",
       "         -0.19426423, -0.18835782, -0.19766521, -0.03348697,  0.6343894 ],\n",
       "        [ 0.54604256, -0.20660006,  0.333811  , -0.19754279, -0.09465379,\n",
       "          0.41109747, -0.55157083,  0.31494752,  0.53669167,  0.49405524],\n",
       "        [-0.22711433, -0.13939938,  0.21537316,  0.48566183, -0.18070081,\n",
       "         -0.03873194, -0.5484212 , -0.13699943,  0.5003418 ,  0.4402901 ]],\n",
       "       dtype=float32),\n",
       " array([ 9.5967539e-03, -7.8274906e-03, -2.8973520e-03, -4.6565398e-03,\n",
       "         2.6624773e-03, -6.5494838e-05, -3.8080576e-03,  7.7339099e-03,\n",
       "        -5.3526592e-03,  4.8894933e-03], dtype=float32),\n",
       " array([[ 0.714005  ],\n",
       "        [-0.5756406 ],\n",
       "        [-0.21756493],\n",
       "        [-0.34468234],\n",
       "        [ 0.20229597],\n",
       "        [-0.00573037],\n",
       "        [-0.27569392],\n",
       "        [ 0.5694553 ],\n",
       "        [-0.40275815],\n",
       "        [ 0.35616797]], dtype=float32),\n",
       " array([0.01349535], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, sgd, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sgd_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1013 - val_loss: 0.0292\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0349 - val_loss: 0.0323\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0330 - val_loss: 0.0192\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0232 - val_loss: 0.0123\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0211 - val_loss: 0.0347\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0223\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0275 - val_loss: 0.0202\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0221 - val_loss: 0.0146\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0201 - val_loss: 0.0257\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0357 - val_loss: 0.0111\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0182 - val_loss: 0.0066\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0177 - val_loss: 0.0123\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0162 - val_loss: 0.0065\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0277 - val_loss: 0.0072\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0135 - val_loss: 0.0057\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0242 - val_loss: 0.0073\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0170 - val_loss: 0.0059\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0160 - val_loss: 0.0054\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0188 - val_loss: 0.0093\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0152 - val_loss: 0.0082\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0158 - val_loss: 0.0048\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0137 - val_loss: 0.0052\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0137 - val_loss: 0.0055\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0167 - val_loss: 0.0084\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0146 - val_loss: 0.0171\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0142 - val_loss: 0.0052\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0122 - val_loss: 0.0064\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0161 - val_loss: 0.0038\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0125 - val_loss: 0.0072\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0121 - val_loss: 0.0234\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0147 - val_loss: 0.0066\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0179 - val_loss: 0.0055\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0163 - val_loss: 0.0063\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0198 - val_loss: 0.0049\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0046\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0122 - val_loss: 0.0049\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0182 - val_loss: 0.0068\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0117 - val_loss: 0.0054\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0140 - val_loss: 0.0056\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0140 - val_loss: 0.0045\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0136 - val_loss: 0.0060\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0095 - val_loss: 0.0131\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0146 - val_loss: 0.0061\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0101 - val_loss: 0.0050\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0148 - val_loss: 0.0079\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0096 - val_loss: 0.0141\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0115 - val_loss: 0.0066\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0153 - val_loss: 0.0052\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0127\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0102 - val_loss: 0.0049\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0099 - val_loss: 0.0169\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0161 - val_loss: 0.0046\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0102 - val_loss: 0.0074\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0102 - val_loss: 0.0046\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0097 - val_loss: 0.0176\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0133 - val_loss: 0.0080\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0088 - val_loss: 0.0152\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0111 - val_loss: 0.0039\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0100 - val_loss: 0.0049\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0153\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0116 - val_loss: 0.0048\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0067 - val_loss: 0.0039\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0072 - val_loss: 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0046\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0067 - val_loss: 0.0114\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0101 - val_loss: 0.0045\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0101 - val_loss: 0.0038\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0043\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0115\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0058 - val_loss: 0.0101\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0115\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0084\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0090\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0071\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0069\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0077\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0086\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0083\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0072\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0032\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0039 - val_loss: 0.0087\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0070\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0067\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0067\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0079\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0096\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0076\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0075\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "0.010828805156052113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 9.78599906e-01, -7.54701614e-01, -1.16646096e-01,\n",
       "          8.80859137e-01, -3.23170692e-01],\n",
       "        [ 1.94833159e+00, -7.75677741e-01, -1.28074750e-01,\n",
       "         -5.75051606e-01, -1.37827128e-01],\n",
       "        [-1.29131877e+00,  3.37375343e-01,  7.63800740e-02,\n",
       "         -1.50479507e+00,  2.95576423e-01],\n",
       "        [ 4.29194957e-01, -1.86303467e-03,  2.30076775e-01,\n",
       "         -8.18101704e-01, -3.82067412e-02],\n",
       "        [-2.01021686e-01,  2.41901651e-02,  1.15593076e-01,\n",
       "         -4.86807317e-01,  1.03044331e-01],\n",
       "        [ 6.85561538e-01, -6.68647289e-01,  4.88949344e-02,\n",
       "          1.62072980e+00, -3.93864453e-01],\n",
       "        [ 9.28017557e-01, -8.50471199e-01,  2.18809485e-01,\n",
       "         -7.80623853e-01, -3.97662371e-02],\n",
       "        [ 8.56747985e-01, -1.38361007e-02, -1.24440596e-01,\n",
       "         -2.48450376e-02, -1.62792876e-01],\n",
       "        [-1.96086913e-01,  2.32188523e-01, -4.16543558e-02,\n",
       "         -3.27066451e-01, -3.00939977e-01],\n",
       "        [ 1.69159055e+00, -4.62307036e-01, -2.18834877e-02,\n",
       "         -2.81011518e-02, -3.85196298e-01],\n",
       "        [-2.93811977e-01,  5.61920643e-01, -1.60327017e-01,\n",
       "         -3.47713113e-01,  3.19494903e-01],\n",
       "        [-1.34753895e+00,  1.35866261e+00,  3.66869792e-02,\n",
       "          6.95899427e-01, -1.91355124e-01],\n",
       "        [-4.46600586e-01, -4.59046870e-01, -1.57067791e-01,\n",
       "          7.36850202e-01,  4.70240951e-01],\n",
       "        [ 4.91688669e-01,  2.62089443e+00,  3.42919081e-01,\n",
       "          3.17883801e+00, -1.10885811e+00],\n",
       "        [ 4.57568198e-01,  4.10355218e-02, -9.16161686e-02,\n",
       "         -1.51523501e-01,  1.53060585e-01],\n",
       "        [ 7.60122955e-01,  1.82453245e-02,  1.48274750e-01,\n",
       "         -4.90730405e-02, -1.37743354e-01],\n",
       "        [-1.00150919e+00,  4.35608737e-02,  1.28601983e-01,\n",
       "         -7.15085447e-01,  1.79866686e-01],\n",
       "        [-2.07000077e-01, -3.30982178e-01, -1.43415928e-01,\n",
       "          9.15677309e-01,  3.91038805e-01],\n",
       "        [-1.41530442e+00,  1.25379789e+00, -3.58413011e-01,\n",
       "         -6.73781708e-03,  1.89416468e-01],\n",
       "        [-2.34010041e-01,  6.46845460e-01,  2.38660336e-01,\n",
       "         -6.48881197e-02, -2.23092005e-01],\n",
       "        [-1.55919337e+00,  1.73558041e-01,  4.53799218e-03,\n",
       "         -3.39766049e+00,  3.16510201e-01],\n",
       "        [-7.21194148e-01,  1.28519464e+00, -1.40525714e-01,\n",
       "         -1.14089549e+00,  3.70176345e-01]], dtype=float32),\n",
       " array([-0.71803457, -0.20324881, -0.18976833, -0.77490216,  0.3318402 ],\n",
       "       dtype=float32),\n",
       " array([[ 6.7561232e-03,  1.4705397e-03, -4.6556517e-03,  9.4482340e-03,\n",
       "          4.6070415e-01,  1.3042659e-02, -7.4272305e-02, -3.5922833e-02,\n",
       "         -5.0237727e-01,  7.9527348e-03],\n",
       "        [ 1.5077021e-02,  7.1790265e-03, -1.6272712e-02,  8.0411676e-03,\n",
       "          7.0052445e-01, -9.9271350e-03, -1.8422292e-01, -1.1354406e-01,\n",
       "         -5.5296344e-01, -2.9101580e-02],\n",
       "        [-2.9677067e-02,  1.3134992e-03,  2.6144041e-02, -4.8491802e-02,\n",
       "          8.1674196e-04,  7.1478030e-04, -3.3380985e-03, -7.1235284e-02,\n",
       "         -7.0944773e-03,  4.4740867e-02],\n",
       "        [ 8.5311765e-03, -3.5011984e-02, -1.1851745e-02,  1.0964240e-02,\n",
       "          5.3392363e-01, -1.1741241e-02,  1.6103445e-01,  1.2906604e-01,\n",
       "         -9.6275616e-01, -2.4521276e-03],\n",
       "        [-2.1432556e-02,  2.0455165e-02,  2.4497760e-02, -3.1840513e-03,\n",
       "          6.7931050e-01, -7.9796679e-02,  1.4060420e-01,  4.0584773e-02,\n",
       "          3.2077108e-02, -6.9396473e-02]], dtype=float32),\n",
       " array([-0.03413165,  0.016333  ,  0.0232226 , -0.02889457,  0.09177367,\n",
       "        -0.00893753,  0.22683331,  0.11342078, -0.4360718 ,  0.00828549],\n",
       "       dtype=float32),\n",
       " array([[ 0.00380979],\n",
       "        [-0.00449764],\n",
       "        [-0.00299433],\n",
       "        [ 0.00640056],\n",
       "        [ 0.00737754],\n",
       "        [-0.01169085],\n",
       "        [ 0.02455141],\n",
       "        [ 0.01716273],\n",
       "        [-0.31964588],\n",
       "        [-0.01098356]], dtype=float32),\n",
       " array([0.24834804], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, RMSprop, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_rmsprop_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 35.5056 - val_loss: 34.3022\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 460us/step - loss: 32.7716 - val_loss: 30.6171\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3248 - val_loss: 26.2560\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.8332 - val_loss: 20.9518\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 19.3930 - val_loss: 14.9729\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 13.4321 - val_loss: 9.0617\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6480 - val_loss: 4.3258\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1714 - val_loss: 1.7772\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3302 - val_loss: 1.8750\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2880 - val_loss: 3.7186\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1182 - val_loss: 5.0242\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8644 - val_loss: 4.8349\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2594 - val_loss: 3.7867\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0067 - val_loss: 2.6690\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8816 - val_loss: 1.8067\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2643 - val_loss: 1.2420\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1250 - val_loss: 0.9764\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2702 - val_loss: 0.9619\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4977 - val_loss: 1.0560\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6385 - val_loss: 1.0985\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5991 - val_loss: 1.0124\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3883 - val_loss: 0.8210\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0890 - val_loss: 0.5997\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8006 - val_loss: 0.4268\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5955 - val_loss: 0.3526\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5047 - val_loss: 0.3814\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5165 - val_loss: 0.4651\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5797 - val_loss: 0.5267\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6220 - val_loss: 0.5147\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5913 - val_loss: 0.4380\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4865 - val_loss: 0.3429\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3480 - val_loss: 0.2638\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2211 - val_loss: 0.2041\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1335 - val_loss: 0.1551\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0946 - val_loss: 0.1150\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1011 - val_loss: 0.0895\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1388 - val_loss: 0.0817\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1864 - val_loss: 0.0882\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2236 - val_loss: 0.1010\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2391 - val_loss: 0.1105\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2310 - val_loss: 0.1081\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2023 - val_loss: 0.0902\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1592 - val_loss: 0.0609\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1100 - val_loss: 0.0308\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0651 - val_loss: 0.0106\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0332 - val_loss: 0.0044\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0094\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0188 - val_loss: 0.0187\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0296 - val_loss: 0.0272\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0447 - val_loss: 0.0321\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0580 - val_loss: 0.0334\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0648 - val_loss: 0.0322\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0633 - val_loss: 0.0301\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0552 - val_loss: 0.0282\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0440 - val_loss: 0.0262\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0333 - val_loss: 0.0237\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0210\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0203 - val_loss: 0.0189\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0191 - val_loss: 0.0177\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0203 - val_loss: 0.0172\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0207 - val_loss: 0.0156\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0131\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0102\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0158 - val_loss: 0.0077\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0136 - val_loss: 0.0062\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0059\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0116 - val_loss: 0.0067\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0136 - val_loss: 0.0077\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0067\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0134 - val_loss: 0.0054\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0043\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0036\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0034\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0024\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0023\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 9.9890e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 9.9492e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 9.9094e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 9.8700e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 9.8308e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0030 - val_loss: 9.7919e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 9.7531e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 9.7148e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 9.6764e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 9.6384e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 9.6005e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 9.5627e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 9.5255e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 9.4881e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 9.4511e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.4144e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.3775e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.3411e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.3049e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.2687e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.2331e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.1972e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 9.1620e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.1266e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 9.0916e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.0567e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.0223e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 8.9878e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.9536e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.9194e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.8856e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.8520e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.8185e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.7852e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.7520e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0028 - val_loss: 8.7191e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.6863e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 8.6537e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.6213e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.5890e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.5570e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 8.5250e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.4933e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0027 - val_loss: 8.4620e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 8.4304e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.3991e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 8.3684e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 8.3375e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.3068e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0027 - val_loss: 8.2763e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 8.2459e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 8.2156e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.1857e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 8.1558e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.1260e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 8.0965e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 8.0669e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 8.0378e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 8.0087e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.9796e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.9509e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.9223e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.8938e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 7.8656e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.8371e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.8092e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.7814e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.7536e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.7261e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.6987e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.6713e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.6442e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.6171e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.5901e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 7.5634e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.5367e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.5104e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.4839e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.4578e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.4317e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.4057e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.3798e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.3541e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.3288e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.3033e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.2782e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.2530e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.2280e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.2032e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.1784e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.1537e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.1291e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.1048e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.0804e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 7.0563e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.0323e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.0084e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 6.9847e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.9611e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 6.9375e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 6.9143e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 6.8907e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.8675e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.8445e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 6.8215e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 6.7989e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0023 - val_loss: 6.7761e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 6.7534e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 6.7311e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.7085e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.6863e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 6.6643e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.6420e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 6.6201e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.5983e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 6.5766e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 6.5549e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.5333e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.5120e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 6.4905e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.4693e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 6.4483e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 6.4274e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 6.4063e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3856e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3650e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.3444e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3240e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3037e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0022 - val_loss: 6.2832e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.2630e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.2431e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.2230e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.2032e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.1834e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.1635e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.1439e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.1245e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.1050e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.0858e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.0665e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.0473e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 6.0283e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 6.0092e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 5.9903e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9716e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9529e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.9341e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9156e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.8971e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.8788e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.8605e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 5.8423e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.8245e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.8063e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 5.7885e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.7706e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0021 - val_loss: 5.7528e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.7351e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.7176e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.7002e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 5.6827e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6654e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6480e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.6308e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.6137e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 5.5966e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.5796e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.5628e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.5461e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 0.0020 - val_loss: 5.5294e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 5.5127e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 5.4962e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.4795e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.4631e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 5.4470e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.4307e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.4144e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 5.3984e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.3823e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.3662e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 5.3504e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.3344e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.3188e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.3032e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2875e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.2719e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 5.2564e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 5.2410e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0019 - val_loss: 5.2257e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.2103e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 5.1951e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.1801e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.1651e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.1499e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.1352e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.1202e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.1055e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.0907e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.0762e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.0613e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.0469e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0324e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.0179e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0035e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.9892e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.9750e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.9609e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 4.9469e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 4.9327e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.9187e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0019 - val_loss: 4.9047e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.8910e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.8772e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.8634e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 4.8495e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.8360e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.8224e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.8088e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.7955e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.7821e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.7689e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.7556e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.7425e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.7292e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 4.7162e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.7029e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0018 - val_loss: 4.6899e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.6769e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6641e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6512e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6386e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6257e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 4.6131e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 4.6004e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.5879e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.5753e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 4.5630e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 4.5506e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.5381e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 4.5260e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.5135e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.5014e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.4891e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4771e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4650e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.4529e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4410e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.4290e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.4173e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4054e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.3937e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3819e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3704e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3587e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3471e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0017 - val_loss: 4.3356e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3240e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.3126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.3013e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.2898e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2785e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 4.2673e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2558e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.2448e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.2337e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2227e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 4.2116e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0016 - val_loss: 4.2005e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.1896e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 4.1787e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0016 - val_loss: 4.1678e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.1569e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.1462e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 4.1355e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.1248e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.1142e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 4.1035e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.0930e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 4.0825e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.0720e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.0615e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 4.0511e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.0407e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 4.0304e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 4.0201e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.0099e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9996e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 3.9895e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9792e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 3.9692e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9592e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.9491e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 3.9391e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9292e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.9192e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 3.9094e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.8995e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0016 - val_loss: 3.8898e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 3.8802e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.8703e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.8606e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 3.8508e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.8414e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.8318e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.8222e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.8128e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.8033e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7938e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7845e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7751e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7656e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7564e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 3.7471e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7377e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7287e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7195e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7103e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7012e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.6921e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6831e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6741e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 3.6652e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6562e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6472e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6385e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6295e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6207e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6120e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6033e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.5945e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.5858e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.5770e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5685e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5599e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5514e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5428e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5342e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.5258e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.5174e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5091e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.5005e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4922e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4838e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 3.4757e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.4673e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4590e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.4508e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4426e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4344e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0014 - val_loss: 3.4263e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4182e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4102e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0014 - val_loss: 3.4021e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3939e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3860e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.3780e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3701e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3621e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0014 - val_loss: 3.3543e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 3.3465e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.3386e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0014 - val_loss: 3.3307e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3229e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3152e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 3.3075e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 3.2997e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.2921e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.2845e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.2768e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.2691e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.2616e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 3.2541e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.2465e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.2389e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.2314e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 3.2240e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.2166e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0013 - val_loss: 3.2091e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.2018e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.1944e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1870e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1797e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1724e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1652e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.1579e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.1507e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.1435e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1363e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.1291e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1219e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1148e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.1076e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1006e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.0936e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.0865e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.0795e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0727e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.0657e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0587e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.0517e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0448e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0380e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0312e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.0243e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0174e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.0106e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.0039e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.9971e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.9904e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.9837e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.9770e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.9703e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 2.9637e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.9571e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.9505e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.9439e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.9373e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.9308e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.9242e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.9177e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.9112e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.9048e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8983e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8918e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 2.8854e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8790e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.8726e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8664e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8600e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8536e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8473e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8410e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.8347e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8285e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8222e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0012 - val_loss: 2.8161e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8099e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8037e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.7976e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.7913e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.7852e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.7792e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.7731e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.7670e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.7608e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.7548e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.7488e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 2.7429e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.7367e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.7308e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 2.7248e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 2.7190e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.7130e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 2.7072e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.7013e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6953e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 2.6895e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 2.6837e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6778e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6719e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6662e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6605e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 2.6547e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6490e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6434e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6376e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6319e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6262e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6205e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6148e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6091e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6036e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5979e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0011 - val_loss: 2.5923e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5869e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 2.5813e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5758e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 2.5702e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5647e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5591e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5537e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5482e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5427e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 2.5373e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 2.5320e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5264e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 2.5210e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5156e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5102e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5049e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.4995e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4943e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4889e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4836e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 2.4784e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.4730e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.4678e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 2.4625e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.4573e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4522e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0010 - val_loss: 2.4468e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4417e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4364e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 2.4314e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.4262e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.4210e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 2.4159e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4108e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.4058e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4006e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.3955e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.3905e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9957e-04 - val_loss: 2.3854e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9739e-04 - val_loss: 2.3803e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9522e-04 - val_loss: 2.3754e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 9.9306e-04 - val_loss: 2.3703e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9089e-04 - val_loss: 2.3653e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8872e-04 - val_loss: 2.3603e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8656e-04 - val_loss: 2.3554e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8441e-04 - val_loss: 2.3504e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8225e-04 - val_loss: 2.3454e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8010e-04 - val_loss: 2.3405e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 9.7794e-04 - val_loss: 2.3356e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7580e-04 - val_loss: 2.3307e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7366e-04 - val_loss: 2.3258e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7152e-04 - val_loss: 2.3208e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6937e-04 - val_loss: 2.3160e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6724e-04 - val_loss: 2.3111e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6512e-04 - val_loss: 2.3064e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6298e-04 - val_loss: 2.3014e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6084e-04 - val_loss: 2.2966e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5873e-04 - val_loss: 2.2918e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 9.5661e-04 - val_loss: 2.2870e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5449e-04 - val_loss: 2.2821e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5237e-04 - val_loss: 2.2775e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5025e-04 - val_loss: 2.2726e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4814e-04 - val_loss: 2.2679e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.4604e-04 - val_loss: 2.2631e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4393e-04 - val_loss: 2.2583e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4181e-04 - val_loss: 2.2537e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3972e-04 - val_loss: 2.2489e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3762e-04 - val_loss: 2.2443e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3553e-04 - val_loss: 2.2396e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3344e-04 - val_loss: 2.2349e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3135e-04 - val_loss: 2.2304e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2926e-04 - val_loss: 2.2257e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2718e-04 - val_loss: 2.2210e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2509e-04 - val_loss: 2.2163e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2301e-04 - val_loss: 2.2117e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2093e-04 - val_loss: 2.2070e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1885e-04 - val_loss: 2.2024e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1678e-04 - val_loss: 2.1980e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1471e-04 - val_loss: 2.1933e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1264e-04 - val_loss: 2.1888e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1058e-04 - val_loss: 2.1841e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0851e-04 - val_loss: 2.1796e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0646e-04 - val_loss: 2.1751e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0440e-04 - val_loss: 2.1706e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0234e-04 - val_loss: 2.1661e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0030e-04 - val_loss: 2.1617e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9825e-04 - val_loss: 2.1571e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9621e-04 - val_loss: 2.1527e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9416e-04 - val_loss: 2.1482e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9211e-04 - val_loss: 2.1437e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9008e-04 - val_loss: 2.1394e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8803e-04 - val_loss: 2.1349e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8601e-04 - val_loss: 2.1304e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8398e-04 - val_loss: 2.1259e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 8.8195e-04 - val_loss: 2.1215e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7992e-04 - val_loss: 2.1172e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7790e-04 - val_loss: 2.1128e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7588e-04 - val_loss: 2.1085e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7385e-04 - val_loss: 2.1040e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7184e-04 - val_loss: 2.0997e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6982e-04 - val_loss: 2.0953e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6781e-04 - val_loss: 2.0911e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6580e-04 - val_loss: 2.0868e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6380e-04 - val_loss: 2.0824e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6179e-04 - val_loss: 2.0781e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5980e-04 - val_loss: 2.0738e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5779e-04 - val_loss: 2.0697e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 8.5579e-04 - val_loss: 2.0652e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.5380e-04 - val_loss: 2.0610e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5181e-04 - val_loss: 2.0567e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4982e-04 - val_loss: 2.0525e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4783e-04 - val_loss: 2.0483e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4585e-04 - val_loss: 2.0440e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 8.4386e-04 - val_loss: 2.0399e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4188e-04 - val_loss: 2.0356e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3991e-04 - val_loss: 2.0315e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3793e-04 - val_loss: 2.0272e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3596e-04 - val_loss: 2.0231e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3400e-04 - val_loss: 2.0189e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.3202e-04 - val_loss: 2.0148e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3007e-04 - val_loss: 2.0107e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2811e-04 - val_loss: 2.0066e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2613e-04 - val_loss: 2.0024e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2418e-04 - val_loss: 1.9984e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.2222e-04 - val_loss: 1.9942e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2027e-04 - val_loss: 1.9901e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1832e-04 - val_loss: 1.9859e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1637e-04 - val_loss: 1.9819e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1443e-04 - val_loss: 1.9778e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1248e-04 - val_loss: 1.9738e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1055e-04 - val_loss: 1.9697e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0861e-04 - val_loss: 1.9657e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0667e-04 - val_loss: 1.9617e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0474e-04 - val_loss: 1.9577e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0280e-04 - val_loss: 1.9537e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0088e-04 - val_loss: 1.9497e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9895e-04 - val_loss: 1.9458e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9704e-04 - val_loss: 1.9417e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9510e-04 - val_loss: 1.9377e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9318e-04 - val_loss: 1.9338e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9127e-04 - val_loss: 1.9298e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8936e-04 - val_loss: 1.9259e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8744e-04 - val_loss: 1.9219e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8553e-04 - val_loss: 1.9180e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8362e-04 - val_loss: 1.9141e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8172e-04 - val_loss: 1.9102e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7982e-04 - val_loss: 1.9063e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 7.7792e-04 - val_loss: 1.9024e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.7601e-04 - val_loss: 1.8985e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7412e-04 - val_loss: 1.8947e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7223e-04 - val_loss: 1.8908e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7034e-04 - val_loss: 1.8869e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6845e-04 - val_loss: 1.8831e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6657e-04 - val_loss: 1.8792e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6468e-04 - val_loss: 1.8754e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6280e-04 - val_loss: 1.8716e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6092e-04 - val_loss: 1.8677e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5905e-04 - val_loss: 1.8639e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5717e-04 - val_loss: 1.8603e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5529e-04 - val_loss: 1.8564e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5342e-04 - val_loss: 1.8527e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5155e-04 - val_loss: 1.8489e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4969e-04 - val_loss: 1.8450e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4783e-04 - val_loss: 1.8414e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 7.4597e-04 - val_loss: 1.8377e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4412e-04 - val_loss: 1.8339e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4226e-04 - val_loss: 1.8302e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4041e-04 - val_loss: 1.8264e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3856e-04 - val_loss: 1.8228e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3671e-04 - val_loss: 1.8190e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3486e-04 - val_loss: 1.8153e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3302e-04 - val_loss: 1.8116e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3118e-04 - val_loss: 1.8080e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2934e-04 - val_loss: 1.8044e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2751e-04 - val_loss: 1.8007e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2567e-04 - val_loss: 1.7971e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2384e-04 - val_loss: 1.7934e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2202e-04 - val_loss: 1.7898e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2018e-04 - val_loss: 1.7862e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1836e-04 - val_loss: 1.7826e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1654e-04 - val_loss: 1.7789e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1472e-04 - val_loss: 1.7754e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1290e-04 - val_loss: 1.7718e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1109e-04 - val_loss: 1.7683e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0927e-04 - val_loss: 1.7646e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0747e-04 - val_loss: 1.7610e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0566e-04 - val_loss: 1.7576e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0386e-04 - val_loss: 1.7541e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0205e-04 - val_loss: 1.7505e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0026e-04 - val_loss: 1.7469e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9845e-04 - val_loss: 1.7435e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9666e-04 - val_loss: 1.7400e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9486e-04 - val_loss: 1.7364e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 6.9307e-04 - val_loss: 1.7329e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9129e-04 - val_loss: 1.7295e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8949e-04 - val_loss: 1.7260e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8771e-04 - val_loss: 1.7226e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8592e-04 - val_loss: 1.7192e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8415e-04 - val_loss: 1.7158e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8238e-04 - val_loss: 1.7122e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8060e-04 - val_loss: 1.7088e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7883e-04 - val_loss: 1.7053e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7706e-04 - val_loss: 1.7019e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7529e-04 - val_loss: 1.6984e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7352e-04 - val_loss: 1.6952e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7177e-04 - val_loss: 1.6918e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7000e-04 - val_loss: 1.6883e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 6.6824e-04 - val_loss: 1.6850e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6650e-04 - val_loss: 1.6816e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6474e-04 - val_loss: 1.6782e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6299e-04 - val_loss: 1.6749e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6124e-04 - val_loss: 1.6716e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5951e-04 - val_loss: 1.6682e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5775e-04 - val_loss: 1.6649e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5601e-04 - val_loss: 1.6616e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5427e-04 - val_loss: 1.6584e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5254e-04 - val_loss: 1.6550e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5080e-04 - val_loss: 1.6517e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4907e-04 - val_loss: 1.6483e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4734e-04 - val_loss: 1.6451e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4562e-04 - val_loss: 1.6418e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4389e-04 - val_loss: 1.6385e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4217e-04 - val_loss: 1.6352e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4046e-04 - val_loss: 1.6321e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3874e-04 - val_loss: 1.6288e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3702e-04 - val_loss: 1.6256e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3531e-04 - val_loss: 1.6224e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3361e-04 - val_loss: 1.6192e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3189e-04 - val_loss: 1.6160e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3019e-04 - val_loss: 1.6129e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2850e-04 - val_loss: 1.6096e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2680e-04 - val_loss: 1.6065e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2509e-04 - val_loss: 1.6032e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2340e-04 - val_loss: 1.6002e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2171e-04 - val_loss: 1.5969e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2002e-04 - val_loss: 1.5938e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1833e-04 - val_loss: 1.5906e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1665e-04 - val_loss: 1.5875e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1496e-04 - val_loss: 1.5844e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1329e-04 - val_loss: 1.5813e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1161e-04 - val_loss: 1.5782e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.0993e-04 - val_loss: 1.5751e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0826e-04 - val_loss: 1.5720e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0659e-04 - val_loss: 1.5690e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0493e-04 - val_loss: 1.5658e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0326e-04 - val_loss: 1.5628e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0160e-04 - val_loss: 1.5596e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9994e-04 - val_loss: 1.5567e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9828e-04 - val_loss: 1.5536e-04\n",
      "0.00015739303489681333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1976997 ,  1.5927104 , -1.1752906 , -1.2031064 , -1.900142  ],\n",
       "        [-0.34487632, -1.3794736 , -0.08579582,  0.4584256 ,  1.3568879 ],\n",
       "        [-0.27764204, -0.22252198, -0.5472197 ,  0.77625304, -0.1435791 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.19651635, -0.64234316, -0.5309899 , -0.8096226 ,  0.5336856 ],\n",
       "       dtype=float32),\n",
       " array([[-0.2966159 ,  0.1727865 ,  0.43303227,  0.21931909, -0.32757246,\n",
       "         -0.12056155,  0.4277477 ,  0.6415886 ,  0.19594418,  0.32523718],\n",
       "        [-0.3642033 ,  0.05506884,  0.5542948 , -0.20617746, -0.16246602,\n",
       "          0.63586855,  0.14169088,  0.35682434,  0.26779062,  0.3255594 ],\n",
       "        [ 0.29197773,  0.5702987 , -0.21816432,  0.50399613,  0.3267495 ,\n",
       "         -0.04499248, -0.1804116 ,  0.7610589 , -0.17289652, -0.33659947],\n",
       "        [ 0.7045552 ,  0.5131875 , -0.7573231 ,  0.6203033 , -0.24380857,\n",
       "          0.42935875, -0.00260475,  0.30407017,  0.00347694,  0.22323215],\n",
       "        [ 0.05688379,  0.22905153,  0.16217014,  0.29945013, -0.1798785 ,\n",
       "          0.70586044,  0.5816123 , -0.59195465, -0.55815256, -0.06511094]],\n",
       "       dtype=float32),\n",
       " array([ 0.48965672, -0.7797932 ,  0.77202576, -0.72065246, -0.71172947,\n",
       "         0.7619231 ,  0.7669423 , -0.76941824, -0.7713639 , -0.71688855],\n",
       "       dtype=float32),\n",
       " array([[ 0.11988759],\n",
       "        [-0.8482902 ],\n",
       "        [ 0.6779066 ],\n",
       "        [-0.46016628],\n",
       "        [-0.42741224],\n",
       "        [ 0.68307364],\n",
       "        [ 0.6434179 ],\n",
       "        [-0.7121318 ],\n",
       "        [-0.64149547],\n",
       "        [-0.41679487]], dtype=float32),\n",
       " array([0.8347762], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_adam_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 35.4389 - val_loss: 31.4910\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 35.4373 - val_loss: 31.4888\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.4348 - val_loss: 31.4860\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4318 - val_loss: 31.4827\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 35.4281 - val_loss: 31.4789\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4240 - val_loss: 31.4747\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.4193 - val_loss: 31.4702\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.4142 - val_loss: 31.4652\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4088 - val_loss: 31.4600\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.4030 - val_loss: 31.4545\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3969 - val_loss: 31.4487\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3905 - val_loss: 31.4427\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3839 - val_loss: 31.4365\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3770 - val_loss: 31.4301\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3700 - val_loss: 31.4235\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3627 - val_loss: 31.4168\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3553 - val_loss: 31.4100\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3478 - val_loss: 31.4030\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3401 - val_loss: 31.3960\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3323 - val_loss: 31.3888\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3244 - val_loss: 31.3816\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.3164 - val_loss: 31.3742\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3083 - val_loss: 31.3668\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3001 - val_loss: 31.3594\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.2919 - val_loss: 31.3519\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2836 - val_loss: 31.3443\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.2752 - val_loss: 31.3367\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2668 - val_loss: 31.3291\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2584 - val_loss: 31.3214\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2499 - val_loss: 31.3137\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2414 - val_loss: 31.3059\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2328 - val_loss: 31.2981\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2242 - val_loss: 31.2903\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.2156 - val_loss: 31.2825\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.2070 - val_loss: 31.2747\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1983 - val_loss: 31.2668\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.1897 - val_loss: 31.2590\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1810 - val_loss: 31.2511\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1723 - val_loss: 31.2432\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1636 - val_loss: 31.2353\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 35.1548 - val_loss: 31.2274\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1461 - val_loss: 31.2195\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 35.1374 - val_loss: 31.2115\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.1286 - val_loss: 31.2036\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1199 - val_loss: 31.1957\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1111 - val_loss: 31.1877\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.1023 - val_loss: 31.1798\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0936 - val_loss: 31.1718\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0848 - val_loss: 31.1639\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0760 - val_loss: 31.1559\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0672 - val_loss: 31.1480\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0585 - val_loss: 31.1400\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0497 - val_loss: 31.1320\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0409 - val_loss: 31.1241\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0321 - val_loss: 31.1161\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0233 - val_loss: 31.1082\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0145 - val_loss: 31.1002\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0058 - val_loss: 31.0922\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9970 - val_loss: 31.0843\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9882 - val_loss: 31.0763\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9794 - val_loss: 31.0683\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9706 - val_loss: 31.0604\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9618 - val_loss: 31.0524\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.9531 - val_loss: 31.0444\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 99us/step - loss: 34.9443 - val_loss: 31.0365\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9355 - val_loss: 31.0285\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9267 - val_loss: 31.0206\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9180 - val_loss: 31.0126\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9092 - val_loss: 31.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9004 - val_loss: 30.9967\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.8916 - val_loss: 30.9887\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.8829 - val_loss: 30.9808\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8741 - val_loss: 30.9728\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8653 - val_loss: 30.9649\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8566 - val_loss: 30.9569\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8478 - val_loss: 30.9490\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.8390 - val_loss: 30.9410\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8303 - val_loss: 30.9331\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8215 - val_loss: 30.9251\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8128 - val_loss: 30.9172\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8040 - val_loss: 30.9092\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7953 - val_loss: 30.9013\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.7865 - val_loss: 30.8934\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7778 - val_loss: 30.8854\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7690 - val_loss: 30.8775\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.7603 - val_loss: 30.8696\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7515 - val_loss: 30.8616\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.7428 - val_loss: 30.8537\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7341 - val_loss: 30.8458\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7253 - val_loss: 30.8378\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7166 - val_loss: 30.8299\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7079 - val_loss: 30.8220\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.6991 - val_loss: 30.8140\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6904 - val_loss: 30.8061\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6817 - val_loss: 30.7982\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6730 - val_loss: 30.7903\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6642 - val_loss: 30.7824\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.6555 - val_loss: 30.7744\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 34.6468 - val_loss: 30.7665\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6381 - val_loss: 30.7586\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6294 - val_loss: 30.7507\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.6207 - val_loss: 30.7428\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6120 - val_loss: 30.7349\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 34.6032 - val_loss: 30.7270\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.5945 - val_loss: 30.7191\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5858 - val_loss: 30.7111\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5771 - val_loss: 30.7032\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5684 - val_loss: 30.6953\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5597 - val_loss: 30.6874\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5510 - val_loss: 30.6795\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5424 - val_loss: 30.6716\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5337 - val_loss: 30.6637\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5250 - val_loss: 30.6558\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5163 - val_loss: 30.6480\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5076 - val_loss: 30.6401\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4989 - val_loss: 30.6322\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4902 - val_loss: 30.6243\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.4816 - val_loss: 30.6164\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4729 - val_loss: 30.6085\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4642 - val_loss: 30.6006\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4555 - val_loss: 30.5927\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4469 - val_loss: 30.5849\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4382 - val_loss: 30.5770\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4295 - val_loss: 30.5691\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 34.4209 - val_loss: 30.5612\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4122 - val_loss: 30.5533\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4035 - val_loss: 30.5455\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3949 - val_loss: 30.5376\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3862 - val_loss: 30.5297\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3776 - val_loss: 30.5218\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3689 - val_loss: 30.5140\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3603 - val_loss: 30.5061\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.3516 - val_loss: 30.4982\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3430 - val_loss: 30.4904\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3343 - val_loss: 30.4825\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3257 - val_loss: 30.4747\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.3171 - val_loss: 30.4668\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3084 - val_loss: 30.4589\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.2998 - val_loss: 30.4511\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 34.2911 - val_loss: 30.4432\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2825 - val_loss: 30.4354\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2739 - val_loss: 30.4275\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2653 - val_loss: 30.4197\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2566 - val_loss: 30.4118\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2480 - val_loss: 30.4040\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2394 - val_loss: 30.3961\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2308 - val_loss: 30.3883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2221 - val_loss: 30.3804\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2135 - val_loss: 30.3726\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2049 - val_loss: 30.3647\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1963 - val_loss: 30.3569\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.1877 - val_loss: 30.3491\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1791 - val_loss: 30.3412\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1705 - val_loss: 30.3334\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 34.1619 - val_loss: 30.3255\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1533 - val_loss: 30.3177\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1447 - val_loss: 30.3099\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1361 - val_loss: 30.3020\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1275 - val_loss: 30.2942\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1189 - val_loss: 30.2864\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1103 - val_loss: 30.2786\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1017 - val_loss: 30.2707\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.0931 - val_loss: 30.2629\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0845 - val_loss: 30.2551\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0759 - val_loss: 30.2473\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.0673 - val_loss: 30.2395\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0588 - val_loss: 30.2316\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0502 - val_loss: 30.2238\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0416 - val_loss: 30.2160\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.0330 - val_loss: 30.2082\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.0244 - val_loss: 30.2004\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0159 - val_loss: 30.1926\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0073 - val_loss: 30.1848\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9987 - val_loss: 30.1770\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9902 - val_loss: 30.1691\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.9816 - val_loss: 30.1613\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.9730 - val_loss: 30.1535\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9645 - val_loss: 30.1457\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9559 - val_loss: 30.1379\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9474 - val_loss: 30.1301\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9388 - val_loss: 30.1223\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9303 - val_loss: 30.1145\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9217 - val_loss: 30.1067\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9132 - val_loss: 30.0990\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9046 - val_loss: 30.0912\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.8961 - val_loss: 30.0834\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8875 - val_loss: 30.0756\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8790 - val_loss: 30.0678\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8704 - val_loss: 30.0600\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.8619 - val_loss: 30.0522\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8534 - val_loss: 30.0444\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8448 - val_loss: 30.0366\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8363 - val_loss: 30.0289\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8278 - val_loss: 30.0211\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8192 - val_loss: 30.0133\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8107 - val_loss: 30.0055\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8022 - val_loss: 29.9977\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7936 - val_loss: 29.9900\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.7851 - val_loss: 29.9822\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7766 - val_loss: 29.9744\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.7681 - val_loss: 29.9667\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7596 - val_loss: 29.9589\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.7511 - val_loss: 29.9511\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7425 - val_loss: 29.9433\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7340 - val_loss: 29.9356\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7255 - val_loss: 29.9278\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.7170 - val_loss: 29.9201\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7085 - val_loss: 29.9123\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.7000 - val_loss: 29.9045\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6915 - val_loss: 29.8968\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6830 - val_loss: 29.8890\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6745 - val_loss: 29.8813\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.6660 - val_loss: 29.8735\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6575 - val_loss: 29.8657\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6490 - val_loss: 29.8580\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6405 - val_loss: 29.8502\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6320 - val_loss: 29.8425\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6235 - val_loss: 29.8347\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6151 - val_loss: 29.8270\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6066 - val_loss: 29.8192\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5981 - val_loss: 29.8115\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5896 - val_loss: 29.8038\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5811 - val_loss: 29.7960\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5727 - val_loss: 29.7883\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.5642 - val_loss: 29.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5557 - val_loss: 29.7728\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5472 - val_loss: 29.7651\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5388 - val_loss: 29.7573\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5303 - val_loss: 29.7496\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5218 - val_loss: 29.7419\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5134 - val_loss: 29.7341\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5049 - val_loss: 29.7264\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4964 - val_loss: 29.7187\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4880 - val_loss: 29.7109\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4795 - val_loss: 29.7032\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4711 - val_loss: 29.6955\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4626 - val_loss: 29.6878\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4542 - val_loss: 29.6800\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4457 - val_loss: 29.6723\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.4373 - val_loss: 29.6646\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4288 - val_loss: 29.6569\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4204 - val_loss: 29.6492\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4119 - val_loss: 29.6414\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4035 - val_loss: 29.6337\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3950 - val_loss: 29.6260\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3866 - val_loss: 29.6183\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3782 - val_loss: 29.6106\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.3697 - val_loss: 29.6029\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3613 - val_loss: 29.5952\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3529 - val_loss: 29.5875\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3444 - val_loss: 29.5797\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3360 - val_loss: 29.5720\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.3276 - val_loss: 29.5643\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3192 - val_loss: 29.5566\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3107 - val_loss: 29.5489\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3023 - val_loss: 29.5412\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2939 - val_loss: 29.5335\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2855 - val_loss: 29.5258\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2771 - val_loss: 29.5181\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2686 - val_loss: 29.5104\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2602 - val_loss: 29.5028\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.2518 - val_loss: 29.4951\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2434 - val_loss: 29.4874\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2350 - val_loss: 29.4797\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2266 - val_loss: 29.4720\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2182 - val_loss: 29.4643\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2098 - val_loss: 29.4566\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2014 - val_loss: 29.4489\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1930 - val_loss: 29.4412\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1846 - val_loss: 29.4336\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.1762 - val_loss: 29.4259\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1678 - val_loss: 29.4182\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1594 - val_loss: 29.4105\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1510 - val_loss: 29.4028\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1426 - val_loss: 29.3952\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1342 - val_loss: 29.3875\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1258 - val_loss: 29.3798\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.1175 - val_loss: 29.3721\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1091 - val_loss: 29.3645\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1007 - val_loss: 29.3568\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0923 - val_loss: 29.3491\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0839 - val_loss: 29.3415\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0756 - val_loss: 29.3338\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0672 - val_loss: 29.3261\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0588 - val_loss: 29.3185\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0504 - val_loss: 29.3108\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.0421 - val_loss: 29.3031\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0337 - val_loss: 29.2955\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.0253 - val_loss: 29.2878\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0170 - val_loss: 29.2802\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0086 - val_loss: 29.2725\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0003 - val_loss: 29.2648\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9919 - val_loss: 29.2572\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9835 - val_loss: 29.2495\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9752 - val_loss: 29.2419\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9668 - val_loss: 29.2342\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9585 - val_loss: 29.2266\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9501 - val_loss: 29.2189\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.9418 - val_loss: 29.2113\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9334 - val_loss: 29.2036\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9251 - val_loss: 29.1960\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9167 - val_loss: 29.1884\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 32.9084 - val_loss: 29.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9000 - val_loss: 29.1731\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.8917 - val_loss: 29.1654\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8834 - val_loss: 29.1578\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8750 - val_loss: 29.1502\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8667 - val_loss: 29.1425\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8584 - val_loss: 29.1349\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.8500 - val_loss: 29.1272\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8417 - val_loss: 29.1196\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.8334 - val_loss: 29.1120\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8250 - val_loss: 29.1043\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.8167 - val_loss: 29.0967\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8084 - val_loss: 29.0891\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.8001 - val_loss: 29.0815\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7917 - val_loss: 29.0738\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7834 - val_loss: 29.0662\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.7751 - val_loss: 29.0586\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.7668 - val_loss: 29.0510\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.7585 - val_loss: 29.0433\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7502 - val_loss: 29.0357\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7418 - val_loss: 29.0281\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7335 - val_loss: 29.0205\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7252 - val_loss: 29.0129\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7169 - val_loss: 29.0052\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7086 - val_loss: 28.9976\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7003 - val_loss: 28.9900\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6920 - val_loss: 28.9824\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6837 - val_loss: 28.9748\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6754 - val_loss: 28.9672\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6671 - val_loss: 28.9596\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6588 - val_loss: 28.9520\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6505 - val_loss: 28.9444\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6422 - val_loss: 28.9368\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6339 - val_loss: 28.9291\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.6256 - val_loss: 28.9215\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.6174 - val_loss: 28.9139\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6091 - val_loss: 28.9063\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6008 - val_loss: 28.8987\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5925 - val_loss: 28.8911\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.5842 - val_loss: 28.8835\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.5759 - val_loss: 28.8759\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5676 - val_loss: 28.8684\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5594 - val_loss: 28.8608\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5511 - val_loss: 28.8532\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5428 - val_loss: 28.8456\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5345 - val_loss: 28.8380\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5263 - val_loss: 28.8304\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5180 - val_loss: 28.8228\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5097 - val_loss: 28.8152\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5015 - val_loss: 28.8076\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.4932 - val_loss: 28.8000\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4849 - val_loss: 28.7925\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.4767 - val_loss: 28.7849\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4684 - val_loss: 28.7773\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4602 - val_loss: 28.7697\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4519 - val_loss: 28.7621\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.4436 - val_loss: 28.7546\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.4354 - val_loss: 28.7470\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4271 - val_loss: 28.7394\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4189 - val_loss: 28.7318\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4106 - val_loss: 28.7242\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4024 - val_loss: 28.7167\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3941 - val_loss: 28.7091\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.3859 - val_loss: 28.7015\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3776 - val_loss: 28.6940\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3694 - val_loss: 28.6864\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.3612 - val_loss: 28.6788\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3529 - val_loss: 28.6713\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.3447 - val_loss: 28.6637\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3364 - val_loss: 28.6561\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3282 - val_loss: 28.6486\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3200 - val_loss: 28.6410\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3117 - val_loss: 28.6334\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3035 - val_loss: 28.6259\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2953 - val_loss: 28.6183\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2871 - val_loss: 28.6108\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2788 - val_loss: 28.6032\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2706 - val_loss: 28.5957\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.2624 - val_loss: 28.5881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2542 - val_loss: 28.5805\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2459 - val_loss: 28.5730\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2377 - val_loss: 28.5654\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2295 - val_loss: 28.5579\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2213 - val_loss: 28.5503\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2131 - val_loss: 28.5428\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2048 - val_loss: 28.5352\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1966 - val_loss: 28.5277\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1884 - val_loss: 28.5202\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1802 - val_loss: 28.5126\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1720 - val_loss: 28.5051\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1638 - val_loss: 28.4975\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1556 - val_loss: 28.4900\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.1474 - val_loss: 28.4824\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1392 - val_loss: 28.4749\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.1310 - val_loss: 28.4674\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1228 - val_loss: 28.4598\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1146 - val_loss: 28.4523\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1064 - val_loss: 28.4448\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0982 - val_loss: 28.4372\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0900 - val_loss: 28.4297\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.0818 - val_loss: 28.4222\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0736 - val_loss: 28.4146\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0654 - val_loss: 28.4071\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.0572 - val_loss: 28.3996\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0491 - val_loss: 28.3921\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0409 - val_loss: 28.3845\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0327 - val_loss: 28.3770\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.0245 - val_loss: 28.3695\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0163 - val_loss: 28.3620\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.0081 - val_loss: 28.3544\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0000 - val_loss: 28.3469\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9918 - val_loss: 28.3394\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9836 - val_loss: 28.3319\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9754 - val_loss: 28.3244\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9673 - val_loss: 28.3168\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9591 - val_loss: 28.3093\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9509 - val_loss: 28.3018\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 31.9428 - val_loss: 28.2943\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.9346 - val_loss: 28.2868\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9264 - val_loss: 28.2793\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9183 - val_loss: 28.2718\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.9101 - val_loss: 28.2643\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.9019 - val_loss: 28.2568\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8938 - val_loss: 28.2492\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8856 - val_loss: 28.2417\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.8775 - val_loss: 28.2342\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8693 - val_loss: 28.2267\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.8612 - val_loss: 28.2192\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.8530 - val_loss: 28.2117\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.8448 - val_loss: 28.2042\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8367 - val_loss: 28.1967\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8285 - val_loss: 28.1892\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8204 - val_loss: 28.1817\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8123 - val_loss: 28.1742\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8041 - val_loss: 28.1667\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7960 - val_loss: 28.1592\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7878 - val_loss: 28.1517\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7797 - val_loss: 28.1443\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 31.7715 - val_loss: 28.1368\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7634 - val_loss: 28.1293\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7553 - val_loss: 28.1218\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7471 - val_loss: 28.1143\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7390 - val_loss: 28.1068\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7309 - val_loss: 28.0993\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7227 - val_loss: 28.0918\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7146 - val_loss: 28.0843\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7065 - val_loss: 28.0769\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6983 - val_loss: 28.0694\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6902 - val_loss: 28.0619\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6821 - val_loss: 28.0544\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.6740 - val_loss: 28.0469\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6659 - val_loss: 28.0395\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6577 - val_loss: 28.0320\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6496 - val_loss: 28.0245\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6415 - val_loss: 28.0170\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.6334 - val_loss: 28.0096\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.6253 - val_loss: 28.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6171 - val_loss: 27.9946\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6090 - val_loss: 27.9871\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6009 - val_loss: 27.9797\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5928 - val_loss: 27.9722\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5847 - val_loss: 27.9647\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5766 - val_loss: 27.9573\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5685 - val_loss: 27.9498\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.5604 - val_loss: 27.9423\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5523 - val_loss: 27.9349\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5442 - val_loss: 27.9274\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5361 - val_loss: 27.9199\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5280 - val_loss: 27.9125\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5199 - val_loss: 27.9050\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5118 - val_loss: 27.8976\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.5037 - val_loss: 27.8901\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4956 - val_loss: 27.8826\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4875 - val_loss: 27.8752\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4794 - val_loss: 27.8677\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4713 - val_loss: 27.8603\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4632 - val_loss: 27.8528\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4551 - val_loss: 27.8454\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4471 - val_loss: 27.8379\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4390 - val_loss: 27.8305\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4309 - val_loss: 27.8230\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4228 - val_loss: 27.8156\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4147 - val_loss: 27.8081\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4066 - val_loss: 27.8007\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3986 - val_loss: 27.7932\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3905 - val_loss: 27.7858\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3824 - val_loss: 27.7783\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3743 - val_loss: 27.7709\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3663 - val_loss: 27.7635\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3582 - val_loss: 27.7560\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3501 - val_loss: 27.7486\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3421 - val_loss: 27.7411\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3340 - val_loss: 27.7337\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.3259 - val_loss: 27.7263\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3179 - val_loss: 27.7188\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3098 - val_loss: 27.7114\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3017 - val_loss: 27.7040\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2937 - val_loss: 27.6965\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2856 - val_loss: 27.6891\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2775 - val_loss: 27.6817\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2695 - val_loss: 27.6742\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2614 - val_loss: 27.6668\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2534 - val_loss: 27.6594\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2453 - val_loss: 27.6519\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2373 - val_loss: 27.6445\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2292 - val_loss: 27.6371\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2212 - val_loss: 27.6297\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2131 - val_loss: 27.6222\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2051 - val_loss: 27.6148\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1970 - val_loss: 27.6074\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1890 - val_loss: 27.6000\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1809 - val_loss: 27.5925\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1729 - val_loss: 27.5851\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1648 - val_loss: 27.5777\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1568 - val_loss: 27.5703\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1488 - val_loss: 27.5629\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1407 - val_loss: 27.5555\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.1327 - val_loss: 27.5480\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1246 - val_loss: 27.5406\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1166 - val_loss: 27.5332\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1086 - val_loss: 27.5258\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1005 - val_loss: 27.5184\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0925 - val_loss: 27.5110\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0845 - val_loss: 27.5036\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0765 - val_loss: 27.4962\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0684 - val_loss: 27.4888\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0604 - val_loss: 27.4814\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0524 - val_loss: 27.4740\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0444 - val_loss: 27.4665\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0363 - val_loss: 27.4591\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0283 - val_loss: 27.4517\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0203 - val_loss: 27.4443\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0123 - val_loss: 27.4369\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0042 - val_loss: 27.4295\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9962 - val_loss: 27.4221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9882 - val_loss: 27.4147\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9802 - val_loss: 27.4073\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.9722 - val_loss: 27.4000\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9642 - val_loss: 27.3926\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9562 - val_loss: 27.3852\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9482 - val_loss: 27.3778\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9402 - val_loss: 27.3704\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9321 - val_loss: 27.3630\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.9241 - val_loss: 27.3556\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9161 - val_loss: 27.3482\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9081 - val_loss: 27.3408\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9001 - val_loss: 27.3334\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8921 - val_loss: 27.3260\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8841 - val_loss: 27.3187\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8761 - val_loss: 27.3113\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8681 - val_loss: 27.3039\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8601 - val_loss: 27.2965\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8521 - val_loss: 27.2891\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8442 - val_loss: 27.2817\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8362 - val_loss: 27.2744\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8282 - val_loss: 27.2670\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8202 - val_loss: 27.2596\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8122 - val_loss: 27.2522\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8042 - val_loss: 27.2448\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7962 - val_loss: 27.2375\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.7882 - val_loss: 27.2301\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7802 - val_loss: 27.2227\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7723 - val_loss: 27.2153\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7643 - val_loss: 27.2080\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7563 - val_loss: 27.2006\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7483 - val_loss: 27.1932\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7403 - val_loss: 27.1859\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7324 - val_loss: 27.1785\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7244 - val_loss: 27.1711\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7164 - val_loss: 27.1638\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7084 - val_loss: 27.1564\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7005 - val_loss: 27.1490\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6925 - val_loss: 27.1417\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6845 - val_loss: 27.1343\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6766 - val_loss: 27.1269\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.6686 - val_loss: 27.1196\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.6606 - val_loss: 27.1122\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6527 - val_loss: 27.1048\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.6447 - val_loss: 27.0975\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6367 - val_loss: 27.0901\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6288 - val_loss: 27.0828\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6208 - val_loss: 27.0754\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6128 - val_loss: 27.0681\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6049 - val_loss: 27.0607\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5969 - val_loss: 27.0534\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5890 - val_loss: 27.0460\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5810 - val_loss: 27.0386\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5731 - val_loss: 27.0313\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5651 - val_loss: 27.0239\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5572 - val_loss: 27.0166\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 30.5492 - val_loss: 27.0092\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.5413 - val_loss: 27.0019\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.5333 - val_loss: 26.9945\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5254 - val_loss: 26.9872\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5174 - val_loss: 26.9799\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5095 - val_loss: 26.9725\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5015 - val_loss: 26.9652\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.4936 - val_loss: 26.9578\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 30.4856 - val_loss: 26.9505\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.4777 - val_loss: 26.9431\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4698 - val_loss: 26.9358\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4618 - val_loss: 26.9285\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.4539 - val_loss: 26.9211\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.4459 - val_loss: 26.9138\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4380 - val_loss: 26.9065\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4301 - val_loss: 26.8991\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4221 - val_loss: 26.8918\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.4142 - val_loss: 26.8844\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.4063 - val_loss: 26.8771\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3983 - val_loss: 26.8698\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3904 - val_loss: 26.8624\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3825 - val_loss: 26.8551\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3746 - val_loss: 26.8478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3666 - val_loss: 26.8405\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3587 - val_loss: 26.8331\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3508 - val_loss: 26.8258\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.3429 - val_loss: 26.8185\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3350 - val_loss: 26.8112\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3270 - val_loss: 26.8038\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3191 - val_loss: 26.7965\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3112 - val_loss: 26.7892\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3033 - val_loss: 26.7819\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2954 - val_loss: 26.7745\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2874 - val_loss: 26.7672\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2795 - val_loss: 26.7599\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2716 - val_loss: 26.7526\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.2637 - val_loss: 26.7453\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2558 - val_loss: 26.7379\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2479 - val_loss: 26.7306\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.2400 - val_loss: 26.7233\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2321 - val_loss: 26.7160\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2242 - val_loss: 26.7087\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2163 - val_loss: 26.7014\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.2084 - val_loss: 26.6941\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2005 - val_loss: 26.6867\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1926 - val_loss: 26.6794\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1847 - val_loss: 26.6721\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1768 - val_loss: 26.6648\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.1689 - val_loss: 26.6575\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1610 - val_loss: 26.6502\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1531 - val_loss: 26.6429\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1452 - val_loss: 26.6356\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1373 - val_loss: 26.6283\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1294 - val_loss: 26.6210\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1215 - val_loss: 26.6137\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1136 - val_loss: 26.6064\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1057 - val_loss: 26.5991\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0978 - val_loss: 26.5918\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0899 - val_loss: 26.5845\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0821 - val_loss: 26.5772\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30.0742 - val_loss: 26.5699\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0663 - val_loss: 26.5626\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0584 - val_loss: 26.5553\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0505 - val_loss: 26.5480\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0426 - val_loss: 26.5407\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0348 - val_loss: 26.5334\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0269 - val_loss: 26.5261\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0190 - val_loss: 26.5188\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0111 - val_loss: 26.5115\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 30.0033 - val_loss: 26.5042\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.9954 - val_loss: 26.4970\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9875 - val_loss: 26.4897\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9796 - val_loss: 26.4824\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9718 - val_loss: 26.4751\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9639 - val_loss: 26.4678\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9560 - val_loss: 26.4605\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9481 - val_loss: 26.4532\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9403 - val_loss: 26.4459\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9324 - val_loss: 26.4387\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9245 - val_loss: 26.4314\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.9167 - val_loss: 26.4241\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9088 - val_loss: 26.4168\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9010 - val_loss: 26.4095\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8931 - val_loss: 26.4023\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.8852 - val_loss: 26.3950\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8774 - val_loss: 26.3877\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8695 - val_loss: 26.3804\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8617 - val_loss: 26.3731\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8538 - val_loss: 26.3659\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8460 - val_loss: 26.3586\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8381 - val_loss: 26.3513\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8302 - val_loss: 26.3441\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8224 - val_loss: 26.3368\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8145 - val_loss: 26.3295\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.8067 - val_loss: 26.3222\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7988 - val_loss: 26.3150\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7910 - val_loss: 26.3077\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7831 - val_loss: 26.3004\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7753 - val_loss: 26.2932\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7675 - val_loss: 26.2859\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7596 - val_loss: 26.2786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.7518 - val_loss: 26.2714\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7439 - val_loss: 26.2641\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.7361 - val_loss: 26.2568\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.7282 - val_loss: 26.2496\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7204 - val_loss: 26.2423\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7126 - val_loss: 26.2351\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7047 - val_loss: 26.2278\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6969 - val_loss: 26.2205\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6891 - val_loss: 26.2133\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6812 - val_loss: 26.2060\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6734 - val_loss: 26.1988\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6656 - val_loss: 26.1915\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6577 - val_loss: 26.1843\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6499 - val_loss: 26.1770\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6421 - val_loss: 26.1697\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6342 - val_loss: 26.1625\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6264 - val_loss: 26.1552\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.6186 - val_loss: 26.1480\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.6108 - val_loss: 26.1407\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6029 - val_loss: 26.1335\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5951 - val_loss: 26.1262\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.5873 - val_loss: 26.1190\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 29.5795 - val_loss: 26.1117\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5716 - val_loss: 26.1045\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5638 - val_loss: 26.0973\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5560 - val_loss: 26.0900\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5482 - val_loss: 26.0828\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5404 - val_loss: 26.0755\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5326 - val_loss: 26.0683\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5247 - val_loss: 26.0610\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5169 - val_loss: 26.0538\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5091 - val_loss: 26.0466\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5013 - val_loss: 26.0393\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4935 - val_loss: 26.0321\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4857 - val_loss: 26.0248\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4779 - val_loss: 26.0176\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4701 - val_loss: 26.0104\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4623 - val_loss: 26.0031\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4545 - val_loss: 25.9959\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4467 - val_loss: 25.9887\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4389 - val_loss: 25.9814\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4311 - val_loss: 25.9742\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4233 - val_loss: 25.9670\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4154 - val_loss: 25.9597\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4076 - val_loss: 25.9525\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3998 - val_loss: 25.9453\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3921 - val_loss: 25.9380\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3843 - val_loss: 25.9308\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.3765 - val_loss: 25.9236\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.3687 - val_loss: 25.9164\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3609 - val_loss: 25.9091\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3531 - val_loss: 25.9019\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3453 - val_loss: 25.8947\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3375 - val_loss: 25.8875\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3297 - val_loss: 25.8802\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3219 - val_loss: 25.8730\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3141 - val_loss: 25.8658\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3063 - val_loss: 25.8586\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2985 - val_loss: 25.8514\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2908 - val_loss: 25.8441\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2830 - val_loss: 25.8369\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2752 - val_loss: 25.8297\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2674 - val_loss: 25.8225\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2596 - val_loss: 25.8153\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2519 - val_loss: 25.8080\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.2441 - val_loss: 25.8008\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.2363 - val_loss: 25.7936\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2285 - val_loss: 25.7864\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2207 - val_loss: 25.7792\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2130 - val_loss: 25.7720\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2052 - val_loss: 25.7648\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1974 - val_loss: 25.7576\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.1896 - val_loss: 25.7504\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1819 - val_loss: 25.7431\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.1741 - val_loss: 25.7359\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 29.1663 - val_loss: 25.7287\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1586 - val_loss: 25.7215\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1508 - val_loss: 25.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1430 - val_loss: 25.7071\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1352 - val_loss: 25.6999\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1275 - val_loss: 25.6927\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1197 - val_loss: 25.6855\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.1120 - val_loss: 25.6783\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1042 - val_loss: 25.6711\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0964 - val_loss: 25.6639\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.0887 - val_loss: 25.6567\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0809 - val_loss: 25.6495\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0731 - val_loss: 25.6423\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0654 - val_loss: 25.6351\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0576 - val_loss: 25.6279\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 29.0499 - val_loss: 25.6207\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0421 - val_loss: 25.6135\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0344 - val_loss: 25.6063\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.0266 - val_loss: 25.5991\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0189 - val_loss: 25.5919\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.0111 - val_loss: 25.5848\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.0033 - val_loss: 25.5776\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9956 - val_loss: 25.5704\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.9878 - val_loss: 25.5632\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9801 - val_loss: 25.5560\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9724 - val_loss: 25.5488\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.9646 - val_loss: 25.5416\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.9569 - val_loss: 25.5344\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9491 - val_loss: 25.5272\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9414 - val_loss: 25.5201\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9336 - val_loss: 25.5129\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9259 - val_loss: 25.5057\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9181 - val_loss: 25.4985\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9104 - val_loss: 25.4913\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.9027 - val_loss: 25.4841\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.8949 - val_loss: 25.4770\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.8872 - val_loss: 25.4698\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8794 - val_loss: 25.4626\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8717 - val_loss: 25.4554\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.8640 - val_loss: 25.4483\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8562 - val_loss: 25.4411\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8485 - val_loss: 25.4339\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.8408 - val_loss: 25.4267\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.8330 - val_loss: 25.4195\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8253 - val_loss: 25.4124\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8176 - val_loss: 25.4052\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8098 - val_loss: 25.3980\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.8021 - val_loss: 25.3909\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 95us/step - loss: 28.7944 - val_loss: 25.3837\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7867 - val_loss: 25.3765\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7789 - val_loss: 25.3693\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.7712 - val_loss: 25.3622\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7635 - val_loss: 25.3550\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.7558 - val_loss: 25.3478\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7480 - val_loss: 25.3407\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7403 - val_loss: 25.3335\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7326 - val_loss: 25.3263\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.7249 - val_loss: 25.3192\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7172 - val_loss: 25.3120\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.7094 - val_loss: 25.3048\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7017 - val_loss: 25.2977\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6940 - val_loss: 25.2905\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.6863 - val_loss: 25.2834\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6786 - val_loss: 25.2762\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6709 - val_loss: 25.2690\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6632 - val_loss: 25.2619\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.6554 - val_loss: 25.2547\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6477 - val_loss: 25.2476\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6400 - val_loss: 25.2404\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6323 - val_loss: 25.2332\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6246 - val_loss: 25.2261\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.6169 - val_loss: 25.2189\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6092 - val_loss: 25.2118\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6015 - val_loss: 25.2046\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.5938 - val_loss: 25.1975\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5861 - val_loss: 25.1903\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5784 - val_loss: 25.1832\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5707 - val_loss: 25.1760\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5630 - val_loss: 25.1689\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 28.5553 - val_loss: 25.1617\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5476 - val_loss: 25.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5399 - val_loss: 25.1474\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5322 - val_loss: 25.1403\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5245 - val_loss: 25.1331\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5168 - val_loss: 25.1260\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.5091 - val_loss: 25.1188\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.5014 - val_loss: 25.1117\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4937 - val_loss: 25.1046\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4860 - val_loss: 25.0974\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4783 - val_loss: 25.0903\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.4706 - val_loss: 25.0831\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4629 - val_loss: 25.0760\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4552 - val_loss: 25.0688\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.4476 - val_loss: 25.0617\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4399 - val_loss: 25.0546\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4322 - val_loss: 25.0474\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4245 - val_loss: 25.0403\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4168 - val_loss: 25.0332\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4091 - val_loss: 25.0260\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4014 - val_loss: 25.0189\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.3938 - val_loss: 25.0118\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3861 - val_loss: 25.0046\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3784 - val_loss: 24.9975\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.3707 - val_loss: 24.9904\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.3630 - val_loss: 24.9832\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3554 - val_loss: 24.9761\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3477 - val_loss: 24.9690\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3400 - val_loss: 24.9618\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3323 - val_loss: 24.9547\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3246 - val_loss: 24.9476\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3170 - val_loss: 24.9405\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.3093 - val_loss: 24.9333\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.3016 - val_loss: 24.9262\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2939 - val_loss: 24.9191\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2863 - val_loss: 24.9119\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2786 - val_loss: 24.9048\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2709 - val_loss: 24.8977\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.2633 - val_loss: 24.8906\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2556 - val_loss: 24.8835\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.2479 - val_loss: 24.8763\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2403 - val_loss: 24.8692\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.2326 - val_loss: 24.8621\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2249 - val_loss: 24.8550\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.2173 - val_loss: 24.8479\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2096 - val_loss: 24.8407\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2019 - val_loss: 24.8336\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.1943 - val_loss: 24.8265\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1866 - val_loss: 24.8194\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1790 - val_loss: 24.8123\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1713 - val_loss: 24.8052\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.1636 - val_loss: 24.7980\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1560 - val_loss: 24.7909\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1483 - val_loss: 24.7838\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1407 - val_loss: 24.7767\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.1330 - val_loss: 24.7696\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1254 - val_loss: 24.7625\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1177 - val_loss: 24.7554\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.1101 - val_loss: 24.7483\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1024 - val_loss: 24.7412\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0948 - val_loss: 24.7341\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0871 - val_loss: 24.7269\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0795 - val_loss: 24.7198\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.0718 - val_loss: 24.7127\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0642 - val_loss: 24.7056\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0565 - val_loss: 24.6985\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.0489 - val_loss: 24.6914\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0412 - val_loss: 24.6843\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.0336 - val_loss: 24.6772\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0259 - val_loss: 24.6701\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0183 - val_loss: 24.6630\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0106 - val_loss: 24.6559\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0030 - val_loss: 24.6488\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9954 - val_loss: 24.6417\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9877 - val_loss: 24.6346\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.9801 - val_loss: 24.6275\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9724 - val_loss: 24.6204\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9648 - val_loss: 24.6133\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9572 - val_loss: 24.6062\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.9495 - val_loss: 24.5991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 27.9419 - val_loss: 24.5921\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9343 - val_loss: 24.5850\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9266 - val_loss: 24.5779\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9190 - val_loss: 24.5708\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9114 - val_loss: 24.5637\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9037 - val_loss: 24.5566\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8961 - val_loss: 24.5495\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.8885 - val_loss: 24.5424\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8808 - val_loss: 24.5353\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8732 - val_loss: 24.5282\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.8656 - val_loss: 24.5211\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8580 - val_loss: 24.5141\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8503 - val_loss: 24.5070\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8427 - val_loss: 24.4999\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.8351 - val_loss: 24.4928\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8275 - val_loss: 24.4857\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8198 - val_loss: 24.4786\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.8122 - val_loss: 24.4716\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.8046 - val_loss: 24.4645\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7970 - val_loss: 24.4574\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7893 - val_loss: 24.4503\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.7817 - val_loss: 24.4432\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7741 - val_loss: 24.4362\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7665 - val_loss: 24.4291\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.7589 - val_loss: 24.4220\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.7513 - val_loss: 24.4149\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7436 - val_loss: 24.4079\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7360 - val_loss: 24.4008\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.7284 - val_loss: 24.3937\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7208 - val_loss: 24.3866\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 27.7132 - val_loss: 24.3796\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7056 - val_loss: 24.3725\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6980 - val_loss: 24.3654\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 27.6904 - val_loss: 24.3583\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.6827 - val_loss: 24.3513\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6751 - val_loss: 24.3442\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.6675 - val_loss: 24.3371\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6599 - val_loss: 24.3301\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6523 - val_loss: 24.3230\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.6447 - val_loss: 24.3159\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6371 - val_loss: 24.3089\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6295 - val_loss: 24.3018\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.6219 - val_loss: 24.2947\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6143 - val_loss: 24.2877\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.6067 - val_loss: 24.2806\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5991 - val_loss: 24.2735\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.5915 - val_loss: 24.2665\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 27.5839 - val_loss: 24.2594\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5763 - val_loss: 24.2523\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5687 - val_loss: 24.2453\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5611 - val_loss: 24.2382\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5535 - val_loss: 24.2312\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5459 - val_loss: 24.2241\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5383 - val_loss: 24.2170\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.5307 - val_loss: 24.2100\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 27.5231 - val_loss: 24.2029\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5155 - val_loss: 24.1959\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.5079 - val_loss: 24.1888\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5004 - val_loss: 24.1818\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4928 - val_loss: 24.1747\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4852 - val_loss: 24.1677\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.4776 - val_loss: 24.1606\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4700 - val_loss: 24.1535\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4624 - val_loss: 24.1465\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4548 - val_loss: 24.1394\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4472 - val_loss: 24.1324\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4397 - val_loss: 24.1253\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4321 - val_loss: 24.1183\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4245 - val_loss: 24.1112\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.4169 - val_loss: 24.1042\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 27.4093 - val_loss: 24.0972\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 27.4017 - val_loss: 24.0901\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.3942 - val_loss: 24.0831\n",
      "22.98951530456543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.8305471 ,  0.7705578 ,  0.27940595,  0.7556379 ,  0.7294787 ],\n",
       "        [-0.03815834,  0.532696  ,  0.5562497 , -0.7589856 ,  0.22267678],\n",
       "        [-0.28797114,  0.74631906,  0.44201115,  0.10418889, -0.5666954 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.05293802,  0.0342578 , -0.0532173 , -0.00606847, -0.15667406],\n",
       "       dtype=float32),\n",
       " array([[-0.1916619 , -0.28779572, -0.00834114,  0.4254611 , -0.50992805,\n",
       "         -0.1459388 , -0.24729462, -0.54075277, -0.4517089 ,  0.5488235 ],\n",
       "        [ 0.5043219 , -0.53915775,  0.13444424, -0.5689076 , -0.00989301,\n",
       "          0.30515406,  0.37299782,  0.04431949,  0.569056  ,  0.43702424],\n",
       "        [ 0.04747498, -0.42674494, -0.20302562, -0.51453274,  0.31469244,\n",
       "         -0.26319045, -0.46886098,  0.30837822, -0.19095482, -0.37331492],\n",
       "        [-0.1821902 ,  0.13624719, -0.5951666 , -0.20916334, -0.17353888,\n",
       "         -0.28358448,  0.4401992 ,  0.26028746,  0.10183384,  0.11201303],\n",
       "        [-0.3423488 ,  0.588493  , -0.61355066,  0.5780125 ,  0.3294372 ,\n",
       "         -0.4246451 , -0.63043624,  0.35142255, -0.5393018 , -0.59806854]],\n",
       "       dtype=float32),\n",
       " array([-0.02565667,  0.03335026,  0.03085246, -0.12759842, -0.12498955,\n",
       "         0.1002003 ,  0.01508125, -0.13299434, -0.03569104,  0.0375764 ],\n",
       "       dtype=float32),\n",
       " array([[-0.13050076],\n",
       "        [ 0.16941439],\n",
       "        [ 0.17205073],\n",
       "        [-0.6719406 ],\n",
       "        [-0.6632859 ],\n",
       "        [ 0.5348365 ],\n",
       "        [ 0.08139296],\n",
       "        [-0.70915574],\n",
       "        [-0.18500485],\n",
       "        [ 0.20714419]], dtype=float32),\n",
       " array([0.19195242], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, sgd, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sgd_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 36.4454 - val_loss: 33.1349\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.8591 - val_loss: 31.1870\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.9850 - val_loss: 29.2790\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 30.0891 - val_loss: 27.4401\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1540 - val_loss: 25.6496\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 26.1897 - val_loss: 23.8919\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.2026 - val_loss: 22.1459\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 22.1993 - val_loss: 20.3926\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 20.1911 - val_loss: 18.6284\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 18.1917 - val_loss: 16.8766\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16.2183 - val_loss: 15.1677\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 14.2949 - val_loss: 13.5228\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 12.4505 - val_loss: 11.9581\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.7126 - val_loss: 10.4856\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1026 - val_loss: 9.1128\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6350 - val_loss: 7.8445\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3185 - val_loss: 6.6858\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1566 - val_loss: 5.6419\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1488 - val_loss: 4.7161\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2906 - val_loss: 3.9093\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5742 - val_loss: 3.2185\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9892 - val_loss: 2.6380\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5228 - val_loss: 2.1591\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1605 - val_loss: 1.7709\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8867 - val_loss: 1.4615\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.6856 - val_loss: 1.2184\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5417 - val_loss: 1.0294\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.4412 - val_loss: 0.8836\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.3719 - val_loss: 0.7710\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.3240 - val_loss: 0.6837\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2903 - val_loss: 0.6150\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2653 - val_loss: 0.5599\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2459 - val_loss: 0.5146\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2297 - val_loss: 0.4761\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2155 - val_loss: 0.4426\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2028 - val_loss: 0.4124\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1911 - val_loss: 0.3848\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1803 - val_loss: 0.3589\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1703 - val_loss: 0.3352\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1611 - val_loss: 0.3119\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1548 - val_loss: 0.3031\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1663 - val_loss: 0.3017\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2245 - val_loss: 0.3252\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2336 - val_loss: 0.3029\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1901 - val_loss: 0.2749\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1527 - val_loss: 0.2631\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.1361 - val_loss: 0.2491\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1271 - val_loss: 0.2423\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1217 - val_loss: 0.2314\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1175 - val_loss: 0.2258\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1143 - val_loss: 0.2156\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1116 - val_loss: 0.2117\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.1097 - val_loss: 0.2014\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1092 - val_loss: 0.2026\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1113 - val_loss: 0.1924\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1179 - val_loss: 0.2085\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1313 - val_loss: 0.1920\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1452 - val_loss: 0.2261\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1523 - val_loss: 0.1767\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1420 - val_loss: 0.2164\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1305 - val_loss: 0.1550\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1169 - val_loss: 0.1979\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1095 - val_loss: 0.1423\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1033 - val_loss: 0.1881\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1010 - val_loss: 0.1335\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0995 - val_loss: 0.1890\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1013 - val_loss: 0.1263\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1039 - val_loss: 0.2033\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1110 - val_loss: 0.1218\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1175 - val_loss: 0.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.1283 - val_loss: 0.1188\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1304 - val_loss: 0.2411\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1343 - val_loss: 0.1118\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1245 - val_loss: 0.2242\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1201 - val_loss: 0.1040\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.1085 - val_loss: 0.2015\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1043 - val_loss: 0.0989\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0974 - val_loss: 0.1887\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0963 - val_loss: 0.0959\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0937 - val_loss: 0.1870\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0960 - val_loss: 0.0945\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0964 - val_loss: 0.1937\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.1016 - val_loss: 0.0950\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1030 - val_loss: 0.2019\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1087 - val_loss: 0.0957\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1071 - val_loss: 0.2013\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1093 - val_loss: 0.0935\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1033 - val_loss: 0.1903\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1020 - val_loss: 0.0892\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0951 - val_loss: 0.1781\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0936 - val_loss: 0.0850\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0888 - val_loss: 0.1715\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0890 - val_loss: 0.0816\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0865 - val_loss: 0.1718\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0889 - val_loss: 0.0792\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0879 - val_loss: 0.1762\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0918 - val_loss: 0.0775\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0906 - val_loss: 0.1789\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0941 - val_loss: 0.0759\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0909 - val_loss: 0.1750\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0926 - val_loss: 0.0747\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0876 - val_loss: 0.1660\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0883 - val_loss: 0.0765\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0841 - val_loss: 0.1565\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0857 - val_loss: 0.0832\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0842 - val_loss: 0.1443\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0850 - val_loss: 0.0836\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0812 - val_loss: 0.1324\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0783 - val_loss: 0.0736\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0744 - val_loss: 0.1386\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0752 - val_loss: 0.0636\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0769 - val_loss: 0.1679\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0862 - val_loss: 0.0584\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0905 - val_loss: 0.1832\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0978 - val_loss: 0.0523\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0868 - val_loss: 0.1532\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0826 - val_loss: 0.0489\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0698 - val_loss: 0.1263\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0663 - val_loss: 0.0498\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0609 - val_loss: 0.1164\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0623 - val_loss: 0.0555\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0639 - val_loss: 0.1238\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0732 - val_loss: 0.0738\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0832 - val_loss: 0.1416\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0949 - val_loss: 0.0790\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0908 - val_loss: 0.1308\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0833 - val_loss: 0.0601\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0723 - val_loss: 0.1260\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0690 - val_loss: 0.0490\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0652 - val_loss: 0.1324\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0680 - val_loss: 0.0442\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0668 - val_loss: 0.1354\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0706 - val_loss: 0.0415\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0671 - val_loss: 0.1275\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0688 - val_loss: 0.0401\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0638 - val_loss: 0.1169\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0651 - val_loss: 0.0412\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0618 - val_loss: 0.1121\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0651 - val_loss: 0.0474\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0653 - val_loss: 0.1170\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0729 - val_loss: 0.0634\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0773 - val_loss: 0.1220\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0828 - val_loss: 0.0637\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0755 - val_loss: 0.1038\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0678 - val_loss: 0.0480\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0588 - val_loss: 0.0989\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0564 - val_loss: 0.0395\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0547 - val_loss: 0.1110\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0593 - val_loss: 0.0374\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0617 - val_loss: 0.1251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0669 - val_loss: 0.1193\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0693 - val_loss: 0.0331\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0616 - val_loss: 0.1028\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0611 - val_loss: 0.0325\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0552 - val_loss: 0.0932\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0567 - val_loss: 0.0374\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0558 - val_loss: 0.0961\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0624 - val_loss: 0.0530\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0679 - val_loss: 0.1047\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0753 - val_loss: 0.0559\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0703 - val_loss: 0.0901\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0635 - val_loss: 0.0407\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0547 - val_loss: 0.0864\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0524 - val_loss: 0.0331\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0510 - val_loss: 0.0996\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0560 - val_loss: 0.0324\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0583 - val_loss: 0.1127\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0652 - val_loss: 0.0310\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0621 - val_loss: 0.1042\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0634 - val_loss: 0.0272\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0556 - val_loss: 0.0879\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0549 - val_loss: 0.0264\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0497 - val_loss: 0.0800\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0515 - val_loss: 0.0314\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0512 - val_loss: 0.0846\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0582 - val_loss: 0.0468\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0638 - val_loss: 0.0942\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0711 - val_loss: 0.0491\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0660 - val_loss: 0.0804\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0595 - val_loss: 0.0347\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0510 - val_loss: 0.0766\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0283\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0474 - val_loss: 0.0891\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0525 - val_loss: 0.0286\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0547 - val_loss: 0.1011\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0614 - val_loss: 0.0272\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0580 - val_loss: 0.0923\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0591 - val_loss: 0.0229\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0514 - val_loss: 0.0767\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0508 - val_loss: 0.0218\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0459 - val_loss: 0.0699\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0479 - val_loss: 0.0267\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0479 - val_loss: 0.0756\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0552 - val_loss: 0.0425\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0611 - val_loss: 0.0869\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0689 - val_loss: 0.0451\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0636 - val_loss: 0.0728\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0568 - val_loss: 0.0305\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0479 - val_loss: 0.0678\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0455 - val_loss: 0.0247\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0440 - val_loss: 0.0794\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0489 - val_loss: 0.0259\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0513 - val_loss: 0.0919\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0582 - val_loss: 0.0250\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0552 - val_loss: 0.0840\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0565 - val_loss: 0.0204\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0689\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0484 - val_loss: 0.0189\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0435 - val_loss: 0.0625\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0456 - val_loss: 0.0237\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0456 - val_loss: 0.0685\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0528 - val_loss: 0.0392\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0586 - val_loss: 0.0803\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0662 - val_loss: 0.0419\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0609 - val_loss: 0.0664\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0276\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0454 - val_loss: 0.0610\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0431 - val_loss: 0.0224\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0416 - val_loss: 0.0722\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0465 - val_loss: 0.0245\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0491 - val_loss: 0.0851\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0562 - val_loss: 0.0240\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0533 - val_loss: 0.0776\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0546 - val_loss: 0.0188\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0470 - val_loss: 0.0625\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0464 - val_loss: 0.0169\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0415 - val_loss: 0.0563\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0435 - val_loss: 0.0213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0435 - val_loss: 0.0626\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0506 - val_loss: 0.0367\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0562 - val_loss: 0.0752\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0641 - val_loss: 0.0400\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0591 - val_loss: 0.0619\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0526 - val_loss: 0.0257\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0437 - val_loss: 0.0558\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0413 - val_loss: 0.0209\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0397 - val_loss: 0.0665\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0446 - val_loss: 0.0237\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0473 - val_loss: 0.0797\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0545 - val_loss: 0.0236\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0517 - val_loss: 0.0725\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0530 - val_loss: 0.0178\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0453 - val_loss: 0.0574\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0447 - val_loss: 0.0154\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0399 - val_loss: 0.0513\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0418 - val_loss: 0.0196\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0417 - val_loss: 0.0577\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0486 - val_loss: 0.0346\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0714\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0623 - val_loss: 0.0389\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0515 - val_loss: 0.0247\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0518\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0399 - val_loss: 0.0199\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0381 - val_loss: 0.0617\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0232\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0456 - val_loss: 0.0750\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0529 - val_loss: 0.0235\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0504 - val_loss: 0.0685\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0518 - val_loss: 0.0173\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0441 - val_loss: 0.0536\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0435 - val_loss: 0.0145\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0386 - val_loss: 0.0474\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0404 - val_loss: 0.0182\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0402 - val_loss: 0.0537\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0469 - val_loss: 0.0328\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0522 - val_loss: 0.0682\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0607 - val_loss: 0.0385\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0569 - val_loss: 0.0568\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0509 - val_loss: 0.0242\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0486\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0388 - val_loss: 0.0193\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0574\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0411 - val_loss: 0.0228\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0439 - val_loss: 0.0710\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0514 - val_loss: 0.0237\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0493 - val_loss: 0.0656\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0509 - val_loss: 0.0173\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0433 - val_loss: 0.0507\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0425 - val_loss: 0.0139\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0443\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0392 - val_loss: 0.0171\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0501\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0452 - val_loss: 0.0310\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0501 - val_loss: 0.0654\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0590 - val_loss: 0.0384\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0562 - val_loss: 0.0555\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0506 - val_loss: 0.0242\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0411 - val_loss: 0.0461\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0379 - val_loss: 0.0189\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0355 - val_loss: 0.0537\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0396 - val_loss: 0.0225\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0423 - val_loss: 0.0675\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0499 - val_loss: 0.0241\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0484 - val_loss: 0.0633\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0503 - val_loss: 0.0175\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0427 - val_loss: 0.0485\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0419 - val_loss: 0.0135\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0417\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0162\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0470\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0435 - val_loss: 0.0293\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0481 - val_loss: 0.0626\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0572 - val_loss: 0.0385\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0555 - val_loss: 0.0548\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0506 - val_loss: 0.0247\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0409 - val_loss: 0.0441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0373 - val_loss: 0.0187\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0345 - val_loss: 0.0503\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0222\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0406 - val_loss: 0.0642\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0483 - val_loss: 0.0245\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0475 - val_loss: 0.0616\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0498 - val_loss: 0.0180\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0423 - val_loss: 0.0469\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0415 - val_loss: 0.0133\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0360 - val_loss: 0.0396\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0373 - val_loss: 0.0154\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0441\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0419 - val_loss: 0.0275\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0460 - val_loss: 0.0599\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0553 - val_loss: 0.0387\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0548 - val_loss: 0.0546\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0509 - val_loss: 0.0254\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0411 - val_loss: 0.0427\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0370 - val_loss: 0.0186\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0336 - val_loss: 0.0473\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0366 - val_loss: 0.0218\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0390 - val_loss: 0.0610\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0467 - val_loss: 0.0250\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0465 - val_loss: 0.0602\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0494 - val_loss: 0.0186\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0421 - val_loss: 0.0459\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0412 - val_loss: 0.0134\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0355 - val_loss: 0.0378\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0366 - val_loss: 0.0147\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0415\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0258\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0570\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0533 - val_loss: 0.0386\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0541 - val_loss: 0.0547\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0513 - val_loss: 0.0264\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0414 - val_loss: 0.0417\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0187\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0330 - val_loss: 0.0446\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0354 - val_loss: 0.0214\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0579\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0449 - val_loss: 0.0253\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0455 - val_loss: 0.0590\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0490 - val_loss: 0.0194\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0420 - val_loss: 0.0451\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0412 - val_loss: 0.0136\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0364\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0359 - val_loss: 0.0142\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0391\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0388 - val_loss: 0.0241\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0420 - val_loss: 0.0541\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0511 - val_loss: 0.0383\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0530 - val_loss: 0.0551\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0517 - val_loss: 0.0277\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0420 - val_loss: 0.0412\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0371 - val_loss: 0.0189\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0325 - val_loss: 0.0423\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0342 - val_loss: 0.0210\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0549\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0431 - val_loss: 0.0256\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0444 - val_loss: 0.0579\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0485 - val_loss: 0.0203\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0420 - val_loss: 0.0447\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0413 - val_loss: 0.0139\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0350 - val_loss: 0.0353\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0137\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0333 - val_loss: 0.0369\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0225\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0401 - val_loss: 0.0511\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0377\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0517 - val_loss: 0.0554\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0520 - val_loss: 0.0291\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0426 - val_loss: 0.0410\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0374 - val_loss: 0.0193\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0322 - val_loss: 0.0403\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0332 - val_loss: 0.0205\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0520\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0413 - val_loss: 0.0256\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0568\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0480 - val_loss: 0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0420 - val_loss: 0.0446\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0414 - val_loss: 0.0143\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0349 - val_loss: 0.0345\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0351 - val_loss: 0.0134\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0325 - val_loss: 0.0350\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0362 - val_loss: 0.0210\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0383 - val_loss: 0.0481\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0467 - val_loss: 0.0366\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0502 - val_loss: 0.0555\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0521 - val_loss: 0.0306\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0434 - val_loss: 0.0412\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0199\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0386\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0202\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0330 - val_loss: 0.0492\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.0255\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0418 - val_loss: 0.0556\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0472 - val_loss: 0.0222\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0420 - val_loss: 0.0445\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0417 - val_loss: 0.0149\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0349 - val_loss: 0.0339\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.0132\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0319 - val_loss: 0.0334\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0197\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0366 - val_loss: 0.0451\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0445 - val_loss: 0.0352\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0484 - val_loss: 0.0554\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0520 - val_loss: 0.0322\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0442 - val_loss: 0.0417\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0387 - val_loss: 0.0206\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0322 - val_loss: 0.0373\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0319 - val_loss: 0.0199\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0318 - val_loss: 0.0465\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0378 - val_loss: 0.0253\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0543\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0463 - val_loss: 0.0231\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0420 - val_loss: 0.0446\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0420 - val_loss: 0.0155\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0350 - val_loss: 0.0334\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0347 - val_loss: 0.0131\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0319\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0341 - val_loss: 0.0185\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0351 - val_loss: 0.0424\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0336\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0465 - val_loss: 0.0548\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0515 - val_loss: 0.0337\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0449 - val_loss: 0.0425\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0396 - val_loss: 0.0215\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0363\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0315 - val_loss: 0.0197\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0441\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0249\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0528\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0452 - val_loss: 0.0239\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0418 - val_loss: 0.0447\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0422 - val_loss: 0.0163\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0332\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0347 - val_loss: 0.0131\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.0307\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0175\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0338 - val_loss: 0.0398\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0406 - val_loss: 0.0317\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0445 - val_loss: 0.0538\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0506 - val_loss: 0.0350\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0454 - val_loss: 0.0435\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0405 - val_loss: 0.0226\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0328 - val_loss: 0.0356\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0313 - val_loss: 0.0196\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0419\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0245\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0373 - val_loss: 0.0512\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0246\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0414 - val_loss: 0.0448\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0424 - val_loss: 0.0170\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0331\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.0132\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0296\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0326 - val_loss: 0.0166\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0326 - val_loss: 0.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0388 - val_loss: 0.0299\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0426 - val_loss: 0.0524\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0495 - val_loss: 0.0360\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0457 - val_loss: 0.0446\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0414 - val_loss: 0.0237\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0353\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0312 - val_loss: 0.0196\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0293 - val_loss: 0.0399\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0240\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0496\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0426 - val_loss: 0.0251\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0410 - val_loss: 0.0449\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0179\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0356 - val_loss: 0.0331\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0350 - val_loss: 0.0133\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0304 - val_loss: 0.0287\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0320 - val_loss: 0.0159\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0316 - val_loss: 0.0353\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0372 - val_loss: 0.0281\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0407 - val_loss: 0.0506\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0481 - val_loss: 0.0366\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0457 - val_loss: 0.0457\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0423 - val_loss: 0.0250\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0339 - val_loss: 0.0351\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0197\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0287 - val_loss: 0.0382\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0236\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0343 - val_loss: 0.0478\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0412 - val_loss: 0.0256\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0448\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0425 - val_loss: 0.0187\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0358 - val_loss: 0.0332\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0136\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0303 - val_loss: 0.0280\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0315 - val_loss: 0.0153\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0307 - val_loss: 0.0334\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0264\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0389 - val_loss: 0.0485\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0465 - val_loss: 0.0369\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0454 - val_loss: 0.0467\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0263\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0345 - val_loss: 0.0352\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0315 - val_loss: 0.0200\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0283 - val_loss: 0.0368\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0311 - val_loss: 0.0231\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0330 - val_loss: 0.0461\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0397 - val_loss: 0.0259\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0396 - val_loss: 0.0447\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0423 - val_loss: 0.0195\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0360 - val_loss: 0.0333\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0139\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0274\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0312 - val_loss: 0.0148\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0299 - val_loss: 0.0317\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0248\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0372 - val_loss: 0.0463\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0449 - val_loss: 0.0475\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0436 - val_loss: 0.0277\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0352 - val_loss: 0.0355\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0318 - val_loss: 0.0204\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0280 - val_loss: 0.0356\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0228\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0317 - val_loss: 0.0444\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0383 - val_loss: 0.0260\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0387 - val_loss: 0.0444\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0420 - val_loss: 0.0202\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0335\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0356 - val_loss: 0.0143\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0269\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0309 - val_loss: 0.0145\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0301\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 0.0234\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0357 - val_loss: 0.0441\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0364\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0441 - val_loss: 0.0482\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0440 - val_loss: 0.0291\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0359\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0279 - val_loss: 0.0346\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0295 - val_loss: 0.0224\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0428\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0378 - val_loss: 0.0440\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0416 - val_loss: 0.0210\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0361 - val_loss: 0.0337\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0358 - val_loss: 0.0147\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0265\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0142\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.0288\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0221\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0343 - val_loss: 0.0418\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0356\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0431 - val_loss: 0.0485\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0442 - val_loss: 0.0304\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0364 - val_loss: 0.0366\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0214\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0339\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0222\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0296 - val_loss: 0.0413\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0355 - val_loss: 0.0260\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0435\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0410 - val_loss: 0.0216\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0339\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0360 - val_loss: 0.0151\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0303 - val_loss: 0.0263\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0306 - val_loss: 0.0140\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0316 - val_loss: 0.0209\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0331 - val_loss: 0.0397\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0400 - val_loss: 0.0346\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0420 - val_loss: 0.0485\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0442 - val_loss: 0.0317\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0370 - val_loss: 0.0373\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0331 - val_loss: 0.0221\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0279 - val_loss: 0.0333\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0285 - val_loss: 0.0220\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0287 - val_loss: 0.0399\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0343 - val_loss: 0.0259\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0429\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0403 - val_loss: 0.0222\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0360 - val_loss: 0.0340\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0155\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0260\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0306 - val_loss: 0.0138\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0279 - val_loss: 0.0265\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0309 - val_loss: 0.0198\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0319 - val_loss: 0.0376\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0385 - val_loss: 0.0334\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0407 - val_loss: 0.0482\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0439 - val_loss: 0.0328\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0375 - val_loss: 0.0381\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0229\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0280 - val_loss: 0.0329\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0281 - val_loss: 0.0220\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0280 - val_loss: 0.0386\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0331 - val_loss: 0.0258\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0346 - val_loss: 0.0423\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0395 - val_loss: 0.0228\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0357 - val_loss: 0.0342\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0362 - val_loss: 0.0160\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0259\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0306 - val_loss: 0.0137\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0256\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0189\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0309 - val_loss: 0.0356\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0371 - val_loss: 0.0321\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0394 - val_loss: 0.0476\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0434 - val_loss: 0.0338\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0378 - val_loss: 0.0389\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0238\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0281 - val_loss: 0.0327\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0220\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0273 - val_loss: 0.0374\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0320 - val_loss: 0.0257\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0336 - val_loss: 0.0416\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0386 - val_loss: 0.0233\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0362 - val_loss: 0.0165\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0305 - val_loss: 0.0258\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0306 - val_loss: 0.0137\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0247\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0181\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0337\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0307\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0381 - val_loss: 0.0466\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0346\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0398\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0348 - val_loss: 0.0247\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0327\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0277 - val_loss: 0.0221\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0267 - val_loss: 0.0364\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0310 - val_loss: 0.0255\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0325 - val_loss: 0.0409\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0377 - val_loss: 0.0237\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0350 - val_loss: 0.0343\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0361 - val_loss: 0.0170\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0306 - val_loss: 0.0258\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0137\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0240\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0173\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0320\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0292\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0454\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0419 - val_loss: 0.0351\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0381 - val_loss: 0.0406\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0257\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0327\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0276 - val_loss: 0.0223\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0355\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0301 - val_loss: 0.0254\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0315 - val_loss: 0.0401\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0241\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0344\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0359 - val_loss: 0.0174\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0306 - val_loss: 0.0257\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0306 - val_loss: 0.0138\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0270 - val_loss: 0.0233\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0167\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0285 - val_loss: 0.0304\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0335 - val_loss: 0.0278\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0356 - val_loss: 0.0440\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0410 - val_loss: 0.0353\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0413\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0357 - val_loss: 0.0266\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0329\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0276 - val_loss: 0.0226\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0258 - val_loss: 0.0348\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0254\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0394\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0245\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0340 - val_loss: 0.0343\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0357 - val_loss: 0.0179\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0257\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0307 - val_loss: 0.0139\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0227\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0161\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0289\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0265\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0344 - val_loss: 0.0424\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0400 - val_loss: 0.0353\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0377 - val_loss: 0.0419\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0360 - val_loss: 0.0276\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0332\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0276 - val_loss: 0.0230\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0343\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0285 - val_loss: 0.0253\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0388\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.0248\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 0.0343\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0353 - val_loss: 0.0183\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0305 - val_loss: 0.0257\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0307 - val_loss: 0.0140\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0269 - val_loss: 0.0222\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0283 - val_loss: 0.0156\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0273 - val_loss: 0.0275\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0317 - val_loss: 0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0333 - val_loss: 0.0407\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0389 - val_loss: 0.0351\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0373 - val_loss: 0.0423\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0362 - val_loss: 0.0286\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0295 - val_loss: 0.0336\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0234\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0251 - val_loss: 0.0338\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0254\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0289 - val_loss: 0.0382\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0339 - val_loss: 0.0251\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0328 - val_loss: 0.0341\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0349 - val_loss: 0.0188\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0257\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0307 - val_loss: 0.0141\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0218\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0281 - val_loss: 0.0152\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0263\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0309 - val_loss: 0.0240\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0323 - val_loss: 0.0390\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0379 - val_loss: 0.0345\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0424\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0294\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0340\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0239\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0336\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0273 - val_loss: 0.0255\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0282 - val_loss: 0.0376\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0330 - val_loss: 0.0254\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0340\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0344 - val_loss: 0.0192\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0257\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0306 - val_loss: 0.0143\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0267 - val_loss: 0.0214\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0280 - val_loss: 0.0148\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0265 - val_loss: 0.0251\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0302 - val_loss: 0.0229\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0373\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0339\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0424\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0362 - val_loss: 0.0302\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0344\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0245\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0334\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0257\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0372\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0322 - val_loss: 0.0257\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0315 - val_loss: 0.0339\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0339 - val_loss: 0.0195\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0256\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0305 - val_loss: 0.0144\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0267 - val_loss: 0.0210\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0145\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0262 - val_loss: 0.0241\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0220\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0356\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0359 - val_loss: 0.0330\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0354 - val_loss: 0.0420\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0360 - val_loss: 0.0308\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0348\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0279 - val_loss: 0.0250\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0333\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0260\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0369\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0314 - val_loss: 0.0261\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0337\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0333 - val_loss: 0.0199\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0296 - val_loss: 0.0255\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0303 - val_loss: 0.0146\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0265 - val_loss: 0.0207\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0277 - val_loss: 0.0142\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0259 - val_loss: 0.0232\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0211\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0341\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0350 - val_loss: 0.0321\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0347 - val_loss: 0.0414\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0312\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0350\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0255\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0244 - val_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0367\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0265\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0336\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0328 - val_loss: 0.0203\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0253\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0147\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0264 - val_loss: 0.0204\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0223\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0287 - val_loss: 0.0203\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0327\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0343 - val_loss: 0.0312\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0341 - val_loss: 0.0407\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0314\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0299 - val_loss: 0.0351\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0260\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0242 - val_loss: 0.0332\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0258 - val_loss: 0.0267\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0365\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0269\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0336\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0322 - val_loss: 0.0206\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0252\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0149\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0262 - val_loss: 0.0201\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0138\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0216\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0196\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0288 - val_loss: 0.0313\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0303\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0335 - val_loss: 0.0397\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0349 - val_loss: 0.0314\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0351\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0277 - val_loss: 0.0264\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0332\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0254 - val_loss: 0.0271\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0256 - val_loss: 0.0365\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0274\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0336\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0317 - val_loss: 0.0210\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0250\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0150\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0259 - val_loss: 0.0197\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0272 - val_loss: 0.0136\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0251 - val_loss: 0.0208\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0280 - val_loss: 0.0190\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0332 - val_loss: 0.0294\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0330 - val_loss: 0.0387\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0345 - val_loss: 0.0312\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0294 - val_loss: 0.0348\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0275 - val_loss: 0.0266\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0237 - val_loss: 0.0330\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0250 - val_loss: 0.0275\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0366\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0293 - val_loss: 0.0280\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0289 - val_loss: 0.0336\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0313 - val_loss: 0.0214\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0249\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0151\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0194\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0135\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0248 - val_loss: 0.0201\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0277 - val_loss: 0.0184\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0280 - val_loss: 0.0290\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0328 - val_loss: 0.0286\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0326 - val_loss: 0.0377\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0342 - val_loss: 0.0308\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0291 - val_loss: 0.0343\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0266\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0328\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0279\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0249 - val_loss: 0.0366\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0290 - val_loss: 0.0286\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0338\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0309 - val_loss: 0.0219\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0248\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0252 - val_loss: 0.0190\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0133\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0245 - val_loss: 0.0194\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0273 - val_loss: 0.0179\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0280\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0279\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0324 - val_loss: 0.0366\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0339 - val_loss: 0.0303\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0335\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0268 - val_loss: 0.0264\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0229 - val_loss: 0.0323\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0241 - val_loss: 0.0281\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0245 - val_loss: 0.0367\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0287 - val_loss: 0.0293\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0285 - val_loss: 0.0341\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0224\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0273 - val_loss: 0.0247\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0280 - val_loss: 0.0154\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0247 - val_loss: 0.0187\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0259 - val_loss: 0.0131\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0240 - val_loss: 0.0187\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0268 - val_loss: 0.0174\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0323 - val_loss: 0.0273\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0323 - val_loss: 0.0357\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0338 - val_loss: 0.0297\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0326\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0259\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0224 - val_loss: 0.0316\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0235 - val_loss: 0.0281\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0367\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0301\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0283 - val_loss: 0.0346\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0307 - val_loss: 0.0231\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0271 - val_loss: 0.0248\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0277 - val_loss: 0.0156\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0183\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0253 - val_loss: 0.0129\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0234 - val_loss: 0.0180\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0261 - val_loss: 0.0168\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0268 - val_loss: 0.0261\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0267\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0324 - val_loss: 0.0348\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0339 - val_loss: 0.0292\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0316\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0253\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0219 - val_loss: 0.0306\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0228 - val_loss: 0.0279\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0233 - val_loss: 0.0364\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0279 - val_loss: 0.0308\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0352\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0239\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0251\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0275 - val_loss: 0.0158\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0239 - val_loss: 0.0180\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0227 - val_loss: 0.0172\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0253 - val_loss: 0.0162\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0262 - val_loss: 0.0251\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0318 - val_loss: 0.0262\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0340\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0343 - val_loss: 0.0287\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0287 - val_loss: 0.0306\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0258 - val_loss: 0.0245\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0214 - val_loss: 0.0293\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0220 - val_loss: 0.0273\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0360\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0315\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0281 - val_loss: 0.0358\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0310 - val_loss: 0.0249\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0273 - val_loss: 0.0255\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0162\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0179\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0126\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0164\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0154\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0253 - val_loss: 0.0239\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0312 - val_loss: 0.0256\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0326 - val_loss: 0.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.0283\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0291 - val_loss: 0.0298\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0258 - val_loss: 0.0237\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0209 - val_loss: 0.0278\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0264\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0216 - val_loss: 0.0350\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0320\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0279 - val_loss: 0.0366\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0312 - val_loss: 0.0260\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0277 - val_loss: 0.0262\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0168\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0235 - val_loss: 0.0178\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0125\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0211 - val_loss: 0.0157\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0242 - val_loss: 0.0225\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0248\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0326 - val_loss: 0.0328\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0356 - val_loss: 0.0282\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0298 - val_loss: 0.0291\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0229\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0207 - val_loss: 0.0262\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0203 - val_loss: 0.0251\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0205 - val_loss: 0.0336\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0253 - val_loss: 0.0321\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0373\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0314 - val_loss: 0.0274\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0282 - val_loss: 0.0272\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0282 - val_loss: 0.0176\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0180\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0233 - val_loss: 0.0125\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0204 - val_loss: 0.0150\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0137\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0228 - val_loss: 0.0209\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0238\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0323 - val_loss: 0.0321\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0364 - val_loss: 0.0282\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0309 - val_loss: 0.0288\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0270 - val_loss: 0.0224\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0208 - val_loss: 0.0247\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0197 - val_loss: 0.0236\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0193 - val_loss: 0.0316\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0238 - val_loss: 0.0318\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0266 - val_loss: 0.0378\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0313 - val_loss: 0.0290\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0285\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0290 - val_loss: 0.0186\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0184\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0232 - val_loss: 0.0126\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0198 - val_loss: 0.0144\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0208 - val_loss: 0.0129\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0224\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0314 - val_loss: 0.0313\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0323 - val_loss: 0.0289\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0283 - val_loss: 0.0221\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0212 - val_loss: 0.0233\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0193 - val_loss: 0.0219\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0182 - val_loss: 0.0292\n",
      "0.026712113991379738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.4121352 ,  0.9020908 ,  0.19666164,  0.1100288 ,  0.48310325],\n",
       "        [-0.1291268 , -0.17443722, -0.6422074 ,  0.0727801 , -0.46893385],\n",
       "        [-0.12209765,  0.18586026,  0.1493269 , -0.59487283, -0.4582646 ]],\n",
       "       dtype=float32),\n",
       " array([-0.55472976, -0.44968447, -0.16833316, -0.2368574 ,  0.27591002],\n",
       "       dtype=float32),\n",
       " array([[-7.90816769e-02, -3.41731519e-01,  2.18523636e-01,\n",
       "         -2.42665172e-01, -5.45350969e-01, -1.30947500e-01,\n",
       "          8.11292410e-01,  5.80937386e-01,  7.61799514e-01,\n",
       "          3.39280039e-01],\n",
       "        [-1.95925042e-01, -4.63499218e-01,  1.47924259e-01,\n",
       "         -6.25007749e-01,  4.29646701e-01, -7.73511469e-01,\n",
       "         -1.55248940e-01,  1.55250980e-02,  7.36702800e-01,\n",
       "          1.32414132e-01],\n",
       "        [ 6.99152410e-01,  7.89372772e-02,  5.51239610e-01,\n",
       "         -2.50712276e-01,  2.95844018e-01, -2.67059356e-01,\n",
       "         -4.67058122e-01,  2.76678443e-01, -4.49477017e-01,\n",
       "          4.95610476e-01],\n",
       "        [ 4.43712920e-01,  4.25178349e-01,  5.82740724e-01,\n",
       "         -3.51953030e-01, -3.39077026e-01, -6.63677096e-01,\n",
       "         -5.26170850e-01,  1.17657147e-01,  6.35641992e-01,\n",
       "         -1.12773806e-01],\n",
       "        [ 1.77664444e-01,  4.10427332e-01, -1.58207312e-01,\n",
       "          6.06168032e-01, -6.12262636e-04,  6.39962196e-01,\n",
       "         -8.61294195e-02, -5.74430168e-01, -1.40704885e-01,\n",
       "          1.82232603e-01]], dtype=float32),\n",
       " array([-0.5537812 ,  0.55529195, -0.5691753 ,  0.55637014,  0.53078884,\n",
       "         0.555581  , -0.553657  , -0.5513832 , -0.5593793 ,  0.58462745],\n",
       "       dtype=float32),\n",
       " array([[-0.8898693 ],\n",
       "        [ 0.7649043 ],\n",
       "        [-0.3790492 ],\n",
       "        [ 0.5089445 ],\n",
       "        [ 0.25146168],\n",
       "        [ 0.996478  ],\n",
       "        [-0.70423424],\n",
       "        [-0.70715165],\n",
       "        [-0.43122047],\n",
       "        [ 0.3246931 ]], dtype=float32),\n",
       " array([0.5713827], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, RMSprop, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_rmsprop_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
