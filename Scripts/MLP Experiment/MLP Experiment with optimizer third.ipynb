{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 421us/step - loss: 15100.9297 - val_loss: 14017.2131\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 11334.1342 - val_loss: 7161.9333\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 3313.4327 - val_loss: 393.5170\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 86.3566 - val_loss: 42.4837\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 29.5619 - val_loss: 27.8923\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.2911 - val_loss: 27.4755\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.9393 - val_loss: 26.8002\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.5078 - val_loss: 26.7930\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1538 - val_loss: 27.0577\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0782 - val_loss: 27.0881\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0442 - val_loss: 27.5853\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 22.26 - 0s 86us/step - loss: 22.0585 - val_loss: 27.6424\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8856 - val_loss: 26.8009\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8253 - val_loss: 26.7014\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6340 - val_loss: 26.9762\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7355 - val_loss: 26.2256\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7552 - val_loss: 26.5231\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6371 - val_loss: 27.0142\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7546 - val_loss: 27.0536\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7143 - val_loss: 27.9806\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.9881 - val_loss: 27.3338\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8414 - val_loss: 26.8159\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7923 - val_loss: 27.4259\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4745 - val_loss: 26.3006\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.6485 - val_loss: 26.6169\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8279 - val_loss: 26.2900\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6809 - val_loss: 26.2291\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6823 - val_loss: 26.4885\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8437 - val_loss: 26.2261\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4073 - val_loss: 26.0744\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6351 - val_loss: 25.9124\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7082 - val_loss: 26.6813\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9776 - val_loss: 26.4335\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4499 - val_loss: 25.6906\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.4420 - val_loss: 25.8972\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5158 - val_loss: 26.2401\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7369 - val_loss: 26.1209\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6292 - val_loss: 25.5281\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.3943 - val_loss: 26.8148\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6795 - val_loss: 26.3682\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6720 - val_loss: 26.0731\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.4022 - val_loss: 25.4128\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5459 - val_loss: 25.8282\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8129 - val_loss: 26.8866\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8116 - val_loss: 25.4564\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9081 - val_loss: 25.3141\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8604 - val_loss: 25.6275\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8082 - val_loss: 25.7795\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6826 - val_loss: 26.1024\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.3625 - val_loss: 26.0700\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1040 - val_loss: 26.0411\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4717 - val_loss: 26.4317\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5427 - val_loss: 25.4221\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6919 - val_loss: 27.0962\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9520 - val_loss: 25.6029\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5507 - val_loss: 26.4242\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3586 - val_loss: 25.8035\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8968 - val_loss: 25.9836\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4028 - val_loss: 26.3350\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6415 - val_loss: 25.8990\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.8357 - val_loss: 26.1431\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0635 - val_loss: 26.3498\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6459 - val_loss: 27.3822\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9784 - val_loss: 26.4873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8381 - val_loss: 25.7362\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6463 - val_loss: 25.4927\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.3050 - val_loss: 25.6081\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.6601 - val_loss: 25.8391\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8145 - val_loss: 27.3498\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3956 - val_loss: 25.2750\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0531 - val_loss: 26.9048\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4779 - val_loss: 25.8963\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8152 - val_loss: 25.8249\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7618 - val_loss: 27.3666\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9515 - val_loss: 25.4811\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1587 - val_loss: 25.7185\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.4922 - val_loss: 25.9190\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0937 - val_loss: 25.8002\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7209 - val_loss: 25.6635\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5125 - val_loss: 25.9457\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.6138 - val_loss: 26.1212\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9169 - val_loss: 26.8646\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9363 - val_loss: 26.0245\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8126 - val_loss: 25.8814\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7165 - val_loss: 26.4710\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.9530 - val_loss: 26.0282\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2559 - val_loss: 26.5330\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8216 - val_loss: 26.1774\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8365 - val_loss: 25.6025\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.1469 - val_loss: 26.5749\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9546 - val_loss: 26.1308\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.5703 - val_loss: 25.2769\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8472 - val_loss: 27.6901\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.6542 - val_loss: 25.2967\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7539 - val_loss: 25.6318\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9204 - val_loss: 25.4338\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6565 - val_loss: 27.9157\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.6415 - val_loss: 25.0630\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4874 - val_loss: 27.1790\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6372 - val_loss: 25.7694\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8632 - val_loss: 25.5837\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1746 - val_loss: 25.8571\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6930 - val_loss: 25.2487\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.7746 - val_loss: 25.4617\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4504 - val_loss: 27.5353\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.6361 - val_loss: 26.6535\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1312 - val_loss: 27.4566\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5845 - val_loss: 25.5940\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9271 - val_loss: 26.7149\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9445 - val_loss: 25.6630\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1845 - val_loss: 26.1952\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.1651 - val_loss: 26.0460\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1223 - val_loss: 25.4145\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1112 - val_loss: 25.2424\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3943 - val_loss: 26.3940\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3070 - val_loss: 26.9293\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8175 - val_loss: 26.5671\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5340 - val_loss: 25.8421\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0755 - val_loss: 26.3752\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.2702 - val_loss: 26.6816\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.8531 - val_loss: 26.0440\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7280 - val_loss: 25.5994\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3572 - val_loss: 26.2820\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1980 - val_loss: 25.3014\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6166 - val_loss: 26.2313\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9292 - val_loss: 26.2483\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1072 - val_loss: 26.2451\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8479 - val_loss: 27.1289\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2583 - val_loss: 26.5639\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3606 - val_loss: 26.5501\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8333 - val_loss: 26.9466\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3833 - val_loss: 26.5791\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6387 - val_loss: 25.0601\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6354 - val_loss: 26.2346\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0602 - val_loss: 27.3670\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7258 - val_loss: 27.4442\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9853 - val_loss: 25.6164\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.6701 - val_loss: 26.3548\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0484 - val_loss: 24.9741\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6037 - val_loss: 24.8948\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.9101 - val_loss: 25.5084\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2467 - val_loss: 25.7282\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7225 - val_loss: 25.6158\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9507 - val_loss: 25.9725\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1929 - val_loss: 27.9161\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.5821 - val_loss: 26.3166\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5141 - val_loss: 25.1135\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3857 - val_loss: 25.6928\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8763 - val_loss: 25.6018\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5361 - val_loss: 25.1018\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3071 - val_loss: 25.0697\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.4415 - val_loss: 26.2710\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9373 - val_loss: 25.2123\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4281 - val_loss: 25.1567\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6815 - val_loss: 24.6328\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5350 - val_loss: 25.9855\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9486 - val_loss: 24.6238\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5622 - val_loss: 25.0354\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.0540 - val_loss: 25.5208\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.2799 - val_loss: 24.7892\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.0550 - val_loss: 24.2125\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.7526 - val_loss: 24.7821\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4051 - val_loss: 23.4402\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.8844 - val_loss: 23.5634\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.0251 - val_loss: 23.4882\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3933 - val_loss: 24.1255\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.2496 - val_loss: 23.5549\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 19.0993 - val_loss: 23.7910\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 19.4795 - val_loss: 24.2133\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.1501 - val_loss: 23.8733\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.1294 - val_loss: 23.6190\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.6969 - val_loss: 23.5959\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.8757 - val_loss: 22.8762\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0923 - val_loss: 23.2005\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3582 - val_loss: 22.7044\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.9418 - val_loss: 22.0246\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6465 - val_loss: 22.1390\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8978 - val_loss: 21.9925\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2686 - val_loss: 21.8736\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1355 - val_loss: 21.1034\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7928 - val_loss: 21.8389\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9145 - val_loss: 22.1559\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1516 - val_loss: 20.4472\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6440 - val_loss: 21.6591\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5145 - val_loss: 20.2390\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1776 - val_loss: 20.7713\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6398 - val_loss: 22.0869\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6698 - val_loss: 20.3347\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6850 - val_loss: 20.9717\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6092 - val_loss: 20.4432\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.8754 - val_loss: 21.1941\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.3160 - val_loss: 18.5643\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.8807 - val_loss: 20.2998\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3512 - val_loss: 18.3399\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1240 - val_loss: 19.7029\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8246 - val_loss: 20.1661\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.2200 - val_loss: 21.4469\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.8179 - val_loss: 18.6382\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.8713 - val_loss: 18.6169\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.7154 - val_loss: 18.4630\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.0274 - val_loss: 20.4740\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.7769 - val_loss: 18.6715\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.7360 - val_loss: 18.9796\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9489 - val_loss: 17.7137\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9373 - val_loss: 19.2649\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5882 - val_loss: 19.1329\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.2741 - val_loss: 17.9658\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.0505 - val_loss: 17.9493\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9497 - val_loss: 22.0458\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9481 - val_loss: 17.7913\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1063 - val_loss: 17.2755\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.0462 - val_loss: 18.4479\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.4903 - val_loss: 18.8521\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6227 - val_loss: 17.2658\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2364 - val_loss: 18.8330\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6019 - val_loss: 16.8284\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2204 - val_loss: 18.4591\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8378 - val_loss: 17.3913\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5308 - val_loss: 16.7107\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7610 - val_loss: 20.7837\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3003 - val_loss: 18.1783\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3044 - val_loss: 16.9156\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1028 - val_loss: 17.6531\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8878 - val_loss: 16.8753\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7884 - val_loss: 17.7012\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.1590 - val_loss: 20.4640\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0357 - val_loss: 17.0393\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9213 - val_loss: 16.3512\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8084 - val_loss: 18.7370\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7556 - val_loss: 16.5920\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3960 - val_loss: 18.7835\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0386 - val_loss: 18.9589\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8366 - val_loss: 16.4110\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7884 - val_loss: 17.9303\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2095 - val_loss: 17.8834\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2589 - val_loss: 18.3354\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3735 - val_loss: 16.1226\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0603 - val_loss: 15.9028\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.4241 - val_loss: 17.4447\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.2475 - val_loss: 17.6549\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1681 - val_loss: 16.1631\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8606 - val_loss: 17.0902\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8463 - val_loss: 16.2849\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7745 - val_loss: 15.9667\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8404 - val_loss: 17.6548\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2271 - val_loss: 20.4578\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7909 - val_loss: 16.8368\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2282 - val_loss: 16.6287\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9792 - val_loss: 16.3320\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3446 - val_loss: 16.8343\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3829 - val_loss: 20.2164\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8703 - val_loss: 16.2103\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5733 - val_loss: 17.9636\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8740 - val_loss: 16.5851\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8810 - val_loss: 15.4246\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3521 - val_loss: 14.9958\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3589 - val_loss: 14.7391\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9666 - val_loss: 16.9136\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5179 - val_loss: 16.0684\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9546 - val_loss: 19.3047\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1433 - val_loss: 15.9708\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.0777 - val_loss: 16.3601\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1098 - val_loss: 14.6518\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5310 - val_loss: 16.5484\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0209 - val_loss: 15.7301\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1697 - val_loss: 17.3252\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3979 - val_loss: 14.0129\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2954 - val_loss: 14.4760\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2695 - val_loss: 14.5179\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9369 - val_loss: 15.0160\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2771 - val_loss: 15.0811\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8303 - val_loss: 16.5117\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4132 - val_loss: 15.0529\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3236 - val_loss: 15.4548\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1222 - val_loss: 14.7986\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5796 - val_loss: 13.9218\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3682 - val_loss: 14.1152\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5272 - val_loss: 14.4538\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8997 - val_loss: 14.5788\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8205 - val_loss: 16.1325\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2508 - val_loss: 16.8349\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8579 - val_loss: 13.9145\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2037 - val_loss: 14.0348\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1441 - val_loss: 13.8334\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8137 - val_loss: 18.2602\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9452 - val_loss: 15.8129\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4126 - val_loss: 14.6466\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6076 - val_loss: 14.4731\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2717 - val_loss: 14.8739\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5808 - val_loss: 14.8764\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8661 - val_loss: 14.4103\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0722 - val_loss: 15.0484\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6769 - val_loss: 13.8859\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8099 - val_loss: 14.5923\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3375 - val_loss: 13.5286\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5563 - val_loss: 13.6425\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9381 - val_loss: 13.0867\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6075 - val_loss: 17.1491\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9186 - val_loss: 14.1634\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2508 - val_loss: 15.7885\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4779 - val_loss: 15.1810\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2037 - val_loss: 15.5866\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6114 - val_loss: 13.8228\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3627 - val_loss: 13.9124\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7088 - val_loss: 13.2224\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2894 - val_loss: 19.4783\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5498 - val_loss: 15.7145\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9592 - val_loss: 13.2470\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4936 - val_loss: 14.4166\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4126 - val_loss: 13.5472\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7357 - val_loss: 13.2112\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2907 - val_loss: 14.8831\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9408 - val_loss: 13.1445\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8922 - val_loss: 12.6523\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7140 - val_loss: 13.6472\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3540 - val_loss: 16.7122\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9461 - val_loss: 13.2655\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6960 - val_loss: 12.9059\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8400 - val_loss: 13.6288\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1092 - val_loss: 14.5762\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6707 - val_loss: 12.5334\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3188 - val_loss: 12.3807\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.1677 - val_loss: 14.7323\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6044 - val_loss: 15.8404\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6123 - val_loss: 14.1204\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4520 - val_loss: 12.9211\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6041 - val_loss: 13.5679\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6979 - val_loss: 12.5291\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4991 - val_loss: 12.7929\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4996 - val_loss: 13.5522\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6635 - val_loss: 15.4429\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7000 - val_loss: 14.1991\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8324 - val_loss: 13.1509\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5390 - val_loss: 14.4227\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7979 - val_loss: 12.6316\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6823 - val_loss: 13.2405\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.3190 - val_loss: 12.7534\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.8149 - val_loss: 15.8748\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4709 - val_loss: 13.7725\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.0400 - val_loss: 15.4241\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9971 - val_loss: 12.0450\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.6890 - val_loss: 13.2450\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.8115 - val_loss: 14.0988\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3703 - val_loss: 12.8908\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.7472 - val_loss: 12.6537\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9339 - val_loss: 13.6189\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2172 - val_loss: 13.3434\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2632 - val_loss: 14.0049\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5012 - val_loss: 13.4571\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3956 - val_loss: 13.0008\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.3499 - val_loss: 12.9710\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4656 - val_loss: 12.7122\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7996 - val_loss: 14.2591\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1875 - val_loss: 15.0669\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9141 - val_loss: 13.4116\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7488 - val_loss: 16.5939\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1337 - val_loss: 12.8969\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0250 - val_loss: 13.5714\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4994 - val_loss: 11.8383\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8639 - val_loss: 12.9103\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0048 - val_loss: 12.4089\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4117 - val_loss: 12.2459\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1385 - val_loss: 12.3626\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1440 - val_loss: 12.6330\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5497 - val_loss: 12.8605\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8752 - val_loss: 12.2845\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2893 - val_loss: 15.2321\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9779 - val_loss: 12.8733\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4815 - val_loss: 11.9476\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8567 - val_loss: 12.7805\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4535 - val_loss: 13.8878\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0533 - val_loss: 13.1888\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1969 - val_loss: 12.9028\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8380 - val_loss: 14.9301\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6673 - val_loss: 12.5197\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7093 - val_loss: 12.7518\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5299 - val_loss: 11.9892\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7918 - val_loss: 12.1209\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8489 - val_loss: 13.0288\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1742 - val_loss: 12.5520\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2196 - val_loss: 11.6511\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4967 - val_loss: 12.9402\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7796 - val_loss: 11.6860\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0283 - val_loss: 12.3996\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3738 - val_loss: 13.2450\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8915 - val_loss: 12.3488\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3858 - val_loss: 12.4665\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7874 - val_loss: 13.4687\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6766 - val_loss: 13.1273\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8670 - val_loss: 11.7252\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7831 - val_loss: 11.9709\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7651 - val_loss: 12.0473\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7978 - val_loss: 12.4948\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3841 - val_loss: 13.0441\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1309 - val_loss: 12.5602\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8118 - val_loss: 11.7897\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6283 - val_loss: 13.1456\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9314 - val_loss: 11.5967\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0198 - val_loss: 12.9403\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8152 - val_loss: 14.5043\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7041 - val_loss: 13.5912\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8826 - val_loss: 11.1971\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6676 - val_loss: 11.7940\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7010 - val_loss: 11.6090\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4545 - val_loss: 11.6737\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6730 - val_loss: 11.5347\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4910 - val_loss: 12.2760\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0483 - val_loss: 13.9438\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2863 - val_loss: 11.6609\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6787 - val_loss: 12.2812\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4066 - val_loss: 11.7200\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7747 - val_loss: 13.3144\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5212 - val_loss: 11.7006\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3141 - val_loss: 11.9558\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1090 - val_loss: 13.2993\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5631 - val_loss: 14.3381\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6934 - val_loss: 11.2991\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3123 - val_loss: 11.3411\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6358 - val_loss: 14.2336\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9442 - val_loss: 12.5553\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4801 - val_loss: 11.3701\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4056 - val_loss: 11.7387\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4281 - val_loss: 12.3432\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1731 - val_loss: 11.9388\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2547 - val_loss: 11.8361\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0188 - val_loss: 12.7698\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9157 - val_loss: 12.1373\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1980 - val_loss: 11.1496\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1389 - val_loss: 12.1535\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0924 - val_loss: 12.9145\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9985 - val_loss: 12.5216\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3356 - val_loss: 11.1641\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2459 - val_loss: 12.7849\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5468 - val_loss: 11.1438\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6187 - val_loss: 13.4619\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6172 - val_loss: 11.2446\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7219 - val_loss: 12.3735\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4269 - val_loss: 11.1176\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1080 - val_loss: 11.2884\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2939 - val_loss: 12.0287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2901 - val_loss: 11.0426\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9104 - val_loss: 12.1585\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7572 - val_loss: 11.8092\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2935 - val_loss: 12.6743\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5659 - val_loss: 11.0165\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2895 - val_loss: 10.6965\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2430 - val_loss: 11.3035\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4482 - val_loss: 11.1480\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2204 - val_loss: 11.5691\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1065 - val_loss: 10.6868\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8485 - val_loss: 10.9937\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0155 - val_loss: 11.8785\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0379 - val_loss: 10.8906\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9781 - val_loss: 11.0871\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1445 - val_loss: 11.3912\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7156 - val_loss: 11.7657\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8065 - val_loss: 10.9715\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8765 - val_loss: 11.6596\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8711 - val_loss: 10.5577\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5591 - val_loss: 12.2101\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9246 - val_loss: 11.8305\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8872 - val_loss: 10.7100\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8998 - val_loss: 12.0290\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8937 - val_loss: 10.8620\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7296 - val_loss: 12.1410\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0824 - val_loss: 11.1216\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1252 - val_loss: 12.1251\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5246 - val_loss: 10.5562\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8715 - val_loss: 12.0611\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9060 - val_loss: 10.4705\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6078 - val_loss: 11.3621\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0174 - val_loss: 10.9143\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9731 - val_loss: 11.2114\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3708 - val_loss: 10.2983\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7801 - val_loss: 10.7437\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8651 - val_loss: 10.2955\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6230 - val_loss: 10.6999\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5177 - val_loss: 12.7026\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7599 - val_loss: 11.1517\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8988 - val_loss: 10.6193\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9354 - val_loss: 10.6249\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6969 - val_loss: 10.5278\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0020 - val_loss: 10.7178\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8804 - val_loss: 10.7439\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6681 - val_loss: 11.1118\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6176 - val_loss: 10.4656\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5651 - val_loss: 11.0134\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1270 - val_loss: 10.7176\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8718 - val_loss: 10.4451\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9092 - val_loss: 10.1907\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8576 - val_loss: 11.2367\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7893 - val_loss: 10.7453\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3157 - val_loss: 11.0812\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9049 - val_loss: 10.8541\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8415 - val_loss: 11.3859\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8373 - val_loss: 11.8894\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0698 - val_loss: 11.6931\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7171 - val_loss: 10.6491\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8958 - val_loss: 11.5215\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8799 - val_loss: 10.7016\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9878 - val_loss: 10.8996\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5551 - val_loss: 10.3625\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8886 - val_loss: 10.4188\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8277 - val_loss: 10.5039\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8915 - val_loss: 10.2351\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5744 - val_loss: 10.6615\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.4950 - val_loss: 10.8451\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6723 - val_loss: 10.4678\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0275 - val_loss: 10.1239\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8758 - val_loss: 11.0779\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7733 - val_loss: 10.0802\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7684 - val_loss: 11.2831\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0471 - val_loss: 11.6321\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5079 - val_loss: 11.9787\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8572 - val_loss: 9.9230\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7163 - val_loss: 11.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1540 - val_loss: 11.1120\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6327 - val_loss: 11.6770\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7171 - val_loss: 10.2711\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6950 - val_loss: 11.0943\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5146 - val_loss: 11.0143\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5061 - val_loss: 10.0685\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5191 - val_loss: 11.0690\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8054 - val_loss: 10.6593\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8296 - val_loss: 11.6236\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6767 - val_loss: 10.0037\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1932 - val_loss: 10.4230\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1278 - val_loss: 10.7555\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4504 - val_loss: 10.4310\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5832 - val_loss: 10.1371\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3550 - val_loss: 11.3096\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1227 - val_loss: 11.0501\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6802 - val_loss: 9.8292\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3594 - val_loss: 11.2710\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7443 - val_loss: 10.9608\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6441 - val_loss: 10.1489\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6657 - val_loss: 11.0224\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4015 - val_loss: 10.0626\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6941 - val_loss: 11.5467\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6680 - val_loss: 10.2888\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2212 - val_loss: 10.4175\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1001 - val_loss: 10.8673\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3696 - val_loss: 9.9394\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0257 - val_loss: 10.8407\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6654 - val_loss: 11.3371\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6043 - val_loss: 12.3966\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4235 - val_loss: 12.0489\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7725 - val_loss: 10.6042\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6244 - val_loss: 10.7974\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3306 - val_loss: 10.5036\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5576 - val_loss: 9.9597\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4786 - val_loss: 10.6167\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7473 - val_loss: 11.3962\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8505 - val_loss: 10.3241\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3976 - val_loss: 10.0551\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3803 - val_loss: 10.1495\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4882 - val_loss: 10.0857\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4330 - val_loss: 11.0258\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3551 - val_loss: 10.0097\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4949 - val_loss: 10.1715\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2623 - val_loss: 9.8021\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3284 - val_loss: 11.2447\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4083 - val_loss: 10.0276\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4584 - val_loss: 11.7288\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7756 - val_loss: 10.4606\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5566 - val_loss: 10.1040\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4402 - val_loss: 10.7487\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5157 - val_loss: 10.3617\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6211 - val_loss: 10.2508\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1813 - val_loss: 10.0889\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3105 - val_loss: 11.4415\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7546 - val_loss: 10.5601\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6836 - val_loss: 9.8198\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3321 - val_loss: 10.9127\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4498 - val_loss: 13.5989\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4160 - val_loss: 11.8689\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8247 - val_loss: 10.3335\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9039 - val_loss: 11.1823\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2979 - val_loss: 9.8271\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3266 - val_loss: 9.9911\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9359 - val_loss: 10.0438\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8584 - val_loss: 9.8691\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7762 - val_loss: 10.6212\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2208 - val_loss: 9.5107\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3956 - val_loss: 10.2620\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4859 - val_loss: 10.1977\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8640 - val_loss: 10.0748\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4313 - val_loss: 9.6956\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3735 - val_loss: 9.7503\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3985 - val_loss: 10.0873\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1904 - val_loss: 10.9528\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4256 - val_loss: 10.3749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4945 - val_loss: 10.9884\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0510 - val_loss: 9.9731\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2749 - val_loss: 9.7073\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9404 - val_loss: 10.0510\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7598 - val_loss: 10.0250\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4545 - val_loss: 10.6065\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5062 - val_loss: 10.3486\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1502 - val_loss: 11.4570\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7207 - val_loss: 10.9362\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5104 - val_loss: 10.3268\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4542 - val_loss: 11.1000\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3392 - val_loss: 10.0257\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2463 - val_loss: 9.8737\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5378 - val_loss: 10.2235\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3296 - val_loss: 10.6305\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6075 - val_loss: 9.9294\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7263 - val_loss: 9.8747\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6534 - val_loss: 11.3335\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2099 - val_loss: 10.2990\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4227 - val_loss: 9.7950\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5414 - val_loss: 9.6927\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4758 - val_loss: 12.2308\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5291 - val_loss: 9.5469\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3310 - val_loss: 10.0408\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4751 - val_loss: 9.7489\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4379 - val_loss: 10.3054\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4278 - val_loss: 9.8547\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8148 - val_loss: 10.2228\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3618 - val_loss: 10.4236\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3340 - val_loss: 11.3290\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5582 - val_loss: 10.0013\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4416 - val_loss: 10.0205\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2327 - val_loss: 13.1338\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8975 - val_loss: 11.0345\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7017 - val_loss: 9.7507\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4519 - val_loss: 10.6781\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4526 - val_loss: 10.2568\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1356 - val_loss: 9.7899\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8944 - val_loss: 10.9794\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5753 - val_loss: 10.4145\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5124 - val_loss: 9.6144\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3552 - val_loss: 9.9497\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3902 - val_loss: 10.0381\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7074 - val_loss: 10.0533\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6757 - val_loss: 9.7381\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9127 - val_loss: 10.8883\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5383 - val_loss: 10.4252\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5707 - val_loss: 10.0122\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4908 - val_loss: 9.7900\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9104 - val_loss: 9.5882\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5197 - val_loss: 9.9174\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1400 - val_loss: 9.9493\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2710 - val_loss: 9.7784\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3216 - val_loss: 9.7576\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0720 - val_loss: 9.4704\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4507 - val_loss: 10.0353\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2942 - val_loss: 10.4140\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6038 - val_loss: 10.8788\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5051 - val_loss: 11.6911\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9151 - val_loss: 11.1391\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0992 - val_loss: 10.1898\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5484 - val_loss: 10.7612\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7133 - val_loss: 9.6619\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5212 - val_loss: 10.8537\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4924 - val_loss: 9.5377\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1869 - val_loss: 9.5043\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5846 - val_loss: 11.1178\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3814 - val_loss: 11.7266\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8273 - val_loss: 9.5323\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5838 - val_loss: 9.5761\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4007 - val_loss: 10.2151\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2114 - val_loss: 9.7306\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4490 - val_loss: 10.1534\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2785 - val_loss: 9.5402\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2496 - val_loss: 11.4677\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5075 - val_loss: 9.7077\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4533 - val_loss: 10.1372\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5069 - val_loss: 11.4636\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3581 - val_loss: 10.4890\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4115 - val_loss: 9.5371\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2851 - val_loss: 10.2179\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4599 - val_loss: 10.7707\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4005 - val_loss: 9.9596\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3295 - val_loss: 9.6031\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4913 - val_loss: 9.9986\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2694 - val_loss: 9.3315\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1937 - val_loss: 9.4924\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1602 - val_loss: 9.2815\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5611 - val_loss: 9.4593\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6172 - val_loss: 9.9602\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2476 - val_loss: 9.6569\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4392 - val_loss: 10.8854\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9344 - val_loss: 10.3813\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0525 - val_loss: 10.1486\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4407 - val_loss: 9.5930\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3864 - val_loss: 9.5305\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3944 - val_loss: 10.0724\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1343 - val_loss: 11.3184\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9609 - val_loss: 9.7835\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5043 - val_loss: 11.8481\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5277 - val_loss: 9.6020\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1521 - val_loss: 10.5800\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0877 - val_loss: 9.4454\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1774 - val_loss: 9.8000\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8644 - val_loss: 11.2494\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9695 - val_loss: 10.4328\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2398 - val_loss: 11.4899\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2810 - val_loss: 9.8204\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3232 - val_loss: 10.5536\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5785 - val_loss: 11.1530\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7534 - val_loss: 9.8238\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5524 - val_loss: 9.7122\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5494 - val_loss: 10.1176\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3417 - val_loss: 9.4634\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7790 - val_loss: 10.5925\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6500 - val_loss: 10.5737\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1962 - val_loss: 9.7221\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4462 - val_loss: 9.3065\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5757 - val_loss: 10.0751\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2243 - val_loss: 11.4125\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3627 - val_loss: 10.2971\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5535 - val_loss: 9.4396\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4421 - val_loss: 9.7540\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4349 - val_loss: 10.2723\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6896 - val_loss: 9.6053\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3278 - val_loss: 9.8947\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3706 - val_loss: 9.3330\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1867 - val_loss: 10.1801\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0616 - val_loss: 10.1616\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5047 - val_loss: 10.1678\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4013 - val_loss: 9.7737\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5099 - val_loss: 11.4864\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7251 - val_loss: 9.4956\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2271 - val_loss: 9.3722\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7035 - val_loss: 11.0528\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1529 - val_loss: 9.9136\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1560 - val_loss: 9.2870\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4893 - val_loss: 9.8423\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9680 - val_loss: 10.1316\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2602 - val_loss: 9.5974\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1752 - val_loss: 11.6175\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2398 - val_loss: 9.5192\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1986 - val_loss: 9.8025\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3616 - val_loss: 9.9958\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3041 - val_loss: 10.2051\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0800 - val_loss: 10.4388\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1409 - val_loss: 10.4500\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5507 - val_loss: 9.7354\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1909 - val_loss: 9.4082\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2434 - val_loss: 10.6825\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7745 - val_loss: 9.3237\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5012 - val_loss: 10.6232\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0457 - val_loss: 11.3840\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3528 - val_loss: 10.4604\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3076 - val_loss: 10.1634\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6201 - val_loss: 11.6934\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4293 - val_loss: 9.4933\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8703 - val_loss: 10.5802\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3857 - val_loss: 9.5456\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3051 - val_loss: 9.8660\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6006 - val_loss: 9.6411\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3903 - val_loss: 9.9584\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2799 - val_loss: 9.6548\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4484 - val_loss: 9.0948\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2020 - val_loss: 10.5409\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6045 - val_loss: 9.5726\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2706 - val_loss: 10.8898\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0246 - val_loss: 9.8591\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9816 - val_loss: 9.9652\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0705 - val_loss: 9.5149\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3243 - val_loss: 9.6369\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1653 - val_loss: 10.0047\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4564 - val_loss: 10.1861\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1960 - val_loss: 11.3898\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4334 - val_loss: 9.3586\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4485 - val_loss: 10.4619\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4281 - val_loss: 9.5656\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7357 - val_loss: 12.5558\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6764 - val_loss: 9.4949\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7409 - val_loss: 13.0416\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7404 - val_loss: 9.7088\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3948 - val_loss: 9.5159\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1740 - val_loss: 10.6011\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5773 - val_loss: 10.8015\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6707 - val_loss: 9.7097\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6148 - val_loss: 10.6934\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4082 - val_loss: 10.1464\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0734 - val_loss: 9.2454\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5712 - val_loss: 10.1064\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3117 - val_loss: 9.8958\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2305 - val_loss: 9.9421\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1656 - val_loss: 10.2226\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0212 - val_loss: 9.4642\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0599 - val_loss: 9.3281\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1033 - val_loss: 9.3685\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5060 - val_loss: 14.7376\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8378 - val_loss: 9.5220\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1806 - val_loss: 9.9453\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4179 - val_loss: 9.3349\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1436 - val_loss: 9.6215\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4761 - val_loss: 10.0950\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0555 - val_loss: 11.2681\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7061 - val_loss: 9.9994\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1606 - val_loss: 9.2936\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3063 - val_loss: 10.5973\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1267 - val_loss: 10.0985\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2555 - val_loss: 10.4776\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3336 - val_loss: 9.9698\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5164 - val_loss: 9.3987\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3728 - val_loss: 9.7180\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3310 - val_loss: 9.2354\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0789 - val_loss: 9.6560\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1975 - val_loss: 9.6280\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3000 - val_loss: 9.2202\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5591 - val_loss: 9.3057\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4136 - val_loss: 9.3262\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7876 - val_loss: 9.7557\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5878 - val_loss: 9.4841\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1069 - val_loss: 10.1207\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6662 - val_loss: 9.4905\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3633 - val_loss: 9.6052\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3362 - val_loss: 9.7757\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3186 - val_loss: 12.0174\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3158 - val_loss: 9.2875\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3489 - val_loss: 9.3785\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4042 - val_loss: 9.3209\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1668 - val_loss: 10.4992\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4452 - val_loss: 9.9508\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3406 - val_loss: 9.8632\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4553 - val_loss: 10.2981\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2883 - val_loss: 9.8052\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0816 - val_loss: 9.5507\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1000 - val_loss: 9.4579\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1758 - val_loss: 10.9020\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1073 - val_loss: 10.4865\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1880 - val_loss: 9.9406\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1571 - val_loss: 9.3367\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2282 - val_loss: 9.7103\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1546 - val_loss: 11.4267\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4723 - val_loss: 9.3808\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2498 - val_loss: 9.8355\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4446 - val_loss: 9.1568\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1694 - val_loss: 9.7050\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2322 - val_loss: 9.4081\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0138 - val_loss: 10.4321\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5558 - val_loss: 10.3166\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6097 - val_loss: 10.4678\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2657 - val_loss: 9.6974\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1113 - val_loss: 12.1791\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2451 - val_loss: 9.0751\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0032 - val_loss: 9.1225\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2880 - val_loss: 9.6487\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5444 - val_loss: 9.6909\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4350 - val_loss: 10.5847\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0614 - val_loss: 10.6770\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4245 - val_loss: 10.4099\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3636 - val_loss: 10.5310\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3467 - val_loss: 9.4621\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2120 - val_loss: 11.1011\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5032 - val_loss: 9.2972\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2936 - val_loss: 9.7807\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7220 - val_loss: 9.7460\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1426 - val_loss: 9.4003\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0126 - val_loss: 9.7064\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2941 - val_loss: 9.0790\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4071 - val_loss: 9.9567\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4838 - val_loss: 10.4121\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2176 - val_loss: 9.7961\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9487 - val_loss: 9.6351\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8197 - val_loss: 10.2829\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3399 - val_loss: 9.4123\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1341 - val_loss: 9.3242\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5751 - val_loss: 9.9216\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3117 - val_loss: 9.1436\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9891 - val_loss: 10.1704\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2997 - val_loss: 9.7240\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2978 - val_loss: 9.3858\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1644 - val_loss: 9.0386\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1416 - val_loss: 8.9609\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1806 - val_loss: 10.9252\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5283 - val_loss: 9.9635\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3294 - val_loss: 9.1384\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5198 - val_loss: 10.4336\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7633 - val_loss: 10.7803\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6724 - val_loss: 9.2968\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4272 - val_loss: 9.6542\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4734 - val_loss: 9.7455\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3365 - val_loss: 9.3208\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2855 - val_loss: 10.7947\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3833 - val_loss: 10.0127\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0993 - val_loss: 10.2367\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3725 - val_loss: 9.4522\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4143 - val_loss: 10.7109\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1765 - val_loss: 9.3569\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2028 - val_loss: 10.0833\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3103 - val_loss: 9.3046\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2334 - val_loss: 9.5475\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5222 - val_loss: 9.7050\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5660 - val_loss: 11.1418\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3691 - val_loss: 10.0922\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9467 - val_loss: 9.3096\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1111 - val_loss: 9.2443\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2969 - val_loss: 9.7968\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3694 - val_loss: 9.0293\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3595 - val_loss: 9.1668\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2527 - val_loss: 10.4008\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4444 - val_loss: 9.8244\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1804 - val_loss: 9.4028\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0817 - val_loss: 9.0651\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6487 - val_loss: 9.3116\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2643 - val_loss: 9.4744\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1908 - val_loss: 9.2459\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0261 - val_loss: 9.8684\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7394 - val_loss: 10.1600\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4395 - val_loss: 9.8124\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3423 - val_loss: 9.1128\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0830 - val_loss: 9.2450\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3340 - val_loss: 9.1907\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1843 - val_loss: 9.4834\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3994 - val_loss: 11.4932\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6169 - val_loss: 9.1927\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3993 - val_loss: 10.8975\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2023 - val_loss: 9.2404\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2578 - val_loss: 10.5886\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3948 - val_loss: 9.8440\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1031 - val_loss: 9.3964\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3659 - val_loss: 10.2998\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4013 - val_loss: 9.1445\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9248 - val_loss: 10.0272\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7506 - val_loss: 9.4382\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3394 - val_loss: 9.7680\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8266 - val_loss: 9.8718\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4308 - val_loss: 9.5850\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6243 - val_loss: 9.1286\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1551 - val_loss: 9.5404\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6779 - val_loss: 12.0931\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5806 - val_loss: 9.2228\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9414 - val_loss: 9.3609\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0715 - val_loss: 9.4249\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9734 - val_loss: 9.3931\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4708 - val_loss: 12.0211\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2880 - val_loss: 9.4416\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7261 - val_loss: 9.7550\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4345 - val_loss: 9.8895\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3897 - val_loss: 9.3199\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0551 - val_loss: 9.2589\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0870 - val_loss: 9.2288\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2644 - val_loss: 9.1715\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5063 - val_loss: 10.2374\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5944 - val_loss: 9.6514\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3267 - val_loss: 11.3551\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2667 - val_loss: 9.7750\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8359 - val_loss: 11.0394\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7851 - val_loss: 9.1352\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1117 - val_loss: 9.6859\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1196 - val_loss: 9.6180\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3018 - val_loss: 8.9887\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9330 - val_loss: 10.5635\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2272 - val_loss: 9.3210\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4358 - val_loss: 9.5689\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3365 - val_loss: 10.3753\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3267 - val_loss: 9.2502\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1495 - val_loss: 10.1672\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5833 - val_loss: 9.0147\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1715 - val_loss: 8.8483\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2015 - val_loss: 10.3768\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9535 - val_loss: 9.3613\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9852 - val_loss: 9.2468\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5451 - val_loss: 10.2925\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3533 - val_loss: 9.1828\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8006 - val_loss: 10.2881\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3137 - val_loss: 10.1728\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2826 - val_loss: 11.8822\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9831 - val_loss: 9.2803\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2307 - val_loss: 9.6646\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1928 - val_loss: 9.6104\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3519 - val_loss: 10.6844\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1538 - val_loss: 9.5232\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1908 - val_loss: 9.3078\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2548 - val_loss: 10.1137\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0975 - val_loss: 9.1086\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4042 - val_loss: 9.2171\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4330 - val_loss: 9.6773\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9869 - val_loss: 10.1182\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2811 - val_loss: 9.3736\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2371 - val_loss: 10.7302\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5756 - val_loss: 9.7154\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2091 - val_loss: 10.1273\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4066 - val_loss: 9.5433\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1490 - val_loss: 9.1480\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0179 - val_loss: 9.5024\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9515 - val_loss: 9.4504\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0394 - val_loss: 9.0190\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5683 - val_loss: 10.8978\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2034 - val_loss: 10.3422\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6013 - val_loss: 9.4428\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2394 - val_loss: 9.7563\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1163 - val_loss: 9.9190\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0128 - val_loss: 10.1163\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.5157 - val_loss: 10.1263\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1633 - val_loss: 9.0021\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1618 - val_loss: 10.0258\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3949 - val_loss: 9.6738\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4910 - val_loss: 9.4901\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2861 - val_loss: 9.4534\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0410 - val_loss: 9.4243\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9319 - val_loss: 10.3687\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3520 - val_loss: 9.2198\n",
      "8.377727370346541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.92684   , -3.2819602 ,  0.16170907,  0.7451401 ,  3.684478  ],\n",
       "        [-0.5120534 ,  0.08816968,  0.18943238,  1.4303167 , -0.20188612],\n",
       "        [-0.39603817,  0.03589958,  0.2904678 ,  1.6199942 ,  0.6786771 ],\n",
       "        [-0.02675521,  0.06636933, -0.12156886, -0.25519815, -0.1550963 ],\n",
       "        [ 0.3170898 , -2.430267  ,  0.17560655, -0.32337746,  0.32187825]],\n",
       "       dtype=float32),\n",
       " array([ 1.3062803, -4.8312626, -1.4084458,  0.7101072,  4.6671124],\n",
       "       dtype=float32),\n",
       " array([[-0.26930195,  0.83421636,  0.66880596,  0.2204506 , -0.08666676,\n",
       "          0.9608654 ,  0.7645459 ,  0.8993816 ,  0.32728025,  0.8621221 ],\n",
       "        [-1.8216622 ,  1.875882  ,  1.1469307 ,  1.066795  , -2.2097967 ,\n",
       "          1.9365895 ,  1.6413672 ,  1.1358248 ,  2.0512748 ,  1.6679956 ],\n",
       "        [-1.9696206 ,  1.7040391 ,  1.6395023 ,  1.9156444 , -1.9847156 ,\n",
       "          1.6884484 ,  1.217574  ,  1.0689583 ,  1.7076293 ,  1.5407608 ],\n",
       "        [ 0.11542796,  0.43356326,  0.6252136 ,  0.4653967 ,  0.04257011,\n",
       "          0.3625291 ,  0.64508545, -0.10832689,  0.474749  ,  0.359758  ],\n",
       "        [ 2.3722506 , -2.3520858 , -2.6424727 , -2.4521596 ,  1.8747305 ,\n",
       "         -1.9874849 , -2.004691  , -2.4658074 , -1.7253743 , -1.722703  ]],\n",
       "       dtype=float32),\n",
       " array([ 1.787763 , -1.7669315, -1.7700292, -1.9217261,  1.8647599,\n",
       "        -1.9094821, -1.785816 , -1.8582963, -1.7628298, -1.851053 ],\n",
       "       dtype=float32),\n",
       " array([[ 2.2058802],\n",
       "        [-2.2226121],\n",
       "        [-2.11011  ],\n",
       "        [-1.6164569],\n",
       "        [ 1.7164854],\n",
       "        [-1.5615175],\n",
       "        [-1.9088793],\n",
       "        [-1.6860768],\n",
       "        [-2.1047711],\n",
       "        [-1.6222862]], dtype=float32),\n",
       " array([1.8010545], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_adam_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 170us/step - loss: 15318.1787 - val_loss: 14838.3338\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13544.0087 - val_loss: 11064.2942\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 5787.1467 - val_loss: 416.2895\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 104.0594 - val_loss: 40.6306\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 32.6991 - val_loss: 30.6646\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 28.0878 - val_loss: 27.6313\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 25.7885 - val_loss: 26.4528\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 24.4678 - val_loss: 25.6734\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.7677 - val_loss: 25.3530\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.3740 - val_loss: 25.2008\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1291 - val_loss: 25.1709\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.8166 - val_loss: 25.1703\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.6349 - val_loss: 25.2340\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5083 - val_loss: 25.1021\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.3224 - val_loss: 25.2590\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.2326 - val_loss: 25.1728\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.0579 - val_loss: 25.2050\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.9565 - val_loss: 25.1587\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.8791 - val_loss: 25.2173\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.7613 - val_loss: 25.1577\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.6850 - val_loss: 25.1278\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.5939 - val_loss: 25.2332\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5186 - val_loss: 25.2742\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 21.4784 - val_loss: 25.2714\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 21.3860 - val_loss: 25.2766\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 59us/step - loss: 21.3029 - val_loss: 25.1793\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.2241 - val_loss: 25.2286\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 21.1764 - val_loss: 25.2189\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.0844 - val_loss: 25.2004\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 21.0669 - val_loss: 25.2099\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 21.1016 - val_loss: 25.1364\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.9364 - val_loss: 25.2197\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.9062 - val_loss: 25.1689\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.8196 - val_loss: 25.2113\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.7793 - val_loss: 25.1737\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.7043 - val_loss: 25.1984\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.6831 - val_loss: 25.1429\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.6069 - val_loss: 25.1611\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.5479 - val_loss: 25.1599\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.5097 - val_loss: 25.1417\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.4839 - val_loss: 25.1031\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.4742 - val_loss: 25.1918\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.3730 - val_loss: 25.1248\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.3353 - val_loss: 25.0911\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.2984 - val_loss: 25.0769\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 20.2437 - val_loss: 25.1352\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.2327 - val_loss: 25.0886\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 20.1739 - val_loss: 25.0718\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 20.1522 - val_loss: 25.0589\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.1093 - val_loss: 25.0920\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.0496 - val_loss: 25.0221\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.0277 - val_loss: 25.0423\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.0068 - val_loss: 25.0751\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.9659 - val_loss: 25.0370\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.9513 - val_loss: 25.0161\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.9175 - val_loss: 25.0137\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.8425 - val_loss: 25.0453\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.8455 - val_loss: 24.9717\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.8402 - val_loss: 24.9930\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.7975 - val_loss: 25.0065\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.7585 - val_loss: 24.9703\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.7150 - val_loss: 25.0077\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.7175 - val_loss: 24.9559\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.7184 - val_loss: 24.9763\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.6616 - val_loss: 24.9497\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.6305 - val_loss: 24.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.5915 - val_loss: 24.9366\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.6102 - val_loss: 24.9570\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.5702 - val_loss: 24.9421\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.5492 - val_loss: 24.9398\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.5554 - val_loss: 24.9449\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.5084 - val_loss: 24.9121\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.4932 - val_loss: 24.8918\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.4898 - val_loss: 24.9510\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.4643 - val_loss: 24.8655\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.4797 - val_loss: 24.8722\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.4389 - val_loss: 24.8579\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.4101 - val_loss: 24.8987\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.4121 - val_loss: 24.8375\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.3939 - val_loss: 24.9084\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.3655 - val_loss: 24.8206\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.3876 - val_loss: 24.8769\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.3639 - val_loss: 24.8312\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.3376 - val_loss: 24.8288\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.3095 - val_loss: 24.8386\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.3094 - val_loss: 24.8362\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.2729 - val_loss: 24.8029\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 19.2947 - val_loss: 24.8088\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.2575 - val_loss: 24.8815\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.2462 - val_loss: 24.7929\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.2437 - val_loss: 24.7734\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.2082 - val_loss: 24.8118\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.2267 - val_loss: 24.7681\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.2097 - val_loss: 24.7992\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.1951 - val_loss: 24.8023\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.1791 - val_loss: 24.7657\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 19.1838 - val_loss: 24.7396\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.1611 - val_loss: 24.7296\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.1484 - val_loss: 24.7730\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.1426 - val_loss: 24.7644\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.1533 - val_loss: 24.7380\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.1368 - val_loss: 24.7213\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.1505 - val_loss: 24.6920\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.1336 - val_loss: 24.7260\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.1255 - val_loss: 24.7015\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.0859 - val_loss: 24.6881\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0820 - val_loss: 24.7039\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 19.0773 - val_loss: 24.6935\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.0731 - val_loss: 24.6955\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.0560 - val_loss: 24.6609\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0458 - val_loss: 24.6787\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.0616 - val_loss: 24.6888\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0255 - val_loss: 24.6529\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0590 - val_loss: 24.6396\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0004 - val_loss: 24.6660\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.0040 - val_loss: 24.6377\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9882 - val_loss: 24.6256\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.9969 - val_loss: 24.6120\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.9861 - val_loss: 24.6401\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.9974 - val_loss: 24.5837\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.9720 - val_loss: 24.5751\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.9600 - val_loss: 24.5927\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.9641 - val_loss: 24.5709\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.9411 - val_loss: 24.6302\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.9674 - val_loss: 24.5724\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9526 - val_loss: 24.5692\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.9242 - val_loss: 24.5370\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.9269 - val_loss: 24.6084\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.9385 - val_loss: 24.5293\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9136 - val_loss: 24.5310\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.8962 - val_loss: 24.5147\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.8955 - val_loss: 24.5149\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.9102 - val_loss: 24.4968\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.8859 - val_loss: 24.5150\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.8774 - val_loss: 24.4996\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8645 - val_loss: 24.4410\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.8987 - val_loss: 24.4573\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.8666 - val_loss: 24.4839\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.8678 - val_loss: 24.4414\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.8648 - val_loss: 24.4279\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.8566 - val_loss: 24.4379\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.8367 - val_loss: 24.4887\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.8445 - val_loss: 24.4102\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.8124 - val_loss: 24.4319\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8241 - val_loss: 24.4240\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8166 - val_loss: 24.3660\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.8027 - val_loss: 24.3788\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.8045 - val_loss: 24.3682\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8113 - val_loss: 24.4120\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.7693 - val_loss: 24.3425\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.8080 - val_loss: 24.3401\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.7678 - val_loss: 24.3289\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.7576 - val_loss: 24.3118\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.7895 - val_loss: 24.2969\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7931 - val_loss: 24.2915\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7280 - val_loss: 24.3192\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.7106 - val_loss: 24.2705\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.7222 - val_loss: 24.2663\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.7059 - val_loss: 24.2598\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.7027 - val_loss: 24.2799\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7025 - val_loss: 24.2436\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.7046 - val_loss: 24.2286\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7221 - val_loss: 24.2273\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.6816 - val_loss: 24.2107\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.6757 - val_loss: 24.1839\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.6555 - val_loss: 24.1776\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.6736 - val_loss: 24.2190\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.6697 - val_loss: 24.2140\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6397 - val_loss: 24.1506\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6460 - val_loss: 24.1800\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6109 - val_loss: 24.1437\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6524 - val_loss: 24.0831\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6560 - val_loss: 24.1095\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.5974 - val_loss: 24.1079\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6077 - val_loss: 24.0677\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.5991 - val_loss: 24.0869\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6434 - val_loss: 24.1007\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6044 - val_loss: 24.0349\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5801 - val_loss: 24.0012\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.5575 - val_loss: 24.0326\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.5624 - val_loss: 24.0446\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.5490 - val_loss: 23.9913\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.5431 - val_loss: 23.9758\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5655 - val_loss: 23.9909\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 18.5358 - val_loss: 23.9695\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.5335 - val_loss: 23.9229\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.5067 - val_loss: 23.9438\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5180 - val_loss: 23.9029\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5268 - val_loss: 23.8849\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.4981 - val_loss: 23.8966\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.5031 - val_loss: 23.8566\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4760 - val_loss: 23.8506\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.4627 - val_loss: 23.8427\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.4626 - val_loss: 23.8186\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.4729 - val_loss: 23.8158\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 18.4347 - val_loss: 23.8252\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.4210 - val_loss: 23.7982\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4853 - val_loss: 23.7481\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.4267 - val_loss: 23.7545\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.4478 - val_loss: 23.7513\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.3886 - val_loss: 23.7477\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3837 - val_loss: 23.7299\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.3782 - val_loss: 23.7117\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.3791 - val_loss: 23.7114\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3784 - val_loss: 23.6937\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.3725 - val_loss: 23.6608\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.3370 - val_loss: 23.6324\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.3427 - val_loss: 23.6289\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.3277 - val_loss: 23.6317\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.3270 - val_loss: 23.5936\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.3145 - val_loss: 23.5893\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.2983 - val_loss: 23.5488\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.2832 - val_loss: 23.5321\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.2983 - val_loss: 23.5609\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.2773 - val_loss: 23.5425\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2662 - val_loss: 23.4874\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.2601 - val_loss: 23.4706\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.2691 - val_loss: 23.4824\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2561 - val_loss: 23.4661\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.2429 - val_loss: 23.4415\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2315 - val_loss: 23.4007\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2267 - val_loss: 23.4034\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.2181 - val_loss: 23.3982\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.2068 - val_loss: 23.3794\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.1926 - val_loss: 23.3361\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.2006 - val_loss: 23.3312\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.1879 - val_loss: 23.3483\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.1639 - val_loss: 23.2953\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.1645 - val_loss: 23.2589\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.1405 - val_loss: 23.2608\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1790 - val_loss: 23.2464\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.1272 - val_loss: 23.2348\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.1550 - val_loss: 23.2146\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.1277 - val_loss: 23.1701\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1072 - val_loss: 23.1644\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0922 - val_loss: 23.1379\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.1036 - val_loss: 23.1144\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1034 - val_loss: 23.1049\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.0435 - val_loss: 23.0678\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0532 - val_loss: 23.0709\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.0411 - val_loss: 23.0520\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.0213 - val_loss: 23.0026\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0359 - val_loss: 22.9945\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0067 - val_loss: 22.9688\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.9985 - val_loss: 22.9527\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.0052 - val_loss: 22.9102\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.9823 - val_loss: 22.9041\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.9693 - val_loss: 22.9284\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.9872 - val_loss: 22.8666\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.9600 - val_loss: 22.8929\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9368 - val_loss: 22.8488\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.9234 - val_loss: 22.8071\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.9239 - val_loss: 22.7969\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.8938 - val_loss: 22.7603\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.9169 - val_loss: 22.7142\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.9009 - val_loss: 22.7303\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.8754 - val_loss: 22.6848\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8622 - val_loss: 22.6909\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.8573 - val_loss: 22.6565\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8453 - val_loss: 22.6221\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8382 - val_loss: 22.6497\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.8319 - val_loss: 22.5314\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.7923 - val_loss: 22.5921\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.7942 - val_loss: 22.5343\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.7967 - val_loss: 22.5106\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.7791 - val_loss: 22.5152\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.7772 - val_loss: 22.4367\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.7518 - val_loss: 22.4687\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.7499 - val_loss: 22.4044\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.7453 - val_loss: 22.3820\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.7180 - val_loss: 22.3688\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.7053 - val_loss: 22.3763\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6854 - val_loss: 22.3125\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6972 - val_loss: 22.3325\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6830 - val_loss: 22.2756\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.6452 - val_loss: 22.2343\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.6384 - val_loss: 22.2246\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.6383 - val_loss: 22.2154\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.6385 - val_loss: 22.1802\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.6137 - val_loss: 22.1683\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6401 - val_loss: 22.1395\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5925 - val_loss: 22.1258\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5808 - val_loss: 22.0945\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5601 - val_loss: 22.0852\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5520 - val_loss: 22.0536\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5521 - val_loss: 21.9915\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5540 - val_loss: 21.9828\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5205 - val_loss: 21.9812\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5371 - val_loss: 21.9222\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.4994 - val_loss: 21.9209\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.4765 - val_loss: 21.8947\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4760 - val_loss: 21.9124\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.4646 - val_loss: 21.8323\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 17.4565 - val_loss: 21.8410\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.4231 - val_loss: 21.7819\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.4457 - val_loss: 21.7668\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 16.92 - 0s 71us/step - loss: 17.4331 - val_loss: 21.7576\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.3985 - val_loss: 21.7669\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.3957 - val_loss: 21.7262\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.3824 - val_loss: 21.6869\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.3775 - val_loss: 21.7226\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.3842 - val_loss: 21.6590\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.3623 - val_loss: 21.6431\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.3431 - val_loss: 21.6010\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3263 - val_loss: 21.5496\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.3414 - val_loss: 21.5402\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.3068 - val_loss: 21.5355\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2806 - val_loss: 21.5204\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.2849 - val_loss: 21.4523\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.2561 - val_loss: 21.4611\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2714 - val_loss: 21.4398\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.2614 - val_loss: 21.4319\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.2404 - val_loss: 21.3849\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.2158 - val_loss: 21.3879\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.2086 - val_loss: 21.3677\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.1977 - val_loss: 21.3596\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.1901 - val_loss: 21.3124\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.1785 - val_loss: 21.2665\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.1727 - val_loss: 21.2783\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.1715 - val_loss: 21.2264\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1524 - val_loss: 21.1985\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.1337 - val_loss: 21.2088\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1199 - val_loss: 21.1762\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.1485 - val_loss: 21.1545\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1369 - val_loss: 21.1341\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.0938 - val_loss: 21.1180\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.0847 - val_loss: 21.1041\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.0745 - val_loss: 21.0830\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.0548 - val_loss: 21.0520\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.0470 - val_loss: 21.0240\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.0809 - val_loss: 21.0140\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.0312 - val_loss: 20.9800\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.0400 - val_loss: 20.9591\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.0169 - val_loss: 20.9666\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9987 - val_loss: 20.9389\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.9931 - val_loss: 20.9171\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.9830 - val_loss: 20.9286\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9959 - val_loss: 20.8834\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.9814 - val_loss: 20.8335\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9591 - val_loss: 20.8597\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9402 - val_loss: 20.8065\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.9273 - val_loss: 20.8029\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.9295 - val_loss: 20.7758\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9175 - val_loss: 20.7713\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9422 - val_loss: 20.7413\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.8990 - val_loss: 20.7458\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.9224 - val_loss: 20.6818\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.9039 - val_loss: 20.7000\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.9036 - val_loss: 20.6392\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.8716 - val_loss: 20.6783\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.8616 - val_loss: 20.6693\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.8742 - val_loss: 20.6571\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.8876 - val_loss: 20.6330\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.8299 - val_loss: 20.6107\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.8343 - val_loss: 20.5978\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.8242 - val_loss: 20.5870\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.8250 - val_loss: 20.5174\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.8256 - val_loss: 20.5369\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7910 - val_loss: 20.5666\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 16.7814 - val_loss: 20.5083\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7905 - val_loss: 20.4803\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7787 - val_loss: 20.4780\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.7656 - val_loss: 20.5178\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7725 - val_loss: 20.4340\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7644 - val_loss: 20.4324\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7337 - val_loss: 20.4087\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.7329 - val_loss: 20.3622\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7174 - val_loss: 20.3890\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.7286 - val_loss: 20.3343\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7152 - val_loss: 20.3582\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7257 - val_loss: 20.3162\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7134 - val_loss: 20.3207\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6871 - val_loss: 20.3280\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6874 - val_loss: 20.2630\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.7035 - val_loss: 20.3001\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.6871 - val_loss: 20.2719\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6477 - val_loss: 20.2401\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.6773 - val_loss: 20.2623\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6467 - val_loss: 20.2363\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 16.6525 - val_loss: 20.2679\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6355 - val_loss: 20.1970\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.6246 - val_loss: 20.2184\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.6250 - val_loss: 20.1695\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6153 - val_loss: 20.1835\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.5933 - val_loss: 20.1599\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5947 - val_loss: 20.1392\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5865 - val_loss: 20.1524\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5838 - val_loss: 20.0964\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.5913 - val_loss: 20.0922\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.5793 - val_loss: 20.0747\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5745 - val_loss: 20.0534\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5727 - val_loss: 20.0530\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5528 - val_loss: 20.0505\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5318 - val_loss: 20.0440\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.5430 - val_loss: 20.0753\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5343 - val_loss: 20.0180\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5337 - val_loss: 20.0325\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5545 - val_loss: 19.9502\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5241 - val_loss: 19.9761\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5172 - val_loss: 19.9616\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5437 - val_loss: 19.9897\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.5209 - val_loss: 19.9189\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.5088 - val_loss: 19.9626\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4857 - val_loss: 19.9399\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.5143 - val_loss: 19.8890\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5015 - val_loss: 19.9081\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.4832 - val_loss: 19.8698\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.4646 - val_loss: 19.8991\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.4702 - val_loss: 19.9370\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4430 - val_loss: 19.8391\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4550 - val_loss: 19.8806\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.4419 - val_loss: 19.8478\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4247 - val_loss: 19.7984\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4383 - val_loss: 19.8347\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4326 - val_loss: 19.8076\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.4276 - val_loss: 19.8041\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.4132 - val_loss: 19.8472\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4068 - val_loss: 19.8130\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.4070 - val_loss: 19.7880\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4054 - val_loss: 19.7570\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3902 - val_loss: 19.7886\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.3864 - val_loss: 19.7567\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.3927 - val_loss: 19.7300\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.3896 - val_loss: 19.7137\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.3783 - val_loss: 19.6935\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.3602 - val_loss: 19.7073\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.3852 - val_loss: 19.6957\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.3725 - val_loss: 19.7030\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.3443 - val_loss: 19.6744\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3722 - val_loss: 19.6584\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3493 - val_loss: 19.6845\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.3263 - val_loss: 19.6540\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3412 - val_loss: 19.6289\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3440 - val_loss: 19.6305\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.3289 - val_loss: 19.6191\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.3223 - val_loss: 19.6392\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.3237 - val_loss: 19.6321\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.3076 - val_loss: 19.5845\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.2977 - val_loss: 19.5936\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2951 - val_loss: 19.5768\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.2951 - val_loss: 19.5591\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2785 - val_loss: 19.5887\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2761 - val_loss: 19.5602\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2699 - val_loss: 19.5516\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2755 - val_loss: 19.5645\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.2623 - val_loss: 19.5000\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.2744 - val_loss: 19.5137\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2553 - val_loss: 19.5407\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.2488 - val_loss: 19.5248\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2808 - val_loss: 19.4811\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.2517 - val_loss: 19.5082\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2445 - val_loss: 19.5395\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2521 - val_loss: 19.4627\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.2505 - val_loss: 19.4637\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2458 - val_loss: 19.4486\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2201 - val_loss: 19.4254\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2245 - val_loss: 19.4748\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.2171 - val_loss: 19.4283\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.2086 - val_loss: 19.4260\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2041 - val_loss: 19.4501\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.2170 - val_loss: 19.4332\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.2098 - val_loss: 19.3655\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1935 - val_loss: 19.4207\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1942 - val_loss: 19.4064\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.1886 - val_loss: 19.3822\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.1866 - val_loss: 19.3978\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.1709 - val_loss: 19.3900\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1946 - val_loss: 19.3367\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.1632 - val_loss: 19.3583\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.1821 - val_loss: 19.3719\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1550 - val_loss: 19.2907\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1541 - val_loss: 19.3256\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 16.1461 - val_loss: 19.3399\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1423 - val_loss: 19.3087\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1534 - val_loss: 19.3109\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.1301 - val_loss: 19.3088\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1364 - val_loss: 19.3104\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1370 - val_loss: 19.2905\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.1510 - val_loss: 19.3128\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.1176 - val_loss: 19.2546\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1270 - val_loss: 19.2189\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1296 - val_loss: 19.2896\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1097 - val_loss: 19.2323\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1082 - val_loss: 19.2516\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1016 - val_loss: 19.2237\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1005 - val_loss: 19.2574\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.1039 - val_loss: 19.2047\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0961 - val_loss: 19.1980\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0853 - val_loss: 19.2312\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1089 - val_loss: 19.2171\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0840 - val_loss: 19.2302\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.0898 - val_loss: 19.1929\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.0836 - val_loss: 19.1833\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.0666 - val_loss: 19.1789\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0766 - val_loss: 19.1495\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.0542 - val_loss: 19.1591\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.0560 - val_loss: 19.1681\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.0532 - val_loss: 19.1688\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.0659 - val_loss: 19.1259\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.0476 - val_loss: 19.1192\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0330 - val_loss: 19.1471\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.0425 - val_loss: 19.1302\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.0314 - val_loss: 19.1186\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.0276 - val_loss: 19.0968\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0255 - val_loss: 19.0957\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0189 - val_loss: 19.1175\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0223 - val_loss: 19.0700\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.0175 - val_loss: 19.0931\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.0213 - val_loss: 19.0713\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0072 - val_loss: 19.0859\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.0165 - val_loss: 19.0929\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 16.0001 - val_loss: 19.0973\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.0003 - val_loss: 19.1098\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.9926 - val_loss: 19.0708\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9935 - val_loss: 19.0307\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9881 - val_loss: 19.0655\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9830 - val_loss: 19.0307\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9997 - val_loss: 19.0635\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9814 - val_loss: 19.0156\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9791 - val_loss: 19.0250\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.9750 - val_loss: 19.0095\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.9567 - val_loss: 19.0130\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.9652 - val_loss: 19.0071\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9528 - val_loss: 19.0031\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9432 - val_loss: 18.9930\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9713 - val_loss: 19.0189\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9521 - val_loss: 18.9703\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.9483 - val_loss: 18.9924\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.9413 - val_loss: 18.9575\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9374 - val_loss: 18.9254\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.9376 - val_loss: 18.9684\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9294 - val_loss: 18.9375\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.9304 - val_loss: 18.9815\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.9227 - val_loss: 18.9406\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9178 - val_loss: 18.9227\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.9141 - val_loss: 18.9305\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.9226 - val_loss: 18.8923\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.9266 - val_loss: 18.9416\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.9113 - val_loss: 18.8925\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.9011 - val_loss: 18.9011\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.9004 - val_loss: 18.9422\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8839 - val_loss: 18.8867\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8911 - val_loss: 18.8780\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 62us/step - loss: 15.8972 - val_loss: 18.8786\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8722 - val_loss: 18.8442\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8733 - val_loss: 18.8671\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8748 - val_loss: 18.8655\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8923 - val_loss: 18.9296\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8681 - val_loss: 18.8464\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8650 - val_loss: 18.8135\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8783 - val_loss: 18.8678\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.8681 - val_loss: 18.8038\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8788 - val_loss: 18.7759\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8586 - val_loss: 18.8705\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8559 - val_loss: 18.8392\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8466 - val_loss: 18.8470\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8383 - val_loss: 18.8443\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8534 - val_loss: 18.8420\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8334 - val_loss: 18.7982\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8332 - val_loss: 18.7903\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8571 - val_loss: 18.8340\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.8437 - val_loss: 18.8090\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.8286 - val_loss: 18.7822\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8209 - val_loss: 18.7798\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8133 - val_loss: 18.7454\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8259 - val_loss: 18.7867\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8416 - val_loss: 18.7603\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8188 - val_loss: 18.7809\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8037 - val_loss: 18.7683\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.7987 - val_loss: 18.7560\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8004 - val_loss: 18.7757\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8056 - val_loss: 18.7391\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.7964 - val_loss: 18.7425\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.8012 - val_loss: 18.7363\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7833 - val_loss: 18.7135\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.7846 - val_loss: 18.7264\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.7769 - val_loss: 18.7412\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7803 - val_loss: 18.7269\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.7808 - val_loss: 18.7408\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.8159 - val_loss: 18.6780\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7986 - val_loss: 18.7178\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7614 - val_loss: 18.6813\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7681 - val_loss: 18.6784\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.7484 - val_loss: 18.7081\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.7648 - val_loss: 18.6973\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7577 - val_loss: 18.7025\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7506 - val_loss: 18.6555\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7447 - val_loss: 18.6872\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7400 - val_loss: 18.6677\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7547 - val_loss: 18.6688\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7476 - val_loss: 18.6950\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7378 - val_loss: 18.6338\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7407 - val_loss: 18.6242\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7436 - val_loss: 18.6629\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7300 - val_loss: 18.6458\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7255 - val_loss: 18.6254\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7141 - val_loss: 18.6407\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7155 - val_loss: 18.6330\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.7118 - val_loss: 18.6306\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7015 - val_loss: 18.6277\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.7396 - val_loss: 18.6070\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7063 - val_loss: 18.6635\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6905 - val_loss: 18.6152\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.6988 - val_loss: 18.5776\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.7028 - val_loss: 18.5891\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6913 - val_loss: 18.6037\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.6917 - val_loss: 18.5667\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6788 - val_loss: 18.5862\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.6824 - val_loss: 18.5864\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.6868 - val_loss: 18.5880\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6670 - val_loss: 18.5467\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.6796 - val_loss: 18.5591\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6860 - val_loss: 18.5620\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6662 - val_loss: 18.5950\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6700 - val_loss: 18.5564\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6527 - val_loss: 18.5415\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6729 - val_loss: 18.5157\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.6623 - val_loss: 18.5338\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6547 - val_loss: 18.5772\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6661 - val_loss: 18.5572\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 15.89 - 0s 73us/step - loss: 15.6681 - val_loss: 18.5452\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6491 - val_loss: 18.5550\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6487 - val_loss: 18.5239\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.6378 - val_loss: 18.5282\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6424 - val_loss: 18.5077\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6378 - val_loss: 18.5005\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6525 - val_loss: 18.4975\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6299 - val_loss: 18.4947\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6266 - val_loss: 18.4998\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6178 - val_loss: 18.4741\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6171 - val_loss: 18.4651\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.6180 - val_loss: 18.4611\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.6150 - val_loss: 18.4949\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6132 - val_loss: 18.5077\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.6037 - val_loss: 18.4777\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6204 - val_loss: 18.4622\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.6042 - val_loss: 18.4844\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6100 - val_loss: 18.4504\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.5918 - val_loss: 18.4208\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.5900 - val_loss: 18.4409\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6046 - val_loss: 18.4891\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.6035 - val_loss: 18.4202\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.5840 - val_loss: 18.4246\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.5755 - val_loss: 18.4481\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.5865 - val_loss: 18.4251\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.5742 - val_loss: 18.4430\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.5732 - val_loss: 18.4233\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5696 - val_loss: 18.3986\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5664 - val_loss: 18.4322\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5641 - val_loss: 18.4109\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5836 - val_loss: 18.4229\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5630 - val_loss: 18.3887\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.5652 - val_loss: 18.3944\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.5662 - val_loss: 18.3789\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.5535 - val_loss: 18.4024\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5510 - val_loss: 18.4157\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5461 - val_loss: 18.3723\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5391 - val_loss: 18.3563\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5427 - val_loss: 18.3354\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.5498 - val_loss: 18.3615\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5476 - val_loss: 18.3838\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.5312 - val_loss: 18.3602\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.5319 - val_loss: 18.3732\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5258 - val_loss: 18.3505\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5267 - val_loss: 18.3771\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.5367 - val_loss: 18.3214\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5250 - val_loss: 18.3490\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5162 - val_loss: 18.3572\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.5188 - val_loss: 18.3613\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.5203 - val_loss: 18.3213\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.5203 - val_loss: 18.3569\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.5158 - val_loss: 18.3077\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.5094 - val_loss: 18.3107\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.4931 - val_loss: 18.3613\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.5078 - val_loss: 18.3561\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5351 - val_loss: 18.3148\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.4878 - val_loss: 18.3248\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4988 - val_loss: 18.3017\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4887 - val_loss: 18.2853\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4872 - val_loss: 18.3030\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4845 - val_loss: 18.2915\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4818 - val_loss: 18.2658\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4843 - val_loss: 18.2742\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4791 - val_loss: 18.3066\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.4716 - val_loss: 18.2507\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4663 - val_loss: 18.2486\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.4628 - val_loss: 18.2713\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4832 - val_loss: 18.2648\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4555 - val_loss: 18.2664\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.4843 - val_loss: 18.2122\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.4465 - val_loss: 18.2936\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.4455 - val_loss: 18.2712\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4499 - val_loss: 18.2794\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4456 - val_loss: 18.2494\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4552 - val_loss: 18.2617\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 56us/step - loss: 15.4347 - val_loss: 18.2348\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4467 - val_loss: 18.2214\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4346 - val_loss: 18.2199\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.4588 - val_loss: 18.1817\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4263 - val_loss: 18.2730\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4492 - val_loss: 18.2257\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.4206 - val_loss: 18.2511\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4287 - val_loss: 18.2279\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4349 - val_loss: 18.2376\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4253 - val_loss: 18.2070\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4247 - val_loss: 18.2106\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4182 - val_loss: 18.2240\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4089 - val_loss: 18.2080\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.4171 - val_loss: 18.1916\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4064 - val_loss: 18.1676\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.4012 - val_loss: 18.2145\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4100 - val_loss: 18.2103\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4053 - val_loss: 18.1546\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3966 - val_loss: 18.1804\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4089 - val_loss: 18.1509\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3783 - val_loss: 18.2061\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3881 - val_loss: 18.1875\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3823 - val_loss: 18.1580\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3825 - val_loss: 18.1600\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3744 - val_loss: 18.1684\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3757 - val_loss: 18.1466\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3854 - val_loss: 18.1691\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 15.40 - 0s 74us/step - loss: 15.3750 - val_loss: 18.1436\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3650 - val_loss: 18.1415\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3662 - val_loss: 18.1524\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3629 - val_loss: 18.1445\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3608 - val_loss: 18.1467\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3647 - val_loss: 18.1410\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3661 - val_loss: 18.1320\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.3650 - val_loss: 18.1353\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3521 - val_loss: 18.1425\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3598 - val_loss: 18.1377\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3584 - val_loss: 18.1069\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3542 - val_loss: 18.1351\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.3410 - val_loss: 18.1034\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.3316 - val_loss: 18.1044\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3445 - val_loss: 18.1064\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3346 - val_loss: 18.0855\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3410 - val_loss: 18.1164\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3208 - val_loss: 18.0797\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.3270 - val_loss: 18.0770\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3183 - val_loss: 18.0799\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3183 - val_loss: 18.1147\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.3287 - val_loss: 18.0951\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.3161 - val_loss: 18.0628\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3166 - val_loss: 18.0980\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3052 - val_loss: 18.0676\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3099 - val_loss: 18.0666\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3084 - val_loss: 18.0789\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3269 - val_loss: 18.0172\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3068 - val_loss: 18.0574\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.2952 - val_loss: 18.1075\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.2950 - val_loss: 18.0657\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2966 - val_loss: 18.0354\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.2930 - val_loss: 18.0479\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2958 - val_loss: 18.0649\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2790 - val_loss: 18.0231\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2927 - val_loss: 18.0118\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2842 - val_loss: 18.0610\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2830 - val_loss: 18.0114\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.2757 - val_loss: 18.0258\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2915 - val_loss: 18.0188\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2736 - val_loss: 18.0074\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.2727 - val_loss: 18.0106\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2686 - val_loss: 18.0277\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2709 - val_loss: 17.9961\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2676 - val_loss: 18.0375\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2603 - val_loss: 18.0289\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2498 - val_loss: 17.9978\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2717 - val_loss: 17.9932\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2587 - val_loss: 18.0036\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2707 - val_loss: 17.9701\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2665 - val_loss: 18.0397\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2770 - val_loss: 17.9509\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.2638 - val_loss: 17.9888\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2406 - val_loss: 17.9742\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2450 - val_loss: 18.0018\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2502 - val_loss: 17.9654\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2674 - val_loss: 18.0189\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2291 - val_loss: 17.9457\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2333 - val_loss: 17.9638\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2278 - val_loss: 17.9643\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2363 - val_loss: 17.9594\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2441 - val_loss: 17.9530\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.2230 - val_loss: 18.0002\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2222 - val_loss: 17.9322\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2485 - val_loss: 17.9431\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2149 - val_loss: 17.9564\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2168 - val_loss: 17.9332\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2073 - val_loss: 17.9515\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2067 - val_loss: 17.9480\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2104 - val_loss: 17.9512\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2116 - val_loss: 17.9388\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2177 - val_loss: 17.9425\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.2123 - val_loss: 17.9117\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2135 - val_loss: 17.9659\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1884 - val_loss: 17.9060\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1998 - val_loss: 17.9236\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1904 - val_loss: 17.8882\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1964 - val_loss: 17.9036\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1888 - val_loss: 17.9267\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1851 - val_loss: 17.9307\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1768 - val_loss: 17.9045\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1848 - val_loss: 17.8983\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1871 - val_loss: 17.9211\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.1728 - val_loss: 17.9217\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1830 - val_loss: 17.8799\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1663 - val_loss: 17.8881\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1727 - val_loss: 17.8868\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1710 - val_loss: 17.8732\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1699 - val_loss: 17.8893\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1566 - val_loss: 17.8795\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1556 - val_loss: 17.8590\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1799 - val_loss: 17.8724\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1524 - val_loss: 17.8696\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.1563 - val_loss: 17.8733\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1406 - val_loss: 17.8673\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1452 - val_loss: 17.8779\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1397 - val_loss: 17.8702\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1438 - val_loss: 17.8379\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1344 - val_loss: 17.8667\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.1353 - val_loss: 17.8609\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1406 - val_loss: 17.8589\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1280 - val_loss: 17.8372\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1379 - val_loss: 17.8659\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1339 - val_loss: 17.8658\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1278 - val_loss: 17.8464\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1299 - val_loss: 17.8600\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1233 - val_loss: 17.8289\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.1239 - val_loss: 17.8270\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1180 - val_loss: 17.8224\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1098 - val_loss: 17.8538\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1154 - val_loss: 17.8376\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1223 - val_loss: 17.8250\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1185 - val_loss: 17.7899\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.1090 - val_loss: 17.8115\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1053 - val_loss: 17.8338\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.1243 - val_loss: 17.8010\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1061 - val_loss: 17.8121\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.0959 - val_loss: 17.8111\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1039 - val_loss: 17.8217\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0982 - val_loss: 17.7698\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0875 - val_loss: 17.8051\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0965 - val_loss: 17.8512\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0947 - val_loss: 17.8100\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.1015 - val_loss: 17.7869\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0807 - val_loss: 17.7675\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.0765 - val_loss: 17.7781\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.0763 - val_loss: 17.7855\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.0741 - val_loss: 17.7680\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.0818 - val_loss: 17.7882\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0731 - val_loss: 17.8229\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.0693 - val_loss: 17.7840\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0833 - val_loss: 17.7531\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.0658 - val_loss: 17.7661\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0604 - val_loss: 17.7613\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.0611 - val_loss: 17.7795\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.0625 - val_loss: 17.7846\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0652 - val_loss: 17.7806\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0573 - val_loss: 17.7619\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.0577 - val_loss: 17.7362\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.0529 - val_loss: 17.7729\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0453 - val_loss: 17.7458\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0480 - val_loss: 17.7401\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0514 - val_loss: 17.7402\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0460 - val_loss: 17.7385\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0445 - val_loss: 17.7404\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0384 - val_loss: 17.7578\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0536 - val_loss: 17.7319\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0280 - val_loss: 17.7328\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0355 - val_loss: 17.7151\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0606 - val_loss: 17.7291\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0435 - val_loss: 17.7186\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.0252 - val_loss: 17.6787\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.0293 - val_loss: 17.7123\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0181 - val_loss: 17.7190\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0208 - val_loss: 17.7058\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0114 - val_loss: 17.7277\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0079 - val_loss: 17.6927\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0072 - val_loss: 17.7075\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0085 - val_loss: 17.7104\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0090 - val_loss: 17.7010\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0138 - val_loss: 17.6861\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0000 - val_loss: 17.7121\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.0128 - val_loss: 17.7228\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0144 - val_loss: 17.7073\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9981 - val_loss: 17.6764\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9912 - val_loss: 17.7303\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.0048 - val_loss: 17.6847\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9834 - val_loss: 17.6860\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9978 - val_loss: 17.6920\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9917 - val_loss: 17.6613\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9942 - val_loss: 17.6914\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.9919 - val_loss: 17.6961\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9800 - val_loss: 17.6623\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9769 - val_loss: 17.6747\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9993 - val_loss: 17.6554\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9739 - val_loss: 17.6546\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.9738 - val_loss: 17.6704\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9683 - val_loss: 17.6519\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9687 - val_loss: 17.6553\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9727 - val_loss: 17.6822\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9788 - val_loss: 17.6447\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9653 - val_loss: 17.6285\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9633 - val_loss: 17.6595\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9663 - val_loss: 17.6460\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9676 - val_loss: 17.6678\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9603 - val_loss: 17.6014\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9584 - val_loss: 17.6345\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9481 - val_loss: 17.6461\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9480 - val_loss: 17.6492\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9500 - val_loss: 17.6548\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9600 - val_loss: 17.6627\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9551 - val_loss: 17.5896\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9474 - val_loss: 17.6187\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9353 - val_loss: 17.6376\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9360 - val_loss: 17.6268\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.9368 - val_loss: 17.6023\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.9412 - val_loss: 17.6136\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9313 - val_loss: 17.6088\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9390 - val_loss: 17.6293\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9268 - val_loss: 17.5879\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9316 - val_loss: 17.5954\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9289 - val_loss: 17.6261\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9227 - val_loss: 17.6136\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9278 - val_loss: 17.6008\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9266 - val_loss: 17.6288\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9083 - val_loss: 17.5677\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9267 - val_loss: 17.6086\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9115 - val_loss: 17.5769\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9078 - val_loss: 17.5830\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9112 - val_loss: 17.5605\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.9111 - val_loss: 17.6070\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9082 - val_loss: 17.5887\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9023 - val_loss: 17.5785\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9080 - val_loss: 17.5776\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8996 - val_loss: 17.5861\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8886 - val_loss: 17.5659\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9021 - val_loss: 17.5931\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9074 - val_loss: 17.5668\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9050 - val_loss: 17.5660\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8877 - val_loss: 17.5928\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 15.59 - 0s 75us/step - loss: 14.8841 - val_loss: 17.5625\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8895 - val_loss: 17.5617\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8976 - val_loss: 17.5340\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8894 - val_loss: 17.5899\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8932 - val_loss: 17.5706\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8803 - val_loss: 17.5289\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8711 - val_loss: 17.5483\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8761 - val_loss: 17.5459\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8797 - val_loss: 17.5516\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.8688 - val_loss: 17.5597\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8652 - val_loss: 17.5480\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8620 - val_loss: 17.5721\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.8639 - val_loss: 17.5582\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8641 - val_loss: 17.5284\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8584 - val_loss: 17.5335\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8650 - val_loss: 17.5470\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8609 - val_loss: 17.5143\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.8466 - val_loss: 17.5276\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.8541 - val_loss: 17.5646\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8453 - val_loss: 17.5195\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8477 - val_loss: 17.5453\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8428 - val_loss: 17.5247\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.8473 - val_loss: 17.4930\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8611 - val_loss: 17.5179\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8436 - val_loss: 17.5201\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8404 - val_loss: 17.4933\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8428 - val_loss: 17.5505\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8407 - val_loss: 17.4983\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8403 - val_loss: 17.5064\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8399 - val_loss: 17.5130\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8335 - val_loss: 17.5283\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.8271 - val_loss: 17.4926\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8357 - val_loss: 17.4972\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8382 - val_loss: 17.5206\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8189 - val_loss: 17.4966\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8208 - val_loss: 17.4657\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8288 - val_loss: 17.5093\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8206 - val_loss: 17.4890\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8291 - val_loss: 17.4620\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8341 - val_loss: 17.4790\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8247 - val_loss: 17.4962\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8066 - val_loss: 17.4705\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8085 - val_loss: 17.4976\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8065 - val_loss: 17.4698\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7963 - val_loss: 17.4671\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8120 - val_loss: 17.5045\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8056 - val_loss: 17.4692\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8080 - val_loss: 17.4903\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7971 - val_loss: 17.4718\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7965 - val_loss: 17.4317\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8024 - val_loss: 17.4586\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8092 - val_loss: 17.4854\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7969 - val_loss: 17.4505\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.8014 - val_loss: 17.4209\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8041 - val_loss: 17.4574\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7841 - val_loss: 17.4499\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.7868 - val_loss: 17.4810\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7898 - val_loss: 17.4642\n",
      "14.97518864775126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.6106284 ,  0.06515915,  0.14764558, -0.02365688,  0.8669707 ],\n",
       "        [ 1.0868931 ,  0.13901785, -0.00301819, -0.02235291,  0.15329546],\n",
       "        [ 0.44952208,  0.15943629,  0.2522569 ,  0.12513375,  0.2537208 ],\n",
       "        [-0.10319894,  0.18265331, -0.13179001,  0.01784311, -0.03227387],\n",
       "        [-0.1455861 ,  0.01175106,  0.2629915 , -0.01273644,  0.47124058]],\n",
       "       dtype=float32),\n",
       " array([ 0.19633093, -1.9195906 , -0.6959626 , -2.2038178 ,  1.2749046 ],\n",
       "       dtype=float32),\n",
       " array([[-0.41821557,  0.01642537,  0.41227722,  0.9299322 , -0.30698398,\n",
       "         -0.646844  ,  0.2780088 , -0.34349254, -0.14153719,  0.1007202 ],\n",
       "        [-0.35933125,  1.1492908 ,  1.3593154 ,  1.5676874 , -0.34274447,\n",
       "         -1.0212884 ,  0.8116155 , -1.0162488 , -0.07069721,  0.07800708],\n",
       "        [-0.71646273,  0.67466563,  0.86960447,  1.4206023 ,  0.14678685,\n",
       "         -1.1435691 ,  0.69368273, -0.7574048 , -0.22103702,  0.51806355],\n",
       "        [ 0.08872592,  1.6197145 ,  1.6694177 ,  2.2376664 ,  0.4885044 ,\n",
       "         -1.1408836 ,  1.7758716 , -1.4484102 ,  0.7521822 ,  1.3941323 ],\n",
       "        [-0.04154044, -0.52848274, -1.148923  , -1.154592  , -0.41188374,\n",
       "          0.9521746 , -0.92464304,  0.5700485 , -0.3337204 ,  0.18192735]],\n",
       "       dtype=float32),\n",
       " array([ 0.28406957, -2.2075696 , -2.2967253 , -2.7448947 , -0.7614567 ,\n",
       "         1.6078292 , -2.1051865 ,  1.1575055 , -0.5062611 , -1.278451  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5021728 ],\n",
       "        [-3.0312092 ],\n",
       "        [-3.4634113 ],\n",
       "        [-4.3365393 ],\n",
       "        [-0.776144  ],\n",
       "        [ 2.664397  ],\n",
       "        [-3.079487  ],\n",
       "        [ 2.2521517 ],\n",
       "        [-0.71659213],\n",
       "        [-1.699211  ]], dtype=float32),\n",
       " array([2.0400085], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, sgd, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sgd_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 179us/step - loss: 14235.5665 - val_loss: 11903.3872\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8729.5507 - val_loss: 5157.4848\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 2598.2095 - val_loss: 660.0799\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 170.6294 - val_loss: 27.6883\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.1689 - val_loss: 26.6126\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.8154 - val_loss: 27.8974\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 24.6234 - val_loss: 27.4644\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.6559 - val_loss: 29.7605\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.6582 - val_loss: 26.4123\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.7064 - val_loss: 28.0311\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.2109 - val_loss: 27.0175\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.4828 - val_loss: 27.9241\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.0469 - val_loss: 27.1059\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.7190 - val_loss: 28.4088\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.8004 - val_loss: 27.3150\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 24.0018 - val_loss: 25.5736\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.3371 - val_loss: 26.9636\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.1106 - val_loss: 35.5976\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.9877 - val_loss: 26.9876\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.5128 - val_loss: 28.5244\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.2679 - val_loss: 26.8410\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.6857 - val_loss: 26.7258\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.6019 - val_loss: 27.5007\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.7383 - val_loss: 26.1524\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.2665 - val_loss: 26.7480\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6169 - val_loss: 25.8606\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.4787 - val_loss: 29.4037\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.3236 - val_loss: 25.2968\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7101 - val_loss: 29.8393\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.7604 - val_loss: 25.5529\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.4441 - val_loss: 27.0402\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 24.5910 - val_loss: 26.8311\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.8275 - val_loss: 30.6903\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.2854 - val_loss: 26.7183\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.7322 - val_loss: 27.6462\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.9830 - val_loss: 26.7434\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.1066 - val_loss: 27.3935\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.4089 - val_loss: 31.6210\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.7266 - val_loss: 26.4349\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0559 - val_loss: 28.6796\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3102 - val_loss: 28.0852\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8179 - val_loss: 27.4322\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.5425 - val_loss: 32.5390\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.6037 - val_loss: 29.7391\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 24.0390 - val_loss: 25.3809\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.4159 - val_loss: 27.5695\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.1834 - val_loss: 28.1130\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.8963 - val_loss: 26.3246\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.8003 - val_loss: 26.4062\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.4089 - val_loss: 26.2088\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.3200 - val_loss: 27.2719\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.7200 - val_loss: 28.8145\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.8275 - val_loss: 29.1704\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.6785 - val_loss: 27.1388\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.1767 - val_loss: 30.7374\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.9651 - val_loss: 30.3486\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.5814 - val_loss: 25.2463\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.7340 - val_loss: 27.5440\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.9862 - val_loss: 25.3780\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.0743 - val_loss: 25.8593\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.4549 - val_loss: 25.4662\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3522 - val_loss: 25.6155\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.9354 - val_loss: 25.2177\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.2673 - val_loss: 25.2503\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.0716 - val_loss: 29.1623\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.7106 - val_loss: 27.3732\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.0712 - val_loss: 29.3447\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.7341 - val_loss: 25.3078\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.2344 - val_loss: 25.6408\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.6286 - val_loss: 24.3973\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.0779 - val_loss: 24.8684\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.1574 - val_loss: 25.1976\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 20.5294 - val_loss: 28.6937\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.2125 - val_loss: 23.6324\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 20.3960 - val_loss: 23.7130\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 19.8433 - val_loss: 25.3665\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.4039 - val_loss: 26.9123\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.3009 - val_loss: 24.9971\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.1676 - val_loss: 26.4061\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.5092 - val_loss: 22.7951\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.2476 - val_loss: 21.8574\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.9965 - val_loss: 24.3019\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.8822 - val_loss: 22.1616\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.5486 - val_loss: 20.6432\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.0362 - val_loss: 21.5207\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.8501 - val_loss: 19.9880\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.1856 - val_loss: 22.5372\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.9210 - val_loss: 23.0524\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.1198 - val_loss: 21.7591\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.7015 - val_loss: 19.0714\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.7217 - val_loss: 21.0234\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.8742 - val_loss: 18.9634\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.4768 - val_loss: 21.4837\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.7568 - val_loss: 19.8038\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.4971 - val_loss: 20.3323\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.4206 - val_loss: 20.9761\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.8689 - val_loss: 19.7197\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.9528 - val_loss: 21.1115\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.8062 - val_loss: 20.7244\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.1682 - val_loss: 18.5883\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.7572 - val_loss: 18.4343\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.7929 - val_loss: 18.8958\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.8260 - val_loss: 18.2626\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.4687 - val_loss: 20.7061\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7657 - val_loss: 19.5479\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.4994 - val_loss: 21.5507\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.7766 - val_loss: 20.4674\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.1837 - val_loss: 22.9233\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.5577 - val_loss: 19.1118\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.8386 - val_loss: 17.8450\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.3272 - val_loss: 24.9787\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.9754 - val_loss: 18.0305\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.4392 - val_loss: 20.3529\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.8243 - val_loss: 23.5823\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.9765 - val_loss: 17.9803\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.5046 - val_loss: 17.9929\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.5920 - val_loss: 17.5699\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.5736 - val_loss: 17.2378\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.5153 - val_loss: 18.9022\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.4169 - val_loss: 18.0605\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.7009 - val_loss: 17.6824\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.4938 - val_loss: 18.5042\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.1199 - val_loss: 17.6759\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.3801 - val_loss: 21.0322\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.5491 - val_loss: 17.9890\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5414 - val_loss: 17.9729\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.3424 - val_loss: 16.7219\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.7806 - val_loss: 16.7638\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.3210 - val_loss: 17.9956\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5804 - val_loss: 17.3627\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.4610 - val_loss: 18.9031\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4887 - val_loss: 17.6478\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.9663 - val_loss: 17.9121\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.4064 - val_loss: 17.8044\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.2078 - val_loss: 18.4539\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.9207 - val_loss: 17.4252\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.2105 - val_loss: 16.9575\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8419 - val_loss: 16.4354\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.0892 - val_loss: 22.2072\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.7987 - val_loss: 18.3196\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.0882 - val_loss: 20.6850\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.7531 - val_loss: 19.3287\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.1169 - val_loss: 16.2198\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.2059 - val_loss: 16.1376\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.0214 - val_loss: 16.5450\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.0577 - val_loss: 19.2735\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4671 - val_loss: 17.5173\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.8615 - val_loss: 16.3924\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3289 - val_loss: 17.9686\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.6191 - val_loss: 16.8296\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8097 - val_loss: 24.0225\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6927 - val_loss: 17.7212\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.3107 - val_loss: 17.8745\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.2816 - val_loss: 23.6220\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.5486 - val_loss: 16.5329\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.3908 - val_loss: 18.7877\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9328 - val_loss: 16.7149\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.8576 - val_loss: 16.1391\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.1103 - val_loss: 16.7006\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.1538 - val_loss: 16.7821\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.4288 - val_loss: 16.5951\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.3530 - val_loss: 16.2892\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2236 - val_loss: 16.0304\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.6121 - val_loss: 16.0383\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.9716 - val_loss: 17.2318\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.9673 - val_loss: 16.2595\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.9036 - val_loss: 18.5381\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.8800 - val_loss: 16.0440\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.3320 - val_loss: 16.2917\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6198 - val_loss: 15.3545\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.3978 - val_loss: 15.7146\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.8063 - val_loss: 17.3688\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.4224 - val_loss: 19.7777\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.7947 - val_loss: 15.8800\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.5663 - val_loss: 17.1243\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.4976 - val_loss: 15.9832\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.8877 - val_loss: 15.5989\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.7946 - val_loss: 14.8716\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.8048 - val_loss: 15.3616\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.1786 - val_loss: 18.1064\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9846 - val_loss: 17.0409\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.2246 - val_loss: 15.7048\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.2676 - val_loss: 15.8139\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.2820 - val_loss: 19.3600\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.7928 - val_loss: 15.1885\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.2617 - val_loss: 19.3554\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.0464 - val_loss: 16.0478\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.3838 - val_loss: 18.9263\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.7982 - val_loss: 18.6365\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.0212 - val_loss: 15.3706\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5260 - val_loss: 16.6697\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.5392 - val_loss: 16.2297\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.2567 - val_loss: 15.4817\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.5652 - val_loss: 15.3053\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.8851 - val_loss: 21.6842\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.6950 - val_loss: 14.6801\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.6541 - val_loss: 15.2436\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.0232 - val_loss: 20.4440\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.5226 - val_loss: 13.9578\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.9202 - val_loss: 15.5778\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.7096 - val_loss: 16.2597\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.7458 - val_loss: 14.3843\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.8457 - val_loss: 14.1316\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.2901 - val_loss: 14.0455\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.4508 - val_loss: 15.9107\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9837 - val_loss: 17.7763\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.3335 - val_loss: 14.1234\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.5723 - val_loss: 15.4683\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.5132 - val_loss: 14.2865\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.1976 - val_loss: 14.9161\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.5904 - val_loss: 12.9611\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1530 - val_loss: 15.3461\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.4624 - val_loss: 13.3469\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.7236 - val_loss: 16.2075\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8313 - val_loss: 14.3153\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.6507 - val_loss: 14.7682\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6772 - val_loss: 17.4738\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.0353 - val_loss: 12.4778\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.0305 - val_loss: 14.3713\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.8809 - val_loss: 13.6023\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9094 - val_loss: 14.9221\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.9983 - val_loss: 13.2041\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.5469 - val_loss: 13.3953\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.0407 - val_loss: 13.0484\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3094 - val_loss: 13.2713\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.9714 - val_loss: 13.6020\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.4643 - val_loss: 15.3813\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.3551 - val_loss: 14.4181\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4803 - val_loss: 12.8776\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0007 - val_loss: 16.9517\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1756 - val_loss: 13.3622\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2976 - val_loss: 15.2197\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9059 - val_loss: 15.0031\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3275 - val_loss: 14.8603\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3684 - val_loss: 13.1399\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5084 - val_loss: 13.5229\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8302 - val_loss: 14.0255\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4484 - val_loss: 14.3531\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.7751 - val_loss: 12.5017\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.1581 - val_loss: 12.8831\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.3360 - val_loss: 14.1720\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.4393 - val_loss: 12.0908\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.5063 - val_loss: 16.1473\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.1143 - val_loss: 18.3440\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6190 - val_loss: 14.2457\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.2734 - val_loss: 14.0447\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3152 - val_loss: 13.2265\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.6286 - val_loss: 12.7009\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9186 - val_loss: 12.5198\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.7039 - val_loss: 12.3314\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.2194 - val_loss: 12.0825\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.5436 - val_loss: 12.4894\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7648 - val_loss: 12.8708\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.1338 - val_loss: 14.7701\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.6265 - val_loss: 13.5446\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8217 - val_loss: 12.5500\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3660 - val_loss: 17.2487\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.7147 - val_loss: 13.7059\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.6463 - val_loss: 14.2330\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0316 - val_loss: 13.8059\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.9627 - val_loss: 12.3482\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6077 - val_loss: 12.4268\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.2633 - val_loss: 16.6628\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.0687 - val_loss: 13.7271\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9998 - val_loss: 12.9212\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.8275 - val_loss: 12.1853\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.5444 - val_loss: 12.9078\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.9548 - val_loss: 12.2460\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4703 - val_loss: 16.2973\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.9521 - val_loss: 13.6105\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.7659 - val_loss: 13.3297\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0143 - val_loss: 13.2364\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.7894 - val_loss: 14.6445\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3680 - val_loss: 19.7093\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2497 - val_loss: 11.3280\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.5552 - val_loss: 11.6815\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.5775 - val_loss: 11.3893\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5661 - val_loss: 18.5076\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.1010 - val_loss: 13.0278\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3760 - val_loss: 11.3093\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.4142 - val_loss: 13.3483\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.2409 - val_loss: 11.4723\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2714 - val_loss: 11.2313\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.4717 - val_loss: 12.4385\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.2108 - val_loss: 11.4137\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.5110 - val_loss: 11.7754\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3984 - val_loss: 10.9299\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0081 - val_loss: 11.0238\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9503 - val_loss: 13.5604\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2587 - val_loss: 10.9950\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0490 - val_loss: 11.6284\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1586 - val_loss: 12.9773\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4208 - val_loss: 11.0113\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9345 - val_loss: 13.9529\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9892 - val_loss: 13.7739\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9517 - val_loss: 11.3557\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9730 - val_loss: 11.3492\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0459 - val_loss: 11.6931\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.3020 - val_loss: 11.1410\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8603 - val_loss: 11.5562\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.1660 - val_loss: 11.1887\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7098 - val_loss: 20.3002\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9156 - val_loss: 10.7833\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5750 - val_loss: 10.4888\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6610 - val_loss: 11.5552\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6393 - val_loss: 10.8000\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7946 - val_loss: 10.6295\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7089 - val_loss: 10.7563\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.8413 - val_loss: 10.8905\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.7052 - val_loss: 11.7301\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.9782 - val_loss: 12.3324\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7169 - val_loss: 12.2219\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0905 - val_loss: 14.5490\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6001 - val_loss: 10.8892\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.1641 - val_loss: 11.0058\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6292 - val_loss: 10.2278\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5596 - val_loss: 10.1788\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.3570 - val_loss: 11.3747\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3798 - val_loss: 11.7390\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7935 - val_loss: 11.7429\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9029 - val_loss: 10.6762\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5708 - val_loss: 11.5030\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9358 - val_loss: 14.0342\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0701 - val_loss: 10.5666\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3592 - val_loss: 14.6544\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6321 - val_loss: 11.5533\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7990 - val_loss: 10.5436\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1795 - val_loss: 10.1772\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5490 - val_loss: 10.5441\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7697 - val_loss: 17.6708\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9962 - val_loss: 12.9212\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8503 - val_loss: 11.6722\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5625 - val_loss: 10.8317\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7750 - val_loss: 10.6681\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1481 - val_loss: 11.9902\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7226 - val_loss: 10.3412\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7618 - val_loss: 11.4380\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2801 - val_loss: 11.6885\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.2280 - val_loss: 12.7055\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4121 - val_loss: 12.5474\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5055 - val_loss: 10.5075\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7215 - val_loss: 12.3991\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4463 - val_loss: 11.4589\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8105 - val_loss: 11.5668\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6560 - val_loss: 14.1997\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0671 - val_loss: 10.6720\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9242 - val_loss: 10.7140\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6338 - val_loss: 10.0237\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3957 - val_loss: 12.0147\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6883 - val_loss: 10.7550\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5129 - val_loss: 12.3146\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4659 - val_loss: 12.2911\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7175 - val_loss: 10.6174\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4561 - val_loss: 11.9372\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.5747 - val_loss: 9.8762\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0605 - val_loss: 11.2023\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6767 - val_loss: 12.5252\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5283 - val_loss: 12.9531\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5887 - val_loss: 10.5317\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5280 - val_loss: 11.3904\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3531 - val_loss: 11.1489\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4129 - val_loss: 13.4948\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3335 - val_loss: 10.5103\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.0664 - val_loss: 10.4410\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4936 - val_loss: 15.4913\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5216 - val_loss: 10.2699\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5269 - val_loss: 12.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4607 - val_loss: 10.6564\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6566 - val_loss: 11.7317\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8284 - val_loss: 9.8128\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2088 - val_loss: 12.1587\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4207 - val_loss: 10.6425\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6032 - val_loss: 10.7117\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2609 - val_loss: 10.6661\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3694 - val_loss: 11.4723\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2934 - val_loss: 10.8460\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9168 - val_loss: 10.6967\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.8095 - val_loss: 9.7880\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3555 - val_loss: 10.4757\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8350 - val_loss: 12.3044\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8215 - val_loss: 10.2274\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4203 - val_loss: 11.3372\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8982 - val_loss: 12.6729\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1507 - val_loss: 12.4344\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8488 - val_loss: 10.7336\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4846 - val_loss: 11.9098\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4963 - val_loss: 13.0908\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4366 - val_loss: 10.8358\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9193 - val_loss: 11.4377\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1313 - val_loss: 15.9264\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9731 - val_loss: 10.8497\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.8484 - val_loss: 10.3276\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.2516 - val_loss: 14.6789\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5719 - val_loss: 14.1700\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8919 - val_loss: 10.6802\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3526 - val_loss: 10.6185\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4010 - val_loss: 11.3107\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5675 - val_loss: 10.5044\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3976 - val_loss: 9.8776\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4040 - val_loss: 11.3921\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3387 - val_loss: 10.1683\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5708 - val_loss: 16.4776\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4161 - val_loss: 9.7491\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8284 - val_loss: 9.9967\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5245 - val_loss: 10.0675\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1222 - val_loss: 10.9211\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.6553 - val_loss: 11.1277\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.5118 - val_loss: 10.7777\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4695 - val_loss: 19.6773\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3623 - val_loss: 11.2283\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1934 - val_loss: 13.3929\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4082 - val_loss: 11.0575\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4133 - val_loss: 11.0961\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4883 - val_loss: 18.2758\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2780 - val_loss: 10.4908\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4180 - val_loss: 9.7214\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5130 - val_loss: 10.6067\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5597 - val_loss: 11.6678\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4296 - val_loss: 11.8443\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6190 - val_loss: 9.9922\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6354 - val_loss: 10.1007\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3440 - val_loss: 9.8890\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5304 - val_loss: 13.9449\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4814 - val_loss: 10.2173\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3146 - val_loss: 9.9071\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5379 - val_loss: 14.1419\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2533 - val_loss: 12.7611\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5165 - val_loss: 11.6629\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6984 - val_loss: 12.8171\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5733 - val_loss: 10.5144\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4816 - val_loss: 10.1425\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7126 - val_loss: 10.6629\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1038 - val_loss: 10.0186\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6453 - val_loss: 12.8416\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5877 - val_loss: 10.3661\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2135 - val_loss: 10.3543\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2373 - val_loss: 11.9751\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7829 - val_loss: 10.0957\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3743 - val_loss: 11.5022\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2746 - val_loss: 10.5154\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4044 - val_loss: 13.2259\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4197 - val_loss: 10.9918\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3649 - val_loss: 10.5919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3638 - val_loss: 10.1370\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1228 - val_loss: 10.0333\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.8837 - val_loss: 10.6093\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2547 - val_loss: 10.3659\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3879 - val_loss: 10.4892\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6248 - val_loss: 10.6882\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4927 - val_loss: 10.3404\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9985 - val_loss: 10.0690\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5282 - val_loss: 15.0984\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3937 - val_loss: 10.4344\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2525 - val_loss: 10.5598\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0400 - val_loss: 10.6813\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4464 - val_loss: 12.8877\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3507 - val_loss: 11.3442\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3020 - val_loss: 10.7051\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.6241 - val_loss: 12.7732\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3485 - val_loss: 10.7304\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2504 - val_loss: 10.5535\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3986 - val_loss: 10.1131\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2600 - val_loss: 10.5323\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6926 - val_loss: 12.1579\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4817 - val_loss: 13.1448\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1881 - val_loss: 16.8390\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4971 - val_loss: 9.6444\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3153 - val_loss: 14.6452\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5443 - val_loss: 10.4631\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0271 - val_loss: 10.0080\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.9396 - val_loss: 10.1706\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5242 - val_loss: 12.0142\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1973 - val_loss: 9.9894\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5764 - val_loss: 10.3024\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2870 - val_loss: 11.5517\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5895 - val_loss: 10.5158\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3737 - val_loss: 9.8918\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9968 - val_loss: 20.7540\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6748 - val_loss: 10.2810\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6492 - val_loss: 9.8237\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2946 - val_loss: 9.6186\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4352 - val_loss: 10.9368\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1603 - val_loss: 9.9341\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7388 - val_loss: 10.8276\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4192 - val_loss: 14.2027\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7950 - val_loss: 12.3012\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8393 - val_loss: 10.9024\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2366 - val_loss: 12.2708\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3966 - val_loss: 10.4719\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2531 - val_loss: 10.5906\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7216 - val_loss: 11.4160\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0501 - val_loss: 10.0966\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3385 - val_loss: 13.6772\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3689 - val_loss: 10.5730\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6575 - val_loss: 11.1156\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2414 - val_loss: 11.8560\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4297 - val_loss: 10.4919\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3464 - val_loss: 10.5899\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5104 - val_loss: 10.5308\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9758 - val_loss: 9.9175\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.4002 - val_loss: 10.4908\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1167 - val_loss: 10.7241\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8582 - val_loss: 10.5443\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0406 - val_loss: 16.5317\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4063 - val_loss: 12.4805\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2321 - val_loss: 11.8163\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5722 - val_loss: 12.4103\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4222 - val_loss: 10.3357\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3909 - val_loss: 11.6782\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1558 - val_loss: 12.5666\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5273 - val_loss: 9.8895\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4988 - val_loss: 10.3405\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1501 - val_loss: 10.7608\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3341 - val_loss: 9.9129\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1847 - val_loss: 15.2397\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2423 - val_loss: 11.1101\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4779 - val_loss: 10.4109\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4428 - val_loss: 11.3763\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2733 - val_loss: 9.5536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8742 - val_loss: 9.8396\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8097 - val_loss: 10.4886\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0624 - val_loss: 18.4329\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4620 - val_loss: 10.9636\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1423 - val_loss: 10.1404\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3701 - val_loss: 10.2950\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3239 - val_loss: 10.0527\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7769 - val_loss: 13.1401\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3265 - val_loss: 9.9313\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0693 - val_loss: 9.5118\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2522 - val_loss: 12.7324\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9797 - val_loss: 9.5730\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1058 - val_loss: 9.5982\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6961 - val_loss: 12.7448\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1936 - val_loss: 11.5029\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2188 - val_loss: 10.6481\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.4204 - val_loss: 9.9482\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.7702 - val_loss: 10.9661\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6418 - val_loss: 10.1521\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5538 - val_loss: 11.9972\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1760 - val_loss: 13.3793\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6326 - val_loss: 14.2011\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2702 - val_loss: 12.1613\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3306 - val_loss: 9.6735\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6152 - val_loss: 12.1749\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0791 - val_loss: 10.0322\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1878 - val_loss: 14.0095\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6646 - val_loss: 10.1966\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4073 - val_loss: 11.3718\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.1229 - val_loss: 10.1890\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2249 - val_loss: 15.6472\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9601 - val_loss: 10.3282\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1491 - val_loss: 11.5683\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1010 - val_loss: 12.0292\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3055 - val_loss: 10.2664\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1178 - val_loss: 10.7680\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1732 - val_loss: 9.7307\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4626 - val_loss: 11.7512\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9237 - val_loss: 11.7769\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4627 - val_loss: 9.7236\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0833 - val_loss: 10.3689\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5716 - val_loss: 10.6290\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3251 - val_loss: 9.9994\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0444 - val_loss: 11.8821\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3196 - val_loss: 10.5164\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1101 - val_loss: 10.8585\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4779 - val_loss: 10.8736\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7408 - val_loss: 14.9748\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2094 - val_loss: 11.4844\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2781 - val_loss: 10.5903\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5842 - val_loss: 14.6630\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3036 - val_loss: 10.6447\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2282 - val_loss: 13.1821\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3518 - val_loss: 10.2279\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0866 - val_loss: 11.6575\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2726 - val_loss: 10.1501\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0827 - val_loss: 10.2576\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6313 - val_loss: 9.6787\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0819 - val_loss: 10.4898\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6747 - val_loss: 9.6061\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1450 - val_loss: 12.3800\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0954 - val_loss: 11.7170\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6165 - val_loss: 10.4075\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9389 - val_loss: 9.6361\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3386 - val_loss: 13.1173\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4364 - val_loss: 9.6401\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.7071 - val_loss: 10.3272\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4658 - val_loss: 11.7286\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5710 - val_loss: 15.5472\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5906 - val_loss: 11.0733\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6592 - val_loss: 10.4155\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2405 - val_loss: 9.8307\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4142 - val_loss: 12.6207\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3540 - val_loss: 12.3136\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1135 - val_loss: 10.7252\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6221 - val_loss: 9.9649\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3833 - val_loss: 10.0923\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3530 - val_loss: 9.6782\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0647 - val_loss: 12.8022\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4579 - val_loss: 9.7366\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.6251 - val_loss: 10.7035\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0003 - val_loss: 10.6583\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4624 - val_loss: 9.9369\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3422 - val_loss: 10.1451\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1108 - val_loss: 11.5981\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9770 - val_loss: 12.5497\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9153 - val_loss: 11.8759\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3841 - val_loss: 10.2329\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8339 - val_loss: 12.0624\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0291 - val_loss: 10.0528\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0987 - val_loss: 10.6912\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2269 - val_loss: 13.5398\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5365 - val_loss: 10.8330\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1302 - val_loss: 11.4993\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2571 - val_loss: 9.8884\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8041 - val_loss: 9.5572\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1542 - val_loss: 9.4343\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6028 - val_loss: 9.9407\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1687 - val_loss: 9.3622\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3941 - val_loss: 10.5398\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4800 - val_loss: 12.1351\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.2338 - val_loss: 16.2286\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6964 - val_loss: 10.1011\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2361 - val_loss: 10.3854\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1620 - val_loss: 11.4177\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2887 - val_loss: 10.7448\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3941 - val_loss: 10.2445\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1383 - val_loss: 9.9616\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6214 - val_loss: 10.1081\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4242 - val_loss: 10.1748\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8616 - val_loss: 10.9649\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3836 - val_loss: 10.0186\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2216 - val_loss: 9.9921\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2803 - val_loss: 13.4850\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2168 - val_loss: 12.5805\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1692 - val_loss: 9.8921\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2031 - val_loss: 11.4068\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0485 - val_loss: 10.4977\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5606 - val_loss: 10.7381\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2803 - val_loss: 10.3698\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1134 - val_loss: 12.0321\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3957 - val_loss: 9.8448\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4676 - val_loss: 14.0218\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1093 - val_loss: 14.8657\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3635 - val_loss: 21.9873\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.7557 - val_loss: 9.8019\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.6604 - val_loss: 10.5988\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4622 - val_loss: 14.5337\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0273 - val_loss: 11.9988\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3181 - val_loss: 12.1946\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1557 - val_loss: 16.2502\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5295 - val_loss: 9.4100\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2241 - val_loss: 13.3811\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1601 - val_loss: 10.9745\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9920 - val_loss: 10.6638\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4545 - val_loss: 10.2648\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6785 - val_loss: 10.8361\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2612 - val_loss: 10.6680\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1611 - val_loss: 9.3667\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2475 - val_loss: 14.2752\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2718 - val_loss: 9.9445\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6543 - val_loss: 10.4460\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1456 - val_loss: 14.4194\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2994 - val_loss: 13.5892\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2676 - val_loss: 11.8282\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1114 - val_loss: 11.1276\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1569 - val_loss: 12.2970\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5741 - val_loss: 10.0530\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2122 - val_loss: 14.8420\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0603 - val_loss: 11.8366\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2763 - val_loss: 9.8301\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7259 - val_loss: 9.7223\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8975 - val_loss: 12.2317\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3496 - val_loss: 10.1589\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3012 - val_loss: 9.8673\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2744 - val_loss: 9.9863\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5858 - val_loss: 10.1964\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0589 - val_loss: 12.5302\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4503 - val_loss: 13.2990\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1830 - val_loss: 15.6432\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2937 - val_loss: 12.6355\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3226 - val_loss: 9.7800\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1924 - val_loss: 10.2244\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9816 - val_loss: 10.6090\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0578 - val_loss: 10.1470\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3157 - val_loss: 10.9262\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9074 - val_loss: 10.9624\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2642 - val_loss: 10.6448\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3297 - val_loss: 9.5275\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2192 - val_loss: 9.9146\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2654 - val_loss: 10.2009\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1330 - val_loss: 10.6934\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3158 - val_loss: 9.4946\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8247 - val_loss: 10.3383\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0443 - val_loss: 9.8999\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7346 - val_loss: 9.4623\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3877 - val_loss: 9.5047\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9270 - val_loss: 11.1051\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4688 - val_loss: 11.9581\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2320 - val_loss: 10.0066\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0370 - val_loss: 11.6685\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4149 - val_loss: 10.4086\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2006 - val_loss: 10.0672\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9114 - val_loss: 13.9245\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6189 - val_loss: 9.7216\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0710 - val_loss: 13.0205\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3394 - val_loss: 13.3846\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5467 - val_loss: 9.6014\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.6103 - val_loss: 10.6019\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2751 - val_loss: 9.7096\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1748 - val_loss: 10.9316\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2662 - val_loss: 11.2516\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4640 - val_loss: 9.4822\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3189 - val_loss: 10.1202\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1256 - val_loss: 10.2416\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2959 - val_loss: 12.4969\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9539 - val_loss: 10.9553\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2180 - val_loss: 10.1667\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2788 - val_loss: 11.0326\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2269 - val_loss: 9.9414\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6210 - val_loss: 10.1034\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2557 - val_loss: 11.5265\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.6459 - val_loss: 10.7918\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9406 - val_loss: 9.6867\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4790 - val_loss: 9.6530\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8986 - val_loss: 15.6644\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2406 - val_loss: 9.6495\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2551 - val_loss: 9.4362\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3444 - val_loss: 9.7449\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1959 - val_loss: 12.0216\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1526 - val_loss: 11.0193\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1493 - val_loss: 9.7086\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1960 - val_loss: 10.9060\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9535 - val_loss: 10.5939\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9926 - val_loss: 10.5121\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3401 - val_loss: 12.8764\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3592 - val_loss: 12.3825\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6559 - val_loss: 9.4659\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8904 - val_loss: 11.1211\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6062 - val_loss: 10.1562\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5071 - val_loss: 12.0285\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2391 - val_loss: 10.2383\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2350 - val_loss: 11.1153\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8009 - val_loss: 10.6914\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3426 - val_loss: 11.8643\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9377 - val_loss: 9.9998\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3238 - val_loss: 11.9518\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1641 - val_loss: 10.7318\n",
      "Epoch 748/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0469 - val_loss: 10.0590\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0230 - val_loss: 9.6468\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3989 - val_loss: 11.3324\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4079 - val_loss: 9.5903\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1425 - val_loss: 13.1156\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4540 - val_loss: 10.7677\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1861 - val_loss: 11.9812\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0247 - val_loss: 10.5013\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3539 - val_loss: 11.8602\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2841 - val_loss: 10.9367\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8621 - val_loss: 10.1989\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4031 - val_loss: 10.0243\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2647 - val_loss: 10.3771\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0799 - val_loss: 9.7019\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8935 - val_loss: 11.4219\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2471 - val_loss: 10.2206\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3546 - val_loss: 9.9970\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1029 - val_loss: 10.0688\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2680 - val_loss: 11.8192\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2709 - val_loss: 10.2530\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1772 - val_loss: 10.2830\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2591 - val_loss: 9.6858\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2184 - val_loss: 11.9698\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3892 - val_loss: 11.3049\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3020 - val_loss: 13.2972\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0372 - val_loss: 10.4644\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7892 - val_loss: 13.3298\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4289 - val_loss: 10.0569\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0661 - val_loss: 9.6900\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9790 - val_loss: 9.9217\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4301 - val_loss: 12.1274\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3642 - val_loss: 17.7248\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1629 - val_loss: 13.4710\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4675 - val_loss: 9.6682\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9622 - val_loss: 11.1909\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3207 - val_loss: 12.1761\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1618 - val_loss: 10.0871\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2211 - val_loss: 10.0442\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8501 - val_loss: 9.4732\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4840 - val_loss: 10.4279\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2504 - val_loss: 10.4044\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9898 - val_loss: 11.3970\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6716 - val_loss: 13.6427\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8732 - val_loss: 9.4104\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3057 - val_loss: 10.1058\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1428 - val_loss: 12.9201\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3870 - val_loss: 12.7894\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9455 - val_loss: 10.9291\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3194 - val_loss: 12.5961\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3506 - val_loss: 9.6454\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6891 - val_loss: 10.0218\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3786 - val_loss: 9.8551\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1865 - val_loss: 10.8427\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1464 - val_loss: 9.5020\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2428 - val_loss: 15.5733\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3937 - val_loss: 9.5782\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0250 - val_loss: 11.7894\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9579 - val_loss: 10.0244\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.7602 - val_loss: 10.0946\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1487 - val_loss: 9.6592\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1508 - val_loss: 10.0081\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2633 - val_loss: 10.2518\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1810 - val_loss: 9.7524\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9083 - val_loss: 9.3769\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4588 - val_loss: 13.3390\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9850 - val_loss: 10.7637\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0194 - val_loss: 9.9243\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4943 - val_loss: 9.9816\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2355 - val_loss: 9.4250\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3583 - val_loss: 12.0791\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0174 - val_loss: 9.4580\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0865 - val_loss: 9.4669\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0469 - val_loss: 12.4482\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1744 - val_loss: 9.9461\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0938 - val_loss: 9.9242\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1943 - val_loss: 10.2938\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9288 - val_loss: 9.5932\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3547 - val_loss: 10.7029\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2995 - val_loss: 10.2861\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0898 - val_loss: 9.6633\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.7921 - val_loss: 10.3388\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5757 - val_loss: 9.9947\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8889 - val_loss: 12.8185\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5084 - val_loss: 11.6237\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3121 - val_loss: 11.1435\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4150 - val_loss: 9.7240\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.8469 - val_loss: 9.7940\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2334 - val_loss: 11.7525\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9062 - val_loss: 9.4173\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4762 - val_loss: 9.6844\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1443 - val_loss: 9.2537\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9214 - val_loss: 12.5076\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5856 - val_loss: 9.4265\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9809 - val_loss: 9.3270\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0656 - val_loss: 9.5878\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0569 - val_loss: 14.5820\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4340 - val_loss: 9.7624\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2131 - val_loss: 10.2492\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9257 - val_loss: 11.0047\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4505 - val_loss: 10.1176\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2996 - val_loss: 10.0415\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0805 - val_loss: 11.5820\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5982 - val_loss: 10.0277\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5536 - val_loss: 9.6165\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2380 - val_loss: 9.4142\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3129 - val_loss: 10.6522\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9786 - val_loss: 9.9964\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6129 - val_loss: 9.5435\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4494 - val_loss: 9.2305\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0797 - val_loss: 9.7166\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4004 - val_loss: 9.3383\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6925 - val_loss: 15.4360\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3620 - val_loss: 11.5544\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2113 - val_loss: 18.5155\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4341 - val_loss: 15.1485\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0944 - val_loss: 10.2004\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0271 - val_loss: 10.9613\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1945 - val_loss: 9.7613\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4501 - val_loss: 9.2076\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.7266 - val_loss: 10.7198\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2078 - val_loss: 9.7643\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6020 - val_loss: 11.4438\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3214 - val_loss: 9.5038\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0584 - val_loss: 10.0759\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1395 - val_loss: 10.4890\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0385 - val_loss: 14.6607\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0381 - val_loss: 9.7417\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8660 - val_loss: 9.6975\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9617 - val_loss: 10.2202\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2627 - val_loss: 10.7485\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2105 - val_loss: 9.3678\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3316 - val_loss: 12.7876\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1471 - val_loss: 9.6060\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8629 - val_loss: 10.2357\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3935 - val_loss: 11.5407\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1357 - val_loss: 11.1546\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1443 - val_loss: 9.4311\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8530 - val_loss: 11.6031\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4724 - val_loss: 9.5231\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4209 - val_loss: 9.7990\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9709 - val_loss: 11.6687\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6509 - val_loss: 10.7194\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1747 - val_loss: 9.5605\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0387 - val_loss: 13.1440\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4669 - val_loss: 10.0931\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7842 - val_loss: 14.0513\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9798 - val_loss: 12.9288\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7910 - val_loss: 10.3368\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8717 - val_loss: 11.1159\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2369 - val_loss: 10.1638\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4218 - val_loss: 10.0343\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2893 - val_loss: 11.3778\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0974 - val_loss: 9.5079\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0800 - val_loss: 9.6094\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6173 - val_loss: 9.1419\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1100 - val_loss: 11.3135\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1920 - val_loss: 9.6723\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0946 - val_loss: 10.5375\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 8.9458 - val_loss: 11.4338\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1700 - val_loss: 9.4908\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5468 - val_loss: 12.2630\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0782 - val_loss: 9.6317\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5301 - val_loss: 9.1364\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8579 - val_loss: 10.9333\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1448 - val_loss: 9.4834\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2894 - val_loss: 9.8577\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1022 - val_loss: 10.2901\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9517 - val_loss: 10.1189\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1777 - val_loss: 9.7230\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0366 - val_loss: 9.7483\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0967 - val_loss: 9.7144\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0355 - val_loss: 12.4987\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9132 - val_loss: 10.4861\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0931 - val_loss: 12.5759\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7890 - val_loss: 10.8006\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1833 - val_loss: 10.7191\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5389 - val_loss: 11.9831\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9293 - val_loss: 11.6700\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0028 - val_loss: 13.6230\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4982 - val_loss: 9.5760\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1594 - val_loss: 11.5623\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9619 - val_loss: 10.6015\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1127 - val_loss: 10.0141\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9111 - val_loss: 10.9036\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8177 - val_loss: 15.9383\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4267 - val_loss: 9.8223\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5584 - val_loss: 10.8726\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7614 - val_loss: 10.7420\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0818 - val_loss: 11.9983\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3255 - val_loss: 9.9410\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8335 - val_loss: 20.7639\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4513 - val_loss: 11.2874\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2420 - val_loss: 12.1502\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0593 - val_loss: 10.9487\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6777 - val_loss: 9.8528\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8890 - val_loss: 9.4507\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.7959 - val_loss: 12.1344\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1007 - val_loss: 10.0872\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8919 - val_loss: 12.4267\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3790 - val_loss: 11.7696\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9615 - val_loss: 9.6670\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4125 - val_loss: 9.8488\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2557 - val_loss: 10.4156\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7614 - val_loss: 10.4670\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4958 - val_loss: 11.0777\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0349 - val_loss: 9.7379\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1712 - val_loss: 9.5816\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7854 - val_loss: 12.6688\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5017 - val_loss: 10.0504\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8112 - val_loss: 9.6847\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7451 - val_loss: 9.6514\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3631 - val_loss: 9.7722\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2235 - val_loss: 10.6240\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9578 - val_loss: 14.1332\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9399 - val_loss: 13.5824\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2933 - val_loss: 10.5514\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4763 - val_loss: 9.6226\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2325 - val_loss: 12.6063\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 9.1704 - val_loss: 12.0373\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9928 - val_loss: 9.5887\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 8.9064 - val_loss: 9.9142\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2101 - val_loss: 10.8093\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1815 - val_loss: 9.9345\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9713 - val_loss: 9.1500\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1935 - val_loss: 10.5557\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8975 - val_loss: 10.4714\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1813 - val_loss: 9.2847\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2371 - val_loss: 9.4393\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2921 - val_loss: 9.5962\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.636 - 0s 83us/step - loss: 9.2317 - val_loss: 9.7286\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0310 - val_loss: 16.2184\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9553 - val_loss: 15.9516\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3547 - val_loss: 11.4079\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6469 - val_loss: 9.5046\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9678 - val_loss: 9.8655\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2161 - val_loss: 10.9935\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8282 - val_loss: 9.4817\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9708 - val_loss: 9.5428\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1386 - val_loss: 13.6791\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9565 - val_loss: 12.7398\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3401 - val_loss: 9.5004\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6742 - val_loss: 12.3867\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3021 - val_loss: 11.2966\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3796 - val_loss: 12.1458\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6981 - val_loss: 9.4932\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8344 - val_loss: 10.4036\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8621 - val_loss: 16.1422\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9848 - val_loss: 9.7337\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9925 - val_loss: 12.0797\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3000 - val_loss: 10.1713\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3522 - val_loss: 12.5093\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0391 - val_loss: 11.5832\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3784 - val_loss: 9.2971\n",
      "8.567304919251299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-5.2773160e-01,  1.9658632e+00, -4.0505700e+00, -3.1017580e+00,\n",
       "          2.2678111e-01],\n",
       "        [-9.7718185e-01, -4.4118536e-01,  2.3990002e-01,  2.8758457e-02,\n",
       "          2.6006827e-01],\n",
       "        [-1.2281326e+00, -3.7994516e-01, -7.4677682e-01, -2.0932406e-03,\n",
       "          4.0763730e-01],\n",
       "        [ 2.0162228e-01, -5.1877890e-02,  1.5202941e-01,  7.0927441e-02,\n",
       "         -1.9420524e-01],\n",
       "        [ 3.4209855e-02,  2.8210995e-01, -3.9546540e-01, -2.4980335e+00,\n",
       "          2.1591848e-01]], dtype=float32),\n",
       " array([-0.6113899,  1.2353743, -4.9203124, -4.6428027, -1.9127222],\n",
       "       dtype=float32),\n",
       " array([[-0.7757531 ,  0.16844755,  0.3920855 , -0.53108996,  0.03681013,\n",
       "          0.44453827,  0.84954506,  0.02229284, -0.6965193 ,  0.12848362],\n",
       "        [ 0.76073897, -0.77224255, -0.46199623,  0.74619955, -0.25548318,\n",
       "         -0.41365287,  0.10224669, -0.762868  ,  0.60065097, -0.56195915],\n",
       "        [ 1.4765929 , -1.0935898 , -2.233196  ,  1.7948748 , -2.0830073 ,\n",
       "         -1.9415424 , -2.225514  , -2.1402795 ,  1.0670125 , -2.254036  ],\n",
       "        [ 1.7378889 , -1.8682047 , -1.3285004 ,  1.633547  , -1.3231149 ,\n",
       "         -1.6888509 , -1.700332  , -1.7012225 ,  1.8178219 , -0.92568696],\n",
       "        [ 2.2976255 , -1.6854419 , -1.958278  ,  1.8294246 , -1.7589688 ,\n",
       "         -1.5641696 , -1.219928  , -1.123813  ,  2.1835508 , -1.5153672 ]],\n",
       "       dtype=float32),\n",
       " array([-2.0797355,  1.9803901,  2.0870695, -1.9608613,  2.0741513,\n",
       "         1.9805893,  2.0051913,  2.0578911, -1.946752 ,  2.0209339],\n",
       "       dtype=float32),\n",
       " array([[-2.171974 ],\n",
       "        [ 1.724749 ],\n",
       "        [ 2.1922176],\n",
       "        [-1.5565027],\n",
       "        [ 2.1050503],\n",
       "        [ 1.7007222],\n",
       "        [ 1.8474259],\n",
       "        [ 2.0673618],\n",
       "        [-1.5335642],\n",
       "        [ 1.8744173]], dtype=float32),\n",
       " array([2.5940118], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, RMSprop, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_rmsprop_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 616us/step - loss: 490.2312 - val_loss: 256.9282\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 170.5092 - val_loss: 62.1869\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 51.0537 - val_loss: 22.7567\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 19.4836 - val_loss: 17.9338\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 13.9624 - val_loss: 15.2112\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 12.1091 - val_loss: 10.7493\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.7469 - val_loss: 9.9669\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 9.6058 - val_loss: 9.5461\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.8235 - val_loss: 11.9273\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9383 - val_loss: 9.3650\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.4836 - val_loss: 9.5668\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3790 - val_loss: 9.3501\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2346 - val_loss: 9.2727\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.1783 - val_loss: 8.9722\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0818 - val_loss: 9.1254\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1822 - val_loss: 8.9842\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5412 - val_loss: 10.5633\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4883 - val_loss: 9.2375\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.3962 - val_loss: 10.0532\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0371 - val_loss: 9.0481\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8067 - val_loss: 10.1848\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9082 - val_loss: 8.9386\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8683 - val_loss: 9.0644\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8057 - val_loss: 9.9935\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3386 - val_loss: 8.9837\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8586 - val_loss: 9.9957\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7009 - val_loss: 9.3644\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8477 - val_loss: 9.4312\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7796 - val_loss: 9.8554\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8860 - val_loss: 9.1663\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6405 - val_loss: 9.4202\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6049 - val_loss: 9.8523\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8556 - val_loss: 9.3010\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6662 - val_loss: 9.3841\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0400 - val_loss: 10.5616\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9438 - val_loss: 9.5356\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6937 - val_loss: 9.9619\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6928 - val_loss: 9.5277\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5964 - val_loss: 9.5608\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4856 - val_loss: 9.5954\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5672 - val_loss: 9.7171\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4909 - val_loss: 9.7906\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4744 - val_loss: 9.8065\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5093 - val_loss: 9.8198\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.6581 - val_loss: 9.7270\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.8115 - val_loss: 10.9727\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1036 - val_loss: 10.1028\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0896 - val_loss: 11.3191\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8302 - val_loss: 9.8723\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7239 - val_loss: 9.9357\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3885 - val_loss: 9.9218\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3810 - val_loss: 9.6942\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4706 - val_loss: 10.0337\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6809 - val_loss: 9.9008\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9308 - val_loss: 10.8119\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6168 - val_loss: 10.1951\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6848 - val_loss: 11.2480\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8478 - val_loss: 9.8951\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2778 - val_loss: 10.6305\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6841 - val_loss: 10.1422\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2262 - val_loss: 10.9350\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6777 - val_loss: 10.0712\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4035 - val_loss: 9.9364\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3445 - val_loss: 10.1421\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3937 - val_loss: 10.1122\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5854 - val_loss: 10.8062\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5940 - val_loss: 10.7163\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3814 - val_loss: 10.4070\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 7.6687 - val_loss: 10.4290\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.1274 - val_loss: 10.9237\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7351 - val_loss: 10.3745\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5991 - val_loss: 10.8048\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4189 - val_loss: 10.4315\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3595 - val_loss: 10.5572\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4090 - val_loss: 10.4770\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3075 - val_loss: 10.3897\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2602 - val_loss: 10.3771\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2887 - val_loss: 10.6229\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3108 - val_loss: 10.4446\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2151 - val_loss: 10.3569\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2101 - val_loss: 10.4790\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2696 - val_loss: 10.3733\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.4143 - val_loss: 10.4588\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4965 - val_loss: 10.1038\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6507 - val_loss: 11.0269\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.6379 - val_loss: 10.4608\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2052 - val_loss: 10.8216\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3639 - val_loss: 10.4483\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4546 - val_loss: 10.6832\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.2351 - val_loss: 10.4741\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2731 - val_loss: 10.6749\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3137 - val_loss: 10.4392\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3361 - val_loss: 10.6092\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1367 - val_loss: 10.3850\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3361 - val_loss: 10.5661\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1126 - val_loss: 10.3424\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2206 - val_loss: 10.5950\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3661 - val_loss: 10.2810\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1886 - val_loss: 10.6555\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1071 - val_loss: 10.3302\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2327 - val_loss: 10.5654\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0532 - val_loss: 10.3382\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1769 - val_loss: 10.3590\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.5999 - val_loss: 9.9828\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8582 - val_loss: 10.5559\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2026 - val_loss: 10.1144\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0403 - val_loss: 10.0657\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9785 - val_loss: 10.2104\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0508 - val_loss: 10.5609\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2003 - val_loss: 10.0085\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0949 - val_loss: 10.2322\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0025 - val_loss: 10.1998\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1049 - val_loss: 9.9762\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9806 - val_loss: 10.0680\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9431 - val_loss: 9.9340\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8964 - val_loss: 10.1030\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9038 - val_loss: 10.0983\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8675 - val_loss: 9.8804\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0494 - val_loss: 9.8693\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8473 - val_loss: 9.9299\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8487 - val_loss: 9.8854\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8711 - val_loss: 9.7335\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8560 - val_loss: 9.9565\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8949 - val_loss: 9.7684\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8803 - val_loss: 9.9441\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8081 - val_loss: 9.6583\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7910 - val_loss: 9.7177\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7707 - val_loss: 9.5856\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8410 - val_loss: 9.7860\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7948 - val_loss: 9.6274\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0574 - val_loss: 9.7303\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9228 - val_loss: 9.7508\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9276 - val_loss: 9.8643\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7703 - val_loss: 9.5666\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8520 - val_loss: 9.5736\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8323 - val_loss: 9.3867\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7307 - val_loss: 9.3112\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0674 - val_loss: 9.7723\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7681 - val_loss: 9.4416\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8656 - val_loss: 9.7200\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6707 - val_loss: 9.5002\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7769 - val_loss: 9.6923\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7202 - val_loss: 9.3501\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7322 - val_loss: 9.4029\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8107 - val_loss: 9.1730\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.7959 - val_loss: 9.0866\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6332 - val_loss: 9.2582\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6539 - val_loss: 9.5572\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7788 - val_loss: 9.0596\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7439 - val_loss: 9.2353\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8744 - val_loss: 9.2548\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7259 - val_loss: 9.1214\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5011 - val_loss: 9.1343\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4677 - val_loss: 9.1629\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4894 - val_loss: 9.1659\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6323 - val_loss: 9.3299\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5556 - val_loss: 9.2331\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5722 - val_loss: 9.2504\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6557 - val_loss: 9.2314\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6180 - val_loss: 8.9970\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3910 - val_loss: 9.2057\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4261 - val_loss: 9.0499\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4534 - val_loss: 9.3195\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6034 - val_loss: 9.0605\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7174 - val_loss: 9.4779\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3837 - val_loss: 9.0596\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3968 - val_loss: 9.1742\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2997 - val_loss: 9.0750\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3055 - val_loss: 9.1276\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4036 - val_loss: 9.3403\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4023 - val_loss: 9.2421\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2846 - val_loss: 9.4056\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2387 - val_loss: 9.2561\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4545 - val_loss: 9.3311\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5195 - val_loss: 9.4325\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3338 - val_loss: 9.2782\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4457 - val_loss: 9.3893\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1274 - val_loss: 9.6203\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2304 - val_loss: 9.4985\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1168 - val_loss: 9.8636\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1802 - val_loss: 9.3671\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2704 - val_loss: 9.4194\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1540 - val_loss: 9.3489\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1862 - val_loss: 9.3470\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0740 - val_loss: 9.4875\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2610 - val_loss: 9.4082\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2761 - val_loss: 9.5234\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5511 - val_loss: 9.6762\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4822 - val_loss: 9.2250\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1715 - val_loss: 9.5062\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9730 - val_loss: 9.2926\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0709 - val_loss: 9.3053\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0250 - val_loss: 9.3853\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9392 - val_loss: 9.4179\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9414 - val_loss: 9.4371\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9364 - val_loss: 9.5705\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9439 - val_loss: 9.5209\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0046 - val_loss: 9.2286\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8763 - val_loss: 9.3638\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9647 - val_loss: 9.3469\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4773 - val_loss: 9.4841\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2357 - val_loss: 9.3249\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9311 - val_loss: 9.1563\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8854 - val_loss: 9.3043\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9873 - val_loss: 9.1766\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3932 - val_loss: 9.5139\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7277 - val_loss: 9.2341\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2045 - val_loss: 9.4464\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3010 - val_loss: 9.2921\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2520 - val_loss: 9.6352\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9717 - val_loss: 9.3082\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9130 - val_loss: 9.2026\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9003 - val_loss: 9.3905\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9555 - val_loss: 9.1677\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8826 - val_loss: 9.4531\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8369 - val_loss: 9.3801\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8466 - val_loss: 9.3248\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9087 - val_loss: 9.2202\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0958 - val_loss: 9.0913\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0851 - val_loss: 9.3646\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9378 - val_loss: 9.5392\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0059 - val_loss: 9.5689\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9239 - val_loss: 9.3648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8008 - val_loss: 9.1355\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9068 - val_loss: 9.1353\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8172 - val_loss: 9.3509\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9248 - val_loss: 9.2963\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8026 - val_loss: 9.2897\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8325 - val_loss: 9.3979\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9063 - val_loss: 9.4932\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9383 - val_loss: 9.3471\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9491 - val_loss: 9.2534\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8431 - val_loss: 9.3693\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7913 - val_loss: 9.1700\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8167 - val_loss: 9.4353\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0908 - val_loss: 9.4106\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9031 - val_loss: 9.2580\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9141 - val_loss: 9.3113\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7682 - val_loss: 9.6464\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8083 - val_loss: 9.5110\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8987 - val_loss: 9.4621\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7926 - val_loss: 9.2434\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7847 - val_loss: 9.2875\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8550 - val_loss: 9.3570\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7470 - val_loss: 9.1642\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8405 - val_loss: 9.3726\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0175 - val_loss: 9.3212\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8100 - val_loss: 9.4906\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7631 - val_loss: 9.2852\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8126 - val_loss: 9.3439\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7918 - val_loss: 9.3704\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8432 - val_loss: 9.4208\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7837 - val_loss: 9.3902\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0800 - val_loss: 9.4728\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1466 - val_loss: 9.5143\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9016 - val_loss: 9.3449\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8838 - val_loss: 9.6487\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9734 - val_loss: 9.3945\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9411 - val_loss: 9.2706\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9226 - val_loss: 9.4433\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7803 - val_loss: 9.6638\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9387 - val_loss: 9.6706\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9079 - val_loss: 9.5891\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9021 - val_loss: 9.3829\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8307 - val_loss: 9.3265\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7923 - val_loss: 9.4390\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7201 - val_loss: 9.4984\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8294 - val_loss: 9.5417\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7796 - val_loss: 9.5106\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7535 - val_loss: 9.3299\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7756 - val_loss: 9.2428\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8356 - val_loss: 9.3869\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0280 - val_loss: 9.5749\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8948 - val_loss: 9.5628\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8160 - val_loss: 9.3787\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9346 - val_loss: 9.3993\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6997 - val_loss: 9.1653\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7379 - val_loss: 9.5475\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7373 - val_loss: 9.3782\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9454 - val_loss: 9.7811\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5379 - val_loss: 9.3022\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9283 - val_loss: 10.0091\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8140 - val_loss: 9.5512\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8033 - val_loss: 9.5359\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8031 - val_loss: 9.6064\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8873 - val_loss: 9.6215\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7988 - val_loss: 9.4931\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8575 - val_loss: 9.5540\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8580 - val_loss: 9.4604\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2379 - val_loss: 9.4310\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8086 - val_loss: 9.3854\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9502 - val_loss: 9.4372\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9610 - val_loss: 9.7112\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7796 - val_loss: 9.5843\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8767 - val_loss: 9.5256\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7023 - val_loss: 9.3769\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6868 - val_loss: 9.3724\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7272 - val_loss: 9.3932\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8270 - val_loss: 9.3491\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7340 - val_loss: 9.3788\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.6728 - val_loss: 9.3860\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6893 - val_loss: 9.3350\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.104 - 0s 107us/step - loss: 5.7594 - val_loss: 9.5427\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8299 - val_loss: 9.3281\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9007 - val_loss: 9.5993\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8887 - val_loss: 9.0716\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9569 - val_loss: 9.3149\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8127 - val_loss: 9.2562\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8689 - val_loss: 9.6065\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7322 - val_loss: 9.4465\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9787 - val_loss: 9.5904\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8076 - val_loss: 9.3098\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9608 - val_loss: 9.2373\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7100 - val_loss: 9.2791\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6565 - val_loss: 9.2611\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7727 - val_loss: 9.3593\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9231 - val_loss: 9.1749\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1801 - val_loss: 9.8524\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0083 - val_loss: 9.1722\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6837 - val_loss: 9.3238\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7538 - val_loss: 9.2598\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8951 - val_loss: 9.4050\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9851 - val_loss: 9.4997\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7015 - val_loss: 9.2328\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7462 - val_loss: 9.3670\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7432 - val_loss: 9.1358\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6758 - val_loss: 9.1374\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7529 - val_loss: 9.4136\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6445 - val_loss: 9.2189\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6063 - val_loss: 9.4041\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6784 - val_loss: 9.1723\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7165 - val_loss: 9.2831\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7316 - val_loss: 9.2465\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6920 - val_loss: 9.1034\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7776 - val_loss: 9.2353\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6761 - val_loss: 9.2332\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7521 - val_loss: 9.2809\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6552 - val_loss: 9.2507\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7853 - val_loss: 9.2856\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6588 - val_loss: 9.4584\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8259 - val_loss: 9.2284\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6624 - val_loss: 9.2997\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8167 - val_loss: 9.0493\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7296 - val_loss: 9.2879\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8983 - val_loss: 9.2573\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6218 - val_loss: 9.2505\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6490 - val_loss: 9.2756\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6944 - val_loss: 9.2166\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8901 - val_loss: 9.2357\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8730 - val_loss: 9.0032\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6258 - val_loss: 9.3204\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6518 - val_loss: 9.1175\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6157 - val_loss: 9.2249\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6944 - val_loss: 9.2561\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8084 - val_loss: 9.4003\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6446 - val_loss: 9.2116\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7509 - val_loss: 9.1750\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7288 - val_loss: 8.9235\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6736 - val_loss: 9.1135\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6281 - val_loss: 9.1027\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6068 - val_loss: 9.0330\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7329 - val_loss: 9.0701\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6422 - val_loss: 9.2197\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6198 - val_loss: 8.9924\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6998 - val_loss: 8.9951\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6652 - val_loss: 9.1770\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6032 - val_loss: 9.1838\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6480 - val_loss: 9.2044\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7683 - val_loss: 8.9858\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8985 - val_loss: 9.2650\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8905 - val_loss: 9.1673\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6518 - val_loss: 9.0509\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6184 - val_loss: 9.3253\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6996 - val_loss: 9.2339\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5722 - val_loss: 9.3013\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7263 - val_loss: 9.1355\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5899 - val_loss: 9.0308\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.9086 - val_loss: 9.1681\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9603 - val_loss: 9.1742\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0134 - val_loss: 9.2052\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9319 - val_loss: 9.0353\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8974 - val_loss: 9.2558\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7642 - val_loss: 8.8104\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6107 - val_loss: 9.1839\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5816 - val_loss: 9.0273\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5503 - val_loss: 9.2901\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5585 - val_loss: 9.0367\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6486 - val_loss: 8.9738\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5662 - val_loss: 9.0262\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6623 - val_loss: 9.0475\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8380 - val_loss: 9.2563\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5873 - val_loss: 9.0857\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6766 - val_loss: 9.2005\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5908 - val_loss: 9.0153\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8104 - val_loss: 8.9353\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6040 - val_loss: 9.1517\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6424 - val_loss: 8.9016\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6104 - val_loss: 9.2306\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 5.7104 - val_loss: 9.0329\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 5.6267 - val_loss: 9.1788\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5854 - val_loss: 8.9600\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5416 - val_loss: 9.0288\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5727 - val_loss: 9.1009\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5818 - val_loss: 9.1392\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4963 - val_loss: 9.1195\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5767 - val_loss: 9.0937\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6906 - val_loss: 8.9133\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7223 - val_loss: 8.9522\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5800 - val_loss: 9.2724\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6692 - val_loss: 9.1266\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8738 - val_loss: 9.3010\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7230 - val_loss: 8.8209\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8633 - val_loss: 9.2169\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7405 - val_loss: 8.9199\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6692 - val_loss: 9.1939\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6433 - val_loss: 8.9283\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6401 - val_loss: 9.2151\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6285 - val_loss: 8.9739\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5703 - val_loss: 9.2247\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8998 - val_loss: 9.3080\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7965 - val_loss: 9.5027\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7721 - val_loss: 8.9866\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5833 - val_loss: 9.0109\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5426 - val_loss: 9.3964\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5933 - val_loss: 9.1428\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5543 - val_loss: 9.0865\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6497 - val_loss: 9.2113\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7216 - val_loss: 8.9692\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5461 - val_loss: 8.9788\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5103 - val_loss: 9.2309\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5159 - val_loss: 9.2723\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5410 - val_loss: 9.1804\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5904 - val_loss: 9.2103\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4726 - val_loss: 8.8739\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6104 - val_loss: 9.0557\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4863 - val_loss: 9.0740\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5251 - val_loss: 9.3085\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6480 - val_loss: 9.0718\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6014 - val_loss: 9.0662\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5459 - val_loss: 9.0399\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4749 - val_loss: 9.1423\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.6299 - val_loss: 9.0844\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6135 - val_loss: 8.9232\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5904 - val_loss: 9.2073\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7023 - val_loss: 8.9937\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5202 - val_loss: 9.3311\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5716 - val_loss: 9.1382\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5886 - val_loss: 9.2535\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5093 - val_loss: 9.1976\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5378 - val_loss: 9.3766\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9461 - val_loss: 9.0721\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7234 - val_loss: 9.5478\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4668 - val_loss: 8.9997\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5498 - val_loss: 9.1630\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5565 - val_loss: 9.1882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7267 - val_loss: 9.1115\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4789 - val_loss: 9.3047\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5394 - val_loss: 8.9981\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6532 - val_loss: 9.2472\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7189 - val_loss: 9.0708\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6586 - val_loss: 9.1494\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4207 - val_loss: 9.1824\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6401 - val_loss: 9.4888\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6363 - val_loss: 9.2093\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.5743 - val_loss: 9.2798\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5596 - val_loss: 9.1653\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5674 - val_loss: 9.0911\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4884 - val_loss: 9.1653\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5160 - val_loss: 9.1866\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4808 - val_loss: 9.4119\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6337 - val_loss: 9.3145\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7898 - val_loss: 9.5828\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5267 - val_loss: 9.0766\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6440 - val_loss: 9.4814\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5951 - val_loss: 9.3118\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6502 - val_loss: 9.7451\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8355 - val_loss: 9.2003\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6374 - val_loss: 9.2574\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4859 - val_loss: 9.2869\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5296 - val_loss: 9.2876\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4484 - val_loss: 9.3128\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5620 - val_loss: 9.4678\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4776 - val_loss: 9.1499\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4907 - val_loss: 9.1149\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4985 - val_loss: 9.4170\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5586 - val_loss: 9.4177\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4729 - val_loss: 9.4133\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4871 - val_loss: 9.3338\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4526 - val_loss: 9.0919\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5339 - val_loss: 9.0280\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5710 - val_loss: 9.3350\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5274 - val_loss: 9.4789\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6093 - val_loss: 9.2977\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5158 - val_loss: 9.1157\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5157 - val_loss: 8.9678\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.4274 - val_loss: 9.1851\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4546 - val_loss: 9.3528\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4556 - val_loss: 9.1712\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5255 - val_loss: 9.1289\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4796 - val_loss: 9.2844\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4217 - val_loss: 9.4487\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4856 - val_loss: 9.5869\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6719 - val_loss: 9.3915\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6798 - val_loss: 9.2737\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5540 - val_loss: 9.4908\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5172 - val_loss: 9.4171\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6698 - val_loss: 9.5301\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4462 - val_loss: 9.3266\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5853 - val_loss: 9.6304\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6178 - val_loss: 9.3758\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5867 - val_loss: 9.4991\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4509 - val_loss: 9.1231\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4945 - val_loss: 9.1820\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4595 - val_loss: 9.5520\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9121 - val_loss: 9.4491\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0386 - val_loss: 9.9016\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8014 - val_loss: 9.3470\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6725 - val_loss: 9.9173\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7732 - val_loss: 9.6601\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9815 - val_loss: 9.8213\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6873 - val_loss: 9.1898\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7588 - val_loss: 9.5016\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7270 - val_loss: 9.1317\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7802 - val_loss: 9.4118\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5972 - val_loss: 9.3351\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4895 - val_loss: 9.3771\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4809 - val_loss: 9.4091\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4636 - val_loss: 9.4092\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5328 - val_loss: 9.3528\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4125 - val_loss: 9.4476\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4926 - val_loss: 9.4411\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5324 - val_loss: 9.1408\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.4534 - val_loss: 9.3213\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5753 - val_loss: 9.3439\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6060 - val_loss: 9.4066\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7579 - val_loss: 9.3756\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6868 - val_loss: 9.3149\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6008 - val_loss: 9.4127\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5281 - val_loss: 9.2357\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6068 - val_loss: 9.4345\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5334 - val_loss: 9.3161\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4766 - val_loss: 9.4831\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6714 - val_loss: 9.5422\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5424 - val_loss: 9.0950\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4669 - val_loss: 9.3072\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4534 - val_loss: 9.4832\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5173 - val_loss: 9.6355\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6771 - val_loss: 9.4711\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6270 - val_loss: 9.7558\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4509 - val_loss: 9.3642\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4433 - val_loss: 9.4780\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5530 - val_loss: 9.6436\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4690 - val_loss: 9.4408\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4498 - val_loss: 9.2393\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4937 - val_loss: 9.3301\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5015 - val_loss: 9.2772\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4267 - val_loss: 9.4978\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4357 - val_loss: 9.2263\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7130 - val_loss: 9.2710\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5507 - val_loss: 9.3577\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6036 - val_loss: 9.2545\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3672 - val_loss: 9.3171\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6259 - val_loss: 9.3942\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5105 - val_loss: 9.4283\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5361 - val_loss: 9.6388\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6233 - val_loss: 9.3681\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4060 - val_loss: 9.4560\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5318 - val_loss: 9.2547\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4932 - val_loss: 9.3933\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5699 - val_loss: 9.6201\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5103 - val_loss: 9.4157\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4480 - val_loss: 9.3401\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5304 - val_loss: 9.3699\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3902 - val_loss: 9.2405\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5335 - val_loss: 9.5439\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6175 - val_loss: 9.3519\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8340 - val_loss: 9.2826\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5392 - val_loss: 9.5206\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3722 - val_loss: 9.3146\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5459 - val_loss: 9.4689\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9993 - val_loss: 9.8543\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8929 - val_loss: 9.4402\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5912 - val_loss: 9.6265\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5311 - val_loss: 9.2892\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4015 - val_loss: 9.4188\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4504 - val_loss: 9.4853\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5088 - val_loss: 9.2903\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4762 - val_loss: 9.4798\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6851 - val_loss: 9.1947\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5268 - val_loss: 9.4468\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4947 - val_loss: 9.2817\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4809 - val_loss: 9.4978\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8185 - val_loss: 9.4520\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5469 - val_loss: 9.5099\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4553 - val_loss: 9.2745\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5330 - val_loss: 9.2152\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4831 - val_loss: 9.4362\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4053 - val_loss: 9.4035\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4639 - val_loss: 9.5453\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4498 - val_loss: 9.4414\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5067 - val_loss: 9.2591\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4328 - val_loss: 9.4726\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4080 - val_loss: 9.6171\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4108 - val_loss: 9.3531\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5214 - val_loss: 9.4670\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4525 - val_loss: 9.4085\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5396 - val_loss: 9.3387\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4564 - val_loss: 9.3768\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4100 - val_loss: 9.4301\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.3993 - val_loss: 9.4731\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3833 - val_loss: 9.3669\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5087 - val_loss: 9.3648\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5505 - val_loss: 9.5490\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3594 - val_loss: 9.5351\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3596 - val_loss: 9.4612\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3380 - val_loss: 9.3109\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4761 - val_loss: 9.4237\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4086 - val_loss: 9.4284\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5316 - val_loss: 9.3585\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6312 - val_loss: 9.6011\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3904 - val_loss: 9.4191\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5194 - val_loss: 9.4941\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4310 - val_loss: 9.6592\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5658 - val_loss: 9.4103\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5675 - val_loss: 9.8383\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5160 - val_loss: 9.4507\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4481 - val_loss: 9.6185\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4675 - val_loss: 9.6402\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4463 - val_loss: 9.5687\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4025 - val_loss: 9.3951\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5520 - val_loss: 9.3497\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8524 - val_loss: 9.3861\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9392 - val_loss: 9.9027\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4216 - val_loss: 9.4493\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4955 - val_loss: 9.4921\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4824 - val_loss: 9.3328\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5459 - val_loss: 9.4803\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4262 - val_loss: 9.3456\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4455 - val_loss: 9.5195\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3919 - val_loss: 9.3397\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3349 - val_loss: 9.4644\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4477 - val_loss: 9.4816\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4218 - val_loss: 9.4648\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3538 - val_loss: 9.5716\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4187 - val_loss: 9.5819\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4007 - val_loss: 9.5490\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3766 - val_loss: 9.3574\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3689 - val_loss: 9.6110\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3668 - val_loss: 9.3792\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3634 - val_loss: 9.4001\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4235 - val_loss: 9.2613\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4604 - val_loss: 9.4465\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5944 - val_loss: 9.9056\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6515 - val_loss: 9.2585\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5302 - val_loss: 9.5791\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4983 - val_loss: 9.4566\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3482 - val_loss: 9.5525\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4365 - val_loss: 9.5188\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6138 - val_loss: 9.7471\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6112 - val_loss: 9.4112\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6703 - val_loss: 9.6789\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5641 - val_loss: 9.5239\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4101 - val_loss: 9.6881\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4876 - val_loss: 9.3369\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6236 - val_loss: 9.6664\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5032 - val_loss: 9.6338\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7724 - val_loss: 9.9660\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7920 - val_loss: 9.4260\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9307 - val_loss: 9.7591\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7904 - val_loss: 9.2018\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5451 - val_loss: 9.4541\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3300 - val_loss: 9.4499\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4556 - val_loss: 9.5809\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5433 - val_loss: 9.7046\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3816 - val_loss: 9.5923\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4645 - val_loss: 9.5650\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3650 - val_loss: 9.5292\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3514 - val_loss: 9.7844\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3419 - val_loss: 9.6936\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4077 - val_loss: 9.6320\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4130 - val_loss: 9.8673\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4042 - val_loss: 9.5996\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4256 - val_loss: 9.8966\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3796 - val_loss: 9.7162\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3635 - val_loss: 9.6926\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3534 - val_loss: 9.3796\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4680 - val_loss: 9.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4230 - val_loss: 9.5988\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5649 - val_loss: 9.5548\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4840 - val_loss: 9.7619\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6028 - val_loss: 9.6864\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3722 - val_loss: 9.8359\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3376 - val_loss: 9.5987\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.3963 - val_loss: 9.4693\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3596 - val_loss: 9.5421\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4249 - val_loss: 9.6621\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4515 - val_loss: 9.4692\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4293 - val_loss: 9.7186\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4851 - val_loss: 9.5008\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3938 - val_loss: 9.5023\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3536 - val_loss: 9.6433\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4115 - val_loss: 9.9308\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4385 - val_loss: 9.6566\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7225 - val_loss: 9.8164\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8845 - val_loss: 9.5377\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5175 - val_loss: 9.7972\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4169 - val_loss: 9.6788\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4119 - val_loss: 9.7014\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4731 - val_loss: 9.4359\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4482 - val_loss: 9.9095\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5920 - val_loss: 9.7561\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3297 - val_loss: 9.7769\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3984 - val_loss: 9.5084\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3027 - val_loss: 9.7464\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3789 - val_loss: 9.8295\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3396 - val_loss: 9.7350\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3471 - val_loss: 9.7544\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4187 - val_loss: 9.7663\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3053 - val_loss: 9.7698\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4094 - val_loss: 9.7778\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3446 - val_loss: 9.6197\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3854 - val_loss: 9.7399\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4161 - val_loss: 9.7435\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3621 - val_loss: 9.6219\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4722 - val_loss: 9.8341\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7152 - val_loss: 9.5612\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4626 - val_loss: 9.7168\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5109 - val_loss: 9.6994\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3295 - val_loss: 9.8887\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6317 - val_loss: 9.7523\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4118 - val_loss: 10.0591\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5187 - val_loss: 9.8798\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6379 - val_loss: 9.9758\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3911 - val_loss: 9.5245\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5848 - val_loss: 9.8979\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5780 - val_loss: 9.8018\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3754 - val_loss: 9.8108\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2874 - val_loss: 9.9235\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3996 - val_loss: 10.0067\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4396 - val_loss: 9.8259\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3724 - val_loss: 10.0090\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3161 - val_loss: 9.8815\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3423 - val_loss: 9.7116\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3823 - val_loss: 9.8816\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3606 - val_loss: 10.0131\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2995 - val_loss: 10.0086\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3639 - val_loss: 9.8397\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2971 - val_loss: 9.8738\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2926 - val_loss: 9.8253\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3091 - val_loss: 9.8373\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5154 - val_loss: 9.8552\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3651 - val_loss: 9.9737\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3169 - val_loss: 9.9185\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3119 - val_loss: 9.9050\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4107 - val_loss: 9.9189\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3360 - val_loss: 9.9596\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4080 - val_loss: 10.2450\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2924 - val_loss: 9.9470\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3348 - val_loss: 10.0712\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3004 - val_loss: 9.9038\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3331 - val_loss: 10.0139\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4172 - val_loss: 9.8948\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6119 - val_loss: 10.0974\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3735 - val_loss: 9.9552\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.3465 - val_loss: 10.1320\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2471 - val_loss: 10.2638\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3070 - val_loss: 10.0918\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3428 - val_loss: 9.9823\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2730 - val_loss: 10.1154\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3931 - val_loss: 10.0652\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5203 - val_loss: 10.2252\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9406 - val_loss: 9.8520\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2940 - val_loss: 9.9758\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3007 - val_loss: 10.0860\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2910 - val_loss: 10.1502\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4142 - val_loss: 9.9885\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.477 - 0s 99us/step - loss: 5.4658 - val_loss: 10.1329\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3423 - val_loss: 10.1139\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3324 - val_loss: 10.1382\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4532 - val_loss: 10.1610\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4686 - val_loss: 10.2082\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3145 - val_loss: 9.8632\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3040 - val_loss: 10.4129\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4091 - val_loss: 10.3780\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3187 - val_loss: 10.0746\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4353 - val_loss: 10.4072\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1862 - val_loss: 10.0608\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4331 - val_loss: 10.5170\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3450 - val_loss: 10.1551\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3522 - val_loss: 10.1239\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3173 - val_loss: 10.2442\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3176 - val_loss: 10.1218\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3343 - val_loss: 10.3782\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2905 - val_loss: 9.9920\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6778 - val_loss: 10.1836\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4189 - val_loss: 10.2118\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3181 - val_loss: 10.4517\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7189 - val_loss: 10.5776\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4558 - val_loss: 10.3254\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5564 - val_loss: 10.3895\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3761 - val_loss: 10.2304\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4421 - val_loss: 10.1275\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3611 - val_loss: 10.1385\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2948 - val_loss: 10.3171\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2139 - val_loss: 10.5247\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3645 - val_loss: 10.2409\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5154 - val_loss: 10.1469\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6372 - val_loss: 10.2994\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6082 - val_loss: 10.1821\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7278 - val_loss: 10.8370\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5251 - val_loss: 10.1208\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2575 - val_loss: 10.1780\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1849 - val_loss: 10.3370\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1891 - val_loss: 10.2640\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2535 - val_loss: 10.0765\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2008 - val_loss: 10.0546\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2830 - val_loss: 10.3250\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2366 - val_loss: 10.4036\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2417 - val_loss: 10.4248\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1726 - val_loss: 10.0842\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1964 - val_loss: 10.2353\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3217 - val_loss: 10.2946\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1841 - val_loss: 10.3359\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2649 - val_loss: 9.8861\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2191 - val_loss: 9.9471\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4062 - val_loss: 10.4231\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3500 - val_loss: 10.5351\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3268 - val_loss: 10.1269\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2593 - val_loss: 10.1531\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1951 - val_loss: 10.0302\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1983 - val_loss: 10.1666\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2389 - val_loss: 10.2945\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2703 - val_loss: 10.4623\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2763 - val_loss: 10.3299\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1996 - val_loss: 10.0223\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3486 - val_loss: 10.1573\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3296 - val_loss: 10.1135\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3211 - val_loss: 10.3641\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2253 - val_loss: 10.2738\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3437 - val_loss: 10.1688\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2666 - val_loss: 10.0607\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 100us/step - loss: 5.1868 - val_loss: 10.2514\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2767 - val_loss: 10.1947\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2795 - val_loss: 9.8882\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2147 - val_loss: 10.2109\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2668 - val_loss: 10.3818\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4109 - val_loss: 10.2858\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7405 - val_loss: 10.5659\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2999 - val_loss: 10.0849\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2084 - val_loss: 10.5116\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1712 - val_loss: 10.3827\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3441 - val_loss: 10.2974\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1854 - val_loss: 10.5874\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2124 - val_loss: 10.0542\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2394 - val_loss: 10.1478\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3338 - val_loss: 10.2921\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1457 - val_loss: 10.1660\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2104 - val_loss: 10.2944\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1638 - val_loss: 10.3774\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1681 - val_loss: 10.0163\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2355 - val_loss: 9.9397\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1875 - val_loss: 10.5951\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2631 - val_loss: 10.4702\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3163 - val_loss: 10.3328\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4409 - val_loss: 10.1804\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2825 - val_loss: 9.9278\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1752 - val_loss: 10.4088\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3269 - val_loss: 10.0621\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1627 - val_loss: 10.5465\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2128 - val_loss: 10.3576\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1589 - val_loss: 10.3115\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1187 - val_loss: 10.1772\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2148 - val_loss: 9.9332\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2312 - val_loss: 10.4053\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1894 - val_loss: 10.2936\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2463 - val_loss: 10.5021\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1765 - val_loss: 10.1343\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2387 - val_loss: 10.0984\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1935 - val_loss: 10.3120\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1196 - val_loss: 10.2178\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2064 - val_loss: 10.1390\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3709 - val_loss: 10.2996\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.4430 - val_loss: 10.1728\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1691 - val_loss: 10.4447\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2535 - val_loss: 10.1713\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2174 - val_loss: 10.2655\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2682 - val_loss: 10.3425\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1895 - val_loss: 10.3092\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2201 - val_loss: 10.2300\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2021 - val_loss: 9.9506\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1161 - val_loss: 9.9574\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1889 - val_loss: 10.1603\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2627 - val_loss: 9.9652\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2638 - val_loss: 10.3282\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2260 - val_loss: 10.2231\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2241 - val_loss: 10.3934\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2013 - val_loss: 10.2728\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4666 - val_loss: 10.4132\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2644 - val_loss: 10.1335\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2589 - val_loss: 10.6116\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5922 - val_loss: 10.5207\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4360 - val_loss: 10.3395\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2973 - val_loss: 10.4590\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2586 - val_loss: 10.1197\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1553 - val_loss: 10.4403\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3315 - val_loss: 10.3862\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1475 - val_loss: 10.5543\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1356 - val_loss: 10.4206\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1798 - val_loss: 10.3144\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2401 - val_loss: 10.3445\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1117 - val_loss: 10.5097\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2146 - val_loss: 10.6101\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4524 - val_loss: 10.3090\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5375 - val_loss: 10.2698\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1760 - val_loss: 10.1041\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1530 - val_loss: 10.4576\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2670 - val_loss: 10.4596\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4779 - val_loss: 10.3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5141 - val_loss: 10.5604\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2454 - val_loss: 10.4989\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2077 - val_loss: 10.1817\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4504 - val_loss: 10.2902\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2311 - val_loss: 10.4967\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1772 - val_loss: 10.2111\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1074 - val_loss: 10.2704\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2256 - val_loss: 10.4437\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1243 - val_loss: 10.4312\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1826 - val_loss: 10.3696\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2808 - val_loss: 10.4809\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4045 - val_loss: 10.3291\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1576 - val_loss: 10.3341\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1379 - val_loss: 10.2181\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1094 - val_loss: 10.4586\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3277 - val_loss: 10.3926\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2796 - val_loss: 10.4847\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1375 - val_loss: 10.3861\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1027 - val_loss: 10.1690\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0901 - val_loss: 10.2398\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1851 - val_loss: 10.3103\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2430 - val_loss: 10.0892\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4066 - val_loss: 10.3498\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4437 - val_loss: 10.4057\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1825 - val_loss: 10.5965\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3315 - val_loss: 10.3320\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1151 - val_loss: 10.4865\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2574 - val_loss: 10.3510\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2034 - val_loss: 10.0938\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2722 - val_loss: 10.6762\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0951 - val_loss: 10.4713\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1288 - val_loss: 10.3000\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1646 - val_loss: 10.2276\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1260 - val_loss: 10.3998\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2267 - val_loss: 10.7821\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1150 - val_loss: 10.4629\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1319 - val_loss: 10.4178\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2647 - val_loss: 10.2612\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1959 - val_loss: 10.6698\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1157 - val_loss: 10.4252\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0894 - val_loss: 10.7817\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2082 - val_loss: 10.5688\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1361 - val_loss: 10.6086\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0730 - val_loss: 10.4502\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1092 - val_loss: 10.6241\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1099 - val_loss: 10.5745\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0706 - val_loss: 10.4370\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1373 - val_loss: 10.4200\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1490 - val_loss: 10.4113\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2056 - val_loss: 10.5310\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2207 - val_loss: 10.3480\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1048 - val_loss: 10.5476\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0712 - val_loss: 10.4050\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1271 - val_loss: 10.6374\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2084 - val_loss: 10.4369\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2243 - val_loss: 10.3070\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0797 - val_loss: 10.3577\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1458 - val_loss: 10.5735\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2008 - val_loss: 10.6067\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1930 - val_loss: 10.5991\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4304 - val_loss: 10.5161\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1626 - val_loss: 10.6100\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0919 - val_loss: 10.5372\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1620 - val_loss: 10.5356\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1147 - val_loss: 10.4630\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2295 - val_loss: 10.7042\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1605 - val_loss: 10.4688\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2343 - val_loss: 10.5419\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1781 - val_loss: 10.3576\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1888 - val_loss: 10.3349\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1863 - val_loss: 10.4302\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0898 - val_loss: 10.3798\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0404 - val_loss: 10.8026\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1230 - val_loss: 10.6196\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0832 - val_loss: 10.6160\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.0764 - val_loss: 10.2676\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0837 - val_loss: 10.3949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0777 - val_loss: 10.2330\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0869 - val_loss: 10.5403\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0950 - val_loss: 10.5324\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1936 - val_loss: 10.4793\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2417 - val_loss: 10.4618\n",
      "7.332846851672157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.1355858 ,  0.9510411 , -1.1605895 , -1.9713963 , -2.5113869 ],\n",
       "        [ 0.43269494,  0.5585832 ,  0.5111336 ,  1.8473979 ,  1.9089156 ],\n",
       "        [-0.10188517, -0.730202  ,  0.40698844, -0.1939    , -1.8813479 ],\n",
       "        [-0.96071243, -1.7670507 ,  0.49660054, -2.3780797 , -2.053761  ],\n",
       "        [-0.4412832 , -0.00680008,  0.74298537,  1.3900087 , -0.01158761],\n",
       "        [ 1.1548195 ,  1.2759582 , -0.43926668,  1.1732944 ,  0.95736253],\n",
       "        [ 1.2927997 ,  0.76727563, -1.4178784 , -0.7417816 ,  0.7567058 ]],\n",
       "       dtype=float32),\n",
       " array([-2.9462733, -2.2932255, -1.8466849,  2.0596015, -2.0462449],\n",
       "       dtype=float32),\n",
       " array([[-0.15562584, -0.125597  ,  0.99511504,  0.29056546, -0.5252284 ,\n",
       "         -0.22972518,  0.7135412 ,  0.6575368 ,  0.4899408 ,  0.60307455],\n",
       "        [ 0.90416306,  0.72518164, -0.6779449 , -1.3438253 ,  0.37544405,\n",
       "          1.2401313 , -0.29122335, -0.64681625, -0.51080805, -0.51136935],\n",
       "        [-0.6325647 ,  0.02354745,  0.36745098, -0.68360955, -0.69639015,\n",
       "         -0.52783155, -0.06390235, -0.2491743 ,  0.4795421 ,  0.1374735 ],\n",
       "        [ 0.5280531 ,  0.7025251 , -0.0015601 ,  1.0096886 ,  0.6984489 ,\n",
       "          0.21977775,  0.00447176, -0.04060934, -0.3730232 ,  0.08815946],\n",
       "        [-0.05970434,  0.39885327, -0.52527225, -0.861139  ,  0.24932013,\n",
       "          0.09585536, -0.29189226, -0.92101663, -0.3617618 , -0.08520904]],\n",
       "       dtype=float32),\n",
       " array([ 1.7768335,  1.8065152, -1.7696441, -1.2901188,  1.7339442,\n",
       "         1.7906011, -1.6914295, -1.7785454, -1.7498806, -1.6187807],\n",
       "       dtype=float32),\n",
       " array([[ 1.555503  ],\n",
       "        [ 1.2665247 ],\n",
       "        [-1.175595  ],\n",
       "        [-0.5699391 ],\n",
       "        [ 1.2865887 ],\n",
       "        [ 1.6908913 ],\n",
       "        [-0.80131274],\n",
       "        [-1.388468  ],\n",
       "        [-1.365541  ],\n",
       "        [-0.9665715 ]], dtype=float32),\n",
       " array([1.6798017], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_adam_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 507us/step - loss: 605.1216 - val_loss: 640.6671\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 603.6480 - val_loss: 638.6114\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 601.5781 - val_loss: 636.3001\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 599.3737 - val_loss: 633.8206\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 597.0316 - val_loss: 631.3019\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 594.6857 - val_loss: 628.7367\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 592.2798 - val_loss: 626.2139\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 589.9444 - val_loss: 623.6284\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 587.5583 - val_loss: 621.0540\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 585.1426 - val_loss: 618.4978\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 582.7534 - val_loss: 615.9236\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 580.3910 - val_loss: 613.3156\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 577.9600 - val_loss: 610.7490\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 575.5774 - val_loss: 608.1614\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 573.1221 - val_loss: 605.6086\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 570.7613 - val_loss: 602.9902\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 568.3139 - val_loss: 600.3770\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 565.8560 - val_loss: 597.7849\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 563.4271 - val_loss: 595.1768\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 560.9733 - val_loss: 592.5870\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 558.5175 - val_loss: 589.9774\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 556.1012 - val_loss: 587.2854\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 553.5557 - val_loss: 584.6109\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 551.0262 - val_loss: 581.9105\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 548.4512 - val_loss: 579.2214\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 545.8913 - val_loss: 576.4761\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 543.2956 - val_loss: 573.6999\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 540.6508 - val_loss: 570.9242\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 538.0496 - val_loss: 568.0498\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 535.3376 - val_loss: 565.2017\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 532.6287 - val_loss: 562.3397\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 529.9055 - val_loss: 559.4415\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 527.1660 - val_loss: 556.4982\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 524.3525 - val_loss: 553.5723\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 521.6001 - val_loss: 550.5868\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 518.7904 - val_loss: 547.5648\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 515.8679 - val_loss: 544.6028\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 513.0698 - val_loss: 541.5114\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 510.0884 - val_loss: 538.4335\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 507.1566 - val_loss: 535.2943\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 504.2215 - val_loss: 532.0870\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 501.1606 - val_loss: 528.9051\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 498.1084 - val_loss: 525.7009\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 495.0222 - val_loss: 522.4756\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 491.9416 - val_loss: 519.1608\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 488.7361 - val_loss: 515.8361\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 485.5710 - val_loss: 512.4280\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 482.3336 - val_loss: 509.0055\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 479.0920 - val_loss: 505.5032\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 475.7374 - val_loss: 501.9679\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 472.3674 - val_loss: 498.3830\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 468.9324 - val_loss: 494.7813\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 465.4699 - val_loss: 491.1236\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 461.9502 - val_loss: 487.4227\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 458.3827 - val_loss: 483.6548\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 454.7921 - val_loss: 479.7883\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 451.0773 - val_loss: 475.8883\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 447.3833 - val_loss: 471.8947\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 443.5183 - val_loss: 467.9316\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 439.7356 - val_loss: 463.8439\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 435.8301 - val_loss: 459.6795\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 431.8488 - val_loss: 455.4936\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 427.7979 - val_loss: 451.2853\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 423.7768 - val_loss: 446.9887\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 419.6209 - val_loss: 442.6639\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 415.4620 - val_loss: 438.2405\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 411.2282 - val_loss: 433.7396\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 406.8926 - val_loss: 429.1972\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 402.5758 - val_loss: 424.5938\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 398.1378 - val_loss: 419.9644\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 393.7175 - val_loss: 415.2250\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 389.1665 - val_loss: 410.4576\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 384.5905 - val_loss: 405.6636\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 380.0165 - val_loss: 400.7815\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 375.2937 - val_loss: 395.8674\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 370.5872 - val_loss: 390.8411\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 365.7750 - val_loss: 385.7830\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 360.9153 - val_loss: 380.6684\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 355.9775 - val_loss: 375.4790\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 351.0618 - val_loss: 370.2164\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 345.9530 - val_loss: 365.0011\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 340.9529 - val_loss: 359.6519\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 335.8494 - val_loss: 354.2107\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 330.6872 - val_loss: 348.7272\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 325.3926 - val_loss: 343.3250\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 320.1689 - val_loss: 337.8357\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 314.9646 - val_loss: 332.2061\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 309.5592 - val_loss: 326.6639\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 304.2888 - val_loss: 321.0331\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 298.8889 - val_loss: 315.4138\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 293.5527 - val_loss: 309.7565\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 288.1916 - val_loss: 304.0613\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 332.339 - 0s 95us/step - loss: 282.7929 - val_loss: 298.3456\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 277.2772 - val_loss: 292.7138\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 271.9323 - val_loss: 286.9875\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 266.5009 - val_loss: 281.2779\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 261.0057 - val_loss: 275.6774\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 255.6830 - val_loss: 269.9863\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 250.2782 - val_loss: 264.2828\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 244.8503 - val_loss: 258.6078\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 239.4929 - val_loss: 252.9278\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 234.1714 - val_loss: 247.2846\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 228.8480 - val_loss: 241.6766\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 223.4672 - val_loss: 236.1951\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 218.3242 - val_loss: 230.6528\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 213.0125 - val_loss: 225.2843\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 207.8740 - val_loss: 219.9001\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 202.8032 - val_loss: 214.4585\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 197.6607 - val_loss: 209.0921\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 192.5830 - val_loss: 203.7881\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 187.6071 - val_loss: 198.5321\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 182.6814 - val_loss: 193.3449\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 177.7509 - val_loss: 188.2726\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 172.9505 - val_loss: 183.2844\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 168.2312 - val_loss: 178.3737\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 163.5993 - val_loss: 173.5157\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 158.9981 - val_loss: 168.7335\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 154.4568 - val_loss: 164.0231\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 150.0234 - val_loss: 159.3694\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 145.6604 - val_loss: 154.7762\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 141.3327 - val_loss: 150.3057\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 137.1119 - val_loss: 145.9150\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 133.0264 - val_loss: 141.5825\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 128.9759 - val_loss: 137.3983\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 125.0017 - val_loss: 133.3787\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 121.2365 - val_loss: 129.3950\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 117.5299 - val_loss: 125.4885\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 113.8408 - val_loss: 121.7157\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 110.3000 - val_loss: 117.9940\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 106.8144 - val_loss: 114.4151\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 103.4550 - val_loss: 110.9302\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 100.1729 - val_loss: 107.5368\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 96.9851 - val_loss: 104.2094\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 93.8833 - val_loss: 100.9676\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 90.8474 - val_loss: 97.8553\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 87.9282 - val_loss: 94.8101\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 85.1197 - val_loss: 91.8375\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 82.3272 - val_loss: 89.0351\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 79.7346 - val_loss: 86.2986\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 77.1629 - val_loss: 83.6811\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 74.6766 - val_loss: 81.1482\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 72.3212 - val_loss: 78.6427\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 69.9606 - val_loss: 76.2652\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 67.7746 - val_loss: 73.9597\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 65.5813 - val_loss: 71.8173\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 63.5860 - val_loss: 69.6817\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 61.6340 - val_loss: 67.6205\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 59.7124 - val_loss: 65.6642\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 57.8830 - val_loss: 63.7820\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 56.0883 - val_loss: 62.0132\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 54.4782 - val_loss: 60.2274\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 52.7819 - val_loss: 58.5815\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 51.2779 - val_loss: 56.9666\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 49.7870 - val_loss: 55.4323\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 48.3781 - val_loss: 53.9516\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 46.9860 - val_loss: 52.5502\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 45.6828 - val_loss: 51.2112\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 44.4567 - val_loss: 49.9328\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 43.2782 - val_loss: 48.7153\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 42.1481 - val_loss: 47.5566\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 41.0781 - val_loss: 46.4577\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 40.0674 - val_loss: 45.4010\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 39.1066 - val_loss: 44.3801\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 38.1837 - val_loss: 43.4220\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 37.3054 - val_loss: 42.5215\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 36.4513 - val_loss: 41.6862\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 35.6978 - val_loss: 40.8395\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 34.9234 - val_loss: 40.0573\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 34.1977 - val_loss: 39.3362\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 33.5318 - val_loss: 38.6267\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 32.8786 - val_loss: 37.9600\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 32.2690 - val_loss: 37.3202\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 31.7034 - val_loss: 36.7065\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 31.1585 - val_loss: 36.1370\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 30.6399 - val_loss: 35.6056\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 30.1460 - val_loss: 35.0984\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 29.7097 - val_loss: 34.5913\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 29.2312 - val_loss: 34.1475\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 28.8323 - val_loss: 33.6957\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 28.4319 - val_loss: 33.2665\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 28.0492 - val_loss: 32.8567\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 27.6843 - val_loss: 32.4749\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 27.3618 - val_loss: 32.1100\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 27.0432 - val_loss: 31.7731\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 26.7336 - val_loss: 31.4653\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 26.4670 - val_loss: 31.1557\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 26.1882 - val_loss: 30.8714\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 25.9416 - val_loss: 30.5973\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 25.7099 - val_loss: 30.3319\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 25.4711 - val_loss: 30.0834\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 25.2559 - val_loss: 29.8360\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 25.0461 - val_loss: 29.6064\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.8359 - val_loss: 29.3977\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 24.6681 - val_loss: 29.1797\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.4969 - val_loss: 28.9724\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.3076 - val_loss: 28.7932\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 24.1515 - val_loss: 28.6182\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 24.0061 - val_loss: 28.4464\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.8688 - val_loss: 28.2826\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 23.7252 - val_loss: 28.1269\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.5933 - val_loss: 27.9785\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 23.4705 - val_loss: 27.8320\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 23.3504 - val_loss: 27.6910\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 23.2308 - val_loss: 27.5629\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.1342 - val_loss: 27.4212\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 23.0192 - val_loss: 27.2997\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.9308 - val_loss: 27.1753\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 22.8333 - val_loss: 27.0630\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.7456 - val_loss: 26.9590\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.6623 - val_loss: 26.8621\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 22.5820 - val_loss: 26.7707\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.5100 - val_loss: 26.6669\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 22.4315 - val_loss: 26.5762\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 22.3592 - val_loss: 26.4883\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 22.2898 - val_loss: 26.4007\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.2232 - val_loss: 26.3117\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 22.1585 - val_loss: 26.2226\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 22.0890 - val_loss: 26.1423\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.0311 - val_loss: 26.0611\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.9750 - val_loss: 25.9811\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.9116 - val_loss: 25.9119\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.8653 - val_loss: 25.8371\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.8087 - val_loss: 25.7697\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.7598 - val_loss: 25.7028\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.7083 - val_loss: 25.6381\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.6619 - val_loss: 25.5758\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 21.6143 - val_loss: 25.5086\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 21.5644 - val_loss: 25.4442\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.5196 - val_loss: 25.3824\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.4787 - val_loss: 25.3189\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.4324 - val_loss: 25.2622\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.3918 - val_loss: 25.2059\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.3496 - val_loss: 25.1542\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.3130 - val_loss: 25.0974\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.2731 - val_loss: 25.0433\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.2330 - val_loss: 24.9909\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.1966 - val_loss: 24.9353\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.1566 - val_loss: 24.8817\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.1189 - val_loss: 24.8252\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.0823 - val_loss: 24.7696\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.0468 - val_loss: 24.7169\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.0096 - val_loss: 24.6682\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.9786 - val_loss: 24.6161\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.9421 - val_loss: 24.5677\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 20.9082 - val_loss: 24.5195\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.8766 - val_loss: 24.4696\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.8434 - val_loss: 24.4272\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.8101 - val_loss: 24.3774\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 20.7780 - val_loss: 24.3306\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.7471 - val_loss: 24.2825\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 20.7141 - val_loss: 24.2377\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.6840 - val_loss: 24.1958\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.6537 - val_loss: 24.1499\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 20.6218 - val_loss: 24.1070\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.5915 - val_loss: 24.0640\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.5620 - val_loss: 24.0176\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.5298 - val_loss: 23.9743\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.4994 - val_loss: 23.9302\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.4709 - val_loss: 23.8881\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.4417 - val_loss: 23.8479\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.4150 - val_loss: 23.8049\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.3835 - val_loss: 23.7680\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 20.3548 - val_loss: 23.7282\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.3286 - val_loss: 23.6868\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.3012 - val_loss: 23.6487\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.2716 - val_loss: 23.6082\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.2454 - val_loss: 23.5674\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.2172 - val_loss: 23.5301\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.1892 - val_loss: 23.4906\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 20.1615 - val_loss: 23.4537\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 20.1352 - val_loss: 23.4156\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 20.1099 - val_loss: 23.3750\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.0814 - val_loss: 23.3406\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.0560 - val_loss: 23.3052\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 20.0305 - val_loss: 23.2642\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 20.0010 - val_loss: 23.2280\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.9746 - val_loss: 23.1891\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.9504 - val_loss: 23.1490\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.9243 - val_loss: 23.1103\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 19.8966 - val_loss: 23.0764\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.8706 - val_loss: 23.0382\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.8453 - val_loss: 22.9989\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.8176 - val_loss: 22.9621\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.7906 - val_loss: 22.9300\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.7674 - val_loss: 22.8934\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.7410 - val_loss: 22.8616\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.7159 - val_loss: 22.8257\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.6909 - val_loss: 22.7919\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.6652 - val_loss: 22.7592\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.6413 - val_loss: 22.7231\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.6156 - val_loss: 22.6863\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.5913 - val_loss: 22.6523\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.5650 - val_loss: 22.6173\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 19.5409 - val_loss: 22.5847\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 19.5168 - val_loss: 22.5498\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.4907 - val_loss: 22.5170\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 19.4674 - val_loss: 22.4838\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.4424 - val_loss: 22.4519\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 19.4188 - val_loss: 22.4174\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.3958 - val_loss: 22.3831\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 19.3710 - val_loss: 22.3502\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.3493 - val_loss: 22.3192\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 19.3243 - val_loss: 22.2891\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 19.3025 - val_loss: 22.2591\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.2806 - val_loss: 22.2265\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.2563 - val_loss: 22.1989\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.2345 - val_loss: 22.1674\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.2114 - val_loss: 22.1383\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.1877 - val_loss: 22.1078\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.1645 - val_loss: 22.0775\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 19.1415 - val_loss: 22.0482\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.1202 - val_loss: 22.0156\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.0963 - val_loss: 21.9884\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 19.0747 - val_loss: 21.9567\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 19.0517 - val_loss: 21.9273\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.0302 - val_loss: 21.8964\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.0069 - val_loss: 21.8711\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.9855 - val_loss: 21.8425\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.9649 - val_loss: 21.8127\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.9432 - val_loss: 21.7820\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 18.9191 - val_loss: 21.7557\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 18.8966 - val_loss: 21.7278\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.8769 - val_loss: 21.7004\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.8547 - val_loss: 21.6704\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.8333 - val_loss: 21.6416\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.8139 - val_loss: 21.6187\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.7905 - val_loss: 21.5870\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.7697 - val_loss: 21.5589\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 11.05 - 0s 80us/step - loss: 18.7479 - val_loss: 21.5312\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 18.7251 - val_loss: 21.5071\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 18.7045 - val_loss: 21.4774\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.6842 - val_loss: 21.4490\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.6628 - val_loss: 21.4203\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.6405 - val_loss: 21.3942\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 18.6197 - val_loss: 21.3706\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.5993 - val_loss: 21.3426\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.5777 - val_loss: 21.3161\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.5570 - val_loss: 21.2887\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 18.5376 - val_loss: 21.2648\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.5165 - val_loss: 21.2375\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 18.4950 - val_loss: 21.2106\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.4750 - val_loss: 21.1863\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 18.4558 - val_loss: 21.1605\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 18.4343 - val_loss: 21.1349\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.4146 - val_loss: 21.1099\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.3960 - val_loss: 21.0827\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.3745 - val_loss: 21.0580\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.3547 - val_loss: 21.0326\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.3361 - val_loss: 21.0090\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.3150 - val_loss: 20.9843\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.2960 - val_loss: 20.9612\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 18.2750 - val_loss: 20.9393\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 18.2559 - val_loss: 20.9132\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.2372 - val_loss: 20.8874\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.2182 - val_loss: 20.8638\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.1982 - val_loss: 20.8391\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.1793 - val_loss: 20.8142\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 18.1589 - val_loss: 20.7896\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.1386 - val_loss: 20.7640\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.1192 - val_loss: 20.7400\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.1014 - val_loss: 20.7146\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0812 - val_loss: 20.6942\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.0627 - val_loss: 20.6720\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.0438 - val_loss: 20.6491\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0261 - val_loss: 20.6235\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0061 - val_loss: 20.6009\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.9895 - val_loss: 20.5791\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.9703 - val_loss: 20.5567\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.9513 - val_loss: 20.5353\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 76us/step - loss: 17.9329 - val_loss: 20.5150\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.9136 - val_loss: 20.4934\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.8972 - val_loss: 20.4719\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.8796 - val_loss: 20.4469\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.8599 - val_loss: 20.4289\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.8416 - val_loss: 20.4040\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 17.8214 - val_loss: 20.3819\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.8049 - val_loss: 20.3614\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.7858 - val_loss: 20.3387\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7678 - val_loss: 20.3160\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.7497 - val_loss: 20.2950\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7308 - val_loss: 20.2732\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.7135 - val_loss: 20.2512\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.6940 - val_loss: 20.2314\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 17.6774 - val_loss: 20.2097\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.6595 - val_loss: 20.1903\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.6414 - val_loss: 20.1717\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.6246 - val_loss: 20.1486\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.6065 - val_loss: 20.1266\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.5877 - val_loss: 20.1053\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5710 - val_loss: 20.0835\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.5526 - val_loss: 20.0632\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.5362 - val_loss: 20.0392\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5171 - val_loss: 20.0212\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4993 - val_loss: 19.9995\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4820 - val_loss: 19.9789\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4676 - val_loss: 19.9550\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.4475 - val_loss: 19.9363\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.4304 - val_loss: 19.9162\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.4144 - val_loss: 19.8972\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.3974 - val_loss: 19.8763\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.3805 - val_loss: 19.8539\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.3627 - val_loss: 19.8375\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.3457 - val_loss: 19.8176\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.3304 - val_loss: 19.7953\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.3153 - val_loss: 19.7724\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2957 - val_loss: 19.7557\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2793 - val_loss: 19.7383\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2638 - val_loss: 19.7179\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2460 - val_loss: 19.6998\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.2308 - val_loss: 19.6843\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2145 - val_loss: 19.6659\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2003 - val_loss: 19.6447\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1810 - val_loss: 19.6300\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.1675 - val_loss: 19.6169\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1511 - val_loss: 19.5980\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1339 - val_loss: 19.5785\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1179 - val_loss: 19.5607\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1005 - val_loss: 19.5449\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.0850 - val_loss: 19.5279\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.0692 - val_loss: 19.5076\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0521 - val_loss: 19.4907\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0378 - val_loss: 19.4711\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0204 - val_loss: 19.4554\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0061 - val_loss: 19.4404\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9913 - val_loss: 19.4218\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.9736 - val_loss: 19.4027\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9586 - val_loss: 19.3840\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.9428 - val_loss: 19.3662\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9279 - val_loss: 19.3494\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9127 - val_loss: 19.3336\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 16.8966 - val_loss: 19.3186\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8813 - val_loss: 19.2998\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8652 - val_loss: 19.2838\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8504 - val_loss: 19.2658\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8350 - val_loss: 19.2469\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8202 - val_loss: 19.2326\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8046 - val_loss: 19.2131\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.7885 - val_loss: 19.1955\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7725 - val_loss: 19.1760\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.7580 - val_loss: 19.1564\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7441 - val_loss: 19.1411\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7275 - val_loss: 19.1222\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7138 - val_loss: 19.1033\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6984 - val_loss: 19.0876\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6829 - val_loss: 19.0667\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 16.6670 - val_loss: 19.0496\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6539 - val_loss: 19.0309\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.6392 - val_loss: 19.0158\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6265 - val_loss: 19.0027\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6095 - val_loss: 18.9873\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.5952 - val_loss: 18.9741\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5796 - val_loss: 18.9581\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 16.5644 - val_loss: 18.9415\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5493 - val_loss: 18.9267\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5363 - val_loss: 18.9095\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5207 - val_loss: 18.8939\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5056 - val_loss: 18.8805\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 11.30 - 0s 76us/step - loss: 16.4911 - val_loss: 18.8657\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.4774 - val_loss: 18.8497\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4628 - val_loss: 18.8338\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.4480 - val_loss: 18.8167\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.4351 - val_loss: 18.8006\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.4186 - val_loss: 18.7855\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.4057 - val_loss: 18.7733\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 16.3915 - val_loss: 18.7613\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.3778 - val_loss: 18.7498\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3631 - val_loss: 18.7349\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3494 - val_loss: 18.7195\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.3372 - val_loss: 18.7012\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.3227 - val_loss: 18.6867\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.3083 - val_loss: 18.6753\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2942 - val_loss: 18.6613\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2800 - val_loss: 18.6476\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2665 - val_loss: 18.6308\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2533 - val_loss: 18.6158\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2388 - val_loss: 18.6031\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.2265 - val_loss: 18.5885\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2127 - val_loss: 18.5756\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.1989 - val_loss: 18.5643\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.1877 - val_loss: 18.5476\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1719 - val_loss: 18.5349\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1582 - val_loss: 18.5229\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1455 - val_loss: 18.5112\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1338 - val_loss: 18.4947\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1182 - val_loss: 18.4846\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.1039 - val_loss: 18.4718\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.0908 - val_loss: 18.4568\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 16.0778 - val_loss: 18.4438\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0648 - val_loss: 18.4316\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0512 - val_loss: 18.4195\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0379 - val_loss: 18.4051\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0245 - val_loss: 18.3911\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0118 - val_loss: 18.3790\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.9988 - val_loss: 18.3661\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9852 - val_loss: 18.3509\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9716 - val_loss: 18.3370\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9594 - val_loss: 18.3229\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9455 - val_loss: 18.3079\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.9323 - val_loss: 18.2955\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9196 - val_loss: 18.2817\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.9063 - val_loss: 18.2739\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8948 - val_loss: 18.2637\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8810 - val_loss: 18.2502\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8691 - val_loss: 18.2374\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8542 - val_loss: 18.2233\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8434 - val_loss: 18.2095\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8300 - val_loss: 18.1971\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8185 - val_loss: 18.1871\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8073 - val_loss: 18.1775\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 15.7908 - val_loss: 18.1620\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7785 - val_loss: 18.1471\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7675 - val_loss: 18.1293\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.7542 - val_loss: 18.1159\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.7399 - val_loss: 18.1067\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7282 - val_loss: 18.0961\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7159 - val_loss: 18.0858\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7036 - val_loss: 18.0754\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6914 - val_loss: 18.0620\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6786 - val_loss: 18.0505\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.6669 - val_loss: 18.0373\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.6535 - val_loss: 18.0253\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 89us/step - loss: 15.6412 - val_loss: 18.0152\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.6300 - val_loss: 18.0026\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.6172 - val_loss: 17.9929\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 15.6057 - val_loss: 17.9816\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5939 - val_loss: 17.9723\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5817 - val_loss: 17.9620\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 15.5694 - val_loss: 17.9507\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5578 - val_loss: 17.9417\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5452 - val_loss: 17.9304\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5342 - val_loss: 17.9170\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5210 - val_loss: 17.9069\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5098 - val_loss: 17.8956\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 15.4982 - val_loss: 17.8849\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4856 - val_loss: 17.8729\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4747 - val_loss: 17.8620\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 15.4625 - val_loss: 17.8492\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4509 - val_loss: 17.8352\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4388 - val_loss: 17.8204\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4271 - val_loss: 17.8092\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4151 - val_loss: 17.8009\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 15.4032 - val_loss: 17.7910\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3919 - val_loss: 17.7783\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 15.3809 - val_loss: 17.7666\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3679 - val_loss: 17.7566\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3562 - val_loss: 17.7472\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.3458 - val_loss: 17.7341\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3343 - val_loss: 17.7259\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.3218 - val_loss: 17.7148\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.3100 - val_loss: 17.7019\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2988 - val_loss: 17.6940\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 15.2861 - val_loss: 17.6827\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2758 - val_loss: 17.6746\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.2633 - val_loss: 17.6604\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 15.2527 - val_loss: 17.6478\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.2399 - val_loss: 17.6378\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.2301 - val_loss: 17.6268\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.2182 - val_loss: 17.6149\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2060 - val_loss: 17.6053\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 15.1943 - val_loss: 17.5985\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1832 - val_loss: 17.5870\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.1717 - val_loss: 17.5782\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.1602 - val_loss: 17.5684\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.1495 - val_loss: 17.5580\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.1382 - val_loss: 17.5480\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.1282 - val_loss: 17.5373\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.1153 - val_loss: 17.5305\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.1041 - val_loss: 17.5204\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.0936 - val_loss: 17.5119\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 15.0838 - val_loss: 17.5040\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0728 - val_loss: 17.4964\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.0601 - val_loss: 17.4863\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.0502 - val_loss: 17.4770\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0382 - val_loss: 17.4637\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.0276 - val_loss: 17.4516\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.0161 - val_loss: 17.4371\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.0043 - val_loss: 17.4249\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9934 - val_loss: 17.4131\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.9821 - val_loss: 17.4026\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.9723 - val_loss: 17.3914\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9607 - val_loss: 17.3817\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9495 - val_loss: 17.3724\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.9382 - val_loss: 17.3662\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9280 - val_loss: 17.3576\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.9184 - val_loss: 17.3500\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9064 - val_loss: 17.3362\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8959 - val_loss: 17.3260\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8851 - val_loss: 17.3140\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8735 - val_loss: 17.3047\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8631 - val_loss: 17.2965\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8522 - val_loss: 17.2871\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8416 - val_loss: 17.2796\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8309 - val_loss: 17.2696\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8206 - val_loss: 17.2582\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.8095 - val_loss: 17.2517\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7991 - val_loss: 17.2417\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 14.7897 - val_loss: 17.2339\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 14.7788 - val_loss: 17.2212\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7683 - val_loss: 17.2073\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7572 - val_loss: 17.1959\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.7460 - val_loss: 17.1878\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 14.7353 - val_loss: 17.1797\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7255 - val_loss: 17.1722\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7145 - val_loss: 17.1662\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.7050 - val_loss: 17.1566\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6939 - val_loss: 17.1484\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6837 - val_loss: 17.1430\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6742 - val_loss: 17.1362\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6643 - val_loss: 17.1287\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.6538 - val_loss: 17.1184\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.6432 - val_loss: 17.1099\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6327 - val_loss: 17.1011\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 14.6237 - val_loss: 17.0960\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6131 - val_loss: 17.0854\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6024 - val_loss: 17.0757\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5927 - val_loss: 17.0694\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5815 - val_loss: 17.0607\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5716 - val_loss: 17.0522\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5621 - val_loss: 17.0447\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5522 - val_loss: 17.0360\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5419 - val_loss: 17.0259\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5321 - val_loss: 17.0150\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5222 - val_loss: 17.0066\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5128 - val_loss: 16.9963\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.5037 - val_loss: 16.9925\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4916 - val_loss: 16.9838\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4825 - val_loss: 16.9702\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4709 - val_loss: 16.9620\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.4622 - val_loss: 16.9536\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 14.4513 - val_loss: 16.9449\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4422 - val_loss: 16.9357\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4321 - val_loss: 16.9290\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4218 - val_loss: 16.9223\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.4117 - val_loss: 16.9123\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 14.4028 - val_loss: 16.9015\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3931 - val_loss: 16.8932\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 14.3826 - val_loss: 16.8884\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.3736 - val_loss: 16.8807\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3625 - val_loss: 16.8732\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3537 - val_loss: 16.8644\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 14.3443 - val_loss: 16.8555\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3340 - val_loss: 16.8490\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3238 - val_loss: 16.8367\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.3137 - val_loss: 16.8282\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3045 - val_loss: 16.8179\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2950 - val_loss: 16.8100\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2856 - val_loss: 16.8041\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 14.2754 - val_loss: 16.7942\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 14.2653 - val_loss: 16.7849\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2563 - val_loss: 16.7756\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 14.2474 - val_loss: 16.7664\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2377 - val_loss: 16.7583\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2280 - val_loss: 16.7518\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2180 - val_loss: 16.7428\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2100 - val_loss: 16.7330\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2008 - val_loss: 16.7237\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1897 - val_loss: 16.7201\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 14.1807 - val_loss: 16.7092\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1706 - val_loss: 16.7032\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1624 - val_loss: 16.6965\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.1512 - val_loss: 16.6869\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1445 - val_loss: 16.6756\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1332 - val_loss: 16.6704\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1239 - val_loss: 16.6640\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1144 - val_loss: 16.6553\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1055 - val_loss: 16.6477\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.0962 - val_loss: 16.6404\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0869 - val_loss: 16.6295\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0777 - val_loss: 16.6224\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 14.0667 - val_loss: 16.6135\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.0573 - val_loss: 16.6020\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0478 - val_loss: 16.5907\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.715 - 0s 91us/step - loss: 14.0378 - val_loss: 16.5826\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 14.0293 - val_loss: 16.5758\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.0188 - val_loss: 16.5662\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.0107 - val_loss: 16.5580\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.0010 - val_loss: 16.5490\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.9923 - val_loss: 16.5410\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9827 - val_loss: 16.5354\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9735 - val_loss: 16.5272\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9654 - val_loss: 16.5182\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9541 - val_loss: 16.5112\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.9462 - val_loss: 16.5050\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9364 - val_loss: 16.4961\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9277 - val_loss: 16.4842\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9194 - val_loss: 16.4760\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.9103 - val_loss: 16.4655\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9012 - val_loss: 16.4582\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.8909 - val_loss: 16.4527\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.8830 - val_loss: 16.4458\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 13.8726 - val_loss: 16.4401\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8637 - val_loss: 16.4350\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8563 - val_loss: 16.4285\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8459 - val_loss: 16.4203\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.8370 - val_loss: 16.4125\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8278 - val_loss: 16.4065\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.8193 - val_loss: 16.4014\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8099 - val_loss: 16.3948\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8011 - val_loss: 16.3868\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7927 - val_loss: 16.3756\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7828 - val_loss: 16.3678\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7740 - val_loss: 16.3597\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7651 - val_loss: 16.3507\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7553 - val_loss: 16.3420\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.7468 - val_loss: 16.3335\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.7379 - val_loss: 16.3249\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.7294 - val_loss: 16.3146\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7190 - val_loss: 16.3070\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7110 - val_loss: 16.3017\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7024 - val_loss: 16.2955\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6935 - val_loss: 16.2866\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6846 - val_loss: 16.2804\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6758 - val_loss: 16.2747\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6665 - val_loss: 16.2659\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6570 - val_loss: 16.2580\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6484 - val_loss: 16.2499\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6399 - val_loss: 16.2426\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6310 - val_loss: 16.2350\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6225 - val_loss: 16.2304\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6130 - val_loss: 16.2227\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6043 - val_loss: 16.2132\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.5960 - val_loss: 16.2055\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.5879 - val_loss: 16.1949\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5797 - val_loss: 16.1878\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.5711 - val_loss: 16.1828\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.5620 - val_loss: 16.1752\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5531 - val_loss: 16.1656\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5441 - val_loss: 16.1581\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5358 - val_loss: 16.1500\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.5269 - val_loss: 16.1424\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5187 - val_loss: 16.1378\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5101 - val_loss: 16.1276\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5026 - val_loss: 16.1202\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4925 - val_loss: 16.1121\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4838 - val_loss: 16.1057\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4769 - val_loss: 16.0954\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 13.4669 - val_loss: 16.0899\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4577 - val_loss: 16.0819\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4494 - val_loss: 16.0746\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4398 - val_loss: 16.0667\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4323 - val_loss: 16.0582\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4238 - val_loss: 16.0473\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4144 - val_loss: 16.0410\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4059 - val_loss: 16.0352\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3977 - val_loss: 16.0286\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3894 - val_loss: 16.0214\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3806 - val_loss: 16.0116\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3714 - val_loss: 16.0040\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3627 - val_loss: 15.9982\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 13.3547 - val_loss: 15.9892\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3466 - val_loss: 15.9830\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 13.3376 - val_loss: 15.9763\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3291 - val_loss: 15.9712\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3203 - val_loss: 15.9643\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3116 - val_loss: 15.9578\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3044 - val_loss: 15.9504\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2956 - val_loss: 15.9438\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2868 - val_loss: 15.9370\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2786 - val_loss: 15.9292\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2702 - val_loss: 15.9233\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2627 - val_loss: 15.9174\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2548 - val_loss: 15.9108\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2460 - val_loss: 15.9029\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2374 - val_loss: 15.8966\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2299 - val_loss: 15.8910\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 13.2221 - val_loss: 15.8852\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2132 - val_loss: 15.8757\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2052 - val_loss: 15.8675\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1968 - val_loss: 15.8603\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.1894 - val_loss: 15.8531\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1804 - val_loss: 15.8476\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1731 - val_loss: 15.8411\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1654 - val_loss: 15.8324\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1567 - val_loss: 15.8277\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1480 - val_loss: 15.8201\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1400 - val_loss: 15.8125\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1317 - val_loss: 15.8050\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1239 - val_loss: 15.7979\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1165 - val_loss: 15.7888\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 13.1088 - val_loss: 15.7805\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1005 - val_loss: 15.7748\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0914 - val_loss: 15.7700\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 13.0847 - val_loss: 15.7649\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.0762 - val_loss: 15.7568\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0678 - val_loss: 15.7513\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0605 - val_loss: 15.7422\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0528 - val_loss: 15.7348\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0441 - val_loss: 15.7265\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0353 - val_loss: 15.7207\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 13.0282 - val_loss: 15.7121\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0196 - val_loss: 15.7058\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0127 - val_loss: 15.6956\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0038 - val_loss: 15.6899\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9961 - val_loss: 15.6833\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9883 - val_loss: 15.6760\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9799 - val_loss: 15.6691\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9731 - val_loss: 15.6650\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9646 - val_loss: 15.6558\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9563 - val_loss: 15.6466\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9485 - val_loss: 15.6389\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9404 - val_loss: 15.6333\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 12.9328 - val_loss: 15.6260\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9238 - val_loss: 15.6201\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9164 - val_loss: 15.6158\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9088 - val_loss: 15.6070\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.9014 - val_loss: 15.6011\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8932 - val_loss: 15.5932\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 12.8850 - val_loss: 15.5864\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8768 - val_loss: 15.5801\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8701 - val_loss: 15.5727\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8622 - val_loss: 15.5655\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8540 - val_loss: 15.5601\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8459 - val_loss: 15.5555\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8391 - val_loss: 15.5502\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8317 - val_loss: 15.5427\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.8243 - val_loss: 15.5344\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8174 - val_loss: 15.5281\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8079 - val_loss: 15.5219\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8005 - val_loss: 15.5150\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7931 - val_loss: 15.5100\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7849 - val_loss: 15.5068\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7778 - val_loss: 15.4975\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7698 - val_loss: 15.4891\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7618 - val_loss: 15.4819\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7550 - val_loss: 15.4765\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 81us/step - loss: 12.7464 - val_loss: 15.4686\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7386 - val_loss: 15.4623\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7316 - val_loss: 15.4553\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.7233 - val_loss: 15.4494\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7162 - val_loss: 15.4420\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7088 - val_loss: 15.4349\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7011 - val_loss: 15.4281\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6933 - val_loss: 15.4199\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6860 - val_loss: 15.4113\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6784 - val_loss: 15.4048\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6706 - val_loss: 15.3971\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6631 - val_loss: 15.3901\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6558 - val_loss: 15.3821\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6483 - val_loss: 15.3748\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6407 - val_loss: 15.3692\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6331 - val_loss: 15.3615\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6270 - val_loss: 15.3538\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6193 - val_loss: 15.3486\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6123 - val_loss: 15.3403\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6036 - val_loss: 15.3344\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5968 - val_loss: 15.3293\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5895 - val_loss: 15.3214\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.5816 - val_loss: 15.3157\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5743 - val_loss: 15.3103\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5667 - val_loss: 15.3031\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5599 - val_loss: 15.2957\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5538 - val_loss: 15.2913\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5460 - val_loss: 15.2832\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5383 - val_loss: 15.2768\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5312 - val_loss: 15.2679\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5238 - val_loss: 15.2595\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5157 - val_loss: 15.2509\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5084 - val_loss: 15.2423\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5012 - val_loss: 15.2367\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4941 - val_loss: 15.2310\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.4866 - val_loss: 15.2245\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.4796 - val_loss: 15.2196\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4726 - val_loss: 15.2091\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.4639 - val_loss: 15.2014\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4573 - val_loss: 15.1924\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.4495 - val_loss: 15.1870\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4427 - val_loss: 15.1800\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4356 - val_loss: 15.1748\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.4288 - val_loss: 15.1686\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4212 - val_loss: 15.1644\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4156 - val_loss: 15.1552\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.4061 - val_loss: 15.1490\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3992 - val_loss: 15.1447\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3916 - val_loss: 15.1371\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3842 - val_loss: 15.1320\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3777 - val_loss: 15.1271\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3702 - val_loss: 15.1199\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3630 - val_loss: 15.1144\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.3560 - val_loss: 15.1059\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3496 - val_loss: 15.1016\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3418 - val_loss: 15.0938\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3345 - val_loss: 15.0861\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3274 - val_loss: 15.0796\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3204 - val_loss: 15.0740\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3136 - val_loss: 15.0689\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3061 - val_loss: 15.0633\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.3007 - val_loss: 15.0565\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.2926 - val_loss: 15.0478\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2855 - val_loss: 15.0407\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 12.2779 - val_loss: 15.0355\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.2717 - val_loss: 15.0289\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.2645 - val_loss: 15.0227\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.2591 - val_loss: 15.0162\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2509 - val_loss: 15.0116\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.2450 - val_loss: 15.0053\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.2380 - val_loss: 15.0007\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.2304 - val_loss: 14.9956\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2235 - val_loss: 14.9879\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.2180 - val_loss: 14.9847\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.2103 - val_loss: 14.9745\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2027 - val_loss: 14.9669\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 81us/step - loss: 12.1959 - val_loss: 14.9593\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1893 - val_loss: 14.9531\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1832 - val_loss: 14.9455\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.1751 - val_loss: 14.9392\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1691 - val_loss: 14.9326\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 12.1627 - val_loss: 14.9256\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.1551 - val_loss: 14.9213\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1479 - val_loss: 14.9172\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.1422 - val_loss: 14.9097\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1350 - val_loss: 14.9054\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1287 - val_loss: 14.8951\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.1206 - val_loss: 14.8885\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1146 - val_loss: 14.8837\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1072 - val_loss: 14.8773\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1003 - val_loss: 14.8700\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0944 - val_loss: 14.8638\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0865 - val_loss: 14.8579\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.0803 - val_loss: 14.8520\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0724 - val_loss: 14.8455\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0663 - val_loss: 14.8386\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.0594 - val_loss: 14.8319\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 12.0542 - val_loss: 14.8217\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0460 - val_loss: 14.8172\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.0413 - val_loss: 14.8094\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0346 - val_loss: 14.8070\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0275 - val_loss: 14.7982\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0205 - val_loss: 14.7917\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0134 - val_loss: 14.7858\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.0062 - val_loss: 14.7806\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.0001 - val_loss: 14.7767\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9932 - val_loss: 14.7717\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 11.9864 - val_loss: 14.7664\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.9801 - val_loss: 14.7608\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.9742 - val_loss: 14.7530\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 11.9676 - val_loss: 14.7463\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9610 - val_loss: 14.7389\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.9535 - val_loss: 14.7350\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 11.9476 - val_loss: 14.7302\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9409 - val_loss: 14.7248\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.9345 - val_loss: 14.7180\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.9281 - val_loss: 14.7118\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9216 - val_loss: 14.7043\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9171 - val_loss: 14.6971\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 11.9083 - val_loss: 14.6926\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.9024 - val_loss: 14.6885\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8968 - val_loss: 14.6787\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.8889 - val_loss: 14.6723\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8820 - val_loss: 14.6677\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8769 - val_loss: 14.6628\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.8694 - val_loss: 14.6563\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.8626 - val_loss: 14.6501\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8568 - val_loss: 14.6451\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8512 - val_loss: 14.6360\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8433 - val_loss: 14.6302\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8370 - val_loss: 14.6248\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8303 - val_loss: 14.6194\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 11.8255 - val_loss: 14.6126\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8186 - val_loss: 14.6030\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8118 - val_loss: 14.5953\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8048 - val_loss: 14.5898\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.7986 - val_loss: 14.5861\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 11.7926 - val_loss: 14.5816\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.7863 - val_loss: 14.5748\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7799 - val_loss: 14.5703\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.7736 - val_loss: 14.5668\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 11.7676 - val_loss: 14.5618\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7614 - val_loss: 14.5575\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.7554 - val_loss: 14.5511\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.7492 - val_loss: 14.5428\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.7424 - val_loss: 14.5385\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.7361 - val_loss: 14.5328\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7298 - val_loss: 14.5267\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7241 - val_loss: 14.5184\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7172 - val_loss: 14.5109\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7110 - val_loss: 14.5047\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7047 - val_loss: 14.4989\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 11.6986 - val_loss: 14.4940\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6935 - val_loss: 14.4850\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6865 - val_loss: 14.4807\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6812 - val_loss: 14.4745\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6743 - val_loss: 14.4682\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6704 - val_loss: 14.4623\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6621 - val_loss: 14.4556\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6560 - val_loss: 14.4499\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6501 - val_loss: 14.4467\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6444 - val_loss: 14.4384\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6380 - val_loss: 14.4329\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6320 - val_loss: 14.4256\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6254 - val_loss: 14.4196\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6192 - val_loss: 14.4141\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6129 - val_loss: 14.4060\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.6076 - val_loss: 14.3980\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6007 - val_loss: 14.3928\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.5953 - val_loss: 14.3874\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.374 - 0s 84us/step - loss: 11.5884 - val_loss: 14.3791\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.5828 - val_loss: 14.3725\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5765 - val_loss: 14.3643\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5708 - val_loss: 14.3584\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5653 - val_loss: 14.3515\n",
      "12.311785342329639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.26519018, -0.30969924,  0.31332922,  0.11838782, -0.49619505],\n",
       "        [-0.29877776,  0.62051237, -0.38825664,  0.13423376, -0.15193045],\n",
       "        [ 0.0805206 ,  0.2352607 , -0.5637564 ,  0.5941172 ,  0.46963477],\n",
       "        [-0.48329857, -0.5644614 ,  0.16716547, -0.21568078,  0.05851074],\n",
       "        [ 0.39602542,  0.10094836, -0.30848545,  0.63181853,  0.6442236 ],\n",
       "        [ 0.5650914 ,  0.07041802,  0.41007155,  0.26524168, -0.00249722],\n",
       "        [-0.0894484 ,  0.13705376, -0.01674587, -0.55452013,  0.5080502 ]],\n",
       "       dtype=float32),\n",
       " array([-0.29672837,  1.3756742 ,  0.57918286, -0.6747706 ,  0.10778167],\n",
       "       dtype=float32),\n",
       " array([[-0.35920596,  0.664683  , -0.49307838,  0.06565339,  0.12241128,\n",
       "          0.8054019 , -0.7028028 ,  0.6012675 , -0.37846255, -0.36771172],\n",
       "        [-1.1111735 ,  0.3894226 , -0.94691825,  0.71315676, -1.0937616 ,\n",
       "          0.63859046, -1.2728937 ,  0.24001203, -0.57645357, -0.24197015],\n",
       "        [-0.58379996,  0.8303262 ,  0.13763455,  0.4341763 , -0.404309  ,\n",
       "         -0.00888549, -0.69186515,  0.4876241 , -0.06381379,  0.42329395],\n",
       "        [ 0.7310943 , -0.42204648, -0.33553103, -0.02892567,  0.78583425,\n",
       "          0.18592082,  0.49074972, -0.01399096, -0.0804916 ,  0.09278119],\n",
       "        [ 0.17979065, -0.4254831 ,  0.20646632, -0.3398873 , -0.515867  ,\n",
       "          0.34297794, -0.04094585,  0.31821033, -0.5168407 , -0.63546836]],\n",
       "       dtype=float32),\n",
       " array([-0.909396  ,  1.065881  , -0.66698736,  0.526704  , -0.80504864,\n",
       "         0.58640224, -1.2968078 ,  0.02522117, -0.9646515 , -0.40093258],\n",
       "       dtype=float32),\n",
       " array([[-1.6045794 ],\n",
       "        [ 1.5987161 ],\n",
       "        [-1.0685145 ],\n",
       "        [ 0.8842884 ],\n",
       "        [-1.3858957 ],\n",
       "        [ 1.0020407 ],\n",
       "        [-2.1475823 ],\n",
       "        [ 0.32339773],\n",
       "        [-1.3359876 ],\n",
       "        [-0.5538801 ]], dtype=float32),\n",
       " array([1.1426728], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, sgd, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sgd_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 611us/step - loss: 574.3944 - val_loss: 547.3311\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 475.0370 - val_loss: 415.7192\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 356.5229 - val_loss: 285.3018\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 227.4343 - val_loss: 155.0317\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 109.6383 - val_loss: 62.0209\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 41.3658 - val_loss: 25.3475\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.9474 - val_loss: 19.9881\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.7274 - val_loss: 18.2081\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.8280 - val_loss: 19.5527\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.7353 - val_loss: 18.7649\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 15.3278 - val_loss: 17.7445\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3656 - val_loss: 18.6680\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.1597 - val_loss: 18.2122\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.8739 - val_loss: 18.6734\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 13.3945 - val_loss: 15.4696\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.0358 - val_loss: 15.2064\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.2359 - val_loss: 18.8485\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 12.5988 - val_loss: 14.6854\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.9232 - val_loss: 18.9003\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 11.5291 - val_loss: 14.8766\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.7212 - val_loss: 14.8503\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.5430 - val_loss: 17.0847\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.8104 - val_loss: 15.0280\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2871 - val_loss: 14.9454\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.2748 - val_loss: 14.6922\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.1862 - val_loss: 14.3789\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.9681 - val_loss: 15.7995\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2045 - val_loss: 13.8207\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.0573 - val_loss: 13.1017\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.7036 - val_loss: 13.1540\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.6459 - val_loss: 13.8016\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.7673 - val_loss: 17.3399\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.4959 - val_loss: 12.7284\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.3879 - val_loss: 17.5850\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.4737 - val_loss: 12.1315\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.0613 - val_loss: 11.4414\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.5570 - val_loss: 12.3312\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9704 - val_loss: 20.3853\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.5603 - val_loss: 11.9372\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.8810 - val_loss: 11.8997\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.0836 - val_loss: 12.1763\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.2277 - val_loss: 12.2001\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.8541 - val_loss: 12.1954\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.5069 - val_loss: 12.5007\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8295 - val_loss: 16.6623\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.1832 - val_loss: 12.2542\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.4679 - val_loss: 11.8172\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.8816 - val_loss: 10.9355\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.3175 - val_loss: 11.7943\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.9569 - val_loss: 10.8520\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.4107 - val_loss: 11.3715\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.7950 - val_loss: 15.3066\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.1561 - val_loss: 11.0284\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.8246 - val_loss: 12.0440\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3195 - val_loss: 16.2446\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.3357 - val_loss: 12.6924\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0090 - val_loss: 13.2693\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.8573 - val_loss: 12.8263\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.0911 - val_loss: 12.5138\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.8490 - val_loss: 11.1629\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.8067 - val_loss: 12.5300\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.1166 - val_loss: 10.4893\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.9102 - val_loss: 10.8433\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.3937 - val_loss: 10.4604\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5191 - val_loss: 11.9633\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.1390 - val_loss: 10.8243\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.7124 - val_loss: 11.1590\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 9.4294 - val_loss: 12.3728\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.6252 - val_loss: 11.5660\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.4552 - val_loss: 10.9516\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1919 - val_loss: 12.0770\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.3007 - val_loss: 11.0262\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.6028 - val_loss: 10.8164\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4868 - val_loss: 11.5932\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6449 - val_loss: 11.7765\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2833 - val_loss: 11.4629\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3532 - val_loss: 11.5492\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1075 - val_loss: 10.8278\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.2596 - val_loss: 10.1080\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.3756 - val_loss: 13.3864\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0923 - val_loss: 14.4738\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2194 - val_loss: 10.6085\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0771 - val_loss: 13.2270\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9759 - val_loss: 12.3953\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0788 - val_loss: 10.7543\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3396 - val_loss: 9.7209\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5836 - val_loss: 10.0551\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9895 - val_loss: 10.0458\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2227 - val_loss: 12.2071\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5175 - val_loss: 12.1532\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2669 - val_loss: 11.1091\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.1396 - val_loss: 10.0678\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1598 - val_loss: 13.2172\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8693 - val_loss: 10.7762\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1465 - val_loss: 10.6630\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4441 - val_loss: 13.4157\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.7286 - val_loss: 10.1835\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 8.2107 - val_loss: 11.1294\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9693 - val_loss: 10.3480\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8119 - val_loss: 10.5347\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2917 - val_loss: 12.9200\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5325 - val_loss: 10.4478\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7644 - val_loss: 13.0441\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2243 - val_loss: 11.0881\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1503 - val_loss: 10.9261\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.1058 - val_loss: 10.8661\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1544 - val_loss: 10.2380\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2091 - val_loss: 10.0658\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.5946 - val_loss: 11.8699\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.1073 - val_loss: 9.9878\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.7067 - val_loss: 10.3561\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2429 - val_loss: 10.3967\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7331 - val_loss: 12.6906\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4336 - val_loss: 10.8558\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.1586 - val_loss: 10.2716\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.4272 - val_loss: 11.5087\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8883 - val_loss: 10.3843\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.2019 - val_loss: 10.1945\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.0434 - val_loss: 11.2407\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2010 - val_loss: 10.4297\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6391 - val_loss: 10.5387\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8673 - val_loss: 10.4864\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5001 - val_loss: 12.4199\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8044 - val_loss: 9.9756\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7559 - val_loss: 11.9965\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1364 - val_loss: 10.6190\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5895 - val_loss: 9.9519\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0262 - val_loss: 10.5740\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9713 - val_loss: 10.8005\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.2661 - val_loss: 10.5776\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8223 - val_loss: 10.0989\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.8216 - val_loss: 9.9372\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2090 - val_loss: 10.0940\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0091 - val_loss: 10.7861\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0999 - val_loss: 10.8313\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.4709 - val_loss: 13.2285\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3253 - val_loss: 13.9017\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1885 - val_loss: 11.6059\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3756 - val_loss: 11.5393\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2173 - val_loss: 10.6954\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9983 - val_loss: 10.5340\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0699 - val_loss: 9.7061\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4615 - val_loss: 10.6574\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8082 - val_loss: 11.0502\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.7507 - val_loss: 10.8429\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0943 - val_loss: 11.3923\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5138 - val_loss: 10.6046\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.8817 - val_loss: 12.7181\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9875 - val_loss: 10.5390\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6425 - val_loss: 13.0714\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3561 - val_loss: 10.6659\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6053 - val_loss: 12.5156\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1425 - val_loss: 11.6573\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9205 - val_loss: 11.5020\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7103 - val_loss: 11.7225\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8496 - val_loss: 10.2233\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7213 - val_loss: 10.2627\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7414 - val_loss: 11.6148\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6194 - val_loss: 10.7841\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0321 - val_loss: 11.0599\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5586 - val_loss: 13.5833\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.9687 - val_loss: 11.5676\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0494 - val_loss: 10.8237\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.7048 - val_loss: 10.3094\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7245 - val_loss: 11.5682\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7871 - val_loss: 10.7624\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3858 - val_loss: 11.4463\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7984 - val_loss: 10.4621\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4655 - val_loss: 10.8575\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5184 - val_loss: 10.4665\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5397 - val_loss: 10.5273\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2177 - val_loss: 10.5301\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.4662 - val_loss: 10.4855\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0019 - val_loss: 11.4916\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5576 - val_loss: 10.4745\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2022 - val_loss: 12.5410\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7220 - val_loss: 11.1292\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1357 - val_loss: 10.9260\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7444 - val_loss: 11.1361\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.5276 - val_loss: 12.1898\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7190 - val_loss: 10.4713\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5334 - val_loss: 10.6896\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7669 - val_loss: 15.0448\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2494 - val_loss: 11.2798\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8867 - val_loss: 11.5081\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7085 - val_loss: 10.7396\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6160 - val_loss: 12.1016\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.6550 - val_loss: 10.2437\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.9498 - val_loss: 10.6539\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5551 - val_loss: 10.5436\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9425 - val_loss: 11.5104\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7577 - val_loss: 11.6293\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4384 - val_loss: 10.6669\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5082 - val_loss: 11.9822\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1451 - val_loss: 10.6582\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6328 - val_loss: 12.5930\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0882 - val_loss: 11.7942\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0832 - val_loss: 10.5567\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3088 - val_loss: 10.9911\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1945 - val_loss: 10.8443\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.7874 - val_loss: 13.2968\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4904 - val_loss: 10.9046\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 8.1587 - val_loss: 10.6960\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.0046 - val_loss: 11.5836\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4417 - val_loss: 10.9871\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.8263 - val_loss: 11.0690\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7589 - val_loss: 11.1108\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5604 - val_loss: 11.2176\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2090 - val_loss: 11.6126\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5740 - val_loss: 11.6786\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3074 - val_loss: 10.7074\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2541 - val_loss: 10.4943\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2806 - val_loss: 10.5664\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8181 - val_loss: 11.4331\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6730 - val_loss: 11.0157\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6621 - val_loss: 10.7632\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3817 - val_loss: 10.3007\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3702 - val_loss: 12.7225\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8250 - val_loss: 10.9747\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8989 - val_loss: 11.2951\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5978 - val_loss: 11.5902\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 8.2172 - val_loss: 11.4541\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3805 - val_loss: 10.7282\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3350 - val_loss: 11.7117\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6360 - val_loss: 11.7614\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8903 - val_loss: 12.9476\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3680 - val_loss: 10.8582\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4730 - val_loss: 13.2438\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4032 - val_loss: 11.4554\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3971 - val_loss: 11.2269\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.3079 - val_loss: 12.2203\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6358 - val_loss: 10.9223\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2815 - val_loss: 11.3921\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5962 - val_loss: 11.6223\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5589 - val_loss: 11.0569\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0900 - val_loss: 10.6193\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5057 - val_loss: 10.4732\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2252 - val_loss: 10.7720\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6442 - val_loss: 11.4818\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3802 - val_loss: 11.9714\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.7610 - val_loss: 11.0015\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6870 - val_loss: 11.0185\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6560 - val_loss: 11.0770\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5625 - val_loss: 11.0586\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8955 - val_loss: 11.1692\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4619 - val_loss: 11.0139\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7891 - val_loss: 10.9392\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1673 - val_loss: 11.5875\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5451 - val_loss: 10.3154\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8043 - val_loss: 10.7505\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7558 - val_loss: 10.6879\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5206 - val_loss: 10.7366\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5145 - val_loss: 13.1381\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8597 - val_loss: 10.7248\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.4454 - val_loss: 10.2444\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2807 - val_loss: 10.7968\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8559 - val_loss: 10.5052\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7278 - val_loss: 11.6737\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2298 - val_loss: 10.5942\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6939 - val_loss: 11.5270\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7207 - val_loss: 11.4162\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4975 - val_loss: 11.2997\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6408 - val_loss: 10.7901\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3230 - val_loss: 11.2410\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.5839 - val_loss: 12.5003\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4621 - val_loss: 12.1120\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.9875 - val_loss: 11.1082\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6832 - val_loss: 11.5930\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1490 - val_loss: 10.9796\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0436 - val_loss: 10.6647\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5622 - val_loss: 11.7230\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3594 - val_loss: 10.6301\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7357 - val_loss: 12.5211\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1920 - val_loss: 11.4639\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6092 - val_loss: 10.6444\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3905 - val_loss: 10.6815\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5378 - val_loss: 12.8470\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5462 - val_loss: 11.1386\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5254 - val_loss: 10.6797\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6889 - val_loss: 10.8513\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3044 - val_loss: 10.3542\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7177 - val_loss: 11.0859\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3008 - val_loss: 10.6511\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8943 - val_loss: 10.6628\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6674 - val_loss: 11.8127\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2997 - val_loss: 11.0430\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5841 - val_loss: 12.0429\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7151 - val_loss: 11.2769\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3824 - val_loss: 10.8379\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5451 - val_loss: 10.5018\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5160 - val_loss: 12.2982\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0169 - val_loss: 10.5297\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2891 - val_loss: 11.2457\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3130 - val_loss: 12.8795\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4730 - val_loss: 10.9697\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7247 - val_loss: 10.9425\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4773 - val_loss: 11.4283\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4450 - val_loss: 10.5031\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 8.1567 - val_loss: 11.3022\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3702 - val_loss: 11.1038\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3471 - val_loss: 12.2247\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6928 - val_loss: 11.0818\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2303 - val_loss: 10.8775\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4525 - val_loss: 10.4879\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8164 - val_loss: 10.6200\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3159 - val_loss: 10.9552\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3207 - val_loss: 10.8278\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9977 - val_loss: 11.7328\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3614 - val_loss: 12.4576\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6805 - val_loss: 11.3624\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2029 - val_loss: 12.3249\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7651 - val_loss: 11.3881\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4363 - val_loss: 11.3678\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2868 - val_loss: 10.5116\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8208 - val_loss: 10.6548\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4606 - val_loss: 11.0335\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4104 - val_loss: 10.7962\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3608 - val_loss: 11.3189\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5196 - val_loss: 12.3853\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0554 - val_loss: 11.0491\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2375 - val_loss: 10.8690\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4297 - val_loss: 11.0512\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6232 - val_loss: 11.4397\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7158 - val_loss: 10.9512\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3940 - val_loss: 10.7434\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3778 - val_loss: 11.5130\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5800 - val_loss: 10.5593\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6538 - val_loss: 11.0562\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6478 - val_loss: 10.3348\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1237 - val_loss: 13.2106\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3154 - val_loss: 12.1358\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4221 - val_loss: 10.7643\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1682 - val_loss: 12.0503\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4502 - val_loss: 11.4634\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6413 - val_loss: 11.1272\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.9274 - val_loss: 10.7624\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.4157 - val_loss: 10.7114\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2023 - val_loss: 11.8684\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.8483 - val_loss: 13.2878\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7605 - val_loss: 10.6619\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1378 - val_loss: 11.9339\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7058 - val_loss: 12.8187\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8711 - val_loss: 10.2380\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1715 - val_loss: 10.6262\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5885 - val_loss: 11.9493\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2392 - val_loss: 10.5367\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2886 - val_loss: 10.4238\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5444 - val_loss: 10.4257\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2246 - val_loss: 10.2950\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1317 - val_loss: 13.2316\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7569 - val_loss: 11.8360\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4030 - val_loss: 12.6699\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5654 - val_loss: 10.7039\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.3554 - val_loss: 11.5275\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4141 - val_loss: 12.5437\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5574 - val_loss: 10.8084\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2826 - val_loss: 11.9889\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2975 - val_loss: 10.2304\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3099 - val_loss: 10.7165\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0923 - val_loss: 10.8028\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.6043 - val_loss: 11.4958\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2143 - val_loss: 12.7940\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5592 - val_loss: 11.0986\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3090 - val_loss: 10.6175\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3765 - val_loss: 12.2729\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3903 - val_loss: 11.0607\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3469 - val_loss: 12.3689\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5506 - val_loss: 11.1811\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4287 - val_loss: 10.6401\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4279 - val_loss: 11.7146\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6866 - val_loss: 10.6771\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0786 - val_loss: 10.6754\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9030 - val_loss: 11.9378\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5515 - val_loss: 10.0751\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2970 - val_loss: 10.5439\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 7.4600 - val_loss: 10.9842\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1403 - val_loss: 11.2208\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5650 - val_loss: 11.2804\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1074 - val_loss: 11.5759\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0105 - val_loss: 11.1443\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9340 - val_loss: 11.1158\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1841 - val_loss: 10.3760\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4853 - val_loss: 11.1680\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9967 - val_loss: 10.7865\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2095 - val_loss: 10.8362\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5181 - val_loss: 10.5752\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2681 - val_loss: 10.5500\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9950 - val_loss: 10.2965\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0705 - val_loss: 11.0582\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0900 - val_loss: 11.0972\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5036 - val_loss: 12.3600\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3279 - val_loss: 11.1929\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.3925 - val_loss: 10.7491\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3801 - val_loss: 12.8090\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6301 - val_loss: 10.3569\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4809 - val_loss: 13.0764\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4769 - val_loss: 12.7011\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3374 - val_loss: 10.3886\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1491 - val_loss: 10.4850\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1497 - val_loss: 12.5040\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1925 - val_loss: 11.4561\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1060 - val_loss: 11.3630\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3140 - val_loss: 10.1906\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5884 - val_loss: 10.6350\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1051 - val_loss: 10.4936\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3786 - val_loss: 11.9039\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8359 - val_loss: 10.6078\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3708 - val_loss: 10.5400\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3560 - val_loss: 10.2116\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.3938 - val_loss: 11.2763\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2215 - val_loss: 10.5133\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0580 - val_loss: 10.6139\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4714 - val_loss: 10.4392\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0196 - val_loss: 10.4815\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0069 - val_loss: 10.4733\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1307 - val_loss: 10.6048\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1723 - val_loss: 11.7072\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3180 - val_loss: 12.2397\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3168 - val_loss: 11.1356\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.7703 - val_loss: 10.7252\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2632 - val_loss: 10.3356\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2089 - val_loss: 10.9511\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9170 - val_loss: 10.1584\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5244 - val_loss: 10.2602\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.900 - 0s 90us/step - loss: 7.4196 - val_loss: 10.3174\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6635 - val_loss: 11.0417\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0403 - val_loss: 10.4158\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.4503 - val_loss: 10.6568\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.2747 - val_loss: 10.6519\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2882 - val_loss: 10.2749\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2752 - val_loss: 10.2298\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1779 - val_loss: 10.4953\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1364 - val_loss: 10.4594\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3479 - val_loss: 12.8218\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9726 - val_loss: 11.6273\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9643 - val_loss: 10.2966\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1899 - val_loss: 12.3886\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4167 - val_loss: 11.8455\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3907 - val_loss: 10.9572\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1010 - val_loss: 10.2544\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1716 - val_loss: 10.3679\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0488 - val_loss: 11.4385\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3285 - val_loss: 11.1245\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0835 - val_loss: 10.5260\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8863 - val_loss: 10.7482\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.1121 - val_loss: 11.2865\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6508 - val_loss: 10.4422\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1323 - val_loss: 11.2965\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1478 - val_loss: 10.1646\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2428 - val_loss: 12.1964\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3568 - val_loss: 11.3412\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2731 - val_loss: 10.6449\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 88us/step - loss: 6.9960 - val_loss: 10.6601\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2045 - val_loss: 10.4450\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2302 - val_loss: 10.6581\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3812 - val_loss: 12.7589\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.2777 - val_loss: 12.4434\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3287 - val_loss: 10.3436\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0152 - val_loss: 10.8386\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2507 - val_loss: 10.1910\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0207 - val_loss: 10.4076\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.4873 - val_loss: 10.6986\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1926 - val_loss: 11.7928\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2682 - val_loss: 10.4499\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9699 - val_loss: 10.1705\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5501 - val_loss: 10.7054\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2466 - val_loss: 12.1649\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7379 - val_loss: 11.2102\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3859 - val_loss: 10.2648\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1421 - val_loss: 10.1391\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0389 - val_loss: 10.8707\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1173 - val_loss: 11.6604\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.7623 - val_loss: 10.4170\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6307 - val_loss: 10.4516\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.1793 - val_loss: 10.0568\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2255 - val_loss: 11.7135\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1558 - val_loss: 10.7140\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0977 - val_loss: 10.7551\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2251 - val_loss: 14.3616\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2344 - val_loss: 13.8155\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1793 - val_loss: 10.9541\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3052 - val_loss: 10.5433\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3055 - val_loss: 11.4844\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3900 - val_loss: 10.9798\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1987 - val_loss: 10.3213\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3433 - val_loss: 10.5061\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1031 - val_loss: 10.3243\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0875 - val_loss: 10.1557\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1294 - val_loss: 10.2820\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3764 - val_loss: 9.9639\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1853 - val_loss: 10.7588\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9676 - val_loss: 11.5057\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2524 - val_loss: 10.5195\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1337 - val_loss: 12.8622\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2188 - val_loss: 10.8788\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3663 - val_loss: 11.5819\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9793 - val_loss: 10.9738\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1110 - val_loss: 13.3016\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1213 - val_loss: 12.0182\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.6822 - val_loss: 10.8498\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1712 - val_loss: 11.5574\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2394 - val_loss: 10.3434\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5097 - val_loss: 10.2203\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0218 - val_loss: 10.3324\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1270 - val_loss: 10.6598\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3186 - val_loss: 10.5593\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7004 - val_loss: 10.2537\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0799 - val_loss: 10.1003\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0046 - val_loss: 9.8692\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0355 - val_loss: 10.0930\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.7139 - val_loss: 10.6960\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0466 - val_loss: 10.6425\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9176 - val_loss: 12.8994\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2415 - val_loss: 10.3960\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3334 - val_loss: 10.1422\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0308 - val_loss: 10.4667\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4396 - val_loss: 10.1619\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8842 - val_loss: 10.6210\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1084 - val_loss: 10.7844\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1171 - val_loss: 11.9970\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4171 - val_loss: 10.3727\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8092 - val_loss: 10.7299\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3605 - val_loss: 10.6281\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1241 - val_loss: 10.0252\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1826 - val_loss: 10.1356\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3120 - val_loss: 10.9168\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9775 - val_loss: 11.1896\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8120 - val_loss: 10.2658\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2884 - val_loss: 10.0437\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.1114 - val_loss: 10.4331\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9358 - val_loss: 10.6691\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0749 - val_loss: 11.0452\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2776 - val_loss: 10.8880\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9471 - val_loss: 11.1815\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.5076 - val_loss: 10.9843\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7487 - val_loss: 13.1641\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0689 - val_loss: 10.8370\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0911 - val_loss: 10.3270\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0344 - val_loss: 10.1009\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8319 - val_loss: 12.5477\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.1315 - val_loss: 10.4406\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1790 - val_loss: 11.1206\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5551 - val_loss: 10.1881\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.700 - 0s 87us/step - loss: 7.0667 - val_loss: 10.0791\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4910 - val_loss: 10.7915\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0885 - val_loss: 10.1716\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2262 - val_loss: 11.5297\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9469 - val_loss: 10.6022\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9420 - val_loss: 12.9905\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3142 - val_loss: 9.8413\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9038 - val_loss: 10.3843\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4188 - val_loss: 9.9357\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0578 - val_loss: 10.3845\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9779 - val_loss: 10.2646\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0483 - val_loss: 10.4234\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9455 - val_loss: 11.6738\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1550 - val_loss: 11.9797\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4357 - val_loss: 10.4657\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1348 - val_loss: 14.7313\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2856 - val_loss: 11.7307\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0553 - val_loss: 11.6034\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0082 - val_loss: 10.0513\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8287 - val_loss: 13.4425\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0050 - val_loss: 11.5302\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2896 - val_loss: 10.6724\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2116 - val_loss: 10.2247\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1354 - val_loss: 10.7818\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1368 - val_loss: 10.1811\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0866 - val_loss: 13.5305\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5274 - val_loss: 10.6822\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9029 - val_loss: 10.1799\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1558 - val_loss: 13.5547\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.1213 - val_loss: 12.3775\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2220 - val_loss: 11.4192\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9706 - val_loss: 9.8642\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0798 - val_loss: 10.0559\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0927 - val_loss: 9.8311\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0489 - val_loss: 10.0865\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9150 - val_loss: 10.1885\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8578 - val_loss: 10.8928\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1456 - val_loss: 9.9933\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1284 - val_loss: 11.0783\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3454 - val_loss: 10.6981\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1508 - val_loss: 9.9611\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8625 - val_loss: 9.8311\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9821 - val_loss: 10.0491\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4069 - val_loss: 10.1584\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9033 - val_loss: 11.5886\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0007 - val_loss: 10.5217\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8442 - val_loss: 10.3311\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0044 - val_loss: 10.0766\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1201 - val_loss: 11.1604\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3627 - val_loss: 11.9259\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3944 - val_loss: 10.7456\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8627 - val_loss: 10.6196\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0775 - val_loss: 10.7655\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2573 - val_loss: 9.7331\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2663 - val_loss: 10.3032\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5934 - val_loss: 10.6272\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1680 - val_loss: 9.8431\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0171 - val_loss: 10.4563\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5798 - val_loss: 10.1754\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0303 - val_loss: 10.2954\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9876 - val_loss: 10.1385\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4198 - val_loss: 10.0034\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0373 - val_loss: 11.1031\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.9025 - val_loss: 10.3033\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1350 - val_loss: 10.1906\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0429 - val_loss: 10.9177\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1827 - val_loss: 11.2439\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9555 - val_loss: 10.0082\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0117 - val_loss: 11.3042\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2058 - val_loss: 10.6323\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5051 - val_loss: 11.0655\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8821 - val_loss: 10.2774\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4551 - val_loss: 10.4948\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9194 - val_loss: 9.9086\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1951 - val_loss: 10.3272\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2600 - val_loss: 10.8614\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.2070 - val_loss: 10.8090\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9090 - val_loss: 10.8429\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2526 - val_loss: 10.1064\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8135 - val_loss: 11.0904\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9163 - val_loss: 10.0142\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9184 - val_loss: 9.6844\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0600 - val_loss: 10.8057\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9431 - val_loss: 10.7124\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9277 - val_loss: 10.8580\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8867 - val_loss: 11.6355\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9424 - val_loss: 9.6976\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9962 - val_loss: 10.0216\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3775 - val_loss: 9.8758\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1056 - val_loss: 9.9953\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.3540 - val_loss: 9.6765\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1470 - val_loss: 10.2211\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7690 - val_loss: 9.8954\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2462 - val_loss: 9.8695\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4414 - val_loss: 10.6889\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0403 - val_loss: 10.4392\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8967 - val_loss: 11.0231\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8095 - val_loss: 10.6383\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8240 - val_loss: 9.6251\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.5606 - val_loss: 9.6540\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9417 - val_loss: 10.9660\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3131 - val_loss: 10.0103\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8797 - val_loss: 10.1079\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1146 - val_loss: 10.3599\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7267 - val_loss: 9.9294\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3624 - val_loss: 9.9564\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1073 - val_loss: 10.1510\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1255 - val_loss: 10.3367\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8650 - val_loss: 10.9724\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6124 - val_loss: 10.4598\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8058 - val_loss: 10.5337\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.2689 - val_loss: 10.5200\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8638 - val_loss: 9.9142\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8762 - val_loss: 10.4271\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7440 - val_loss: 12.5565\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1659 - val_loss: 10.0121\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8541 - val_loss: 10.4647\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8066 - val_loss: 10.5095\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1151 - val_loss: 10.1201\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0111 - val_loss: 11.0693\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6937 - val_loss: 11.1177\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2154 - val_loss: 10.6450\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8429 - val_loss: 9.9046\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8500 - val_loss: 9.9276\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3825 - val_loss: 10.6853\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.6260 - val_loss: 10.7002\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9405 - val_loss: 10.1668\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0009 - val_loss: 10.9803\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7300 - val_loss: 10.5536\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0498 - val_loss: 9.7540\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0436 - val_loss: 10.3799\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8358 - val_loss: 10.1407\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8580 - val_loss: 11.1479\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0085 - val_loss: 9.9211\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7986 - val_loss: 12.1175\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9937 - val_loss: 10.2015\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8236 - val_loss: 11.5413\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8883 - val_loss: 9.9263\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6951 - val_loss: 9.7451\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5840 - val_loss: 10.4101\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.9483 - val_loss: 9.8079\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8892 - val_loss: 9.6076\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.9599 - val_loss: 9.9277\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9425 - val_loss: 9.9892\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7313 - val_loss: 10.3821\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8037 - val_loss: 12.0628\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9827 - val_loss: 10.7141\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1729 - val_loss: 10.0587\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0229 - val_loss: 9.6611\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7239 - val_loss: 9.4855\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8128 - val_loss: 11.1404\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0053 - val_loss: 9.8194\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8900 - val_loss: 9.5762\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0167 - val_loss: 10.9441\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9269 - val_loss: 10.0132\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7078 - val_loss: 10.2252\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5819 - val_loss: 9.8693\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9785 - val_loss: 9.9466\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9077 - val_loss: 11.2731\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9784 - val_loss: 10.2562\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8647 - val_loss: 11.7244\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8558 - val_loss: 10.1975\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0762 - val_loss: 10.9046\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8244 - val_loss: 10.0719\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8253 - val_loss: 9.7726\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8480 - val_loss: 11.7503\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6421 - val_loss: 10.4822\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9026 - val_loss: 9.7978\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5565 - val_loss: 10.4179\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2014 - val_loss: 9.7992\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.8296 - val_loss: 10.2483\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2150 - val_loss: 11.4692\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9532 - val_loss: 10.4015\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7429 - val_loss: 12.5101\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1317 - val_loss: 10.3007\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6998 - val_loss: 12.6198\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8468 - val_loss: 11.2299\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2892 - val_loss: 10.1739\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.6498 - val_loss: 10.5995\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9656 - val_loss: 11.4126\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9408 - val_loss: 9.8389\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8067 - val_loss: 9.3961\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7677 - val_loss: 9.5710\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0113 - val_loss: 10.0395\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7132 - val_loss: 10.7559\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7768 - val_loss: 9.7086\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7975 - val_loss: 9.6963\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1524 - val_loss: 9.7702\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8008 - val_loss: 11.3246\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0621 - val_loss: 12.1159\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8580 - val_loss: 10.8236\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9361 - val_loss: 10.1279\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6463 - val_loss: 9.6409\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8953 - val_loss: 9.5456\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8030 - val_loss: 10.1015\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5679 - val_loss: 9.8936\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4032 - val_loss: 9.8179\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3031 - val_loss: 9.9238\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7776 - val_loss: 13.3877\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0494 - val_loss: 9.5277\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7685 - val_loss: 11.2625\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8009 - val_loss: 9.6294\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7735 - val_loss: 9.7215\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7418 - val_loss: 10.1106\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8626 - val_loss: 10.7177\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8967 - val_loss: 10.8941\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8442 - val_loss: 12.0969\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1104 - val_loss: 10.7697\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6757 - val_loss: 11.7270\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.1448 - val_loss: 9.9622\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9342 - val_loss: 9.4168\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7602 - val_loss: 9.5087\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.7172 - val_loss: 10.1443\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1733 - val_loss: 9.8946\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7833 - val_loss: 9.3960\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8746 - val_loss: 9.8269\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0348 - val_loss: 10.1064\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.9219 - val_loss: 9.6790\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7223 - val_loss: 10.0249\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6797 - val_loss: 9.7217\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5047 - val_loss: 9.8376\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9027 - val_loss: 9.6336\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6385 - val_loss: 9.6831\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9459 - val_loss: 10.2659\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8462 - val_loss: 9.3814\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8457 - val_loss: 11.4599\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0638 - val_loss: 10.0619\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8084 - val_loss: 9.8866\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9272 - val_loss: 9.6530\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7137 - val_loss: 10.1819\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5565 - val_loss: 10.2684\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6658 - val_loss: 10.4973\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8340 - val_loss: 10.1685\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5716 - val_loss: 10.3946\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9119 - val_loss: 10.2579\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6418 - val_loss: 10.0040\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9479 - val_loss: 9.9454\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8150 - val_loss: 9.8829\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5800 - val_loss: 9.8804\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2229 - val_loss: 9.9919\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5459 - val_loss: 9.4724\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.7251 - val_loss: 9.8577\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7825 - val_loss: 9.5365\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7555 - val_loss: 9.5373\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7603 - val_loss: 10.1970\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7260 - val_loss: 10.2755\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0150 - val_loss: 9.5850\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8794 - val_loss: 9.3439\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7085 - val_loss: 10.4629\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6392 - val_loss: 10.4240\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5289 - val_loss: 10.6535\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6471 - val_loss: 9.9460\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0241 - val_loss: 10.6623\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7324 - val_loss: 10.6497\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4814 - val_loss: 10.6764\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7815 - val_loss: 10.8688\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6367 - val_loss: 10.2853\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6150 - val_loss: 10.9559\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.6307 - val_loss: 10.6053\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6893 - val_loss: 14.9859\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4426 - val_loss: 9.5472\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4903 - val_loss: 9.9102\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1578 - val_loss: 9.8943\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6561 - val_loss: 9.7808\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.7651 - val_loss: 10.3470\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7556 - val_loss: 9.1011\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7488 - val_loss: 10.7021\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9723 - val_loss: 9.6402\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8949 - val_loss: 10.8914\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7857 - val_loss: 10.2002\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9113 - val_loss: 9.4307\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7103 - val_loss: 9.4013\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6116 - val_loss: 10.3137\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8088 - val_loss: 9.5262\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6604 - val_loss: 11.0474\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7532 - val_loss: 9.6292\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.594 - 0s 91us/step - loss: 6.7779 - val_loss: 10.3492\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4660 - val_loss: 10.3512\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7424 - val_loss: 10.6016\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3801 - val_loss: 9.7407\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6782 - val_loss: 10.0876\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.5701 - val_loss: 9.9336\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9789 - val_loss: 10.5430\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.6559 - val_loss: 9.4531\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9210 - val_loss: 11.5245\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5039 - val_loss: 9.7823\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9855 - val_loss: 9.4979\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5270 - val_loss: 10.9072\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9362 - val_loss: 9.5924\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8842 - val_loss: 10.2615\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0999 - val_loss: 9.3085\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4992 - val_loss: 9.1653\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1072 - val_loss: 9.6241\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6248 - val_loss: 9.6748\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 6.5677 - val_loss: 9.8542\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8366 - val_loss: 9.3841\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5101 - val_loss: 9.4759\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.6684 - val_loss: 9.8645\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6618 - val_loss: 11.5784\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5944 - val_loss: 10.4323\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7684 - val_loss: 9.4510\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5950 - val_loss: 10.1392\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5910 - val_loss: 10.3716\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.8074 - val_loss: 10.0226\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8680 - val_loss: 9.4326\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7048 - val_loss: 10.5570\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5515 - val_loss: 10.3148\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8302 - val_loss: 9.6989\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5781 - val_loss: 10.0286\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.1950 - val_loss: 9.4535\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5486 - val_loss: 10.0348\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6793 - val_loss: 9.8754\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5652 - val_loss: 11.3740\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7108 - val_loss: 9.3855\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5179 - val_loss: 9.4722\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0613 - val_loss: 9.2051\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4352 - val_loss: 11.9019\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7873 - val_loss: 9.7342\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1634 - val_loss: 9.3704\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7906 - val_loss: 9.5001\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8440 - val_loss: 10.6209\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4152 - val_loss: 10.3770\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4298 - val_loss: 9.3815\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.5533 - val_loss: 12.3870\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1517 - val_loss: 9.2360\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5774 - val_loss: 10.9816\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8501 - val_loss: 11.0780\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6290 - val_loss: 10.6726\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4774 - val_loss: 11.9274\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4199 - val_loss: 9.7002\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4651 - val_loss: 10.5582\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9153 - val_loss: 10.9692\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7240 - val_loss: 9.6546\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7976 - val_loss: 10.2285\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8240 - val_loss: 10.1004\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5876 - val_loss: 10.1074\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0905 - val_loss: 9.4117\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3276 - val_loss: 9.8796\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0816 - val_loss: 9.3735\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6463 - val_loss: 9.6510\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4867 - val_loss: 9.4577\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8774 - val_loss: 9.5669\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6825 - val_loss: 10.8653\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9568 - val_loss: 9.5973\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.201 - 0s 98us/step - loss: 6.4920 - val_loss: 9.9989\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8255 - val_loss: 9.9904\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7213 - val_loss: 9.1689\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1193 - val_loss: 9.4709\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6325 - val_loss: 9.3865\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8689 - val_loss: 9.5812\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7591 - val_loss: 9.5824\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4423 - val_loss: 9.5426\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6123 - val_loss: 9.6384\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8211 - val_loss: 9.5673\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8233 - val_loss: 9.9916\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7292 - val_loss: 9.9330\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7281 - val_loss: 9.3072\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8917 - val_loss: 11.3522\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5611 - val_loss: 9.5584\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7332 - val_loss: 11.7903\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9562 - val_loss: 9.7405\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7250 - val_loss: 9.9495\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0701 - val_loss: 10.7748\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5079 - val_loss: 9.7062\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5779 - val_loss: 10.1997\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7224 - val_loss: 9.2398\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7448 - val_loss: 9.6355\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6368 - val_loss: 9.6786\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5346 - val_loss: 9.2569\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6661 - val_loss: 9.7301\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4152 - val_loss: 10.3021\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.4187 - val_loss: 9.3205\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6642 - val_loss: 11.3639\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0117 - val_loss: 9.7159\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4571 - val_loss: 10.5677\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0116 - val_loss: 9.5736\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3258 - val_loss: 11.8445\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6947 - val_loss: 9.1771\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5756 - val_loss: 12.6802\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8097 - val_loss: 11.0814\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8678 - val_loss: 11.7853\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9754 - val_loss: 9.5794\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5559 - val_loss: 9.3776\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6760 - val_loss: 11.6132\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6925 - val_loss: 10.2355\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.4580 - val_loss: 10.9603\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9251 - val_loss: 11.2559\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4819 - val_loss: 10.2245\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9298 - val_loss: 9.8070\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7250 - val_loss: 9.5867\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7692 - val_loss: 9.2853\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4102 - val_loss: 10.3173\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5589 - val_loss: 11.0781\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7941 - val_loss: 10.2627\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9057 - val_loss: 9.7656\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6793 - val_loss: 10.0392\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8961 - val_loss: 10.6056\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5572 - val_loss: 9.9719\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7143 - val_loss: 9.1128\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6255 - val_loss: 10.2315\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6701 - val_loss: 9.4482\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4234 - val_loss: 9.8552\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6979 - val_loss: 10.9894\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6302 - val_loss: 13.2413\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2972 - val_loss: 11.3106\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7015 - val_loss: 9.2067\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8072 - val_loss: 9.8204\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7773 - val_loss: 10.1821\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7495 - val_loss: 9.4083\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5897 - val_loss: 10.0079\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7831 - val_loss: 9.5237\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6102 - val_loss: 10.1801\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5557 - val_loss: 9.8018\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7986 - val_loss: 9.5856\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6805 - val_loss: 10.0696\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3291 - val_loss: 9.5217\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2006 - val_loss: 9.0609\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5561 - val_loss: 10.4028\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.8879 - val_loss: 9.4852\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7721 - val_loss: 9.4169\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6089 - val_loss: 10.2777\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6876 - val_loss: 10.2814\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8173 - val_loss: 10.6274\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8413 - val_loss: 9.8401\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.4635 - val_loss: 11.1363\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5513 - val_loss: 8.9695\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9343 - val_loss: 9.4940\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7059 - val_loss: 9.6522\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4094 - val_loss: 10.0732\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7866 - val_loss: 8.9877\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5372 - val_loss: 10.5144\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5081 - val_loss: 10.7161\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3483 - val_loss: 9.4958\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5500 - val_loss: 10.3518\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6687 - val_loss: 10.7788\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6084 - val_loss: 9.6350\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9852 - val_loss: 9.4962\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3507 - val_loss: 9.4258\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4977 - val_loss: 10.2449\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7030 - val_loss: 9.3375\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6352 - val_loss: 10.1407\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6753 - val_loss: 9.4847\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0337 - val_loss: 9.5828\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4929 - val_loss: 10.1500\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6099 - val_loss: 9.1777\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4545 - val_loss: 10.3436\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8944 - val_loss: 9.7825\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5540 - val_loss: 11.1872\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.7180 - val_loss: 9.0474\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4683 - val_loss: 9.4997\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3697 - val_loss: 10.2518\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7303 - val_loss: 9.0426\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8842 - val_loss: 9.2125\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7252 - val_loss: 9.1173\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6397 - val_loss: 9.3963\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5534 - val_loss: 10.4593\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9526 - val_loss: 9.3224\n",
      "8.418632361848475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.9194338 ,  1.1333501 ,  1.633902  ,  1.2145857 ,  0.21644014],\n",
       "        [-1.6962245 ,  1.0549319 , -0.32198128, -0.9354039 , -0.38935444],\n",
       "        [ 0.831562  ,  0.9823663 ,  0.18948533, -0.5177159 ,  0.02019707],\n",
       "        [ 0.32788152, -0.4750337 , -0.75743586,  0.36078483,  0.673329  ],\n",
       "        [-0.13353384,  0.21440934, -0.0337398 , -1.0063103 , -0.2418501 ],\n",
       "        [-1.9717413 ,  0.6557197 ,  0.19731179,  0.48653534, -0.26119944],\n",
       "        [ 0.11370736, -0.09005906, -0.3879497 ,  1.4666969 , -0.14133136]],\n",
       "       dtype=float32),\n",
       " array([-2.2606797 ,  1.1657685 ,  2.362478  ,  2.1019611 , -0.01859286],\n",
       "       dtype=float32),\n",
       " array([[ 0.693732  ,  0.07137936,  0.42482084, -0.605629  ,  0.7224768 ,\n",
       "         -0.7093322 , -0.74295974, -0.18425886, -0.91097474, -0.06839804],\n",
       "        [ 0.91033924, -1.0121555 ,  0.9812546 , -0.12327425,  0.70182806,\n",
       "         -0.8012934 , -0.8114219 ,  0.66358215, -0.86572164,  0.38702586],\n",
       "        [-0.8012143 ,  0.75383145, -0.68374926,  1.2851672 , -1.1049598 ,\n",
       "          1.0901557 ,  0.94310325, -1.370283  ,  1.1331915 , -1.4975134 ],\n",
       "        [-0.40615502,  0.61772305, -0.6478453 ,  0.24536137, -0.8458686 ,\n",
       "          0.0402512 ,  0.7024649 , -0.69062537,  0.15899831, -0.20121647],\n",
       "        [ 0.72494704, -1.41409   ,  0.3217147 , -1.2242777 ,  0.6817819 ,\n",
       "         -1.160725  , -0.93364096,  0.6894038 , -0.66274863,  1.3233241 ]],\n",
       "       dtype=float32),\n",
       " array([-1.0793025 ,  1.1426506 , -0.94226795,  1.1457903 , -1.1120228 ,\n",
       "         0.9932956 ,  1.0486612 , -1.0857832 ,  1.0632843 , -1.099603  ],\n",
       "       dtype=float32),\n",
       " array([[-0.85574496],\n",
       "        [ 1.1603466 ],\n",
       "        [-0.5155691 ],\n",
       "        [ 1.2096131 ],\n",
       "        [-1.0315953 ],\n",
       "        [ 0.71041703],\n",
       "        [ 0.7937095 ],\n",
       "        [-0.7673753 ],\n",
       "        [ 0.8403706 ],\n",
       "        [-0.95343804]], dtype=float32),\n",
       " array([1.3735914], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, RMSprop, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_rmsprop_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.0644\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1341 - val_loss: 0.0615\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0954 - val_loss: 0.0305\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0652 - val_loss: 0.0678\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0510 - val_loss: 0.0208\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0207 - val_loss: 0.0165\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0255 - val_loss: 0.0097\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0213 - val_loss: 0.0094\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0184 - val_loss: 0.0070\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0139 - val_loss: 0.0079\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0095 - val_loss: 0.0051\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0091\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0081\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0041 - val_loss: 0.0071\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0044 - val_loss: 0.0095\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0073\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0065\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 108us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 224us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 98us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "0.005973733030259609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.74030954,  0.3146958 ,  0.7497738 ,  0.55560756, -0.3412879 ],\n",
       "        [ 0.57891   ,  0.06820694,  0.40552258, -0.3317556 , -0.07173084],\n",
       "        [ 0.78854215, -0.18321228,  0.04109332, -0.36616966, -0.781797  ],\n",
       "        [ 0.19663054,  0.06569327,  0.5075768 , -0.08712752,  0.27043134],\n",
       "        [ 0.25546685,  0.09687472,  0.2534934 , -0.03519319,  0.26828328],\n",
       "        [-0.73063266, -0.5608398 ,  0.34035873, -0.06075739, -0.6558311 ],\n",
       "        [ 0.2619733 ,  0.285457  ,  0.36613446,  0.00537155, -0.27280027],\n",
       "        [-0.2415304 ,  0.6199488 ,  0.4111679 ,  0.54069245, -0.19252339],\n",
       "        [-0.4500729 , -0.92395854,  0.19867781, -0.19394769, -0.1515075 ],\n",
       "        [ 0.62895   ,  1.7142737 , -0.18603234,  0.42516747, -0.495509  ],\n",
       "        [ 0.14318705,  0.6520148 ,  0.09665535, -0.36531088, -0.32650274],\n",
       "        [ 0.35333183,  1.1119828 ,  0.05291332,  0.6647812 , -0.4951954 ],\n",
       "        [ 0.6712026 ,  0.724882  ,  0.33256117, -0.2680109 ,  0.07979652],\n",
       "        [-2.0637224 , -0.49609244,  0.33124274, -0.39846683, -0.3019706 ],\n",
       "        [-0.11526694, -0.3729607 ,  0.47251537, -0.30770785, -0.08157209],\n",
       "        [ 0.23250411,  0.79397476,  0.5392994 ,  0.3148263 , -0.5300608 ],\n",
       "        [ 0.06129416, -0.4279664 ,  0.6980548 ,  0.13579221,  0.13609324],\n",
       "        [-0.11167532,  0.18888655,  0.6993281 , -0.5106134 ,  0.495755  ],\n",
       "        [ 0.24841714, -1.4900613 ,  0.05293871, -1.263333  , -0.7400856 ],\n",
       "        [-0.7964936 ,  0.01660647,  0.09210331, -0.02817404, -0.06885216],\n",
       "        [ 2.1316707 , -0.33572   , -0.18142192,  0.33243525,  0.20147605],\n",
       "        [ 0.1032007 ,  0.48657277,  0.5645414 , -0.44449747, -0.5347752 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.543963  ,  0.10784905,  0.2876984 ,  0.14160183, -0.24169709],\n",
       "       dtype=float32),\n",
       " array([[-0.1265614 ,  0.3859557 ,  0.52244973,  0.43042266,  0.6090942 ,\n",
       "         -0.555473  , -0.40204936,  0.27688786,  0.3679874 ,  0.03374109],\n",
       "        [ 0.1441319 , -0.23368089,  0.08967605, -0.20575699, -0.51971513,\n",
       "          0.5461603 ,  0.28113016, -0.5741302 ,  0.06197739, -0.43080103],\n",
       "        [ 0.18136069, -0.05388946,  0.27830476, -0.01652995,  0.30013034,\n",
       "         -0.17267784,  0.29781085,  0.09057079, -0.17597805,  0.281282  ],\n",
       "        [ 0.4519171 ,  0.42770526, -0.28710306, -0.3596822 ,  0.4422716 ,\n",
       "          0.3561583 ,  0.04818033,  0.4050466 ,  0.07174424, -0.180998  ],\n",
       "        [ 0.12966636,  0.4074503 ,  0.46054104,  0.21551622,  0.27379504,\n",
       "         -0.2635657 , -0.43077835,  0.42939684,  0.14147858, -0.01239572]],\n",
       "       dtype=float32),\n",
       " array([-0.0603179 ,  0.09199759, -0.13738294,  0.07322495,  0.01477121,\n",
       "        -0.10510669, -0.17689262,  0.09388399, -0.0121216 ,  0.03364267],\n",
       "       dtype=float32),\n",
       " array([[ 0.0126316 ],\n",
       "        [ 0.1426586 ],\n",
       "        [-0.11910918],\n",
       "        [-0.02107146],\n",
       "        [-0.48104692],\n",
       "        [ 0.05724181],\n",
       "        [ 0.14568576],\n",
       "        [-0.49110034],\n",
       "        [-0.01077412],\n",
       "        [-0.01795234]], dtype=float32),\n",
       " array([-0.00307256], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_adam_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0568\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0759 - val_loss: 0.0568\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0758 - val_loss: 0.0568\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0758 - val_loss: 0.0568\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0758 - val_loss: 0.0568\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0758 - val_loss: 0.0567\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0758 - val_loss: 0.0567\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0757 - val_loss: 0.0567\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0757 - val_loss: 0.0567\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0757 - val_loss: 0.0567\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0756 - val_loss: 0.0567\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0756 - val_loss: 0.0567\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0756 - val_loss: 0.0567\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0756 - val_loss: 0.0567\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0755 - val_loss: 0.0567\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0755 - val_loss: 0.0567\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0755 - val_loss: 0.0567\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0755 - val_loss: 0.0566\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0754 - val_loss: 0.0566\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0754 - val_loss: 0.0566\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0754 - val_loss: 0.0566\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0754 - val_loss: 0.0566\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0753 - val_loss: 0.0566\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0753 - val_loss: 0.0566\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0753 - val_loss: 0.0566\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0753 - val_loss: 0.0566\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0752 - val_loss: 0.0566\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0752 - val_loss: 0.0566\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0752 - val_loss: 0.0565\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0751 - val_loss: 0.0565\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0751 - val_loss: 0.0565\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0751 - val_loss: 0.0565\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0751 - val_loss: 0.0565\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0750 - val_loss: 0.0565\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0750 - val_loss: 0.0565\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0750 - val_loss: 0.0565\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0750 - val_loss: 0.0565\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0749 - val_loss: 0.0565\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0749 - val_loss: 0.0565\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0749 - val_loss: 0.0565\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0749 - val_loss: 0.0564\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0748 - val_loss: 0.0564\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0748 - val_loss: 0.0564\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0748 - val_loss: 0.0564\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0748 - val_loss: 0.0564\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0747 - val_loss: 0.0564\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0747 - val_loss: 0.0564\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0747 - val_loss: 0.0564\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0747 - val_loss: 0.0564\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0747 - val_loss: 0.0564\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0746 - val_loss: 0.0564\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0746 - val_loss: 0.0564\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0746 - val_loss: 0.0563\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0746 - val_loss: 0.0563\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0745 - val_loss: 0.0563\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0745 - val_loss: 0.0563\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0745 - val_loss: 0.0563\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0745 - val_loss: 0.0563\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0744 - val_loss: 0.0563\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0744 - val_loss: 0.0563\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0744 - val_loss: 0.0563\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0744 - val_loss: 0.0563\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0743 - val_loss: 0.0563\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0743 - val_loss: 0.0563\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0743 - val_loss: 0.0562\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0743 - val_loss: 0.0562\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0742 - val_loss: 0.0562\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0742 - val_loss: 0.0562\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 97us/step - loss: 0.0742 - val_loss: 0.0562\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0742 - val_loss: 0.0562\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0741 - val_loss: 0.0562\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0741 - val_loss: 0.0562\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0741 - val_loss: 0.0562\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0741 - val_loss: 0.0562\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0741 - val_loss: 0.0562\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0740 - val_loss: 0.0562\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0740 - val_loss: 0.0562\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0740 - val_loss: 0.0561\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0740 - val_loss: 0.0561\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0739 - val_loss: 0.0561\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0739 - val_loss: 0.0561\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0739 - val_loss: 0.0561\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0739 - val_loss: 0.0561\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0738 - val_loss: 0.0561\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0738 - val_loss: 0.0561\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0738 - val_loss: 0.0561\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0738 - val_loss: 0.0561\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0738 - val_loss: 0.0561\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0737 - val_loss: 0.0561\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0737 - val_loss: 0.0561\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0737 - val_loss: 0.0560\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0737 - val_loss: 0.0560\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0736 - val_loss: 0.0560\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0736 - val_loss: 0.0560\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0736 - val_loss: 0.0560\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0736 - val_loss: 0.0560\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0735 - val_loss: 0.0560\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0735 - val_loss: 0.0560\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0735 - val_loss: 0.0560\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0735 - val_loss: 0.0560\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0735 - val_loss: 0.0560\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0734 - val_loss: 0.0560\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0734 - val_loss: 0.0560\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0734 - val_loss: 0.0560\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0734 - val_loss: 0.0559\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0733 - val_loss: 0.0559\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0733 - val_loss: 0.0559\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0733 - val_loss: 0.0559\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0733 - val_loss: 0.0559\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0733 - val_loss: 0.0559\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0732 - val_loss: 0.0559\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0732 - val_loss: 0.0559\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0732 - val_loss: 0.0559\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0732 - val_loss: 0.0559\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0732 - val_loss: 0.0559\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0731 - val_loss: 0.0559\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0731 - val_loss: 0.0559\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0731 - val_loss: 0.0559\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0731 - val_loss: 0.0558\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0730 - val_loss: 0.0558\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0730 - val_loss: 0.0558\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0730 - val_loss: 0.0558\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0730 - val_loss: 0.0558\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0730 - val_loss: 0.0558\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0729 - val_loss: 0.0558\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0729 - val_loss: 0.0558\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0729 - val_loss: 0.0558\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0729 - val_loss: 0.0558\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0729 - val_loss: 0.0558\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0728 - val_loss: 0.0558\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0728 - val_loss: 0.0558\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0728 - val_loss: 0.0558\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0728 - val_loss: 0.0557\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0728 - val_loss: 0.0557\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0727 - val_loss: 0.0557\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0727 - val_loss: 0.0557\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0727 - val_loss: 0.0557\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0727 - val_loss: 0.0557\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0727 - val_loss: 0.0557\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0726 - val_loss: 0.0557\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0726 - val_loss: 0.0557\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0726 - val_loss: 0.0557\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0726 - val_loss: 0.0557\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0726 - val_loss: 0.0557\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0725 - val_loss: 0.0557\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0725 - val_loss: 0.0557\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0725 - val_loss: 0.0556\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0725 - val_loss: 0.0556\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0725 - val_loss: 0.0556\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0724 - val_loss: 0.0556\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0724 - val_loss: 0.0556\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0724 - val_loss: 0.0556\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0724 - val_loss: 0.0556\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0724 - val_loss: 0.0556\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0723 - val_loss: 0.0556\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0723 - val_loss: 0.0556\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0723 - val_loss: 0.0556\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0723 - val_loss: 0.0556\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0723 - val_loss: 0.0556\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0722 - val_loss: 0.0556\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0722 - val_loss: 0.0556\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0722 - val_loss: 0.0555\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0722 - val_loss: 0.0555\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0722 - val_loss: 0.0555\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0721 - val_loss: 0.0555\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0721 - val_loss: 0.0555\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0721 - val_loss: 0.0555\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0721 - val_loss: 0.0555\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0721 - val_loss: 0.0555\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0720 - val_loss: 0.0555\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0720 - val_loss: 0.0555\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0720 - val_loss: 0.0555\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0720 - val_loss: 0.0555\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0720 - val_loss: 0.0555\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0719 - val_loss: 0.0555\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0719 - val_loss: 0.0555\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0719 - val_loss: 0.0555\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0719 - val_loss: 0.0554\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0719 - val_loss: 0.0554\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0718 - val_loss: 0.0554\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0718 - val_loss: 0.0554\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0718 - val_loss: 0.0554\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0718 - val_loss: 0.0554\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0718 - val_loss: 0.0554\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0717 - val_loss: 0.0554\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0717 - val_loss: 0.0554\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0717 - val_loss: 0.0554\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0717 - val_loss: 0.0554\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0717 - val_loss: 0.0554\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0554\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0554\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0554\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0716 - val_loss: 0.0553\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0553\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0715 - val_loss: 0.0553\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0715 - val_loss: 0.0553\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0715 - val_loss: 0.0553\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0715 - val_loss: 0.0553\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0715 - val_loss: 0.0553\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0715 - val_loss: 0.0553\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0714 - val_loss: 0.0553\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0714 - val_loss: 0.0553\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0714 - val_loss: 0.0553\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0714 - val_loss: 0.0553\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0714 - val_loss: 0.0553\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0713 - val_loss: 0.0553\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0713 - val_loss: 0.0553\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0713 - val_loss: 0.0553\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0713 - val_loss: 0.0552\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0713 - val_loss: 0.0552\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0713 - val_loss: 0.0552\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0712 - val_loss: 0.0552\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0712 - val_loss: 0.0552\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0712 - val_loss: 0.0552\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0712 - val_loss: 0.0552\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0712 - val_loss: 0.0552\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0711 - val_loss: 0.0552\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0711 - val_loss: 0.0552\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0711 - val_loss: 0.0552\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0711 - val_loss: 0.0552\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0711 - val_loss: 0.0552\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0711 - val_loss: 0.0552\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0710 - val_loss: 0.0552\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0710 - val_loss: 0.0552\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0710 - val_loss: 0.0551\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0710 - val_loss: 0.0551\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0710 - val_loss: 0.0551\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0710 - val_loss: 0.0551\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0709 - val_loss: 0.0551\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0709 - val_loss: 0.0551\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0709 - val_loss: 0.0551\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0709 - val_loss: 0.0551\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0709 - val_loss: 0.0551\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0551\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0551\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0551\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0708 - val_loss: 0.0551\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0551\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0551\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0707 - val_loss: 0.0551\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0707 - val_loss: 0.0551\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 80us/step - loss: 0.0707 - val_loss: 0.0550\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0707 - val_loss: 0.0550\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0707 - val_loss: 0.0550\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0707 - val_loss: 0.0550\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0706 - val_loss: 0.0550\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0706 - val_loss: 0.0550\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0706 - val_loss: 0.0550\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0706 - val_loss: 0.0550\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0706 - val_loss: 0.0550\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0706 - val_loss: 0.0550\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0704 - val_loss: 0.0550\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0704 - val_loss: 0.0550\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0704 - val_loss: 0.0549\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0704 - val_loss: 0.0549\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0704 - val_loss: 0.0549\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0704 - val_loss: 0.0549\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0703 - val_loss: 0.0549\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0703 - val_loss: 0.0549\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0703 - val_loss: 0.0549\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0703 - val_loss: 0.0549\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0703 - val_loss: 0.0549\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0703 - val_loss: 0.0549\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0702 - val_loss: 0.0549\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0702 - val_loss: 0.0549\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0702 - val_loss: 0.0549\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0702 - val_loss: 0.0549\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0702 - val_loss: 0.0549\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0702 - val_loss: 0.0549\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0701 - val_loss: 0.0549\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0701 - val_loss: 0.0549\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0701 - val_loss: 0.0548\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0701 - val_loss: 0.0548\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0701 - val_loss: 0.0548\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0701 - val_loss: 0.0548\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0700 - val_loss: 0.0548\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0700 - val_loss: 0.0548\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0700 - val_loss: 0.0548\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0700 - val_loss: 0.0548\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0700 - val_loss: 0.0548\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0700 - val_loss: 0.0548\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0699 - val_loss: 0.0548\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0699 - val_loss: 0.0548\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0699 - val_loss: 0.0548\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0699 - val_loss: 0.0548\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0699 - val_loss: 0.0548\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0699 - val_loss: 0.0548\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0698 - val_loss: 0.0548\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0698 - val_loss: 0.0548\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0698 - val_loss: 0.0547\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0698 - val_loss: 0.0547\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0698 - val_loss: 0.0547\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0698 - val_loss: 0.0547\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0697 - val_loss: 0.0547\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0696 - val_loss: 0.0547\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0696 - val_loss: 0.0547\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0696 - val_loss: 0.0547\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0696 - val_loss: 0.0547\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0696 - val_loss: 0.0547\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0696 - val_loss: 0.0547\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0547\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0546\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0546\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0695 - val_loss: 0.0546\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0546\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0546\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0694 - val_loss: 0.0546\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0693 - val_loss: 0.0546\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0692 - val_loss: 0.0545\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0692 - val_loss: 0.0545\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0692 - val_loss: 0.0545\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0692 - val_loss: 0.0545\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0692 - val_loss: 0.0545\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.057 - 0s 91us/step - loss: 0.0692 - val_loss: 0.0545\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0545\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0690 - val_loss: 0.0545\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0690 - val_loss: 0.0545\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0690 - val_loss: 0.0545\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0690 - val_loss: 0.0545\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0690 - val_loss: 0.0545\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0690 - val_loss: 0.0544\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0690 - val_loss: 0.0544\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0689 - val_loss: 0.0544\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0689 - val_loss: 0.0544\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0689 - val_loss: 0.0544\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0689 - val_loss: 0.0544\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0689 - val_loss: 0.0544\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0689 - val_loss: 0.0544\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0688 - val_loss: 0.0544\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0544\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0687 - val_loss: 0.0544\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0544\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0544\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0544\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0687 - val_loss: 0.0543\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0686 - val_loss: 0.0543\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0543\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0543\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0543\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0685 - val_loss: 0.0543\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0685 - val_loss: 0.0543\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0685 - val_loss: 0.0543\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0684 - val_loss: 0.0543\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0684 - val_loss: 0.0543\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0684 - val_loss: 0.0543\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0684 - val_loss: 0.0543\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0684 - val_loss: 0.0543\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0684 - val_loss: 0.0542\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0684 - val_loss: 0.0542\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0683 - val_loss: 0.0542\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0682 - val_loss: 0.0542\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0681 - val_loss: 0.0542\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0681 - val_loss: 0.0542\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0681 - val_loss: 0.0542\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0681 - val_loss: 0.0542\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0681 - val_loss: 0.0541\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0681 - val_loss: 0.0541\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0681 - val_loss: 0.0541\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.074 - 0s 98us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0680 - val_loss: 0.0541\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0679 - val_loss: 0.0541\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0678 - val_loss: 0.0541\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0678 - val_loss: 0.0541\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0678 - val_loss: 0.0540\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0678 - val_loss: 0.0540\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0678 - val_loss: 0.0540\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0678 - val_loss: 0.0540\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0678 - val_loss: 0.0540\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0678 - val_loss: 0.0540\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0677 - val_loss: 0.0540\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0676 - val_loss: 0.0540\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0676 - val_loss: 0.0539\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0675 - val_loss: 0.0539\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0675 - val_loss: 0.0539\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0675 - val_loss: 0.0539\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0675 - val_loss: 0.0539\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0675 - val_loss: 0.0539\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0675 - val_loss: 0.0539\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0675 - val_loss: 0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0674 - val_loss: 0.0539\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0673 - val_loss: 0.0539\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0673 - val_loss: 0.0539\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0673 - val_loss: 0.0539\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0673 - val_loss: 0.0539\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0673 - val_loss: 0.0539\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0673 - val_loss: 0.0539\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0673 - val_loss: 0.0538\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0673 - val_loss: 0.0538\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0672 - val_loss: 0.0538\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0671 - val_loss: 0.0538\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0670 - val_loss: 0.0538\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0670 - val_loss: 0.0538\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0670 - val_loss: 0.0537\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0670 - val_loss: 0.0537\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0670 - val_loss: 0.0537\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0670 - val_loss: 0.0537\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0670 - val_loss: 0.0537\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0670 - val_loss: 0.0537\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0669 - val_loss: 0.0537\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0668 - val_loss: 0.0537\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0668 - val_loss: 0.0536\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0667 - val_loss: 0.0536\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0666 - val_loss: 0.0536\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0665 - val_loss: 0.0536\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0665 - val_loss: 0.0536\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0665 - val_loss: 0.0535\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0665 - val_loss: 0.0535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0665 - val_loss: 0.0535\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0665 - val_loss: 0.0535\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0665 - val_loss: 0.0535\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0665 - val_loss: 0.0535\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0664 - val_loss: 0.0535\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 80us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0663 - val_loss: 0.0535\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0663 - val_loss: 0.0534\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0663 - val_loss: 0.0534\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0534\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0661 - val_loss: 0.0534\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0660 - val_loss: 0.0534\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0660 - val_loss: 0.0534\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0660 - val_loss: 0.0533\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0533\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0658 - val_loss: 0.0533\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0658 - val_loss: 0.0533\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0658 - val_loss: 0.0533\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0658 - val_loss: 0.0533\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0658 - val_loss: 0.0533\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0658 - val_loss: 0.0532\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0658 - val_loss: 0.0532\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0658 - val_loss: 0.0532\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0658 - val_loss: 0.0532\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0532\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 615/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0656 - val_loss: 0.0532\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0655 - val_loss: 0.0531\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0654 - val_loss: 0.0531\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0653 - val_loss: 0.0531\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0531\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0653 - val_loss: 0.0531\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0653 - val_loss: 0.0530\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0530\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0653 - val_loss: 0.0530\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0530\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0530\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0530\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0652 - val_loss: 0.0530\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0651 - val_loss: 0.0530\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0651 - val_loss: 0.0530\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0651 - val_loss: 0.0530\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0651 - val_loss: 0.0530\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0651 - val_loss: 0.0530\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0651 - val_loss: 0.0530\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0651 - val_loss: 0.0529\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0651 - val_loss: 0.0529\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0651 - val_loss: 0.0529\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0650 - val_loss: 0.0529\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0649 - val_loss: 0.0529\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0649 - val_loss: 0.0528\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 693/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0648 - val_loss: 0.0528\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0647 - val_loss: 0.0528\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0646 - val_loss: 0.0528\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0646 - val_loss: 0.0527\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0645 - val_loss: 0.0527\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0527\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0644 - val_loss: 0.0527\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0527\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0527\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0644 - val_loss: 0.0526\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0526\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0644 - val_loss: 0.0526\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0526\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0644 - val_loss: 0.0526\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0526\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0643 - val_loss: 0.0526\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0642 - val_loss: 0.0526\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0642 - val_loss: 0.0526\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0642 - val_loss: 0.0526\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0642 - val_loss: 0.0526\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0526\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0642 - val_loss: 0.0526\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0525\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0525\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0525\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0642 - val_loss: 0.0525\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0642 - val_loss: 0.0525\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0641 - val_loss: 0.0525\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0640 - val_loss: 0.0525\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0524\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0640 - val_loss: 0.0524\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0640 - val_loss: 0.0524\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0640 - val_loss: 0.0524\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0639 - val_loss: 0.0524\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0524\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0523\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0523\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0523\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0638 - val_loss: 0.0523\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0637 - val_loss: 0.0523\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0636 - val_loss: 0.0523\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0636 - val_loss: 0.0522\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0636 - val_loss: 0.0522\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0636 - val_loss: 0.0522\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0636 - val_loss: 0.0522\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0635 - val_loss: 0.0522\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0634 - val_loss: 0.0522\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0634 - val_loss: 0.0521\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0634 - val_loss: 0.0521\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0634 - val_loss: 0.0521\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0634 - val_loss: 0.0521\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 848/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0633 - val_loss: 0.0521\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.056 - 0s 91us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0521\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0632 - val_loss: 0.0520\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0520\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0520\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0520\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0631 - val_loss: 0.0520\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0630 - val_loss: 0.0520\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 86us/step - loss: 0.0630 - val_loss: 0.0520\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0630 - val_loss: 0.0520\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0520\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0520\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0630 - val_loss: 0.0519\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0519\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0519\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0628 - val_loss: 0.0519\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0519\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0628 - val_loss: 0.0519\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0519\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0628 - val_loss: 0.0518\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0518\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0518\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 76us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0517\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0625 - val_loss: 0.0517\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 45us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0624 - val_loss: 0.0516\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0516\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0515\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0623 - val_loss: 0.0515\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0623 - val_loss: 0.0515\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0622 - val_loss: 0.0515\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0621 - val_loss: 0.0515\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0621 - val_loss: 0.0515\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0515\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0515\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0515\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0621 - val_loss: 0.0515\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0621 - val_loss: 0.0514\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0514\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0514\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0621 - val_loss: 0.0514\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0621 - val_loss: 0.0514\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0621 - val_loss: 0.0514\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0620 - val_loss: 0.0514\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0620 - val_loss: 0.0514\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0620 - val_loss: 0.0514\n",
      "0.08182893693447113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.32830662,  0.2967176 , -0.15410584,  0.12707569,  0.42532948],\n",
       "        [ 0.42293137,  0.32847103,  0.36824897,  0.2350426 ,  0.09040204],\n",
       "        [ 0.33595762, -0.05446576, -0.27066475, -0.21815567,  0.07014158],\n",
       "        [-0.17458367,  0.2179738 , -0.43622857, -0.00713356,  0.24799232],\n",
       "        [ 0.4282931 ,  0.3506481 ,  0.3720785 ,  0.14501937, -0.37635833],\n",
       "        [ 0.29348272, -0.2959374 ,  0.46123862, -0.17226104, -0.23436987],\n",
       "        [-0.22771536, -0.15250465,  0.36093733, -0.10753572,  0.12690161],\n",
       "        [ 0.28682417, -0.11349607,  0.11926742, -0.430047  ,  0.34092727],\n",
       "        [-0.18491907,  0.44185424, -0.00642083, -0.08693419,  0.04187988],\n",
       "        [-0.33756962, -0.0199553 ,  0.41007975,  0.46810055, -0.42826802],\n",
       "        [ 0.3661651 , -0.21436523, -0.12946492,  0.02425014, -0.2741015 ],\n",
       "        [ 0.29413012, -0.16408733, -0.2197242 , -0.05383405,  0.13959703],\n",
       "        [ 0.09571302, -0.01731401,  0.4350091 , -0.3648045 , -0.2990119 ],\n",
       "        [ 0.07844742,  0.19109656, -0.37944874, -0.4185691 ,  0.13847856],\n",
       "        [-0.11180647, -0.05926324,  0.2587535 , -0.25054342, -0.38077444],\n",
       "        [-0.02223035, -0.2970636 , -0.12290643, -0.40232322,  0.02212521],\n",
       "        [ 0.15101717,  0.04018518, -0.29623982, -0.04158029, -0.36643955],\n",
       "        [ 0.26659253,  0.09127624, -0.40376273, -0.12416641, -0.11456788],\n",
       "        [ 0.25127447, -0.03788072,  0.35599944, -0.43731064, -0.46367687],\n",
       "        [-0.35831517, -0.3788233 ,  0.04546817,  0.04945291,  0.14571102],\n",
       "        [-0.3587616 , -0.26581064,  0.04898586,  0.4303893 ,  0.20270902],\n",
       "        [ 0.32548586,  0.30100456, -0.18984157,  0.32214582,  0.2640014 ]],\n",
       "       dtype=float32),\n",
       " array([-5.8650813e-04, -1.1100115e-03, -3.9480910e-05, -4.8548981e-04,\n",
       "        -5.8137177e-04], dtype=float32),\n",
       " array([[ 0.20482665, -0.36648753, -0.23347083,  0.12764998,  0.11626635,\n",
       "          0.6342977 ,  0.47824365,  0.05276658, -0.43882573, -0.02098528],\n",
       "        [ 0.16818866, -0.11927965,  0.62680787, -0.20839639, -0.30153042,\n",
       "         -0.33143198, -0.62710077,  0.61401504,  0.624679  ,  0.13660963],\n",
       "        [ 0.3620779 ,  0.11647957, -0.22941762,  0.36869594, -0.60352045,\n",
       "         -0.5084101 , -0.37394914, -0.6223777 , -0.2834197 , -0.4390351 ],\n",
       "        [ 0.34755546,  0.23866951, -0.51892877,  0.26316935, -0.5908599 ,\n",
       "          0.16892926,  0.16147201,  0.31653035, -0.32482278, -0.21593802],\n",
       "        [-0.55831265,  0.24567275,  0.26155353,  0.15765579,  0.50556785,\n",
       "          0.45791885,  0.08394698, -0.05301251,  0.01403309,  0.01963984]],\n",
       "       dtype=float32),\n",
       " array([-0.00277244, -0.00260341, -0.0003604 ,  0.00264295, -0.00059881,\n",
       "         0.00234643, -0.0017783 , -0.00013232, -0.00107897, -0.00065926],\n",
       "       dtype=float32),\n",
       " array([[-0.72694725],\n",
       "        [-0.6899375 ],\n",
       "        [-0.09350716],\n",
       "        [ 0.69423956],\n",
       "        [-0.1582831 ],\n",
       "        [ 0.6127398 ],\n",
       "        [-0.4706382 ],\n",
       "        [-0.03937129],\n",
       "        [-0.28350314],\n",
       "        [-0.17362303]], dtype=float32),\n",
       " array([0.00379771], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, sgd, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sgd_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1797 - val_loss: 0.0143\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0308 - val_loss: 0.0117\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0254 - val_loss: 0.0135\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0394 - val_loss: 0.0077\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0246 - val_loss: 0.0190\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0206 - val_loss: 0.0091\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0158 - val_loss: 0.0078\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0505 - val_loss: 0.0056\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0167 - val_loss: 0.0074\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0227 - val_loss: 0.0216\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0234 - val_loss: 0.0149\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0152 - val_loss: 0.0418\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0341 - val_loss: 0.0105\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0208 - val_loss: 0.0118\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0130 - val_loss: 0.0058\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0161 - val_loss: 0.0468\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0326 - val_loss: 0.0061\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0239 - val_loss: 0.0189\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0182 - val_loss: 0.0101\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0210 - val_loss: 0.0111\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0204 - val_loss: 0.0237\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0168 - val_loss: 0.0190\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0190 - val_loss: 0.0079\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0112 - val_loss: 0.0074\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0356 - val_loss: 0.0157\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0164 - val_loss: 0.0061\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0108 - val_loss: 0.0359\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0075\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0103 - val_loss: 0.0058\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0222 - val_loss: 0.0131\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0329 - val_loss: 0.0084\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0119 - val_loss: 0.0051\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0276 - val_loss: 0.0126\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0136 - val_loss: 0.0073\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0139 - val_loss: 0.0076\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0113 - val_loss: 0.0219\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0241 - val_loss: 0.0059\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0237 - val_loss: 0.0154\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0241 - val_loss: 0.0187\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0130 - val_loss: 0.0060\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0173 - val_loss: 0.0071\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0115 - val_loss: 0.0178\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0237 - val_loss: 0.0087\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0106 - val_loss: 0.0075\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0111 - val_loss: 0.0190\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0171 - val_loss: 0.0083\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0134 - val_loss: 0.0093\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0171 - val_loss: 0.0071\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0141 - val_loss: 0.0113\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0103 - val_loss: 0.0064\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0126 - val_loss: 0.0184\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0114 - val_loss: 0.0065\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0113 - val_loss: 0.0061\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0095\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0223\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0169 - val_loss: 0.0070\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0127\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0156 - val_loss: 0.0072\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0124 - val_loss: 0.0060\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0164 - val_loss: 0.0062\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0109 - val_loss: 0.0078\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0109 - val_loss: 0.0054\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0108 - val_loss: 0.0052\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0116 - val_loss: 0.0053\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0091 - val_loss: 0.0112\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0134 - val_loss: 0.0058\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0116 - val_loss: 0.0050\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0139\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0115 - val_loss: 0.0053\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0102 - val_loss: 0.0050\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0087 - val_loss: 0.0131\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0073 - val_loss: 0.0120\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0110 - val_loss: 0.0069\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0078 - val_loss: 0.0042\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0045\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0097\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 90us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0096\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0056 - val_loss: 0.0088\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0037\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0090\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0089 - val_loss: 0.0036\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0073\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0071 - val_loss: 0.0035\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0075 - val_loss: 0.0038\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 534/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0051 - val_loss: 0.0081\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0076\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0039\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0083\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0032\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0085\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0100\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0078\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0079\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0079\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 843/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0030 - val_loss: 0.0078\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0081\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0031 - val_loss: 0.0072\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0087\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0079\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0074\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 104us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 998/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "0.007098103407770395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5582802 , -0.04097692, -0.396288  ,  1.0269827 ,  0.04957781],\n",
       "        [ 0.05195243, -1.020368  ,  0.8871208 , -0.6734438 , -0.34357658],\n",
       "        [ 0.6671675 ,  0.21326268, -0.2777804 , -0.76889265,  0.03472825],\n",
       "        [ 0.3636443 , -0.6600855 , -0.30317295,  0.24650797, -0.209651  ],\n",
       "        [ 0.09387331,  0.4269042 ,  0.9981767 , -0.24441618, -0.07885956],\n",
       "        [ 0.07322767, -0.1910683 ,  0.5353461 ,  0.6229598 ,  0.04038649],\n",
       "        [ 0.5303899 , -1.6075166 ,  0.673626  , -0.4315118 ,  0.11180747],\n",
       "        [-0.03200595, -0.4392968 , -0.46041298,  0.317933  , -0.12328755],\n",
       "        [ 0.43916726, -0.36721978,  0.3815556 , -0.15650061,  0.00657681],\n",
       "        [ 0.14763746, -0.71152484, -0.47883058,  0.5012954 , -0.03977246],\n",
       "        [-0.48034444, -0.01123167, -0.10017574, -0.49393874, -0.01887495],\n",
       "        [-2.507587  ,  1.23152   ,  0.17993413, -0.4119466 ,  0.26920363],\n",
       "        [-0.6396042 ,  0.56893194, -0.9171665 , -0.37330353,  0.33030975],\n",
       "        [-3.8663263 , -0.6302184 ,  1.8651887 ,  2.7779758 , -0.6368296 ],\n",
       "        [-1.2126715 ,  0.34874967, -0.416187  , -0.12081788,  0.09214298],\n",
       "        [ 0.27663943, -0.24396214, -0.70901847,  0.27713448, -0.02711454],\n",
       "        [ 0.49576816,  0.10873631,  0.2317746 , -0.63526255,  0.08546397],\n",
       "        [-0.31771582,  0.7598349 , -0.06152983,  0.18334997,  0.50517046],\n",
       "        [ 0.78491527,  1.6545789 , -1.1662996 , -0.70137733,  0.6332838 ],\n",
       "        [-0.20529494,  0.24016696,  0.37601325,  1.4484605 , -0.29618657],\n",
       "        [ 1.9201332 , -0.07096944,  0.26485547, -2.8800058 , -0.24512228],\n",
       "        [ 0.54776293, -0.30642468,  1.0514879 , -1.2097106 , -0.61292934]],\n",
       "       dtype=float32),\n",
       " array([ 0.73763794,  0.3244498 , -0.5512979 , -0.72952527,  0.24895296],\n",
       "       dtype=float32),\n",
       " array([[-4.75371033e-02,  4.24172319e-02,  4.38810065e-02,\n",
       "         -4.14438173e-02,  3.34200621e-01, -2.81191200e-01,\n",
       "         -5.31521365e-02, -4.55923937e-02,  4.82331552e-02,\n",
       "          3.51512916e-02],\n",
       "        [ 2.82192416e-02, -5.43349981e-03,  2.60169934e-02,\n",
       "         -1.16087338e-02,  3.13987821e-01, -1.01992294e-01,\n",
       "         -6.08769245e-02,  6.98922249e-03, -2.66843066e-02,\n",
       "          5.45815714e-02],\n",
       "        [-2.44510807e-02,  1.81692466e-02,  1.10583249e-02,\n",
       "         -1.85750006e-03, -1.92124501e-01, -3.28199938e-02,\n",
       "          5.03619909e-02, -4.29320037e-02,  5.82676344e-02,\n",
       "         -5.49744889e-02],\n",
       "        [ 2.78571359e-04, -1.61218399e-04,  9.20850225e-03,\n",
       "          1.99137512e-03, -9.08351839e-01,  7.36873507e-01,\n",
       "          2.32566074e-02, -5.00704683e-02,  1.33989826e-01,\n",
       "         -2.04689223e-02],\n",
       "        [-4.48309816e-02,  5.25882430e-02,  2.99411602e-02,\n",
       "         -8.85431655e-03, -2.47948945e-01, -5.50804079e-01,\n",
       "         -2.36268770e-02, -7.85271078e-03,  9.84561443e-03,\n",
       "         -1.48725472e-02]], dtype=float32),\n",
       " array([ 0.01813089, -0.01176683, -0.00619889,  0.00650602, -0.5791053 ,\n",
       "         0.5619334 ,  0.0169891 , -0.03223264,  0.07661975, -0.01250837],\n",
       "       dtype=float32),\n",
       " array([[ 0.00226463],\n",
       "        [-0.00483459],\n",
       "        [-0.00449304],\n",
       "        [ 0.00571501],\n",
       "        [-0.29298303],\n",
       "        [ 0.1339012 ],\n",
       "        [ 0.01031672],\n",
       "        [ 0.00656217],\n",
       "        [-0.00437662],\n",
       "        [-0.00247633]], dtype=float32),\n",
       " array([0.3035076], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, RMSprop, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_rmsprop_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 36.1891 - val_loss: 33.0761\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 33.1270 - val_loss: 26.4314\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 28.9321 - val_loss: 19.9079\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 23.4839 - val_loss: 13.6145\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.0663 - val_loss: 8.4651\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 10.4356 - val_loss: 4.8048\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9532 - val_loss: 2.2354\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6288 - val_loss: 1.1806\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0918 - val_loss: 1.5670\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8566 - val_loss: 2.7105\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6316 - val_loss: 3.4143\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8015 - val_loss: 3.4660\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8617 - val_loss: 3.0790\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6536 - val_loss: 2.4372\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6456 - val_loss: 1.6737\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.9410 - val_loss: 0.9532\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.5000 - val_loss: 0.4647\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2898 - val_loss: 0.3425\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2981 - val_loss: 0.5892\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4892 - val_loss: 1.0465\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7696 - val_loss: 1.4563\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0066 - val_loss: 1.6104\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0989 - val_loss: 1.4654\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0302 - val_loss: 1.1256\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.8540 - val_loss: 0.7459\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6432 - val_loss: 0.4457\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4527 - val_loss: 0.2724\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3074 - val_loss: 0.2049\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2065 - val_loss: 0.1870\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1366 - val_loss: 0.1687\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0880 - val_loss: 0.1353\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0642 - val_loss: 0.1035\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0742 - val_loss: 0.0949\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1171 - val_loss: 0.1119\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1745 - val_loss: 0.1370\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2201 - val_loss: 0.1514\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2355 - val_loss: 0.1481\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2163 - val_loss: 0.1313\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1712 - val_loss: 0.1090\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1170 - val_loss: 0.0874\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0711 - val_loss: 0.0692\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0545\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0309 - val_loss: 0.0422\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0283 - val_loss: 0.0318\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0247\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0232\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.0291\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0419 - val_loss: 0.0416\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0491 - val_loss: 0.0563\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0548 - val_loss: 0.0666\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0565 - val_loss: 0.0670\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0527 - val_loss: 0.0563\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0436 - val_loss: 0.0387\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0316 - val_loss: 0.0217\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0200 - val_loss: 0.0112\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0086\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0113\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0074 - val_loss: 0.0149\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0168\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0167\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0156\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9692e-04 - val_loss: 0.0010\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8997e-04 - val_loss: 9.8854e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8301e-04 - val_loss: 9.7816e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7607e-04 - val_loss: 9.6868e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6918e-04 - val_loss: 9.5973e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6237e-04 - val_loss: 9.5083e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5567e-04 - val_loss: 9.4161e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 9.4907e-04 - val_loss: 9.3181e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4257e-04 - val_loss: 9.2133e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3613e-04 - val_loss: 9.1028e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2974e-04 - val_loss: 8.9892e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2341e-04 - val_loss: 8.8760e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1713e-04 - val_loss: 8.7666e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1091e-04 - val_loss: 8.6645e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0475e-04 - val_loss: 8.5720e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9862e-04 - val_loss: 8.4899e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9254e-04 - val_loss: 8.4176e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8652e-04 - val_loss: 8.3536e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8053e-04 - val_loss: 8.2956e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7460e-04 - val_loss: 8.2397e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6874e-04 - val_loss: 8.1841e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6294e-04 - val_loss: 8.1247e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5719e-04 - val_loss: 8.0610e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5151e-04 - val_loss: 7.9917e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4586e-04 - val_loss: 7.9171e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4027e-04 - val_loss: 7.8383e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3472e-04 - val_loss: 7.7577e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2921e-04 - val_loss: 7.6765e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2376e-04 - val_loss: 7.5967e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.1835e-04 - val_loss: 7.5193e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1299e-04 - val_loss: 7.4450e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0766e-04 - val_loss: 7.3736e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0238e-04 - val_loss: 7.3050e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9715e-04 - val_loss: 7.2382e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9197e-04 - val_loss: 7.1725e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.8683e-04 - val_loss: 7.1072e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8174e-04 - val_loss: 7.0415e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7668e-04 - val_loss: 6.9757e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7169e-04 - val_loss: 6.9094e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.6672e-04 - val_loss: 6.8430e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6179e-04 - val_loss: 6.7775e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5690e-04 - val_loss: 6.7132e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5207e-04 - val_loss: 6.6506e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4726e-04 - val_loss: 6.5902e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4249e-04 - val_loss: 6.5322e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3776e-04 - val_loss: 6.4764e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3308e-04 - val_loss: 6.4221e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2843e-04 - val_loss: 6.3693e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2383e-04 - val_loss: 6.3167e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1924e-04 - val_loss: 6.2641e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1472e-04 - val_loss: 6.2113e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1022e-04 - val_loss: 6.1574e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.0575e-04 - val_loss: 6.1028e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0133e-04 - val_loss: 6.0477e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9694e-04 - val_loss: 5.9922e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9257e-04 - val_loss: 5.9368e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8826e-04 - val_loss: 5.8820e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8398e-04 - val_loss: 5.8278e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7973e-04 - val_loss: 5.7746e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7551e-04 - val_loss: 5.7226e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7133e-04 - val_loss: 5.6714e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6717e-04 - val_loss: 5.6214e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6306e-04 - val_loss: 5.5720e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5897e-04 - val_loss: 5.5233e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5492e-04 - val_loss: 5.4750e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5090e-04 - val_loss: 5.4269e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4691e-04 - val_loss: 5.3793e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4296e-04 - val_loss: 5.3318e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3903e-04 - val_loss: 5.2847e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3513e-04 - val_loss: 5.2380e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3127e-04 - val_loss: 5.1919e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2743e-04 - val_loss: 5.1466e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2363e-04 - val_loss: 5.1019e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1984e-04 - val_loss: 5.0577e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1609e-04 - val_loss: 5.0143e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 6.1239e-04 - val_loss: 4.9715e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0869e-04 - val_loss: 4.9291e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0503e-04 - val_loss: 4.8870e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0141e-04 - val_loss: 4.8450e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9780e-04 - val_loss: 4.8034e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9423e-04 - val_loss: 4.7617e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9066e-04 - val_loss: 4.7202e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8714e-04 - val_loss: 4.6787e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8365e-04 - val_loss: 4.6378e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8018e-04 - val_loss: 4.5972e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7673e-04 - val_loss: 4.5567e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7332e-04 - val_loss: 4.5168e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6992e-04 - val_loss: 4.4776e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6655e-04 - val_loss: 4.4388e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6322e-04 - val_loss: 4.4001e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5989e-04 - val_loss: 4.3623e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5661e-04 - val_loss: 4.3248e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5335e-04 - val_loss: 4.2877e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5010e-04 - val_loss: 4.2506e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4687e-04 - val_loss: 4.2141e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4368e-04 - val_loss: 4.1777e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 5.4051e-04 - val_loss: 4.1418e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3736e-04 - val_loss: 4.1061e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3424e-04 - val_loss: 4.0707e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3114e-04 - val_loss: 4.0357e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2806e-04 - val_loss: 4.0009e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2501e-04 - val_loss: 3.9666e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2197e-04 - val_loss: 3.9327e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1896e-04 - val_loss: 3.8991e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1597e-04 - val_loss: 3.8658e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1300e-04 - val_loss: 3.8326e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1006e-04 - val_loss: 3.7998e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0713e-04 - val_loss: 3.7673e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0423e-04 - val_loss: 3.7348e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0134e-04 - val_loss: 3.7025e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9848e-04 - val_loss: 3.6708e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9565e-04 - val_loss: 3.6393e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9282e-04 - val_loss: 3.6079e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9003e-04 - val_loss: 3.5768e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8725e-04 - val_loss: 3.5460e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 4.8449e-04 - val_loss: 3.5155e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.8175e-04 - val_loss: 3.4854e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7903e-04 - val_loss: 3.4555e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7632e-04 - val_loss: 3.4259e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.7365e-04 - val_loss: 3.3966e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7098e-04 - val_loss: 3.3675e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6834e-04 - val_loss: 3.3387e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6571e-04 - val_loss: 3.3100e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6310e-04 - val_loss: 3.2817e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6051e-04 - val_loss: 3.2537e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5795e-04 - val_loss: 3.2257e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5540e-04 - val_loss: 3.1979e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5287e-04 - val_loss: 3.1707e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5034e-04 - val_loss: 3.1435e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4785e-04 - val_loss: 3.1167e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4537e-04 - val_loss: 3.0899e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4290e-04 - val_loss: 3.0636e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4046e-04 - val_loss: 3.0374e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3803e-04 - val_loss: 3.0112e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3562e-04 - val_loss: 2.9856e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3323e-04 - val_loss: 2.9600e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3085e-04 - val_loss: 2.9345e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2848e-04 - val_loss: 2.9094e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2614e-04 - val_loss: 2.8844e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2380e-04 - val_loss: 2.8597e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2149e-04 - val_loss: 2.8351e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1920e-04 - val_loss: 2.8108e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1691e-04 - val_loss: 2.7866e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1464e-04 - val_loss: 2.7627e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1240e-04 - val_loss: 2.7389e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1016e-04 - val_loss: 2.7155e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0794e-04 - val_loss: 2.6922e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0573e-04 - val_loss: 2.6692e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0355e-04 - val_loss: 2.6462e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0137e-04 - val_loss: 2.6235e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9921e-04 - val_loss: 2.6010e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9707e-04 - val_loss: 2.5787e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9494e-04 - val_loss: 2.5566e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9282e-04 - val_loss: 2.5346e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9071e-04 - val_loss: 2.5129e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8863e-04 - val_loss: 2.4913e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8655e-04 - val_loss: 2.4698e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8450e-04 - val_loss: 2.4486e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8245e-04 - val_loss: 2.4275e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8042e-04 - val_loss: 2.4066e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7839e-04 - val_loss: 2.3858e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7638e-04 - val_loss: 2.3653e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7440e-04 - val_loss: 2.3450e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7243e-04 - val_loss: 2.3247e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7046e-04 - val_loss: 2.3048e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6850e-04 - val_loss: 2.2849e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6657e-04 - val_loss: 2.2652e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6464e-04 - val_loss: 2.2457e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6273e-04 - val_loss: 2.2262e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6083e-04 - val_loss: 2.2069e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5893e-04 - val_loss: 2.1879e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5706e-04 - val_loss: 2.1690e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5520e-04 - val_loss: 2.1504e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5335e-04 - val_loss: 2.1317e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5151e-04 - val_loss: 2.1133e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4968e-04 - val_loss: 2.0950e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4787e-04 - val_loss: 2.0768e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4606e-04 - val_loss: 2.0588e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4427e-04 - val_loss: 2.0411e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4249e-04 - val_loss: 2.0233e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4073e-04 - val_loss: 2.0057e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3897e-04 - val_loss: 1.9883e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3722e-04 - val_loss: 1.9711e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3549e-04 - val_loss: 1.9540e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3376e-04 - val_loss: 1.9370e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3205e-04 - val_loss: 1.9202e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3036e-04 - val_loss: 1.9035e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2867e-04 - val_loss: 1.8869e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2699e-04 - val_loss: 1.8705e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2532e-04 - val_loss: 1.8542e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2367e-04 - val_loss: 1.8380e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2202e-04 - val_loss: 1.8219e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2038e-04 - val_loss: 1.8060e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1876e-04 - val_loss: 1.7903e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1715e-04 - val_loss: 1.7747e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1554e-04 - val_loss: 1.7591e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1395e-04 - val_loss: 1.7437e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1237e-04 - val_loss: 1.7285e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1079e-04 - val_loss: 1.7134e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0923e-04 - val_loss: 1.6984e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0768e-04 - val_loss: 1.6835e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0613e-04 - val_loss: 1.6687e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.0460e-04 - val_loss: 1.6540e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0307e-04 - val_loss: 1.6395e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0156e-04 - val_loss: 1.6251e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0005e-04 - val_loss: 1.6108e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9857e-04 - val_loss: 1.5965e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9708e-04 - val_loss: 1.5825e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9560e-04 - val_loss: 1.5686e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9413e-04 - val_loss: 1.5547e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9267e-04 - val_loss: 1.5410e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9123e-04 - val_loss: 1.5273e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8979e-04 - val_loss: 1.5140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8836e-04 - val_loss: 1.5006e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8694e-04 - val_loss: 1.4873e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8552e-04 - val_loss: 1.4740e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8412e-04 - val_loss: 1.4610e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8272e-04 - val_loss: 1.4481e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8134e-04 - val_loss: 1.4352e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7996e-04 - val_loss: 1.4225e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7860e-04 - val_loss: 1.4097e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7723e-04 - val_loss: 1.3972e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7588e-04 - val_loss: 1.3848e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7453e-04 - val_loss: 1.3724e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7319e-04 - val_loss: 1.3601e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7187e-04 - val_loss: 1.3480e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 2.7055e-04 - val_loss: 1.3360e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6924e-04 - val_loss: 1.3240e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6794e-04 - val_loss: 1.3122e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6665e-04 - val_loss: 1.3005e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6536e-04 - val_loss: 1.2888e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6408e-04 - val_loss: 1.2773e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.6281e-04 - val_loss: 1.2658e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6155e-04 - val_loss: 1.2543e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6029e-04 - val_loss: 1.2431e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5904e-04 - val_loss: 1.2319e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5780e-04 - val_loss: 1.2207e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5657e-04 - val_loss: 1.2098e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5534e-04 - val_loss: 1.1988e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5413e-04 - val_loss: 1.1879e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5292e-04 - val_loss: 1.1772e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5171e-04 - val_loss: 1.1665e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5052e-04 - val_loss: 1.1560e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4933e-04 - val_loss: 1.1455e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4815e-04 - val_loss: 1.1351e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4698e-04 - val_loss: 1.1248e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4581e-04 - val_loss: 1.1146e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4465e-04 - val_loss: 1.1044e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4350e-04 - val_loss: 1.0944e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4235e-04 - val_loss: 1.0843e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4121e-04 - val_loss: 1.0744e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4008e-04 - val_loss: 1.0646e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3896e-04 - val_loss: 1.0548e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3784e-04 - val_loss: 1.0452e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3673e-04 - val_loss: 1.0355e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3562e-04 - val_loss: 1.0260e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3453e-04 - val_loss: 1.0166e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3343e-04 - val_loss: 1.0072e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3235e-04 - val_loss: 9.9796e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3127e-04 - val_loss: 9.8874e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3020e-04 - val_loss: 9.7964e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2913e-04 - val_loss: 9.7063e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2808e-04 - val_loss: 9.6161e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2702e-04 - val_loss: 9.5271e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2597e-04 - val_loss: 9.4392e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2493e-04 - val_loss: 9.3514e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2390e-04 - val_loss: 9.2642e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2287e-04 - val_loss: 9.1781e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2185e-04 - val_loss: 9.0919e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2083e-04 - val_loss: 9.0070e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1982e-04 - val_loss: 8.9230e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1882e-04 - val_loss: 8.8394e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1782e-04 - val_loss: 8.7570e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1683e-04 - val_loss: 8.6745e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1584e-04 - val_loss: 8.5936e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1486e-04 - val_loss: 8.5125e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1389e-04 - val_loss: 8.4320e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.1292e-04 - val_loss: 8.3527e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1196e-04 - val_loss: 8.2745e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1100e-04 - val_loss: 8.1967e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1004e-04 - val_loss: 8.1189e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0910e-04 - val_loss: 8.0415e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0815e-04 - val_loss: 7.9658e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0722e-04 - val_loss: 7.8898e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0629e-04 - val_loss: 7.8151e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0537e-04 - val_loss: 7.7403e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0445e-04 - val_loss: 7.6661e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0353e-04 - val_loss: 7.5937e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.0263e-04 - val_loss: 7.5206e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0172e-04 - val_loss: 7.4488e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0083e-04 - val_loss: 7.3774e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9993e-04 - val_loss: 7.3069e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9904e-04 - val_loss: 7.2361e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9817e-04 - val_loss: 7.1667e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9728e-04 - val_loss: 7.0975e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 1.9641e-04 - val_loss: 7.0290e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9554e-04 - val_loss: 6.9615e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9468e-04 - val_loss: 6.8940e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9382e-04 - val_loss: 6.8276e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9297e-04 - val_loss: 6.7610e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9213e-04 - val_loss: 6.6950e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9128e-04 - val_loss: 6.6305e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9044e-04 - val_loss: 6.5658e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8961e-04 - val_loss: 6.5013e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8878e-04 - val_loss: 6.4388e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8796e-04 - val_loss: 6.3754e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8714e-04 - val_loss: 6.3130e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8632e-04 - val_loss: 6.2503e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8552e-04 - val_loss: 6.1886e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8472e-04 - val_loss: 6.1274e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8391e-04 - val_loss: 6.0677e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8312e-04 - val_loss: 6.0072e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8232e-04 - val_loss: 5.9475e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8154e-04 - val_loss: 5.8890e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8076e-04 - val_loss: 5.8307e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7997e-04 - val_loss: 5.7730e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7920e-04 - val_loss: 5.7150e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7844e-04 - val_loss: 5.6586e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7767e-04 - val_loss: 5.6018e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7692e-04 - val_loss: 5.5462e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7616e-04 - val_loss: 5.4906e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 1.7541e-04 - val_loss: 5.4354e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7466e-04 - val_loss: 5.3806e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7392e-04 - val_loss: 5.3261e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7317e-04 - val_loss: 5.2726e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7244e-04 - val_loss: 5.2197e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7171e-04 - val_loss: 5.1666e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7098e-04 - val_loss: 5.1143e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7026e-04 - val_loss: 5.0622e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6954e-04 - val_loss: 5.0107e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6882e-04 - val_loss: 4.9597e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6811e-04 - val_loss: 4.9093e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6741e-04 - val_loss: 4.8589e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6671e-04 - val_loss: 4.8090e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6601e-04 - val_loss: 4.7597e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6532e-04 - val_loss: 4.7108e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6462e-04 - val_loss: 4.6621e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6393e-04 - val_loss: 4.6145e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6325e-04 - val_loss: 4.5665e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6258e-04 - val_loss: 4.5192e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6190e-04 - val_loss: 4.4731e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6123e-04 - val_loss: 4.4260e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6056e-04 - val_loss: 4.3803e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5989e-04 - val_loss: 4.3345e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5924e-04 - val_loss: 4.2892e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5858e-04 - val_loss: 4.2438e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5793e-04 - val_loss: 4.1999e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5728e-04 - val_loss: 4.1561e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5663e-04 - val_loss: 4.1120e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5599e-04 - val_loss: 4.0687e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5535e-04 - val_loss: 4.0258e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5471e-04 - val_loss: 3.9835e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5408e-04 - val_loss: 3.9411e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5345e-04 - val_loss: 3.8995e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5283e-04 - val_loss: 3.8578e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5221e-04 - val_loss: 3.8164e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5159e-04 - val_loss: 3.7754e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5097e-04 - val_loss: 3.7352e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5036e-04 - val_loss: 3.6954e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4975e-04 - val_loss: 3.6558e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4915e-04 - val_loss: 3.6162e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4855e-04 - val_loss: 3.5771e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4795e-04 - val_loss: 3.5385e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4735e-04 - val_loss: 3.5003e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4676e-04 - val_loss: 3.4620e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4617e-04 - val_loss: 3.4246e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4559e-04 - val_loss: 3.3873e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4501e-04 - val_loss: 3.3504e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4443e-04 - val_loss: 3.3138e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4385e-04 - val_loss: 3.2773e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4328e-04 - val_loss: 3.2413e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4271e-04 - val_loss: 3.2054e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4214e-04 - val_loss: 3.1705e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4159e-04 - val_loss: 3.1352e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4102e-04 - val_loss: 3.1005e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4046e-04 - val_loss: 3.0663e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3991e-04 - val_loss: 3.0323e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3936e-04 - val_loss: 2.9984e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3881e-04 - val_loss: 2.9650e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3826e-04 - val_loss: 2.9318e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3772e-04 - val_loss: 2.8987e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3719e-04 - val_loss: 2.8663e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3665e-04 - val_loss: 2.8337e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3611e-04 - val_loss: 2.8017e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3558e-04 - val_loss: 2.7702e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3506e-04 - val_loss: 2.7385e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3453e-04 - val_loss: 2.7073e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3401e-04 - val_loss: 2.6765e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3349e-04 - val_loss: 2.6457e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3297e-04 - val_loss: 2.6156e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3246e-04 - val_loss: 2.5857e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3195e-04 - val_loss: 2.5561e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3144e-04 - val_loss: 2.5267e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3094e-04 - val_loss: 2.4972e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3043e-04 - val_loss: 2.4683e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2993e-04 - val_loss: 2.4397e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2943e-04 - val_loss: 2.4113e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2894e-04 - val_loss: 2.3832e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2845e-04 - val_loss: 2.3555e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2796e-04 - val_loss: 2.3278e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2747e-04 - val_loss: 2.3005e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2699e-04 - val_loss: 2.2733e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2650e-04 - val_loss: 2.2468e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2602e-04 - val_loss: 2.2201e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2555e-04 - val_loss: 2.1937e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2507e-04 - val_loss: 2.1677e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2460e-04 - val_loss: 2.1416e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2413e-04 - val_loss: 2.1163e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2366e-04 - val_loss: 2.0908e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2320e-04 - val_loss: 2.0658e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2274e-04 - val_loss: 2.0408e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2228e-04 - val_loss: 2.0164e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2182e-04 - val_loss: 1.9919e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2137e-04 - val_loss: 1.9679e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2092e-04 - val_loss: 1.9437e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2046e-04 - val_loss: 1.9199e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2002e-04 - val_loss: 1.8968e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1957e-04 - val_loss: 1.8736e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1913e-04 - val_loss: 1.8505e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1869e-04 - val_loss: 1.8277e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1825e-04 - val_loss: 1.8051e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1782e-04 - val_loss: 1.7829e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1738e-04 - val_loss: 1.7608e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1695e-04 - val_loss: 1.7391e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1652e-04 - val_loss: 1.7174e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1610e-04 - val_loss: 1.6957e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1567e-04 - val_loss: 1.6746e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1525e-04 - val_loss: 1.6534e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1483e-04 - val_loss: 1.6327e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1441e-04 - val_loss: 1.6121e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1399e-04 - val_loss: 1.5913e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1358e-04 - val_loss: 1.5714e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1317e-04 - val_loss: 1.5514e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1276e-04 - val_loss: 1.5315e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.1235e-04 - val_loss: 1.5121e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1195e-04 - val_loss: 1.4925e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1155e-04 - val_loss: 1.4733e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1114e-04 - val_loss: 1.4546e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1074e-04 - val_loss: 1.4357e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1034e-04 - val_loss: 1.4169e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0995e-04 - val_loss: 1.3985e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0956e-04 - val_loss: 1.3801e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.0917e-04 - val_loss: 1.3624e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0878e-04 - val_loss: 1.3445e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0839e-04 - val_loss: 1.3266e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0801e-04 - val_loss: 1.3094e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0762e-04 - val_loss: 1.2919e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0724e-04 - val_loss: 1.2748e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0687e-04 - val_loss: 1.2577e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0649e-04 - val_loss: 1.2410e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0611e-04 - val_loss: 1.2244e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0574e-04 - val_loss: 1.2080e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0537e-04 - val_loss: 1.1919e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0500e-04 - val_loss: 1.1757e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0463e-04 - val_loss: 1.1599e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0427e-04 - val_loss: 1.1441e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0390e-04 - val_loss: 1.1288e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0354e-04 - val_loss: 1.1132e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0318e-04 - val_loss: 1.0978e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0282e-04 - val_loss: 1.0829e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0247e-04 - val_loss: 1.0680e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0212e-04 - val_loss: 1.0533e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0176e-04 - val_loss: 1.0386e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0141e-04 - val_loss: 1.0242e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0106e-04 - val_loss: 1.0102e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0071e-04 - val_loss: 9.9598e-06\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0037e-04 - val_loss: 9.8216e-06\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0002e-04 - val_loss: 9.6844e-06\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9679e-05 - val_loss: 9.5485e-06\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9340e-05 - val_loss: 9.4135e-06\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9002e-05 - val_loss: 9.2815e-06\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8664e-05 - val_loss: 9.1479e-06\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8330e-05 - val_loss: 9.0175e-06\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7995e-05 - val_loss: 8.8893e-06\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7660e-05 - val_loss: 8.7624e-06\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7335e-05 - val_loss: 8.6340e-06\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7005e-05 - val_loss: 8.5098e-06\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6677e-05 - val_loss: 8.3877e-06\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6354e-05 - val_loss: 8.2672e-06\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6031e-05 - val_loss: 8.1483e-06\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5706e-05 - val_loss: 8.0288e-06\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5385e-05 - val_loss: 7.9118e-06\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 92us/step - loss: 9.5068e-05 - val_loss: 7.7949e-06\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4749e-05 - val_loss: 7.6813e-06\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4435e-05 - val_loss: 7.5685e-06\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4120e-05 - val_loss: 7.4570e-06\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3805e-05 - val_loss: 7.3463e-06\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3497e-05 - val_loss: 7.2385e-06\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.3190e-05 - val_loss: 7.1306e-06\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2878e-05 - val_loss: 7.0256e-06\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2574e-05 - val_loss: 6.9186e-06\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2270e-05 - val_loss: 6.8140e-06\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1962e-05 - val_loss: 6.7127e-06\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1663e-05 - val_loss: 6.6114e-06\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1364e-05 - val_loss: 6.5108e-06\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1062e-05 - val_loss: 6.4129e-06\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0769e-05 - val_loss: 6.3148e-06\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0471e-05 - val_loss: 6.2188e-06\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0179e-05 - val_loss: 6.1241e-06\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9885e-05 - val_loss: 6.0314e-06\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9588e-05 - val_loss: 5.9382e-06\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9302e-05 - val_loss: 5.8475e-06\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9012e-05 - val_loss: 5.7573e-06\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8727e-05 - val_loss: 5.6674e-06\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8442e-05 - val_loss: 5.5797e-06\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8156e-05 - val_loss: 5.4933e-06\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7874e-05 - val_loss: 5.4081e-06\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7593e-05 - val_loss: 5.3237e-06\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7313e-05 - val_loss: 5.2403e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7032e-05 - val_loss: 5.1581e-06\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6756e-05 - val_loss: 5.0781e-06\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6480e-05 - val_loss: 4.9977e-06\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6207e-05 - val_loss: 4.9191e-06\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5933e-05 - val_loss: 4.8408e-06\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5661e-05 - val_loss: 4.7639e-06\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5388e-05 - val_loss: 4.6889e-06\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5123e-05 - val_loss: 4.6150e-06\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4852e-05 - val_loss: 4.5411e-06\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4585e-05 - val_loss: 4.4690e-06\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4317e-05 - val_loss: 4.3969e-06\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4056e-05 - val_loss: 4.3257e-06\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3794e-05 - val_loss: 4.2572e-06\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3532e-05 - val_loss: 4.1888e-06\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3271e-05 - val_loss: 4.1213e-06\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3008e-05 - val_loss: 4.0553e-06\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2754e-05 - val_loss: 3.9892e-06\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.2498e-05 - val_loss: 3.9250e-06\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2244e-05 - val_loss: 3.8618e-06\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1985e-05 - val_loss: 3.7996e-06\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1734e-05 - val_loss: 3.7381e-06\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1481e-05 - val_loss: 3.6780e-06\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1233e-05 - val_loss: 3.6176e-06\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0981e-05 - val_loss: 3.5590e-06\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0735e-05 - val_loss: 3.5012e-06\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0487e-05 - val_loss: 3.4442e-06\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.0242e-05 - val_loss: 3.3885e-06\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9998e-05 - val_loss: 3.3336e-06\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9753e-05 - val_loss: 3.2805e-06\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9515e-05 - val_loss: 3.2266e-06\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9273e-05 - val_loss: 3.1749e-06\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9034e-05 - val_loss: 3.1229e-06\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8793e-05 - val_loss: 3.0717e-06\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 7.8559e-05 - val_loss: 3.0218e-06\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8319e-05 - val_loss: 2.9725e-06\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8087e-05 - val_loss: 2.9251e-06\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7849e-05 - val_loss: 2.8780e-06\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7618e-05 - val_loss: 2.8314e-06\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7382e-05 - val_loss: 2.7859e-06\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7155e-05 - val_loss: 2.7412e-06\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6926e-05 - val_loss: 2.6973e-06\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6695e-05 - val_loss: 2.6537e-06\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6470e-05 - val_loss: 2.6116e-06\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6242e-05 - val_loss: 2.5696e-06\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6015e-05 - val_loss: 2.5294e-06\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5791e-05 - val_loss: 2.4894e-06\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5568e-05 - val_loss: 2.4500e-06\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5345e-05 - val_loss: 2.4116e-06\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5127e-05 - val_loss: 2.3740e-06\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4906e-05 - val_loss: 2.3376e-06\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4687e-05 - val_loss: 2.3007e-06\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4470e-05 - val_loss: 2.2653e-06\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4254e-05 - val_loss: 2.2301e-06\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4037e-05 - val_loss: 2.1964e-06\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3819e-05 - val_loss: 2.1631e-06\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3606e-05 - val_loss: 2.1297e-06\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3394e-05 - val_loss: 2.0983e-06\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3182e-05 - val_loss: 2.0663e-06\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.2969e-05 - val_loss: 2.0360e-06\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2762e-05 - val_loss: 2.0060e-06\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2553e-05 - val_loss: 1.9766e-06\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2343e-05 - val_loss: 1.9485e-06\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2139e-05 - val_loss: 1.9204e-06\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1931e-05 - val_loss: 1.8931e-06\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1723e-05 - val_loss: 1.8665e-06\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1519e-05 - val_loss: 1.8406e-06\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1318e-05 - val_loss: 1.8157e-06\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.1116e-05 - val_loss: 1.7915e-06\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0914e-05 - val_loss: 1.7677e-06\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0716e-05 - val_loss: 1.7438e-06\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0513e-05 - val_loss: 1.7210e-06\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0320e-05 - val_loss: 1.6991e-06\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0118e-05 - val_loss: 1.6772e-06\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9920e-05 - val_loss: 1.6561e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9726e-05 - val_loss: 1.6358e-06\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9533e-05 - val_loss: 1.6162e-06\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9338e-05 - val_loss: 1.5976e-06\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9145e-05 - val_loss: 1.5787e-06\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8954e-05 - val_loss: 1.5607e-06\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8761e-05 - val_loss: 1.5432e-06\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8571e-05 - val_loss: 1.5265e-06\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8379e-05 - val_loss: 1.5101e-06\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8194e-05 - val_loss: 1.4947e-06\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8004e-05 - val_loss: 1.4797e-06\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7817e-05 - val_loss: 1.4653e-06\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7631e-05 - val_loss: 1.4511e-06\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 6.7446e-05 - val_loss: 1.4375e-06\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7260e-05 - val_loss: 1.4248e-06\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7080e-05 - val_loss: 1.4119e-06\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6894e-05 - val_loss: 1.3999e-06\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6713e-05 - val_loss: 1.3887e-06\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6532e-05 - val_loss: 1.3776e-06\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6351e-05 - val_loss: 1.3674e-06\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6174e-05 - val_loss: 1.3575e-06\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5997e-05 - val_loss: 1.3482e-06\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5817e-05 - val_loss: 1.3396e-06\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5641e-05 - val_loss: 1.3308e-06\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5463e-05 - val_loss: 1.3234e-06\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5289e-05 - val_loss: 1.3156e-06\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5116e-05 - val_loss: 1.3093e-06\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4942e-05 - val_loss: 1.3025e-06\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4768e-05 - val_loss: 1.2955e-06\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4593e-05 - val_loss: 1.2906e-06\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4422e-05 - val_loss: 1.2856e-06\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4255e-05 - val_loss: 1.2810e-06\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4084e-05 - val_loss: 1.2761e-06\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3913e-05 - val_loss: 1.2728e-06\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3746e-05 - val_loss: 1.2688e-06\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3578e-05 - val_loss: 1.2666e-06\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3410e-05 - val_loss: 1.2638e-06\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3243e-05 - val_loss: 1.2626e-06\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3079e-05 - val_loss: 1.2608e-06\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2914e-05 - val_loss: 1.2599e-06\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2750e-05 - val_loss: 1.2591e-06\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2589e-05 - val_loss: 1.2582e-06\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2427e-05 - val_loss: 1.2582e-06\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2264e-05 - val_loss: 1.2592e-06\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2106e-05 - val_loss: 1.2598e-06\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1944e-05 - val_loss: 1.2610e-06\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1782e-05 - val_loss: 1.2631e-06\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1623e-05 - val_loss: 1.2646e-06\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1465e-05 - val_loss: 1.2671e-06\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1309e-05 - val_loss: 1.2701e-06\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1154e-05 - val_loss: 1.2739e-06\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0996e-05 - val_loss: 1.2768e-06\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.0839e-05 - val_loss: 1.2803e-06\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0684e-05 - val_loss: 1.2855e-06\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0533e-05 - val_loss: 1.2900e-06\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0379e-05 - val_loss: 1.2954e-06\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0228e-05 - val_loss: 1.3001e-06\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0076e-05 - val_loss: 1.3057e-06\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9924e-05 - val_loss: 1.3121e-06\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9772e-05 - val_loss: 1.3180e-06\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9622e-05 - val_loss: 1.3251e-06\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9471e-05 - val_loss: 1.3319e-06\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9323e-05 - val_loss: 1.3400e-06\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9181e-05 - val_loss: 1.3481e-06\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9030e-05 - val_loss: 1.3558e-06\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8883e-05 - val_loss: 1.3630e-06\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8738e-05 - val_loss: 1.3722e-06\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8591e-05 - val_loss: 1.3810e-06\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8446e-05 - val_loss: 1.3900e-06\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.8302e-05 - val_loss: 1.3996e-06\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8158e-05 - val_loss: 1.4108e-06\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8013e-05 - val_loss: 1.4214e-06\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7873e-05 - val_loss: 1.4323e-06\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7732e-05 - val_loss: 1.4418e-06\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.7592e-05 - val_loss: 1.4528e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7447e-05 - val_loss: 1.4646e-06\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7309e-05 - val_loss: 1.4757e-06\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7171e-05 - val_loss: 1.4882e-06\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7033e-05 - val_loss: 1.4999e-06\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6892e-05 - val_loss: 1.5132e-06\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6753e-05 - val_loss: 1.5253e-06\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6619e-05 - val_loss: 1.5389e-06\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6483e-05 - val_loss: 1.5514e-06\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6345e-05 - val_loss: 1.5651e-06\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6214e-05 - val_loss: 1.5791e-06\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6077e-05 - val_loss: 1.5933e-06\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5946e-05 - val_loss: 1.6077e-06\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.5813e-05 - val_loss: 1.6230e-06\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5678e-05 - val_loss: 1.6377e-06\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5545e-05 - val_loss: 1.6523e-06\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5415e-05 - val_loss: 1.6672e-06\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5283e-05 - val_loss: 1.6836e-06\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5151e-05 - val_loss: 1.6986e-06\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5022e-05 - val_loss: 1.7145e-06\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4891e-05 - val_loss: 1.7314e-06\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4767e-05 - val_loss: 1.7483e-06\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.4635e-05 - val_loss: 1.7647e-06\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4507e-05 - val_loss: 1.7812e-06\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4380e-05 - val_loss: 1.7988e-06\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4254e-05 - val_loss: 1.8160e-06\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4130e-05 - val_loss: 1.8341e-06\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4003e-05 - val_loss: 1.8523e-06\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3877e-05 - val_loss: 1.8707e-06\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3755e-05 - val_loss: 1.8889e-06\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3628e-05 - val_loss: 1.9071e-06\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3503e-05 - val_loss: 1.9246e-06\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3384e-05 - val_loss: 1.9433e-06\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 5.3258e-05 - val_loss: 1.9628e-06\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3138e-05 - val_loss: 1.9816e-06\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3014e-05 - val_loss: 2.0005e-06\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.2896e-05 - val_loss: 2.0205e-06\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2773e-05 - val_loss: 2.0408e-06\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2653e-05 - val_loss: 2.0611e-06\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2534e-05 - val_loss: 2.0803e-06\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.2415e-05 - val_loss: 2.1010e-06\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2297e-05 - val_loss: 2.1209e-06\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2180e-05 - val_loss: 2.1417e-06\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2061e-05 - val_loss: 2.1635e-06\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1944e-05 - val_loss: 2.1858e-06\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1828e-05 - val_loss: 2.2066e-06\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1712e-05 - val_loss: 2.2275e-06\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1597e-05 - val_loss: 2.2481e-06\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1482e-05 - val_loss: 2.2695e-06\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1365e-05 - val_loss: 2.2908e-06\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1250e-05 - val_loss: 2.3136e-06\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1138e-05 - val_loss: 2.3355e-06\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1027e-05 - val_loss: 2.3592e-06\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0912e-05 - val_loss: 2.3808e-06\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0801e-05 - val_loss: 2.4034e-06\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0690e-05 - val_loss: 2.4258e-06\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0577e-05 - val_loss: 2.4485e-06\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0465e-05 - val_loss: 2.4724e-06\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0355e-05 - val_loss: 2.4947e-06\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0247e-05 - val_loss: 2.5186e-06\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0136e-05 - val_loss: 2.5421e-06\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0027e-05 - val_loss: 2.5652e-06\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9919e-05 - val_loss: 2.5895e-06\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9809e-05 - val_loss: 2.6125e-06\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9701e-05 - val_loss: 2.6369e-06\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9595e-05 - val_loss: 2.6609e-06\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 4.9487e-05 - val_loss: 2.6855e-06\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9382e-05 - val_loss: 2.7103e-06\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9275e-05 - val_loss: 2.7348e-06\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9169e-05 - val_loss: 2.7582e-06\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9067e-05 - val_loss: 2.7827e-06\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8961e-05 - val_loss: 2.8072e-06\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8855e-05 - val_loss: 2.8319e-06\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.8748e-05 - val_loss: 2.8561e-06\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8647e-05 - val_loss: 2.8819e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8545e-05 - val_loss: 2.9080e-06\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8441e-05 - val_loss: 2.9335e-06\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8342e-05 - val_loss: 2.9592e-06\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8237e-05 - val_loss: 2.9837e-06\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8137e-05 - val_loss: 3.0090e-06\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8034e-05 - val_loss: 3.0344e-06\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7936e-05 - val_loss: 3.0611e-06\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7834e-05 - val_loss: 3.0862e-06\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7735e-05 - val_loss: 3.1115e-06\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7635e-05 - val_loss: 3.1382e-06\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.7535e-05 - val_loss: 3.1652e-06\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7436e-05 - val_loss: 3.1910e-06\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.7339e-05 - val_loss: 3.2177e-06\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7239e-05 - val_loss: 3.2446e-06\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7140e-05 - val_loss: 3.2702e-06\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7046e-05 - val_loss: 3.2960e-06\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6946e-05 - val_loss: 3.3218e-06\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6852e-05 - val_loss: 3.3499e-06\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6757e-05 - val_loss: 3.3775e-06\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6661e-05 - val_loss: 3.4026e-06\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6568e-05 - val_loss: 3.4295e-06\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6469e-05 - val_loss: 3.4579e-06\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6375e-05 - val_loss: 3.4838e-06\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6281e-05 - val_loss: 3.5108e-06\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6188e-05 - val_loss: 3.5379e-06\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.6094e-05 - val_loss: 3.5660e-06\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6001e-05 - val_loss: 3.5936e-06\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5908e-05 - val_loss: 3.6203e-06\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5818e-05 - val_loss: 3.6472e-06\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5724e-05 - val_loss: 3.6755e-06\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5634e-05 - val_loss: 3.7007e-06\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5543e-05 - val_loss: 3.7310e-06\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5451e-05 - val_loss: 3.7575e-06\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5360e-05 - val_loss: 3.7852e-06\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5269e-05 - val_loss: 3.8131e-06\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5179e-05 - val_loss: 3.8409e-06\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5092e-05 - val_loss: 3.8683e-06\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5001e-05 - val_loss: 3.8955e-06\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4909e-05 - val_loss: 3.9240e-06\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4821e-05 - val_loss: 3.9534e-06\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4734e-05 - val_loss: 3.9811e-06\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4646e-05 - val_loss: 4.0082e-06\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4558e-05 - val_loss: 4.0355e-06\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4472e-05 - val_loss: 4.0639e-06\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4385e-05 - val_loss: 4.0921e-06\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4298e-05 - val_loss: 4.1209e-06\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4212e-05 - val_loss: 4.1491e-06\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4129e-05 - val_loss: 4.1769e-06\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4042e-05 - val_loss: 4.2051e-06\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3955e-05 - val_loss: 4.2339e-06\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3870e-05 - val_loss: 4.2610e-06\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3786e-05 - val_loss: 4.2912e-06\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3703e-05 - val_loss: 4.3198e-06\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3618e-05 - val_loss: 4.3476e-06\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3533e-05 - val_loss: 4.3753e-06\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3451e-05 - val_loss: 4.4041e-06\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3367e-05 - val_loss: 4.4311e-06\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3284e-05 - val_loss: 4.4602e-06\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3203e-05 - val_loss: 4.4872e-06\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3120e-05 - val_loss: 4.5157e-06\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3038e-05 - val_loss: 4.5452e-06\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2957e-05 - val_loss: 4.5727e-06\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2877e-05 - val_loss: 4.6033e-06\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2794e-05 - val_loss: 4.6318e-06\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2714e-05 - val_loss: 4.6596e-06\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2634e-05 - val_loss: 4.6879e-06\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.2556e-05 - val_loss: 4.7170e-06\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2472e-05 - val_loss: 4.7464e-06\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2395e-05 - val_loss: 4.7737e-06\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2316e-05 - val_loss: 4.8024e-06\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2237e-05 - val_loss: 4.8306e-06\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2158e-05 - val_loss: 4.8595e-06\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2081e-05 - val_loss: 4.8862e-06\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2002e-05 - val_loss: 4.9161e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1925e-05 - val_loss: 4.9441e-06\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1844e-05 - val_loss: 4.9753e-06\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1769e-05 - val_loss: 5.0023e-06\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1693e-05 - val_loss: 5.0307e-06\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1615e-05 - val_loss: 5.0611e-06\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1539e-05 - val_loss: 5.0906e-06\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1464e-05 - val_loss: 5.1170e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1387e-05 - val_loss: 5.1458e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1311e-05 - val_loss: 5.1759e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1237e-05 - val_loss: 5.2042e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1160e-05 - val_loss: 5.2312e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1086e-05 - val_loss: 5.2580e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1012e-05 - val_loss: 5.2893e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0938e-05 - val_loss: 5.3162e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0863e-05 - val_loss: 5.3479e-06\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0791e-05 - val_loss: 5.3739e-06\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0718e-05 - val_loss: 5.4043e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0645e-05 - val_loss: 5.4331e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0572e-05 - val_loss: 5.4596e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0497e-05 - val_loss: 5.4871e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0425e-05 - val_loss: 5.5174e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0354e-05 - val_loss: 5.5435e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0283e-05 - val_loss: 5.5725e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0210e-05 - val_loss: 5.5994e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0139e-05 - val_loss: 5.6310e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0066e-05 - val_loss: 5.6574e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9998e-05 - val_loss: 5.6867e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9926e-05 - val_loss: 5.7151e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9859e-05 - val_loss: 5.7437e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9788e-05 - val_loss: 5.7719e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9719e-05 - val_loss: 5.7994e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9649e-05 - val_loss: 5.8293e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9578e-05 - val_loss: 5.8553e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9510e-05 - val_loss: 5.8843e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9439e-05 - val_loss: 5.9116e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9374e-05 - val_loss: 5.9407e-06\n",
      "1.1056516086682677e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.06979   , -0.7961142 ,  0.64475465, -0.9167824 , -0.7710856 ],\n",
       "        [-0.00570277,  0.1451112 ,  0.06422856,  0.00160196,  0.18474798],\n",
       "        [-0.40886483,  0.8349889 ,  1.4544225 , -1.2489926 , -0.7169367 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.52216   , -0.5162961 ,  0.8141388 , -0.61387265,  0.70759046],\n",
       "       dtype=float32),\n",
       " array([[ 0.13249971, -0.02749045, -0.06980216, -0.43331832,  0.29314613,\n",
       "         -0.41388956,  0.18524103,  0.33450633,  0.38046607, -0.32907957],\n",
       "        [-0.3927727 ,  0.04278682,  0.3939044 , -0.19297487,  0.00772749,\n",
       "          0.48491824,  0.12695453, -0.38771734,  0.12690748, -0.0568864 ],\n",
       "        [ 0.31674573, -0.22700183, -0.43078703, -0.26720774, -0.4426306 ,\n",
       "         -0.03089639,  0.21196915,  0.7741325 ,  0.11010344, -0.06774402],\n",
       "        [ 0.4648844 ,  0.139644  ,  0.09781236, -0.6226803 , -0.34589076,\n",
       "         -0.07471814,  0.24983853, -0.14483215,  0.15308753, -0.42063817],\n",
       "        [ 0.744189  ,  0.09776539, -0.39871383,  0.1119473 , -0.64281774,\n",
       "         -0.07505864,  0.6346993 , -0.36344874,  0.28656253, -0.4092339 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.72099304,  0.6508109 , -0.72446734, -0.6689664 , -0.74432707,\n",
       "        -0.71578264,  0.72240174,  0.7328315 , -0.70241374,  0.66111094],\n",
       "       dtype=float32),\n",
       " array([[ 0.64064866],\n",
       "        [ 0.28260595],\n",
       "        [-0.7140785 ],\n",
       "        [-0.2543078 ],\n",
       "        [-0.79663473],\n",
       "        [-0.7034219 ],\n",
       "        [ 0.39001465],\n",
       "        [ 0.9086892 ],\n",
       "        [-0.6271176 ],\n",
       "        [ 0.40209246]], dtype=float32),\n",
       " array([0.7715601], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_adam_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 36.4329 - val_loss: 42.8862\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 36.4312 - val_loss: 42.8836\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.4288 - val_loss: 42.8802\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.4258 - val_loss: 42.8761\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.4222 - val_loss: 42.8715\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.4181 - val_loss: 42.8663\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 36.4135 - val_loss: 42.8607\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.4085 - val_loss: 42.8546\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.4031 - val_loss: 42.8482\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3974 - val_loss: 42.8414\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 36.3914 - val_loss: 42.8343\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3851 - val_loss: 42.8270\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3785 - val_loss: 42.8194\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 36.3717 - val_loss: 42.8115\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3648 - val_loss: 42.8035\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.3576 - val_loss: 42.7953\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3503 - val_loss: 42.7869\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3429 - val_loss: 42.7784\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3353 - val_loss: 42.7697\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3276 - val_loss: 42.7609\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 36.3198 - val_loss: 42.7520\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.3119 - val_loss: 42.7430\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.3039 - val_loss: 42.7340\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2958 - val_loss: 42.7249\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 36.2877 - val_loss: 42.7156\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2795 - val_loss: 42.7064\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2712 - val_loss: 42.6971\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2630 - val_loss: 42.6877\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2546 - val_loss: 42.6783\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2462 - val_loss: 42.6688\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2378 - val_loss: 42.6593\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2294 - val_loss: 42.6498\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2209 - val_loss: 42.6403\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.2124 - val_loss: 42.6307\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.2039 - val_loss: 42.6211\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1954 - val_loss: 42.6115\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.1868 - val_loss: 42.6019\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1782 - val_loss: 42.5922\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1696 - val_loss: 42.5826\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1611 - val_loss: 42.5729\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1524 - val_loss: 42.5632\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 36.1438 - val_loss: 42.5535\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1352 - val_loss: 42.5438\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.1266 - val_loss: 42.5341\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1179 - val_loss: 42.5244\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1093 - val_loss: 42.5147\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.1007 - val_loss: 42.5050\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.0920 - val_loss: 42.4953\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0834 - val_loss: 42.4856\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0747 - val_loss: 42.4758\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0660 - val_loss: 42.4661\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0574 - val_loss: 42.4564\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0487 - val_loss: 42.4467\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0401 - val_loss: 42.4370\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0314 - val_loss: 42.4272\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0227 - val_loss: 42.4175\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0141 - val_loss: 42.4078\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0054 - val_loss: 42.3981\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9968 - val_loss: 42.3883\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9881 - val_loss: 42.3786\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9794 - val_loss: 42.3689\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9708 - val_loss: 42.3592\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9621 - val_loss: 42.3495\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9535 - val_loss: 42.3398\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9448 - val_loss: 42.3301\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9362 - val_loss: 42.3203\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9275 - val_loss: 42.3106\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9189 - val_loss: 42.3009\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 35.9102 - val_loss: 42.2912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9016 - val_loss: 42.2815\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8929 - val_loss: 42.2718\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8843 - val_loss: 42.2621\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8757 - val_loss: 42.2525\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8670 - val_loss: 42.2428\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.8584 - val_loss: 42.2331\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.8498 - val_loss: 42.2234\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.8411 - val_loss: 42.2137\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8325 - val_loss: 42.2041\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.8239 - val_loss: 42.1944\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8153 - val_loss: 42.1847\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8066 - val_loss: 42.1750\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7980 - val_loss: 42.1654\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7894 - val_loss: 42.1557\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7808 - val_loss: 42.1461\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7722 - val_loss: 42.1364\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7636 - val_loss: 42.1268\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7550 - val_loss: 42.1171\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7463 - val_loss: 42.1075\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7377 - val_loss: 42.0978\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7291 - val_loss: 42.0882\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7206 - val_loss: 42.0786\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7120 - val_loss: 42.0689\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7034 - val_loss: 42.0593\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6948 - val_loss: 42.0497\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6862 - val_loss: 42.0400\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 35.6776 - val_loss: 42.0304\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6690 - val_loss: 42.0208\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6604 - val_loss: 42.0112\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.6519 - val_loss: 42.0016\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.6433 - val_loss: 41.9920\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.6347 - val_loss: 41.9824\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6261 - val_loss: 41.9728\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6176 - val_loss: 41.9632\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6090 - val_loss: 41.9536\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6004 - val_loss: 41.9440\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5919 - val_loss: 41.9344\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5833 - val_loss: 41.9248\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.5748 - val_loss: 41.9152\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5662 - val_loss: 41.9056\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.5576 - val_loss: 41.8961\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5491 - val_loss: 41.8865\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5406 - val_loss: 41.8769\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5320 - val_loss: 41.8674\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5235 - val_loss: 41.8578\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.5149 - val_loss: 41.8482\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.5064 - val_loss: 41.8387\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4978 - val_loss: 41.8291\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4893 - val_loss: 41.8196\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.4808 - val_loss: 41.8100\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.4723 - val_loss: 41.8005\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4637 - val_loss: 41.7909\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4552 - val_loss: 41.7814\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4467 - val_loss: 41.7718\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4382 - val_loss: 41.7623\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4296 - val_loss: 41.7528\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.4211 - val_loss: 41.7433\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4126 - val_loss: 41.7337\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4041 - val_loss: 41.7242\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3956 - val_loss: 41.7147\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3871 - val_loss: 41.7052\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3786 - val_loss: 41.6957\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3701 - val_loss: 41.6861\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3616 - val_loss: 41.6766\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3531 - val_loss: 41.6671\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3446 - val_loss: 41.6576\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3361 - val_loss: 41.6481\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3276 - val_loss: 41.6386\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3191 - val_loss: 41.6292\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3107 - val_loss: 41.6197\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3022 - val_loss: 41.6102\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2937 - val_loss: 41.6007\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2852 - val_loss: 41.5912\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2767 - val_loss: 41.5817\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2683 - val_loss: 41.5723\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2598 - val_loss: 41.5628\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 35.2513 - val_loss: 41.5533\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2429 - val_loss: 41.5439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2344 - val_loss: 41.5344\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2259 - val_loss: 41.5249\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2175 - val_loss: 41.5155\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2090 - val_loss: 41.5060\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2006 - val_loss: 41.4966\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 35.1921 - val_loss: 41.4871\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1837 - val_loss: 41.4777\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1752 - val_loss: 41.4682\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1668 - val_loss: 41.4588\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.1583 - val_loss: 41.4494\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.1499 - val_loss: 41.4399\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.1415 - val_loss: 41.4305\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1330 - val_loss: 41.4211\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1246 - val_loss: 41.4117\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1162 - val_loss: 41.4022\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.1077 - val_loss: 41.3928\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0993 - val_loss: 41.3834\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0909 - val_loss: 41.3740\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0825 - val_loss: 41.3646\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.0741 - val_loss: 41.3552\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0656 - val_loss: 41.3458\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0572 - val_loss: 41.3364\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.0488 - val_loss: 41.3270\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0404 - val_loss: 41.3176\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.0320 - val_loss: 41.3082\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 35.0236 - val_loss: 41.2988\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.0152 - val_loss: 41.2894\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0068 - val_loss: 41.2800\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9984 - val_loss: 41.2707\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9900 - val_loss: 41.2613\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9816 - val_loss: 41.2519\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9732 - val_loss: 41.2425\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9648 - val_loss: 41.2332\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9564 - val_loss: 41.2238\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9480 - val_loss: 41.2144\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 34.9396 - val_loss: 41.2051\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9313 - val_loss: 41.1957\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9229 - val_loss: 41.1864\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.9145 - val_loss: 41.1770\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.9061 - val_loss: 41.1677\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8978 - val_loss: 41.1583\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.8894 - val_loss: 41.1490\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8810 - val_loss: 41.1396\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.8726 - val_loss: 41.1303\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8643 - val_loss: 41.1210\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8559 - val_loss: 41.1116\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8476 - val_loss: 41.1023\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.8392 - val_loss: 41.0930\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8308 - val_loss: 41.0837\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.8225 - val_loss: 41.0743\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.8141 - val_loss: 41.0650\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8058 - val_loss: 41.0557\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7974 - val_loss: 41.0464\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 34.7891 - val_loss: 41.0371\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.7808 - val_loss: 41.0278\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7724 - val_loss: 41.0185\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.7641 - val_loss: 41.0092\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.7558 - val_loss: 40.9999\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7474 - val_loss: 40.9906\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7391 - val_loss: 40.9813\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7308 - val_loss: 40.9720\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7224 - val_loss: 40.9627\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.7141 - val_loss: 40.9534\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.7058 - val_loss: 40.9441\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6975 - val_loss: 40.9349\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6891 - val_loss: 40.9256\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6808 - val_loss: 40.9163\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6725 - val_loss: 40.9071\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6642 - val_loss: 40.8978\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6559 - val_loss: 40.8885\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.6476 - val_loss: 40.8793\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.6393 - val_loss: 40.8700\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6310 - val_loss: 40.8607\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.6227 - val_loss: 40.8515\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6144 - val_loss: 40.8422\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.6061 - val_loss: 40.8330\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5978 - val_loss: 40.8237\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5895 - val_loss: 40.8145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.5812 - val_loss: 40.8053\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.5729 - val_loss: 40.7960\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.5646 - val_loss: 40.7868\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.5563 - val_loss: 40.7776\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.5481 - val_loss: 40.7683\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.5398 - val_loss: 40.7591\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.5315 - val_loss: 40.7499\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 34.5232 - val_loss: 40.7407\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.5150 - val_loss: 40.7315\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.5067 - val_loss: 40.7222\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4984 - val_loss: 40.7130\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.4902 - val_loss: 40.7038\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4819 - val_loss: 40.6946\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4736 - val_loss: 40.6854\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4654 - val_loss: 40.6762\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4571 - val_loss: 40.6670\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4488 - val_loss: 40.6578\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4406 - val_loss: 40.6486\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4323 - val_loss: 40.6394\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4241 - val_loss: 40.6302\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4158 - val_loss: 40.6211\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4076 - val_loss: 40.6119\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3994 - val_loss: 40.6027\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3911 - val_loss: 40.5935\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3829 - val_loss: 40.5843\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3746 - val_loss: 40.5752\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3664 - val_loss: 40.5660\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3582 - val_loss: 40.5568\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3499 - val_loss: 40.5477\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3417 - val_loss: 40.5385\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3335 - val_loss: 40.5294\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3252 - val_loss: 40.5202\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.3170 - val_loss: 40.5111\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3088 - val_loss: 40.5019\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3006 - val_loss: 40.4928\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2924 - val_loss: 40.4836\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2842 - val_loss: 40.4745\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2759 - val_loss: 40.4653\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2677 - val_loss: 40.4562\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.2595 - val_loss: 40.4471\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2513 - val_loss: 40.4379\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.2431 - val_loss: 40.4288\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2349 - val_loss: 40.4197\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2267 - val_loss: 40.4105\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2185 - val_loss: 40.4014\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2103 - val_loss: 40.3923\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2021 - val_loss: 40.3832\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1939 - val_loss: 40.3741\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1857 - val_loss: 40.3650\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1775 - val_loss: 40.3559\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1694 - val_loss: 40.3468\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1612 - val_loss: 40.3377\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1530 - val_loss: 40.3286\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1448 - val_loss: 40.3195\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1366 - val_loss: 40.3104\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1285 - val_loss: 40.3013\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1203 - val_loss: 40.2922\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1121 - val_loss: 40.2831\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1039 - val_loss: 40.2740\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0958 - val_loss: 40.2649\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.0876 - val_loss: 40.2559\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0794 - val_loss: 40.2468\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.0713 - val_loss: 40.2377\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.0631 - val_loss: 40.2286\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.0550 - val_loss: 40.2196\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0468 - val_loss: 40.2105\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0386 - val_loss: 40.2014\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0305 - val_loss: 40.1924\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0223 - val_loss: 40.1833\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.0142 - val_loss: 40.1743\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.0061 - val_loss: 40.1652\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9979 - val_loss: 40.1562\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9898 - val_loss: 40.1471\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9816 - val_loss: 40.1381\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.9735 - val_loss: 40.1290\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9653 - val_loss: 40.1200\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9572 - val_loss: 40.1109\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9491 - val_loss: 40.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9409 - val_loss: 40.0929\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9328 - val_loss: 40.0838\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9247 - val_loss: 40.0748\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9166 - val_loss: 40.0658\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9084 - val_loss: 40.0568\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9003 - val_loss: 40.0477\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.8922 - val_loss: 40.0387\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8841 - val_loss: 40.0297\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8760 - val_loss: 40.0207\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.8679 - val_loss: 40.0117\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8598 - val_loss: 40.0027\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8516 - val_loss: 39.9937\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8435 - val_loss: 39.9847\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.8354 - val_loss: 39.9757\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8273 - val_loss: 39.9667\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.8192 - val_loss: 39.9577\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.8111 - val_loss: 39.9487\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8030 - val_loss: 39.9397\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.7949 - val_loss: 39.9307\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7868 - val_loss: 39.9217\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7787 - val_loss: 39.9128\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7707 - val_loss: 39.9038\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7626 - val_loss: 39.8948\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.7545 - val_loss: 39.8858\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7464 - val_loss: 39.8769\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7383 - val_loss: 39.8679\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7302 - val_loss: 39.8589\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7222 - val_loss: 39.8499\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7141 - val_loss: 39.8410\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7060 - val_loss: 39.8320\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6979 - val_loss: 39.8231\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.6899 - val_loss: 39.8141\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6818 - val_loss: 39.8052\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.6737 - val_loss: 39.7962\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.6657 - val_loss: 39.7873\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6576 - val_loss: 39.7783\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.6495 - val_loss: 39.7694\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.6415 - val_loss: 39.7604\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6334 - val_loss: 39.7515\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6254 - val_loss: 39.7426\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6173 - val_loss: 39.7336\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.6093 - val_loss: 39.7247\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6012 - val_loss: 39.7158\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5932 - val_loss: 39.7068\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5851 - val_loss: 39.6979\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5771 - val_loss: 39.6890\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5690 - val_loss: 39.6801\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5610 - val_loss: 39.6712\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5530 - val_loss: 39.6623\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5449 - val_loss: 39.6533\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5369 - val_loss: 39.6444\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5289 - val_loss: 39.6355\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5208 - val_loss: 39.6266\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.5128 - val_loss: 39.6177\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5048 - val_loss: 39.6088\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.4967 - val_loss: 39.5999\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4887 - val_loss: 39.5910\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4807 - val_loss: 39.5822\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4727 - val_loss: 39.5733\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4647 - val_loss: 39.5644\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4566 - val_loss: 39.5555\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4486 - val_loss: 39.5466\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4406 - val_loss: 39.5377\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4326 - val_loss: 39.5289\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4246 - val_loss: 39.5200\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4166 - val_loss: 39.5111\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4086 - val_loss: 39.5022\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.4006 - val_loss: 39.4934\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.3926 - val_loss: 39.4845\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.3846 - val_loss: 39.4756\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.3766 - val_loss: 39.4668\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.3686 - val_loss: 39.4579\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.3606 - val_loss: 39.4491\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3526 - val_loss: 39.4402\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3446 - val_loss: 39.4314\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3366 - val_loss: 39.4225\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3287 - val_loss: 39.4137\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3207 - val_loss: 39.4048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3127 - val_loss: 39.3960\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3047 - val_loss: 39.3872\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2967 - val_loss: 39.3783\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.2887 - val_loss: 39.3695\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.2808 - val_loss: 39.3606\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2728 - val_loss: 39.3518\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2648 - val_loss: 39.3430\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2569 - val_loss: 39.3342\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2489 - val_loss: 39.3253\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2409 - val_loss: 39.3165\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2330 - val_loss: 39.3077\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2250 - val_loss: 39.2989\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.2170 - val_loss: 39.2901\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2091 - val_loss: 39.2813\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.2011 - val_loss: 39.2725\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1932 - val_loss: 39.2637\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1852 - val_loss: 39.2549\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.1773 - val_loss: 39.2461\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1693 - val_loss: 39.2373\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1614 - val_loss: 39.2285\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.1534 - val_loss: 39.2197\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.1455 - val_loss: 39.2109\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1375 - val_loss: 39.2021\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1296 - val_loss: 39.1933\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1216 - val_loss: 39.1845\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1137 - val_loss: 39.1757\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1058 - val_loss: 39.1670\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0978 - val_loss: 39.1582\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0899 - val_loss: 39.1494\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.0820 - val_loss: 39.1406\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0740 - val_loss: 39.1319\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0661 - val_loss: 39.1231\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0582 - val_loss: 39.1143\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.0503 - val_loss: 39.1056\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.0423 - val_loss: 39.0968\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0344 - val_loss: 39.0880\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0265 - val_loss: 39.0793\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0186 - val_loss: 39.0705\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0107 - val_loss: 39.0618\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0028 - val_loss: 39.0530\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.9949 - val_loss: 39.0443\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.9869 - val_loss: 39.0355\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.9790 - val_loss: 39.0268\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.9711 - val_loss: 39.0180\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.9632 - val_loss: 39.0093\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9553 - val_loss: 39.0006\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9474 - val_loss: 38.9918\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 32.9395 - val_loss: 38.9831\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.9316 - val_loss: 38.9744\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.9237 - val_loss: 38.9656\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9158 - val_loss: 38.9569\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.9079 - val_loss: 38.9482\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.9001 - val_loss: 38.9395\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8922 - val_loss: 38.9307\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.8843 - val_loss: 38.9220\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.8764 - val_loss: 38.9133\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8685 - val_loss: 38.9046\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8606 - val_loss: 38.8959\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8528 - val_loss: 38.8872\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8449 - val_loss: 38.8785\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8370 - val_loss: 38.8698\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.8291 - val_loss: 38.8611\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8213 - val_loss: 38.8524\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8134 - val_loss: 38.8437\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8055 - val_loss: 38.8350\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7976 - val_loss: 38.8263\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7898 - val_loss: 38.8176\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7819 - val_loss: 38.8089\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7740 - val_loss: 38.8002\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7662 - val_loss: 38.7915\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7583 - val_loss: 38.7829\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7505 - val_loss: 38.7742\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7426 - val_loss: 38.7655\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7348 - val_loss: 38.7568\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7269 - val_loss: 38.7482\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7191 - val_loss: 38.7395\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7112 - val_loss: 38.7308\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7034 - val_loss: 38.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 32.6955 - val_loss: 38.7135\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.6877 - val_loss: 38.7048\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6798 - val_loss: 38.6962\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6720 - val_loss: 38.6875\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6642 - val_loss: 38.6789\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6563 - val_loss: 38.6702\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6485 - val_loss: 38.6616\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.6406 - val_loss: 38.6529\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6328 - val_loss: 38.6443\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6250 - val_loss: 38.6356\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6171 - val_loss: 38.6270\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6093 - val_loss: 38.6183\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6015 - val_loss: 38.6097\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5937 - val_loss: 38.6011\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.5859 - val_loss: 38.5924\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5780 - val_loss: 38.5838\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5702 - val_loss: 38.5752\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.5624 - val_loss: 38.5666\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5546 - val_loss: 38.5579\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5468 - val_loss: 38.5493\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5390 - val_loss: 38.5407\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5311 - val_loss: 38.5321\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5233 - val_loss: 38.5235\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.5155 - val_loss: 38.5148\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5077 - val_loss: 38.5062\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.4999 - val_loss: 38.4976\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.4921 - val_loss: 38.4890\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4843 - val_loss: 38.4804\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.4765 - val_loss: 38.4718\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4687 - val_loss: 38.4632\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4609 - val_loss: 38.4546\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4531 - val_loss: 38.4460\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4453 - val_loss: 38.4374\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.4375 - val_loss: 38.4288\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4298 - val_loss: 38.4202\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4220 - val_loss: 38.4116\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4142 - val_loss: 38.4031\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4064 - val_loss: 38.3945\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3986 - val_loss: 38.3859\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3908 - val_loss: 38.3773\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3831 - val_loss: 38.3687\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.3753 - val_loss: 38.3602\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.3675 - val_loss: 38.3516\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3597 - val_loss: 38.3430\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3520 - val_loss: 38.3345\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3442 - val_loss: 38.3259\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3364 - val_loss: 38.3173\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3287 - val_loss: 38.3088\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3209 - val_loss: 38.3002\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3131 - val_loss: 38.2916\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3054 - val_loss: 38.2831\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2976 - val_loss: 38.2745\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.2898 - val_loss: 38.2660\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2821 - val_loss: 38.2574\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.2743 - val_loss: 38.2489\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2666 - val_loss: 38.2403\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2588 - val_loss: 38.2318\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2511 - val_loss: 38.2233\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2433 - val_loss: 38.2147\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.2356 - val_loss: 38.2062\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2278 - val_loss: 38.1977\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2201 - val_loss: 38.1891\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2123 - val_loss: 38.1806\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2046 - val_loss: 38.1721\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.1968 - val_loss: 38.1635\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1891 - val_loss: 38.1550\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.1814 - val_loss: 38.1465\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.1736 - val_loss: 38.1380\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.1659 - val_loss: 38.1294\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.1582 - val_loss: 38.1209\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.1504 - val_loss: 38.1124\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1427 - val_loss: 38.1039\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1350 - val_loss: 38.0954\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1273 - val_loss: 38.0869\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1195 - val_loss: 38.0784\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.1118 - val_loss: 38.0699\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1041 - val_loss: 38.0614\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0964 - val_loss: 38.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0886 - val_loss: 38.0444\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.0809 - val_loss: 38.0359\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.0732 - val_loss: 38.0274\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0655 - val_loss: 38.0189\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0578 - val_loss: 38.0104\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0501 - val_loss: 38.0019\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0424 - val_loss: 37.9934\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.0347 - val_loss: 37.9849\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.0270 - val_loss: 37.9765\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0192 - val_loss: 37.9680\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0115 - val_loss: 37.9595\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.0038 - val_loss: 37.9510\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9961 - val_loss: 37.9426\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9884 - val_loss: 37.9341\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9808 - val_loss: 37.9256\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.9731 - val_loss: 37.9171\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9654 - val_loss: 37.9087\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9577 - val_loss: 37.9002\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.9500 - val_loss: 37.8918\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9423 - val_loss: 37.8833\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9346 - val_loss: 37.8748\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.9269 - val_loss: 37.8664\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.9192 - val_loss: 37.8579\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.9116 - val_loss: 37.8495\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.9039 - val_loss: 37.8410\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.8962 - val_loss: 37.8326\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8885 - val_loss: 37.8241\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8808 - val_loss: 37.8157\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.8732 - val_loss: 37.8072\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.8655 - val_loss: 37.7988\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.8578 - val_loss: 37.7904\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8501 - val_loss: 37.7819\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.8425 - val_loss: 37.7735\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8348 - val_loss: 37.7651\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8271 - val_loss: 37.7566\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.8195 - val_loss: 37.7482\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.8118 - val_loss: 37.7398\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8042 - val_loss: 37.7314\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 31.7965 - val_loss: 37.7229\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7888 - val_loss: 37.7145\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7812 - val_loss: 37.7061\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7735 - val_loss: 37.6977\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 95us/step - loss: 31.7659 - val_loss: 37.6893\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.7582 - val_loss: 37.6808\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7506 - val_loss: 37.6724\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.7429 - val_loss: 37.6640\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7353 - val_loss: 37.6556\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.7276 - val_loss: 37.6472\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7200 - val_loss: 37.6388\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7123 - val_loss: 37.6304\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7047 - val_loss: 37.6220\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.6971 - val_loss: 37.6136\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6894 - val_loss: 37.6052\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6818 - val_loss: 37.5968\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6741 - val_loss: 37.5884\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6665 - val_loss: 37.5801\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.6589 - val_loss: 37.5717\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.6512 - val_loss: 37.5633\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6436 - val_loss: 37.5549\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.6360 - val_loss: 37.5465\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.6284 - val_loss: 37.5381\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.6207 - val_loss: 37.5298\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6131 - val_loss: 37.5214\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6055 - val_loss: 37.5130\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.5979 - val_loss: 37.5046\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5902 - val_loss: 37.4963\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.5826 - val_loss: 37.4879\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.5750 - val_loss: 37.4795\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.5674 - val_loss: 37.4712\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5598 - val_loss: 37.4628\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.5522 - val_loss: 37.4544\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.5446 - val_loss: 37.4461\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.5370 - val_loss: 37.4377\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5293 - val_loss: 37.4294\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.5217 - val_loss: 37.4210\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5141 - val_loss: 37.4127\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5065 - val_loss: 37.4043\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.4989 - val_loss: 37.3960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4913 - val_loss: 37.3876\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.4837 - val_loss: 37.3793\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.4761 - val_loss: 37.3710\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4685 - val_loss: 37.3626\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4609 - val_loss: 37.3543\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4534 - val_loss: 37.3459\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4458 - val_loss: 37.3376\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4382 - val_loss: 37.3293\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.4306 - val_loss: 37.3210\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.4230 - val_loss: 37.3126\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4154 - val_loss: 37.3043\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.4078 - val_loss: 37.2960\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.4002 - val_loss: 37.2877\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3927 - val_loss: 37.2793\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3851 - val_loss: 37.2710\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.3775 - val_loss: 37.2627\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.3699 - val_loss: 37.2544\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3623 - val_loss: 37.2461\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.3548 - val_loss: 37.2378\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.3472 - val_loss: 37.2295\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3396 - val_loss: 37.2211\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.3321 - val_loss: 37.2128\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3245 - val_loss: 37.2045\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.3169 - val_loss: 37.1962\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3094 - val_loss: 37.1879\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3018 - val_loss: 37.1796\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2942 - val_loss: 37.1714\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2867 - val_loss: 37.1631\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.2791 - val_loss: 37.1548\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2716 - val_loss: 37.1465\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2640 - val_loss: 37.1382\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.2564 - val_loss: 37.1299\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.2489 - val_loss: 37.1216\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.2413 - val_loss: 37.1133\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2338 - val_loss: 37.1050\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.2262 - val_loss: 37.0968\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.2187 - val_loss: 37.0885\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2111 - val_loss: 37.0802\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.2036 - val_loss: 37.0719\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.1960 - val_loss: 37.0637\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.1885 - val_loss: 37.0554\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1810 - val_loss: 37.0471\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1734 - val_loss: 37.0389\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.1659 - val_loss: 37.0306\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1583 - val_loss: 37.0223\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1508 - val_loss: 37.0141\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.1433 - val_loss: 37.0058\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1357 - val_loss: 36.9976\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1282 - val_loss: 36.9893\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.1207 - val_loss: 36.9810\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.1132 - val_loss: 36.9728\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1056 - val_loss: 36.9645\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.0981 - val_loss: 36.9563\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.0906 - val_loss: 36.9481\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0830 - val_loss: 36.9398\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0755 - val_loss: 36.9316\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.0680 - val_loss: 36.9233\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.0605 - val_loss: 36.9151\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.0530 - val_loss: 36.9068\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.0455 - val_loss: 36.8986\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0379 - val_loss: 36.8904\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0304 - val_loss: 36.8821\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0229 - val_loss: 36.8739\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0154 - val_loss: 36.8657\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.0079 - val_loss: 36.8575\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0004 - val_loss: 36.8492\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9929 - val_loss: 36.8410\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9854 - val_loss: 36.8328\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9779 - val_loss: 36.8246\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.9704 - val_loss: 36.8164\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.9629 - val_loss: 36.8081\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9554 - val_loss: 36.7999\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.9479 - val_loss: 36.7917\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.9404 - val_loss: 36.7835\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9329 - val_loss: 36.7753\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9254 - val_loss: 36.7671\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9179 - val_loss: 36.7589\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9104 - val_loss: 36.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.9029 - val_loss: 36.7425\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8954 - val_loss: 36.7343\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.8879 - val_loss: 36.7261\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8804 - val_loss: 36.7179\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.8730 - val_loss: 36.7097\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8655 - val_loss: 36.7015\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8580 - val_loss: 36.6933\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.8505 - val_loss: 36.6851\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.8430 - val_loss: 36.6769\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.8355 - val_loss: 36.6687\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8281 - val_loss: 36.6605\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.8206 - val_loss: 36.6524\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8131 - val_loss: 36.6442\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8057 - val_loss: 36.6360\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7982 - val_loss: 36.6278\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7907 - val_loss: 36.6196\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7832 - val_loss: 36.6115\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7758 - val_loss: 36.6033\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7683 - val_loss: 36.5951\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7608 - val_loss: 36.5870\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7534 - val_loss: 36.5788\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7459 - val_loss: 36.5706\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7385 - val_loss: 36.5625\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7310 - val_loss: 36.5543\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7235 - val_loss: 36.5461\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7161 - val_loss: 36.5380\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7086 - val_loss: 36.5298\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 30.7012 - val_loss: 36.5217\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.6937 - val_loss: 36.5135\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6863 - val_loss: 36.5054\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6788 - val_loss: 36.4972\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6714 - val_loss: 36.4891\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6639 - val_loss: 36.4809\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6565 - val_loss: 36.4728\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30.6490 - val_loss: 36.4646\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.6416 - val_loss: 36.4565\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6341 - val_loss: 36.4484\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6267 - val_loss: 36.4402\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.6193 - val_loss: 36.4321\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6118 - val_loss: 36.4240\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6044 - val_loss: 36.4158\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5970 - val_loss: 36.4077\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.5895 - val_loss: 36.3996\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5821 - val_loss: 36.3914\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5747 - val_loss: 36.3833\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5672 - val_loss: 36.3752\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5598 - val_loss: 36.3671\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5524 - val_loss: 36.3589\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5449 - val_loss: 36.3508\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5375 - val_loss: 36.3427\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5301 - val_loss: 36.3346\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.5227 - val_loss: 36.3265\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5152 - val_loss: 36.3184\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5078 - val_loss: 36.3102\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 30.5004 - val_loss: 36.3021\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.4930 - val_loss: 36.2940\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4856 - val_loss: 36.2859\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 30.4782 - val_loss: 36.2778\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 92us/step - loss: 30.4707 - val_loss: 36.2697\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.4633 - val_loss: 36.2616\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.4559 - val_loss: 36.2535\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4485 - val_loss: 36.2454\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4411 - val_loss: 36.2373\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 92us/step - loss: 30.4337 - val_loss: 36.2292\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.4263 - val_loss: 36.2211\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4189 - val_loss: 36.2131\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4115 - val_loss: 36.2050\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4041 - val_loss: 36.1969\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3967 - val_loss: 36.1888\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3893 - val_loss: 36.1807\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3819 - val_loss: 36.1726\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.3745 - val_loss: 36.1645\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3671 - val_loss: 36.1565\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.3597 - val_loss: 36.1484\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.3523 - val_loss: 36.1403\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3449 - val_loss: 36.1322\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3375 - val_loss: 36.1242\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3301 - val_loss: 36.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3227 - val_loss: 36.1080\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3154 - val_loss: 36.1000\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3080 - val_loss: 36.0919\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3006 - val_loss: 36.0838\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.2932 - val_loss: 36.0758\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2858 - val_loss: 36.0677\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2784 - val_loss: 36.0596\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.2711 - val_loss: 36.0516\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2637 - val_loss: 36.0435\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2563 - val_loss: 36.0355\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.2489 - val_loss: 36.0274\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2416 - val_loss: 36.0194\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2342 - val_loss: 36.0113\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.2268 - val_loss: 36.0033\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2194 - val_loss: 35.9952\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2121 - val_loss: 35.9872\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2047 - val_loss: 35.9791\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.1973 - val_loss: 35.9711\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1900 - val_loss: 35.9631\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1826 - val_loss: 35.9550\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1753 - val_loss: 35.9470\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1679 - val_loss: 35.9389\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1605 - val_loss: 35.9309\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1532 - val_loss: 35.9229\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.1458 - val_loss: 35.9149\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.1385 - val_loss: 35.9068\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1311 - val_loss: 35.8988\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1237 - val_loss: 35.8908\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.1164 - val_loss: 35.8827\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1090 - val_loss: 35.8747\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1017 - val_loss: 35.8667\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0943 - val_loss: 35.8587\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0870 - val_loss: 35.8507\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0796 - val_loss: 35.8427\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0723 - val_loss: 35.8346\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0650 - val_loss: 35.8266\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0576 - val_loss: 35.8186\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0503 - val_loss: 35.8106\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0429 - val_loss: 35.8026\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0356 - val_loss: 35.7946\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0283 - val_loss: 35.7866\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0209 - val_loss: 35.7786\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0136 - val_loss: 35.7706\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0063 - val_loss: 35.7626\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9989 - val_loss: 35.7546\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9916 - val_loss: 35.7466\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.9843 - val_loss: 35.7386\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9769 - val_loss: 35.7306\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9696 - val_loss: 35.7226\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9623 - val_loss: 35.7146\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9549 - val_loss: 35.7066\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9476 - val_loss: 35.6986\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9403 - val_loss: 35.6907\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9330 - val_loss: 35.6827\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9257 - val_loss: 35.6747\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.9183 - val_loss: 35.6667\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9110 - val_loss: 35.6587\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9037 - val_loss: 35.6508\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8964 - val_loss: 35.6428\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8891 - val_loss: 35.6348\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.8818 - val_loss: 35.6268\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8744 - val_loss: 35.6189\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.8671 - val_loss: 35.6109\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8598 - val_loss: 35.6029\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8525 - val_loss: 35.5950\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8452 - val_loss: 35.5870\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8379 - val_loss: 35.5790\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 29.8306 - val_loss: 35.5711\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8233 - val_loss: 35.5631\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8160 - val_loss: 35.5551\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8087 - val_loss: 35.5472\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8014 - val_loss: 35.5392\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7941 - val_loss: 35.5313\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7868 - val_loss: 35.5233\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7795 - val_loss: 35.5154\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7722 - val_loss: 35.5074\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7649 - val_loss: 35.4995\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7576 - val_loss: 35.4915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7503 - val_loss: 35.4836\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.7430 - val_loss: 35.4756\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7357 - val_loss: 35.4677\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7284 - val_loss: 35.4598\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7212 - val_loss: 35.4518\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7139 - val_loss: 35.4439\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7066 - val_loss: 35.4359\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6993 - val_loss: 35.4280\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6920 - val_loss: 35.4201\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6847 - val_loss: 35.4121\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6775 - val_loss: 35.4042\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6702 - val_loss: 35.3963\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6629 - val_loss: 35.3884\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6556 - val_loss: 35.3804\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.6483 - val_loss: 35.3725\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6411 - val_loss: 35.3646\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6338 - val_loss: 35.3567\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.6265 - val_loss: 35.3488\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6193 - val_loss: 35.3408\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6120 - val_loss: 35.3329\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6047 - val_loss: 35.3250\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.5974 - val_loss: 35.3171\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5902 - val_loss: 35.3092\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5829 - val_loss: 35.3013\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5756 - val_loss: 35.2934\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5684 - val_loss: 35.2855\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5611 - val_loss: 35.2775\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.5539 - val_loss: 35.2696\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5466 - val_loss: 35.2617\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5393 - val_loss: 35.2538\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5321 - val_loss: 35.2459\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.5248 - val_loss: 35.2380\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.5176 - val_loss: 35.2301\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5103 - val_loss: 35.2222\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5031 - val_loss: 35.2144\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4958 - val_loss: 35.2065\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.4886 - val_loss: 35.1986\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4813 - val_loss: 35.1907\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4741 - val_loss: 35.1828\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4668 - val_loss: 35.1749\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4596 - val_loss: 35.1670\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.4523 - val_loss: 35.1591\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4451 - val_loss: 35.1513\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4379 - val_loss: 35.1434\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4306 - val_loss: 35.1355\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4234 - val_loss: 35.1276\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.4161 - val_loss: 35.1197\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4089 - val_loss: 35.1119\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4017 - val_loss: 35.1040\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3944 - val_loss: 35.0961\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3872 - val_loss: 35.0882\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3800 - val_loss: 35.0804\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3727 - val_loss: 35.0725\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3655 - val_loss: 35.0646\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3583 - val_loss: 35.0568\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3510 - val_loss: 35.0489\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3438 - val_loss: 35.0411\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3366 - val_loss: 35.0332\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3294 - val_loss: 35.0253\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3221 - val_loss: 35.0175\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3149 - val_loss: 35.0096\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3077 - val_loss: 35.0018\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3005 - val_loss: 34.9939\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2932 - val_loss: 34.9861\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2860 - val_loss: 34.9782\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2788 - val_loss: 34.9704\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.2716 - val_loss: 34.9625\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.2644 - val_loss: 34.9547\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.2572 - val_loss: 34.9468\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2500 - val_loss: 34.9390\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2427 - val_loss: 34.9311\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2355 - val_loss: 34.9233\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.2283 - val_loss: 34.9155\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.2211 - val_loss: 34.9076\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2139 - val_loss: 34.8998\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2067 - val_loss: 34.8920\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.1995 - val_loss: 34.8841\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.1923 - val_loss: 34.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1851 - val_loss: 34.8685\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1779 - val_loss: 34.8606\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1707 - val_loss: 34.8528\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.1635 - val_loss: 34.8450\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1563 - val_loss: 34.8372\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1491 - val_loss: 34.8293\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1419 - val_loss: 34.8215\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1347 - val_loss: 34.8137\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1275 - val_loss: 34.8059\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1203 - val_loss: 34.7981\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.1131 - val_loss: 34.7903\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1059 - val_loss: 34.7824\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0987 - val_loss: 34.7746\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0916 - val_loss: 34.7668\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0844 - val_loss: 34.7590\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0772 - val_loss: 34.7512\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0700 - val_loss: 34.7434\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0628 - val_loss: 34.7356\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0556 - val_loss: 34.7278\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0484 - val_loss: 34.7200\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.0413 - val_loss: 34.7122\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.0341 - val_loss: 34.7044\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0269 - val_loss: 34.6966\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.0197 - val_loss: 34.6888\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0126 - val_loss: 34.6810\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0054 - val_loss: 34.6732\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9982 - val_loss: 34.6654\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9910 - val_loss: 34.6576\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.9839 - val_loss: 34.6498\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9767 - val_loss: 34.6420\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9695 - val_loss: 34.6342\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 28.9623 - val_loss: 34.6265\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9552 - val_loss: 34.6187\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.9480 - val_loss: 34.6109\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9408 - val_loss: 34.6031\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9337 - val_loss: 34.5953\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.9265 - val_loss: 34.5876\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9194 - val_loss: 34.5798\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9122 - val_loss: 34.5720\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.9050 - val_loss: 34.5642\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.8979 - val_loss: 34.5564\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.8907 - val_loss: 34.5487\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8836 - val_loss: 34.5409\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.8764 - val_loss: 34.5331\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8693 - val_loss: 34.5254\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 28.8621 - val_loss: 34.5176\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8549 - val_loss: 34.5098\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8478 - val_loss: 34.5021\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.8406 - val_loss: 34.4943\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8335 - val_loss: 34.4865\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8263 - val_loss: 34.4788\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8192 - val_loss: 34.4710\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8121 - val_loss: 34.4633\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8049 - val_loss: 34.4555\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7978 - val_loss: 34.4478\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.7906 - val_loss: 34.4400\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7835 - val_loss: 34.4323\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7763 - val_loss: 34.4245\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7692 - val_loss: 34.4168\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7621 - val_loss: 34.4090\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7549 - val_loss: 34.4013\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7478 - val_loss: 34.3935\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.7407 - val_loss: 34.3858\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7335 - val_loss: 34.3780\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.7264 - val_loss: 34.3703\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.7192 - val_loss: 34.3626\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7121 - val_loss: 34.3548\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7050 - val_loss: 34.3471\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6979 - val_loss: 34.3393\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6907 - val_loss: 34.3316\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.6836 - val_loss: 34.3239\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.6765 - val_loss: 34.3162\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6694 - val_loss: 34.3084\n",
      "31.284351348876953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.43328637,  0.61841697,  0.4175151 , -0.54024446, -0.30533135],\n",
       "        [ 0.32229295, -0.80676603, -0.07286493, -0.58304614,  0.46756256],\n",
       "        [ 0.37517905, -0.5873628 , -0.08248745,  0.7249734 ,  0.08239289]],\n",
       "       dtype=float32),\n",
       " array([-0.00223206,  0.07089156,  0.04177709, -0.11450855,  0.05202231],\n",
       "       dtype=float32),\n",
       " array([[-0.20162421, -0.50155556,  0.41630778, -0.21395391,  0.06132128,\n",
       "          0.5246591 , -0.04366466,  0.38296893,  0.12880528,  0.3228862 ],\n",
       "        [ 0.3694427 ,  0.23171738, -0.2943108 ,  0.33254442,  0.3371436 ,\n",
       "         -0.12001829,  0.606845  ,  0.43571863, -0.6092993 ,  0.10571722],\n",
       "        [-0.21710646, -0.4683766 , -0.03660404,  0.29019648,  0.205823  ,\n",
       "          0.1370113 ,  0.14389914, -0.46675196,  0.60453   , -0.02389203],\n",
       "        [-0.45574063,  0.07799549,  0.22872703,  0.2731684 , -0.05105175,\n",
       "         -0.5864233 , -0.2467764 , -0.21987729,  0.22584309, -0.3252195 ],\n",
       "        [-0.59373724, -0.6211349 , -0.53187734, -0.51769316, -0.14333373,\n",
       "         -0.15634185, -0.00824833, -0.6326182 ,  0.1677777 , -0.14781986]],\n",
       "       dtype=float32),\n",
       " array([ 0.06889614, -0.06525125, -0.09588672, -0.04246572,  0.13105184,\n",
       "         0.0613331 ,  0.11414153, -0.08208733, -0.07836983,  0.05165869],\n",
       "       dtype=float32),\n",
       " array([[ 0.3510377 ],\n",
       "        [-0.34547606],\n",
       "        [-0.49945074],\n",
       "        [-0.22643049],\n",
       "        [ 0.6782781 ],\n",
       "        [ 0.3186257 ],\n",
       "        [ 0.5905617 ],\n",
       "        [-0.4298767 ],\n",
       "        [-0.40455663],\n",
       "        [ 0.26778552]], dtype=float32),\n",
       " array([0.19507936], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, sgd, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sgd_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 35.9832 - val_loss: 33.1375\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 33.4489 - val_loss: 30.7183\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4503 - val_loss: 28.3691\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4378 - val_loss: 26.0517\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.3629 - val_loss: 23.7424\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2590 - val_loss: 21.4755\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 23.1727 - val_loss: 19.2899\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 21.1431 - val_loss: 17.2198\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 19.1947 - val_loss: 15.2978\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 17.3414 - val_loss: 13.5498\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 15.5928 - val_loss: 11.9840\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 13.9546 - val_loss: 10.5956\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.4304 - val_loss: 9.3722\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 11.0215 - val_loss: 8.2978\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.7282 - val_loss: 7.3546\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5491 - val_loss: 6.5260\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4819 - val_loss: 5.7978\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5228 - val_loss: 5.1581\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6674 - val_loss: 4.5965\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9101 - val_loss: 4.1028\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2447 - val_loss: 3.6669\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6641 - val_loss: 3.2797\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1608 - val_loss: 2.9330\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7264 - val_loss: 2.6203\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3527 - val_loss: 2.3364\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0319 - val_loss: 2.0778\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7566 - val_loss: 1.8418\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.5202 - val_loss: 1.6267\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3169 - val_loss: 1.4311\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1419 - val_loss: 1.2542\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.9909 - val_loss: 1.0949\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8606 - val_loss: 0.9524\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7478 - val_loss: 0.8256\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6503 - val_loss: 0.7136\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.5658 - val_loss: 0.6150\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4926 - val_loss: 0.5289\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4293 - val_loss: 0.4541\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3745 - val_loss: 0.3894\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3272 - val_loss: 0.3339\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2864 - val_loss: 0.2866\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2513 - val_loss: 0.2465\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2212 - val_loss: 0.2127\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1955 - val_loss: 0.1844\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1735 - val_loss: 0.1613\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1550 - val_loss: 0.1409\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1394 - val_loss: 0.1316\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1281 - val_loss: 0.1100\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1374 - val_loss: 0.1703\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1856 - val_loss: 0.1002\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1596 - val_loss: 0.1193\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1178 - val_loss: 0.0786\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0985 - val_loss: 0.0926\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0883 - val_loss: 0.0715\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0822 - val_loss: 0.0818\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0778 - val_loss: 0.0652\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0744 - val_loss: 0.0780\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0717 - val_loss: 0.0566\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0702 - val_loss: 0.0848\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0711 - val_loss: 0.0426\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0786 - val_loss: 0.1131\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0898 - val_loss: 0.0337\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0961 - val_loss: 0.1184\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0937 - val_loss: 0.0342\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0982 - val_loss: 0.1187\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0982 - val_loss: 0.0422\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0989 - val_loss: 0.1059\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0884 - val_loss: 0.0417\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0801 - val_loss: 0.0870\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0705 - val_loss: 0.0385\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0655 - val_loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0614 - val_loss: 0.0350\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0606 - val_loss: 0.0794\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0612 - val_loss: 0.0319\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0670 - val_loss: 0.0990\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0765 - val_loss: 0.0399\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0937 - val_loss: 0.1230\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0975 - val_loss: 0.0499\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0984 - val_loss: 0.1075\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0814 - val_loss: 0.0451\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0756 - val_loss: 0.0888\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0663 - val_loss: 0.0419\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0663 - val_loss: 0.0818\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0643 - val_loss: 0.0392\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0677 - val_loss: 0.0766\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0669 - val_loss: 0.0302\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0681 - val_loss: 0.0663\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0654 - val_loss: 0.0203\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0632 - val_loss: 0.0569\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0580 - val_loss: 0.0172\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0523 - val_loss: 0.0500\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0474 - val_loss: 0.0168\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0457 - val_loss: 0.0556\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0484 - val_loss: 0.0280\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0636 - val_loss: 0.1055\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0921 - val_loss: 0.0824\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1207 - val_loss: 0.1170\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0939 - val_loss: 0.0624\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0746 - val_loss: 0.0665\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0501 - val_loss: 0.0350\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0417 - val_loss: 0.0464\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0357 - val_loss: 0.0279\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0476\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0384 - val_loss: 0.0320\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0485 - val_loss: 0.0634\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0617 - val_loss: 0.0347\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0748 - val_loss: 0.0597\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0716 - val_loss: 0.0185\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0611 - val_loss: 0.0413\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0478 - val_loss: 0.0115\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0401 - val_loss: 0.0367\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0373 - val_loss: 0.0165\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0433 - val_loss: 0.0585\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0574 - val_loss: 0.0493\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0806 - val_loss: 0.0875\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0802 - val_loss: 0.0618\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0746 - val_loss: 0.0640\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0522 - val_loss: 0.0398\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0413\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0331 - val_loss: 0.0276\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0348\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0264\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0436\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0358 - val_loss: 0.0380\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0513 - val_loss: 0.0658\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0687 - val_loss: 0.0399\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0817 - val_loss: 0.0506\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0692 - val_loss: 0.0152\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0545 - val_loss: 0.0301\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0095\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0355 - val_loss: 0.0298\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0358 - val_loss: 0.0204\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0447 - val_loss: 0.0473\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0528 - val_loss: 0.0426\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0617 - val_loss: 0.0562\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0548 - val_loss: 0.0471\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0517 - val_loss: 0.0458\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0404 - val_loss: 0.0365\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0330\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0272\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0268 - val_loss: 0.0273\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0249\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0249 - val_loss: 0.0313\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0263 - val_loss: 0.0337\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0348 - val_loss: 0.0582\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0526 - val_loss: 0.0669\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0897 - val_loss: 0.0747\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0951 - val_loss: 0.0348\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0758 - val_loss: 0.0291\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0452 - val_loss: 0.0082\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0234 - val_loss: 0.0069\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0188\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0192\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0352\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0459 - val_loss: 0.0399\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0455\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0491 - val_loss: 0.0471\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0476 - val_loss: 0.0412\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0381 - val_loss: 0.0395\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0345 - val_loss: 0.0306\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0245\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0221 - val_loss: 0.0262\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0295\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0253 - val_loss: 0.0393\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0383 - val_loss: 0.0637\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 0.0652 - val_loss: 0.0697\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0989 - val_loss: 0.0544\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0807 - val_loss: 0.0235\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0547 - val_loss: 0.0179\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0321 - val_loss: 0.0071\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0106\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0194 - val_loss: 0.0095\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0175\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0267\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0412 - val_loss: 0.0353\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0482 - val_loss: 0.0460\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0537 - val_loss: 0.0405\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0447 - val_loss: 0.0454\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0413 - val_loss: 0.0338\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0321 - val_loss: 0.0364\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0290 - val_loss: 0.0255\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0236 - val_loss: 0.0285\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0221 - val_loss: 0.0216\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0198 - val_loss: 0.0272\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0274\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0425\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0635\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0645 - val_loss: 0.0773\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0996 - val_loss: 0.0529\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0799 - val_loss: 0.0254\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0532 - val_loss: 0.0149\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 108us/step - loss: 0.0305 - val_loss: 0.0076\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0214 - val_loss: 0.0078\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 0.0099\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0136\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0263 - val_loss: 0.0269\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0385 - val_loss: 0.0305\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0460 - val_loss: 0.0464\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0520 - val_loss: 0.0364\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0434 - val_loss: 0.0458\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0401 - val_loss: 0.0314\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0312 - val_loss: 0.0378\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0246\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0232 - val_loss: 0.0302\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0204\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0192 - val_loss: 0.0278\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0235\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0210 - val_loss: 0.0382\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0509\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0485 - val_loss: 0.0805\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0891 - val_loss: 0.0649\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0899 - val_loss: 0.0382\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0660 - val_loss: 0.0176\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0364 - val_loss: 0.0098\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0234 - val_loss: 0.0064\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0171 - val_loss: 0.0088\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0171 - val_loss: 0.0087\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0208 - val_loss: 0.0217\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0307 - val_loss: 0.0232\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0404 - val_loss: 0.0442\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0505 - val_loss: 0.0340\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0455 - val_loss: 0.0482\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0432 - val_loss: 0.0314\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0412\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0304 - val_loss: 0.0258\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0245 - val_loss: 0.0334\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0229 - val_loss: 0.0208\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0196 - val_loss: 0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0194 - val_loss: 0.0207\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0189 - val_loss: 0.0334\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0229 - val_loss: 0.0360\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0322 - val_loss: 0.0677\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0621 - val_loss: 0.0750\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0903 - val_loss: 0.0612\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0861 - val_loss: 0.0264\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0498 - val_loss: 0.0149\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0069\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0195 - val_loss: 0.0086\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0059\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0173 - val_loss: 0.0168\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0237 - val_loss: 0.0159\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0384\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0449 - val_loss: 0.0302\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0460 - val_loss: 0.0495\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0467 - val_loss: 0.0312\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.0442\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0333 - val_loss: 0.0270\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0369\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0221\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0208 - val_loss: 0.0310\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0200 - val_loss: 0.0197\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0309\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0199 - val_loss: 0.0260\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0493\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0371 - val_loss: 0.0637\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0659 - val_loss: 0.0841\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0964 - val_loss: 0.0452\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0711 - val_loss: 0.0265\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0459 - val_loss: 0.0103\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0262 - val_loss: 0.0097\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0186 - val_loss: 0.0046\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0182 - val_loss: 0.0095\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0296\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0358 - val_loss: 0.0245\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0489\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0495 - val_loss: 0.0309\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0412 - val_loss: 0.0472\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0379 - val_loss: 0.0279\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0402\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0271 - val_loss: 0.0239\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0340\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0215 - val_loss: 0.0206\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0189 - val_loss: 0.0314\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0198 - val_loss: 0.0406\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0268 - val_loss: 0.0465\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0809\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0783 - val_loss: 0.0613\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0816 - val_loss: 0.0426\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0629 - val_loss: 0.0162\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0362 - val_loss: 0.0129\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0052\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0175 - val_loss: 0.0070\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0206 - val_loss: 0.0243\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0194\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0380 - val_loss: 0.0452\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0472 - val_loss: 0.0293\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0426 - val_loss: 0.0483\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0406 - val_loss: 0.0278\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0419\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0245\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0237 - val_loss: 0.0357\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0207\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0195 - val_loss: 0.0311\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0181 - val_loss: 0.0325\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0203 - val_loss: 0.0263\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0239 - val_loss: 0.0531\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0395 - val_loss: 0.0657\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0695 - val_loss: 0.0857\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0958 - val_loss: 0.0413\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0655 - val_loss: 0.0252\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0407 - val_loss: 0.0086\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0095\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0165 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0078\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0289\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0227\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0498\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0498 - val_loss: 0.0305\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0418 - val_loss: 0.0488\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0295 - val_loss: 0.0417\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0272 - val_loss: 0.0250\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0364\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0234\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0196 - val_loss: 0.0363\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0212 - val_loss: 0.0305\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0541\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0569\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0577 - val_loss: 0.0649\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0710 - val_loss: 0.0325\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0546 - val_loss: 0.0239\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0411 - val_loss: 0.0094\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0277 - val_loss: 0.0128\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0223 - val_loss: 0.0057\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0198 - val_loss: 0.0179\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0233 - val_loss: 0.0123\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0368\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0400 - val_loss: 0.0258\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0429 - val_loss: 0.0494\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0452 - val_loss: 0.0278\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0358 - val_loss: 0.0436\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0241\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0255 - val_loss: 0.0369\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0209\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0204 - val_loss: 0.0319\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0200 - val_loss: 0.0179\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0180 - val_loss: 0.0291\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0187 - val_loss: 0.0166\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0184 - val_loss: 0.0304\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0210 - val_loss: 0.0182\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0229 - val_loss: 0.0359\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.0212\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0319 - val_loss: 0.0411\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0389 - val_loss: 0.0238\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0437 - val_loss: 0.0499\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0686 - val_loss: 0.0394\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0866 - val_loss: 0.0336\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0607 - val_loss: 0.0164\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0104\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0179 - val_loss: 0.0151\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0159 - val_loss: 0.0132\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0194 - val_loss: 0.0349\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0305 - val_loss: 0.0343\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0435 - val_loss: 0.0651\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0579 - val_loss: 0.0408\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0512 - val_loss: 0.0515\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0456 - val_loss: 0.0227\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0308 - val_loss: 0.0286\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0187 - val_loss: 0.0094\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0170\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0221 - val_loss: 0.0104\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0266 - val_loss: 0.0193\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0351 - val_loss: 0.0135\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0389 - val_loss: 0.0233\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0414 - val_loss: 0.0152\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0371 - val_loss: 0.0181\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0348 - val_loss: 0.0362\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0390 - val_loss: 0.0223\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0410\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0397 - val_loss: 0.0219\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0331 - val_loss: 0.0371\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0311 - val_loss: 0.0196\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0342\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0253 - val_loss: 0.0193\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0234 - val_loss: 0.0327\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0256 - val_loss: 0.0166\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0304\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0329 - val_loss: 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0364\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0502 - val_loss: 0.0211\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0433 - val_loss: 0.0207\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0311 - val_loss: 0.0093\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0205 - val_loss: 0.0090\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0145 - val_loss: 0.0183\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0266 - val_loss: 0.0628\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0592 - val_loss: 0.0750\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0914 - val_loss: 0.1004\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0949 - val_loss: 0.0372\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0489 - val_loss: 0.0342\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0303 - val_loss: 0.0102\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0138\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0038\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0077\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0265 - val_loss: 0.0160\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0392 - val_loss: 0.0146\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0273\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0436 - val_loss: 0.0229\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0399 - val_loss: 0.0416\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0430 - val_loss: 0.0301\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0516\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0498 - val_loss: 0.0295\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0440 - val_loss: 0.0439\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0406 - val_loss: 0.0192\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0285 - val_loss: 0.0295\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0131\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0192 - val_loss: 0.0240\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0195 - val_loss: 0.0120\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0242\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0250 - val_loss: 0.0143\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0301 - val_loss: 0.0286\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0379 - val_loss: 0.0185\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0387 - val_loss: 0.0241\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0116\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0255 - val_loss: 0.0133\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0187 - val_loss: 0.0060\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0114 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0098 - val_loss: 0.0044\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0123 - val_loss: 0.0064\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0155 - val_loss: 0.0190\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0968\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0905 - val_loss: 0.0977\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1093 - val_loss: 0.1053\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0868 - val_loss: 0.0424\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0459 - val_loss: 0.0434\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0400 - val_loss: 0.0234\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0243\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0298 - val_loss: 0.0133\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0235 - val_loss: 0.0146\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0204 - val_loss: 0.0083\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0159 - val_loss: 0.0071\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0168 - val_loss: 0.0090\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0248 - val_loss: 0.0164\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0314 - val_loss: 0.0368\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0433 - val_loss: 0.0271\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0482 - val_loss: 0.0465\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0533 - val_loss: 0.0240\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0419 - val_loss: 0.0336\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0363 - val_loss: 0.0146\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0220\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0103\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0193 - val_loss: 0.0175\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0204 - val_loss: 0.0100\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0167\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0293 - val_loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0176\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0127\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0320 - val_loss: 0.0174\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0125\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0225 - val_loss: 0.0237\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0240 - val_loss: 0.0206\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0293 - val_loss: 0.0487\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0459 - val_loss: 0.0420\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0581 - val_loss: 0.0667\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0625 - val_loss: 0.0317\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0407 - val_loss: 0.0383\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0306 - val_loss: 0.0155\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0200 - val_loss: 0.0219\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0169 - val_loss: 0.0089\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0166\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0162 - val_loss: 0.0092\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0201 - val_loss: 0.0217\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0182\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0365 - val_loss: 0.0251\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0373 - val_loss: 0.0145\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0136\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0212 - val_loss: 0.0073\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0150 - val_loss: 0.0071\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0115 - val_loss: 0.0068\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0126 - val_loss: 0.0239\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0445\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0563 - val_loss: 0.1128\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1080 - val_loss: 0.0706\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0860 - val_loss: 0.0641\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0583 - val_loss: 0.0195\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0196\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0064\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0064 - val_loss: 0.0099\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0147\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0271\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0368 - val_loss: 0.0234\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0571 - val_loss: 0.0332\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0692 - val_loss: 0.0187\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0518 - val_loss: 0.0296\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0433 - val_loss: 0.0175\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0347 - val_loss: 0.0334\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0349 - val_loss: 0.0195\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0301 - val_loss: 0.0339\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0191\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0320\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0179\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0223 - val_loss: 0.0293\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0155\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0227 - val_loss: 0.0136\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0233 - val_loss: 0.0260\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0282 - val_loss: 0.0167\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0282\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0373 - val_loss: 0.0167\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0194\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.0096\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0213 - val_loss: 0.0103\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0158 - val_loss: 0.0064\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0126 - val_loss: 0.0070\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0139 - val_loss: 0.0166\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0239 - val_loss: 0.0582\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 100us/step - loss: 0.0558 - val_loss: 0.0806\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0951 - val_loss: 0.1061\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1007 - val_loss: 0.0390\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0484 - val_loss: 0.0330\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0283 - val_loss: 0.0103\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0130\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 92us/step - loss: 0.0070 - val_loss: 0.0094\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0065 - val_loss: 0.0115\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0171 - val_loss: 0.0241\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0535\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0434 - val_loss: 0.0520\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0536 - val_loss: 0.0736\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0615 - val_loss: 0.0425\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0455 - val_loss: 0.0436\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0179\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0185\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0098\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0312 - val_loss: 0.0206\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0444 - val_loss: 0.0084\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0299 - val_loss: 0.0100\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0061\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0160 - val_loss: 0.0157\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 0.0147\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0209 - val_loss: 0.0311\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0283 - val_loss: 0.0295\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0341 - val_loss: 0.0513\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0435 - val_loss: 0.0397\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0436 - val_loss: 0.0565\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0468 - val_loss: 0.0331\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0427\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0345 - val_loss: 0.0213\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0299\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0150\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0211 - val_loss: 0.0253\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0236 - val_loss: 0.0148\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0267 - val_loss: 0.0274\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0343 - val_loss: 0.0178\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0242\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0123\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0135\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0193 - val_loss: 0.0062\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0139 - val_loss: 0.0079\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0108 - val_loss: 0.0041\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0198 - val_loss: 0.0179\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0574\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0611 - val_loss: 0.1031\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1254 - val_loss: 0.1267\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.1276 - val_loss: 0.0360\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0464 - val_loss: 0.0270\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0075\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0090\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0062 - val_loss: 0.0146\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0094 - val_loss: 0.0123\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0239\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0190 - val_loss: 0.0161\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0224 - val_loss: 0.0296\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0231\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0393 - val_loss: 0.0416\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0482 - val_loss: 0.0235\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0131\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0244 - val_loss: 0.0186\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.0081\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0161 - val_loss: 0.0145\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0150 - val_loss: 0.0072\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0145 - val_loss: 0.0152\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0093\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0179 - val_loss: 0.0211\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0158\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0267 - val_loss: 0.0346\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0342 - val_loss: 0.0290\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0393 - val_loss: 0.0561\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0483 - val_loss: 0.0508\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0540 - val_loss: 0.0881\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0784 - val_loss: 0.0655\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0761 - val_loss: 0.0551\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0608 - val_loss: 0.0192\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0053\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0029\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0120 - val_loss: 0.0070\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0194\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0392 - val_loss: 0.0413\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0546 - val_loss: 0.0314\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0533 - val_loss: 0.0431\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0513 - val_loss: 0.0226\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0356 - val_loss: 0.0267\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0131\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0207 - val_loss: 0.0174\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0183 - val_loss: 0.0093\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0166 - val_loss: 0.0085\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0176 - val_loss: 0.0137\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0224 - val_loss: 0.0095\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0155\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0346 - val_loss: 0.0113\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0335 - val_loss: 0.0200\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0336 - val_loss: 0.0167\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0346\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0301\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0405 - val_loss: 0.0504\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0459 - val_loss: 0.0341\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0383 - val_loss: 0.0444\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0353 - val_loss: 0.0241\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0257 - val_loss: 0.0292\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0142\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0171 - val_loss: 0.0198\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0164 - val_loss: 0.0101\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0195\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0210 - val_loss: 0.0151\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0277 - val_loss: 0.0267\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0356 - val_loss: 0.0176\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0348 - val_loss: 0.0191\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0092\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0206 - val_loss: 0.0097\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0145 - val_loss: 0.0046\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0086 - val_loss: 0.0034\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0214\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0306 - val_loss: 0.0825\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0839 - val_loss: 0.1120\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.1326 - val_loss: 0.1041\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1032 - val_loss: 0.0274\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0339 - val_loss: 0.0203\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0161 - val_loss: 0.0062\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0076 - val_loss: 0.0087\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0090\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0163\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0138\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0150 - val_loss: 0.0228\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0264\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0270 - val_loss: 0.0226\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0403\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0470 - val_loss: 0.0237\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0397 - val_loss: 0.0293\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0329 - val_loss: 0.0136\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0238 - val_loss: 0.0184\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0196 - val_loss: 0.0084\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0139\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0148 - val_loss: 0.0072\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0144 - val_loss: 0.0137\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0157 - val_loss: 0.0085\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 0.0164\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0245 - val_loss: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0268 - val_loss: 0.0122\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0258 - val_loss: 0.0160\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0228 - val_loss: 0.0090\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0192 - val_loss: 0.0153\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0180 - val_loss: 0.0153\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0233 - val_loss: 0.0561\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0501 - val_loss: 0.0875\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0919 - val_loss: 0.1195\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.1075 - val_loss: 0.0535\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0591 - val_loss: 0.0389\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0385 - val_loss: 0.0141\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0197 - val_loss: 0.0118\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0051\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0036\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0145 - val_loss: 0.0086\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0189\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0195\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0390 - val_loss: 0.0374\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0512 - val_loss: 0.0297\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0493 - val_loss: 0.0411\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0481 - val_loss: 0.0234\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0340 - val_loss: 0.0289\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0282 - val_loss: 0.0164\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0203 - val_loss: 0.0238\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0186 - val_loss: 0.0175\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0170 - val_loss: 0.0303\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0198 - val_loss: 0.0280\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0224 - val_loss: 0.0435\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0271 - val_loss: 0.0340\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0430\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0265 - val_loss: 0.0323\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0450\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0293 - val_loss: 0.0418\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0343 - val_loss: 0.0554\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0423 - val_loss: 0.0397\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0364 - val_loss: 0.0365\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0302 - val_loss: 0.0197\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0209 - val_loss: 0.0201\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0167 - val_loss: 0.0193\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0218 - val_loss: 0.0155\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0306\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0416 - val_loss: 0.0203\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0391 - val_loss: 0.0277\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0366 - val_loss: 0.0145\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0191\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0259 - val_loss: 0.0108\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0240 - val_loss: 0.0144\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0125\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0091\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0231 - val_loss: 0.0109\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0191 - val_loss: 0.0083\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0159 - val_loss: 0.0148\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0210 - val_loss: 0.0355\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0335 - val_loss: 0.0405\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0470 - val_loss: 0.0677\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0602 - val_loss: 0.0444\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0467 - val_loss: 0.0468\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0220\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0232\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0168 - val_loss: 0.0112\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0118 - val_loss: 0.0151\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0147\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0115 - val_loss: 0.0200\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0194 - val_loss: 0.0321\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0425\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0293\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0347 - val_loss: 0.0427\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0371 - val_loss: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0474 - val_loss: 0.0702\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0766 - val_loss: 0.0364\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0545 - val_loss: 0.0193\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0330 - val_loss: 0.0065\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0169 - val_loss: 0.0050\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0026\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0079 - val_loss: 0.0029\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0116 - val_loss: 0.0068\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0162 - val_loss: 0.0201\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0257 - val_loss: 0.0229\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0362 - val_loss: 0.0487\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0499 - val_loss: 0.0428\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0478 - val_loss: 0.0589\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0473 - val_loss: 0.0407\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0347 - val_loss: 0.0474\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0309 - val_loss: 0.0326\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0237 - val_loss: 0.0376\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0279\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0192 - val_loss: 0.0335\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0195 - val_loss: 0.0266\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0185 - val_loss: 0.0336\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0280\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0205 - val_loss: 0.0374\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0321\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0450\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0377\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0318 - val_loss: 0.0515\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0377\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0342 - val_loss: 0.0463\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0351 - val_loss: 0.0280\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0287 - val_loss: 0.0333\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0271 - val_loss: 0.0182\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0220 - val_loss: 0.0241\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0212 - val_loss: 0.0135\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0186 - val_loss: 0.0211\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0198 - val_loss: 0.0139\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0248\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0298 - val_loss: 0.0184\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0377 - val_loss: 0.0251\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0402 - val_loss: 0.0151\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0306 - val_loss: 0.0129\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0199 - val_loss: 0.0070\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0126 - val_loss: 0.0059\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0092 - val_loss: 0.0165\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0167 - val_loss: 0.0289\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0364 - val_loss: 0.0734\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0749 - val_loss: 0.0645\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0799 - val_loss: 0.0639\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0651 - val_loss: 0.0240\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0307 - val_loss: 0.0206\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0188 - val_loss: 0.0081\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0162 - val_loss: 0.0190\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0275 - val_loss: 0.0171\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0419 - val_loss: 0.0261\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0566 - val_loss: 0.0181\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0473 - val_loss: 0.0254\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0171\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0264\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0244 - val_loss: 0.0298\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0229\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0342\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0262 - val_loss: 0.0252\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0333\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0217\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0211 - val_loss: 0.0275\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0206 - val_loss: 0.0175\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0181 - val_loss: 0.0243\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0188 - val_loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0185 - val_loss: 0.0274\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0256\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0267 - val_loss: 0.0467\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0415 - val_loss: 0.0474\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0504 - val_loss: 0.0496\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0491 - val_loss: 0.0242\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0296 - val_loss: 0.0172\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0196 - val_loss: 0.0068\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0072\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0124 - val_loss: 0.0051\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0157 - val_loss: 0.0125\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0102\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0268 - val_loss: 0.0182\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0295 - val_loss: 0.0158\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0299 - val_loss: 0.0324\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0299\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0471\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0392 - val_loss: 0.0378\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0339 - val_loss: 0.0484\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0334 - val_loss: 0.0342\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0266 - val_loss: 0.0392\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0271\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0201 - val_loss: 0.0323\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0251\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0188 - val_loss: 0.0331\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0214 - val_loss: 0.0285\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0227 - val_loss: 0.0370\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0264 - val_loss: 0.0297\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0258 - val_loss: 0.0356\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0273 - val_loss: 0.0260\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0249 - val_loss: 0.0330\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0269 - val_loss: 0.0245\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0266 - val_loss: 0.0353\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0319 - val_loss: 0.0264\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0328 - val_loss: 0.0380\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0361 - val_loss: 0.0257\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0305 - val_loss: 0.0356\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0239\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0261 - val_loss: 0.0281\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0134\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0208 - val_loss: 0.0159\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0203 - val_loss: 0.0107\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0164\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0231 - val_loss: 0.0125\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0219 - val_loss: 0.0128\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0186 - val_loss: 0.0083\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0149 - val_loss: 0.0075\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0187 - val_loss: 0.0272\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0369 - val_loss: 0.0695\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0745 - val_loss: 0.0631\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0793 - val_loss: 0.0628\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0638 - val_loss: 0.0246\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0295 - val_loss: 0.0214\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0180 - val_loss: 0.0097\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0146\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0147\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0271\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0161 - val_loss: 0.0274\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0198 - val_loss: 0.0392\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0236 - val_loss: 0.0350\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0505\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0332 - val_loss: 0.0494\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0414 - val_loss: 0.0645\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0528 - val_loss: 0.0426\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0429 - val_loss: 0.0377\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0353 - val_loss: 0.0174\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0230 - val_loss: 0.0170\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0205 - val_loss: 0.0092\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0203 - val_loss: 0.0158\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0247 - val_loss: 0.0101\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0147\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0230 - val_loss: 0.0085\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0196 - val_loss: 0.0140\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0202 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0203 - val_loss: 0.0182\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0157\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0238\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0177\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0313 - val_loss: 0.0221\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0320 - val_loss: 0.0139\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0271 - val_loss: 0.0180\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0265 - val_loss: 0.0118\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0233 - val_loss: 0.0182\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.0137\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0235 - val_loss: 0.0234\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0263 - val_loss: 0.0205\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0262 - val_loss: 0.0367\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0312 - val_loss: 0.0376\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0340 - val_loss: 0.0533\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0389 - val_loss: 0.0341\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0296 - val_loss: 0.0321\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0233 - val_loss: 0.0167\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0157 - val_loss: 0.0184\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0121 - val_loss: 0.0184\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0387\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0357 - val_loss: 0.0433\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0463 - val_loss: 0.0463\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0455 - val_loss: 0.0249\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0284 - val_loss: 0.0204\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0203 - val_loss: 0.0103\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0150 - val_loss: 0.0138\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0222 - val_loss: 0.0215\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0310 - val_loss: 0.0158\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0222\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0303 - val_loss: 0.0141\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0245 - val_loss: 0.0200\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0237 - val_loss: 0.0145\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0164\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0209\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0270 - val_loss: 0.0133\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0144\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0343 - val_loss: 0.0097\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0311 - val_loss: 0.0096\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0242 - val_loss: 0.0060\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0165 - val_loss: 0.0100\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0165 - val_loss: 0.0248\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0251 - val_loss: 0.0316\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0564\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0507 - val_loss: 0.0455\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0453 - val_loss: 0.0486\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.0261\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0247 - val_loss: 0.0252\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0187 - val_loss: 0.0146\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0132 - val_loss: 0.0179\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0246\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0297\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0442\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0333 - val_loss: 0.0379\n",
      "0.036145277321338654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.15763532, -0.2957779 , -0.3428785 ,  0.4227206 , -0.16910464],\n",
       "        [ 0.14497595,  0.5587817 ,  0.48592293, -0.13342984, -0.15758625],\n",
       "        [ 0.2225825 , -0.3541512 ,  0.57343173,  0.2374038 , -0.8061031 ]],\n",
       "       dtype=float32),\n",
       " array([-0.5702358 ,  0.20676765, -0.29827484, -0.38649628, -0.31167793],\n",
       "       dtype=float32),\n",
       " array([[-0.431567  , -0.8111289 , -0.78987247,  0.16132315, -0.19184472,\n",
       "         -0.29530847, -0.19785976,  0.7799659 , -0.15891474, -0.22259642],\n",
       "        [ 0.49031386,  0.35086226, -0.25271568,  0.37449893, -0.31349105,\n",
       "         -0.04559926,  0.25191182, -0.15535133, -0.02649643,  0.24068083],\n",
       "        [ 0.02410328, -0.15771222, -0.39661303,  0.20237395, -0.4487569 ,\n",
       "         -0.50105244,  0.28005004, -0.40933287,  0.4084921 , -0.30130005],\n",
       "        [ 0.42676318, -0.4013149 ,  0.24488227, -0.6704315 ,  0.41123033,\n",
       "         -0.2917545 , -0.33668187,  0.54069686,  0.45476985,  0.37890977],\n",
       "        [-0.7914646 , -0.00664136, -0.4404633 ,  0.30635437, -0.36825877,\n",
       "         -0.80048776, -0.7439477 ,  0.23208694,  0.2343041 ,  0.00105385]],\n",
       "       dtype=float32),\n",
       " array([ 0.50451267,  0.50336576,  0.5083541 ,  0.5129445 ,  0.53039014,\n",
       "         0.5018937 ,  0.5368159 , -0.513228  , -0.5036326 ,  0.5399524 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.6442495 ],\n",
       "        [ 0.7516792 ],\n",
       "        [ 0.8942226 ],\n",
       "        [ 1.0300614 ],\n",
       "        [ 0.3699795 ],\n",
       "        [ 0.56083155],\n",
       "        [ 0.39554727],\n",
       "        [-0.6306128 ],\n",
       "        [-0.96519697],\n",
       "        [ 0.33065167]], dtype=float32),\n",
       " array([0.5156327], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, RMSprop, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_rmsprop_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
